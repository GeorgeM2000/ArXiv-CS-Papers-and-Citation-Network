{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Libraries & Tools***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import requests\n",
    "import io\n",
    "import re\n",
    "import os\n",
    "import math\n",
    "from tqdm import tqdm \n",
    "from datetime import datetime\n",
    "from concurrent.futures import ProcessPoolExecutor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***PDF Extraction & Analysis***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Helper Functions & General Variables***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_pdf(paper_id):\n",
    "    response = requests.get(f\"https://arxiv.org/pdf/{paper_id}\")\n",
    "    if response.status_code == 200:\n",
    "        return io.BytesIO(response.content)\n",
    "    else:\n",
    "        #raise Exception(f\"Failed to download PDF. Status code: {response.status_code}\")\n",
    "        return None \n",
    "\n",
    "def extract_text_from_pdf(pdf):\n",
    "    try:\n",
    "        doc = fitz.open(pdf) # If we're downloading th PDFs use: fitz.open(\"pdf\", pdf)\n",
    "        text = \"\"\n",
    "        for page in doc:\n",
    "            text += page.get_text(\"text\") + \"\\n\"\n",
    "        return text if text.strip() else None  # Return None if empty\n",
    "    except Exception as e:\n",
    "        #print(f\"❌ Failed to extract text from {pdf}: {e}\")\n",
    "        return None  # Failed to extract text\n",
    "\n",
    "def extract_introduction(text, word_limit=500):\n",
    "    lines = text.split(\"\\n\")\n",
    "    introduction_found = False\n",
    "    extracted_text = []\n",
    "    word_count = 0\n",
    "    \n",
    "    #section_pattern = re.compile(r'^\\s*(\\d+\\.?|[IVXLCDM]+\\.?|[A-Z]\\.?)\\s+(INTRODUCTION|Introduction|introduction)\\s*$')\n",
    "    section_pattern = re.compile(r'^\\s*(?:\\d+\\.?|[IVXLCDM]+\\.?|[A-Z]\\.?)?\\s*(INTRODUCTION|Introduction|introduction)\\s*$')\n",
    "\n",
    "    \n",
    "    for line in lines:\n",
    "        if not introduction_found:\n",
    "            if section_pattern.match(line):\n",
    "                introduction_found = True\n",
    "        else:\n",
    "            #words = line.split()\n",
    "            words = re.findall(r\"\\b\\w+\\b\", line)\n",
    "            try:\n",
    "                if word_count + len(words) > word_limit:\n",
    "                    # Find the position of the last word to include\n",
    "                    remaining_words = word_limit - word_count\n",
    "                    last_word = words[remaining_words - 1]  # Last word to keep\n",
    "\n",
    "                    # Find where this last word appears in the original line\n",
    "                    last_word_index = line.find(last_word) + len(last_word)\n",
    "\n",
    "                    # Append the original line up to this point (preserving punctuation)\n",
    "                    extracted_text.append(line[:last_word_index])\n",
    "                    break\n",
    "                else:\n",
    "                    extracted_text.append(line)\n",
    "                    word_count += len(words)\n",
    "            except Exception:\n",
    "                break  \n",
    "    \n",
    "    cleaned_text = re.sub(r'(\\w+)-\\s+(\\w+)', r'\\1\\2', \" \".join(extracted_text))\n",
    "    return cleaned_text.strip() if cleaned_text.strip() else None  # None if intro not found\n",
    "\n",
    "\n",
    "def update_output_file(output_file, successful_retries):\n",
    "    # Read the file into a list\n",
    "    with open(output_file, \"r\") as f:\n",
    "        lines = f.readlines()  # Read all lines\n",
    "\n",
    "    # Update the correct indices\n",
    "    for index, new_text in successful_retries:\n",
    "        if 0 <= index < len(lines):  # Ensure index is valid\n",
    "            lines[index] = new_text.strip() + \"\\n\" \n",
    "    \n",
    "    # Write back the updated lines\n",
    "    with open(output_file, \"w\") as f:\n",
    "        f.writelines(lines)\n",
    "\n",
    "\n",
    "def concatenate_files(file1, file2, output_file):\n",
    "    with open(file1, 'r', encoding='utf-8') as f1, open(file2, 'r', encoding='utf-8') as f2, open(output_file, 'w', encoding='utf-8') as out:\n",
    "        for line1, line2 in zip(f1, f2):\n",
    "            if \"FAILED\" in line2:\n",
    "                out.write(f\"{line1.strip()}\\n\")\n",
    "            else:\n",
    "                out.write(f\"{line1.strip()}. {line2.strip()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_file = \"graph-v2/Node_IDs.txt\"  # File containing one ID per line\n",
    "\n",
    "output_file = \"graph-v2/ANC_500.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Serial***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process PDFs stored in directories\n",
    "def process_pdfs(pdf_dirs, results):\n",
    "    successes = 0\n",
    "    failures = []\n",
    "\n",
    "    for directory in pdf_dirs:\n",
    "        for filename in tqdm(os.listdir(directory), desc=\"Processing files\", unit=\"file\"):\n",
    "            if filename.endswith(\".pdf\"):\n",
    "                pdf_path = os.path.join(directory, filename)\n",
    "\n",
    "                text = extract_text_from_pdf(pdf_path)\n",
    "                if text is None:\n",
    "                    #print(f\"Skipping {filename}: Failed to extract text\")\n",
    "                    failures.append(filename.replace(\"_\", \"/\").replace(\".pdf\", \"\"))\n",
    "                    continue\n",
    "\n",
    "                intro_text = extract_introduction(text)\n",
    "                if intro_text is None:\n",
    "                    #print(f\"Skipping {filename}: No introduction found\")\n",
    "                    failures.append(filename.replace(\"_\", \"/\").replace(\".pdf\", \"\"))\n",
    "                    continue\n",
    "\n",
    "                results[filename.replace(\"_\", \"/\").replace(\".pdf\", \"\")] = intro_text\n",
    "                successes += 1\n",
    "                #print(f\"✅ Extracted Introduction from {filename}\")\n",
    "\n",
    "    return results, successes, failures  # Dictionary { \"filename.pdf\": \"Introduction text\" }\n",
    "\n",
    "\n",
    "\n",
    "# Function to process individual papers\n",
    "def process_pdf(paper_id):\n",
    "    try:\n",
    "        pdf_stream = download_pdf(paper_id)\n",
    "        if not pdf_stream:\n",
    "            print(f\"{paper_id} failed to download\")\n",
    "            return None\n",
    "        \n",
    "        text = extract_text_from_pdf(pdf_stream)\n",
    "        if text is None: \n",
    "            print(f\"Failed to extract text from {paper_id}\")\n",
    "            return None\n",
    "        \n",
    "        introduction_text = extract_introduction(text)\n",
    "        if introduction_text is None:\n",
    "            print(f\"Failed to extract text from introduction section for {paper_id}\")\n",
    "            return None\n",
    "        \n",
    "        return introduction_text\n",
    "    except Exception as e:\n",
    "        return None #f\"Error: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_ids = [\"0704.1274\", \"0704.1028\", \"0704.0954\", \"0704.1308\"] # For selected papers\n",
    "successful_retries = []\n",
    "\n",
    "for paper_id in paper_ids: # for idx, paper_id in failed_papers[0]:\n",
    "    intro_text = process_pdf(paper_id)\n",
    "    if intro_text:\n",
    "        print(f\"\\n==================================================\")\n",
    "        print(intro_text)\n",
    "        print(f\"==================================================\\n\")\n",
    "        #successful_retries.append((idx, intro_text)) # \"successful_retries\" will be used with \"failed_papers\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_dirs = ['Papers 1', 'Papers 2', 'Papers 3', 'Papers 4', 'Papers 5', 'Papers 6']\n",
    "\n",
    "results = {}\n",
    "\n",
    "with open(id_file, \"r\") as f:\n",
    "    paper_ids = {line.strip() for line in f}  # Use a set for faster lookups\n",
    "\n",
    "for paper_id in paper_ids:\n",
    "    results[paper_id] = \"FAILED\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1809.01604',\n",
       " 'cmp-lg/9406023',\n",
       " '1307.1630',\n",
       " 'cs/0511028',\n",
       " '1507.05122',\n",
       " '1709.01305',\n",
       " '1811.01721',\n",
       " '1307.6458',\n",
       " '1807.07247',\n",
       " '1812.10924',\n",
       " '1502.06895',\n",
       " '1605.02401',\n",
       " '1206.5253',\n",
       " '1711.04731',\n",
       " '1811.08764',\n",
       " '1703.08580',\n",
       " '1806.03332',\n",
       " '1808.07733',\n",
       " '1605.06492',\n",
       " '1901.03775',\n",
       " '1812.02207',\n",
       " '1803.00384',\n",
       " '1405.5864',\n",
       " '1806.06237',\n",
       " '1812.07858',\n",
       " '1504.02141',\n",
       " '1603.05359',\n",
       " '1803.06077',\n",
       " '1803.08554',\n",
       " '1604.04879',\n",
       " '0711.1056',\n",
       " '1804.02508',\n",
       " '1802.05581',\n",
       " '1808.06645',\n",
       " '1402.2224',\n",
       " '1509.01951',\n",
       " '1510.08583',\n",
       " '1805.01220',\n",
       " '1501.06206',\n",
       " '1809.06065',\n",
       " '0911.4530',\n",
       " '1704.01523',\n",
       " '1809.08343',\n",
       " '1811.09678',\n",
       " '1002.2780',\n",
       " '1204.4249',\n",
       " '1610.00843',\n",
       " '1511.09180',\n",
       " '1808.04816',\n",
       " '1710.08167',\n",
       " '1511.06566',\n",
       " '1809.00970',\n",
       " '1808.07456',\n",
       " '1901.06086',\n",
       " '1309.5843',\n",
       " '1705.09407',\n",
       " '0801.3272',\n",
       " '1605.09519',\n",
       " '1303.4085',\n",
       " '1809.01733',\n",
       " '1809.10934',\n",
       " '1707.01825',\n",
       " '1603.02366',\n",
       " '1806.08698',\n",
       " '1504.00353',\n",
       " '1801.01627',\n",
       " '1804.07942',\n",
       " '1502.07802',\n",
       " '1204.0867',\n",
       " '1711.05408',\n",
       " '1509.08880',\n",
       " '1808.09955',\n",
       " '1511.06388',\n",
       " '1803.06852',\n",
       " '1206.2248',\n",
       " '1808.07967',\n",
       " '1609.08017',\n",
       " '1705.11175',\n",
       " '1809.06260',\n",
       " '1706.06681',\n",
       " '1707.05246',\n",
       " '1402.2011',\n",
       " '1709.00149',\n",
       " '1611.09345',\n",
       " '1809.09170',\n",
       " '1709.01779',\n",
       " '1602.07630',\n",
       " '1610.06283',\n",
       " '1802.10171',\n",
       " '1405.2982',\n",
       " '1411.4617',\n",
       " '1712.01600',\n",
       " 'cs/0509032',\n",
       " '1711.02488',\n",
       " '1509.01774',\n",
       " '1806.09351',\n",
       " '1802.00420',\n",
       " '1808.08460',\n",
       " '1102.0522',\n",
       " '1506.05855',\n",
       " '1708.06959',\n",
       " '1802.10264',\n",
       " '1803.02852',\n",
       " '1402.2447',\n",
       " '1703.00512',\n",
       " '1506.06216',\n",
       " '1712.07686',\n",
       " '1710.04019',\n",
       " '1407.7390',\n",
       " '1710.10898',\n",
       " '1707.06892',\n",
       " '1808.07528',\n",
       " '1511.06645',\n",
       " '1604.05668',\n",
       " '1606.03504',\n",
       " '1704.08063',\n",
       " '1312.6197',\n",
       " '1803.11366',\n",
       " '1805.00979',\n",
       " '1806.09771',\n",
       " '1002.1436',\n",
       " '1703.00978',\n",
       " '1710.07797',\n",
       " '0712.3277',\n",
       " '1702.08536',\n",
       " '1810.03944',\n",
       " '1012.3476',\n",
       " '1602.08877',\n",
       " '1001.2738',\n",
       " '1805.10367',\n",
       " '1609.01962',\n",
       " '1604.04795',\n",
       " '1702.02526',\n",
       " '1812.00117',\n",
       " '1711.01062',\n",
       " '1412.0980',\n",
       " '1707.03069',\n",
       " '1707.01009',\n",
       " '1703.07051',\n",
       " '1805.08443',\n",
       " '1810.12558',\n",
       " '1701.05544',\n",
       " '1607.06792',\n",
       " '1210.3312',\n",
       " '1706.03148',\n",
       " '1503.01910',\n",
       " '1708.00667',\n",
       " '1804.00521',\n",
       " '1502.05556',\n",
       " '1611.09464',\n",
       " '1309.5823',\n",
       " '1807.09289',\n",
       " '1811.07945',\n",
       " '1901.08770',\n",
       " '1705.06196',\n",
       " '1705.05394',\n",
       " '1701.05973',\n",
       " '1803.08624',\n",
       " '1208.6231',\n",
       " '1805.11183',\n",
       " 'cs/0204026',\n",
       " '1708.02901',\n",
       " '1711.04141',\n",
       " '1504.06165',\n",
       " '1708.01641',\n",
       " '1211.3169',\n",
       " '1710.04142',\n",
       " '1007.3622',\n",
       " '1810.04632',\n",
       " '1805.06641',\n",
       " '1812.01662',\n",
       " '1812.02099',\n",
       " '1707.05697',\n",
       " '1204.2435',\n",
       " '1702.06354',\n",
       " '1807.03257',\n",
       " '1702.07108',\n",
       " '1712.00202',\n",
       " '1508.04306',\n",
       " '1611.05384',\n",
       " '1803.00773',\n",
       " '1707.04610',\n",
       " '1708.02637',\n",
       " '1401.6432',\n",
       " '1812.06515',\n",
       " '1403.1023',\n",
       " '1807.02371',\n",
       " '1812.03230',\n",
       " '0806.2682',\n",
       " '0904.1812',\n",
       " '1806.05241',\n",
       " '1710.10689',\n",
       " '1705.10470',\n",
       " '1512.08103',\n",
       " 'cs/9906002',\n",
       " '1803.08071',\n",
       " '1901.03674',\n",
       " '1705.06400',\n",
       " '0711.4175',\n",
       " '1802.00917',\n",
       " '1808.09907',\n",
       " '1804.11239',\n",
       " '1807.07803',\n",
       " '1005.2770',\n",
       " '1308.3558',\n",
       " '1511.08887',\n",
       " '1503.05667',\n",
       " '1511.04777',\n",
       " '1707.01450',\n",
       " '1901.10674',\n",
       " '1409.2905',\n",
       " '1811.04026',\n",
       " '1410.6558',\n",
       " '1802.04592',\n",
       " '1007.3808',\n",
       " '1707.00189',\n",
       " '1804.01640',\n",
       " '1711.10789',\n",
       " '1010.5416',\n",
       " '1805.05487',\n",
       " '1811.04784',\n",
       " '1802.07412',\n",
       " '1901.10170',\n",
       " '1612.00583',\n",
       " '1806.04728',\n",
       " '1712.03660',\n",
       " '1805.03829',\n",
       " '1811.08039',\n",
       " '1707.05373',\n",
       " '1809.02147',\n",
       " '1509.00244',\n",
       " '1406.0053',\n",
       " '1707.08063',\n",
       " '0903.2226',\n",
       " '1806.08514',\n",
       " '1804.08144',\n",
       " '1806.00194',\n",
       " '1811.05381',\n",
       " '1412.6618',\n",
       " '0908.0358',\n",
       " '1101.3354',\n",
       " '1812.10784',\n",
       " '1409.6911',\n",
       " '1706.08476',\n",
       " '1604.04333',\n",
       " '1709.05256',\n",
       " '1703.04730',\n",
       " '1310.1177',\n",
       " '1810.01733',\n",
       " '1812.02171',\n",
       " '1401.0978',\n",
       " '1511.07356',\n",
       " '1802.02488',\n",
       " '1708.07455',\n",
       " '1806.03547',\n",
       " '1811.01057',\n",
       " '1901.05574',\n",
       " '1609.02646',\n",
       " '1710.03839',\n",
       " '1808.01124',\n",
       " '1809.10097',\n",
       " '1411.7666',\n",
       " '1412.7056',\n",
       " '1505.00670',\n",
       " '1202.3775',\n",
       " '1803.04687',\n",
       " '1503.03438',\n",
       " '1610.08871',\n",
       " '1308.0870',\n",
       " '1711.11543',\n",
       " '1711.00811',\n",
       " '1809.08993',\n",
       " '1708.06819',\n",
       " '1706.01824',\n",
       " '1706.05721',\n",
       " '1711.04951',\n",
       " '1807.06722',\n",
       " '1811.10105',\n",
       " '1203.4867',\n",
       " '1808.04189',\n",
       " '1703.00099',\n",
       " '1510.01032',\n",
       " '1804.07274',\n",
       " '1504.07339',\n",
       " '1807.11622',\n",
       " '1309.6301',\n",
       " 'cs/0509044',\n",
       " '1711.10337',\n",
       " '1411.3229',\n",
       " '1203.5602',\n",
       " '1710.02909',\n",
       " '1808.03246',\n",
       " '1812.07484',\n",
       " '1503.04371',\n",
       " '1203.2936',\n",
       " '1309.7109',\n",
       " '1404.4108',\n",
       " '1801.00406',\n",
       " '1801.02101',\n",
       " '1105.3416',\n",
       " '1708.00187',\n",
       " '1809.05375',\n",
       " '1710.00555',\n",
       " '1112.6384',\n",
       " '1212.6643',\n",
       " '1307.2482',\n",
       " '1708.02863',\n",
       " '1510.00252',\n",
       " '1712.00846',\n",
       " '1403.1497',\n",
       " '1812.01593',\n",
       " '1102.3493',\n",
       " '1611.03473',\n",
       " '1403.3378',\n",
       " '1708.02973',\n",
       " '1612.00576',\n",
       " '1606.05681',\n",
       " '1711.09357',\n",
       " '1706.08564',\n",
       " '1712.02743',\n",
       " '1702.04858',\n",
       " '1611.05720',\n",
       " '1711.03985',\n",
       " '1805.09927',\n",
       " '1804.03635',\n",
       " '1603.06598',\n",
       " '1405.3224',\n",
       " '1806.08730',\n",
       " '1506.02222',\n",
       " '1602.06979',\n",
       " '1701.08118',\n",
       " '1808.03114',\n",
       " '0807.2724',\n",
       " '1806.02514',\n",
       " '1103.0999',\n",
       " '1901.07441',\n",
       " '1802.00434',\n",
       " '1611.05923',\n",
       " '1612.04065',\n",
       " '1311.3534',\n",
       " '1703.01256',\n",
       " '1807.09358',\n",
       " '1711.06606',\n",
       " '1304.5850',\n",
       " '1811.01249',\n",
       " '1810.09660',\n",
       " '1407.2921',\n",
       " '1810.13098',\n",
       " '1709.01472',\n",
       " '1703.08524',\n",
       " '1503.08155',\n",
       " '1612.00410',\n",
       " '1105.5853',\n",
       " '1507.07267',\n",
       " '1710.05941',\n",
       " '1112.5309',\n",
       " '1709.07417',\n",
       " '1802.09431',\n",
       " '1301.2030',\n",
       " '1601.07576',\n",
       " '1802.08760',\n",
       " '1808.06560',\n",
       " '1612.00628',\n",
       " '1807.10584',\n",
       " '1807.06962',\n",
       " '1302.2855',\n",
       " '1511.07236',\n",
       " '1810.01398',\n",
       " '1901.10124',\n",
       " '1709.01434',\n",
       " '1511.06457',\n",
       " '1003.1354',\n",
       " '0803.1733',\n",
       " '1803.06417',\n",
       " '1810.06999',\n",
       " '1701.06532',\n",
       " '0704.0304',\n",
       " '1807.05195',\n",
       " '1807.11637',\n",
       " '1703.02930',\n",
       " '1311.6091',\n",
       " '1212.0248',\n",
       " '1608.08306',\n",
       " '1606.02348',\n",
       " '1505.06807',\n",
       " '1702.00932',\n",
       " '1803.07544',\n",
       " '1208.0645',\n",
       " '1608.03902',\n",
       " '1505.05899',\n",
       " '1406.5311',\n",
       " '1109.4994',\n",
       " '1505.02186',\n",
       " '1505.02417',\n",
       " '1309.0790',\n",
       " '1611.05162',\n",
       " '0911.5703',\n",
       " '1804.08597',\n",
       " '1701.07717',\n",
       " '1704.05753',\n",
       " '1708.04968',\n",
       " '1709.02082',\n",
       " '1812.10617',\n",
       " '1806.09792',\n",
       " '1707.03377',\n",
       " '1710.07990',\n",
       " '1709.06662',\n",
       " '1803.02999',\n",
       " '1703.09470',\n",
       " '1809.00357',\n",
       " '1809.03368',\n",
       " '1208.4423',\n",
       " '1502.07523',\n",
       " '1712.02466',\n",
       " '1810.06208',\n",
       " '1801.04063',\n",
       " '1803.05428',\n",
       " '1412.0035',\n",
       " '1708.06297',\n",
       " '1802.09030',\n",
       " '1607.03474',\n",
       " '1608.06111',\n",
       " '1111.4580',\n",
       " '1806.10714',\n",
       " '1605.06523',\n",
       " '0903.0666',\n",
       " 'cs/0407060',\n",
       " '1803.00057',\n",
       " '1711.02637',\n",
       " '1702.03040',\n",
       " '1809.10374',\n",
       " '1304.1018',\n",
       " '1711.02348',\n",
       " '1302.4405',\n",
       " '1412.0823',\n",
       " '1703.04977',\n",
       " '1608.00778',\n",
       " '1410.6264',\n",
       " '1702.02779',\n",
       " '1602.00223',\n",
       " '1810.11027',\n",
       " '1612.04799',\n",
       " '1607.06641',\n",
       " '1603.04042',\n",
       " '1804.09398',\n",
       " '1805.10796',\n",
       " '1809.09910',\n",
       " '1812.02900',\n",
       " '1308.3513',\n",
       " '1708.02550',\n",
       " '1811.04064',\n",
       " '1509.00825',\n",
       " '1705.00652',\n",
       " '1704.06369',\n",
       " '1708.03816',\n",
       " '1701.06181',\n",
       " '1701.01212',\n",
       " '1706.03692',\n",
       " '1708.03447',\n",
       " '1606.07548',\n",
       " '1810.03644',\n",
       " '1811.10984',\n",
       " '1811.12704',\n",
       " '1604.04888',\n",
       " '1804.00891',\n",
       " '1711.10317',\n",
       " '1803.11303',\n",
       " '1410.5509',\n",
       " '1801.00443',\n",
       " '1508.00092',\n",
       " '1811.04437',\n",
       " '1310.7001',\n",
       " '1610.09289',\n",
       " '1605.08283',\n",
       " '1607.00455',\n",
       " '1704.07056',\n",
       " '1812.03640',\n",
       " '1810.01185',\n",
       " '1707.09183',\n",
       " '1708.00065',\n",
       " '1809.01791',\n",
       " '1804.08042',\n",
       " '1806.02246',\n",
       " '1507.08711',\n",
       " '1804.06439',\n",
       " '1111.1051',\n",
       " '1712.01496',\n",
       " '1504.01452',\n",
       " '1704.02201',\n",
       " '1812.07394',\n",
       " '1409.1411',\n",
       " '1811.05187',\n",
       " '1812.10761',\n",
       " '1406.1943',\n",
       " '1808.01265',\n",
       " '1803.00657',\n",
       " '1708.06425',\n",
       " '1801.08186',\n",
       " '1712.02250',\n",
       " '1812.05313',\n",
       " '1511.04103',\n",
       " '1003.1266',\n",
       " '1812.10366',\n",
       " '1805.04625',\n",
       " '1610.09028',\n",
       " '1511.06147',\n",
       " '1812.09818',\n",
       " '1712.00371',\n",
       " '1811.04151',\n",
       " '1408.5601',\n",
       " '0812.4487',\n",
       " '1805.06956',\n",
       " '1808.08558',\n",
       " '1809.05884',\n",
       " '1711.08267',\n",
       " '1811.01926',\n",
       " '1608.03638',\n",
       " '1512.02949',\n",
       " '1101.0064',\n",
       " '1807.01279',\n",
       " '1611.05128',\n",
       " '1206.6682',\n",
       " '1706.06802',\n",
       " '1709.05480',\n",
       " '1611.08991',\n",
       " '1812.04920',\n",
       " '1101.4450',\n",
       " '1506.05187',\n",
       " '1803.05768',\n",
       " '1808.06289',\n",
       " '1802.01666',\n",
       " '1712.08467',\n",
       " '1512.06492',\n",
       " '1811.11881',\n",
       " '1812.08972',\n",
       " '1412.8060',\n",
       " '1106.4507',\n",
       " '1802.02568',\n",
       " '1808.00931',\n",
       " '1001.2596',\n",
       " '1612.05001',\n",
       " '1704.05120',\n",
       " '1707.00995',\n",
       " '1611.06788',\n",
       " '1708.05478',\n",
       " '1812.03031',\n",
       " '1807.04067',\n",
       " '1511.06939',\n",
       " '1505.01740',\n",
       " '1111.6278',\n",
       " '1603.08631',\n",
       " '1901.09671',\n",
       " '1310.8487',\n",
       " '1502.05680',\n",
       " '1512.00142',\n",
       " '1503.01102',\n",
       " '1711.05165',\n",
       " '1811.02539',\n",
       " '1210.2440',\n",
       " '1501.07867',\n",
       " '1510.04935',\n",
       " '1806.01313',\n",
       " '1210.2159',\n",
       " '1810.11957',\n",
       " '1603.06141',\n",
       " '1801.09500',\n",
       " '1203.3887',\n",
       " '1512.06789',\n",
       " '1805.01167',\n",
       " '1804.08333',\n",
       " '1805.08019',\n",
       " '1804.02322',\n",
       " '1212.4093',\n",
       " '1709.02975',\n",
       " '1503.03163',\n",
       " '1501.02917',\n",
       " '1412.1587',\n",
       " '1011.3516',\n",
       " '1801.06700',\n",
       " '1806.01337',\n",
       " '1805.10528',\n",
       " '1807.08333',\n",
       " '1808.07931',\n",
       " '0708.4311',\n",
       " '1407.0088',\n",
       " '1612.04759',\n",
       " '1802.09405',\n",
       " '1707.06480',\n",
       " '1307.1960',\n",
       " '1401.3737',\n",
       " '1806.09202',\n",
       " '1801.05931',\n",
       " '1711.11556',\n",
       " '1611.06241',\n",
       " '1410.8349',\n",
       " '1502.06644',\n",
       " '1806.09445',\n",
       " '1807.11648',\n",
       " '1805.10572',\n",
       " '1703.01842',\n",
       " '1405.0203',\n",
       " '0903.4443',\n",
       " '1207.3790',\n",
       " '1707.09074',\n",
       " '0807.1267',\n",
       " '1708.04299',\n",
       " '1711.08819',\n",
       " '1804.02692',\n",
       " '1803.06975',\n",
       " '1704.07352',\n",
       " '1807.11254',\n",
       " '1810.09390',\n",
       " '1502.05742',\n",
       " '1702.02034',\n",
       " '1704.04613',\n",
       " '1711.01941',\n",
       " '1004.3692',\n",
       " '1804.08228',\n",
       " '1811.11103',\n",
       " '1804.08229',\n",
       " '1610.05735',\n",
       " '1804.00815',\n",
       " '1808.07118',\n",
       " '1507.03641',\n",
       " '1708.05123',\n",
       " '1105.0286',\n",
       " '1602.04567',\n",
       " '1812.00477',\n",
       " '1810.09150',\n",
       " '1110.2417',\n",
       " '1603.07252',\n",
       " '1606.01455',\n",
       " '1610.05551',\n",
       " '1303.7454',\n",
       " '1708.00111',\n",
       " '1801.01803',\n",
       " '1505.00880',\n",
       " '1802.07442',\n",
       " '1801.04354',\n",
       " '1809.07941',\n",
       " '1812.00602',\n",
       " '1710.09318',\n",
       " '1802.00469',\n",
       " '1005.1524',\n",
       " '1808.10442',\n",
       " '1705.08395',\n",
       " '1705.07565',\n",
       " '1707.03195',\n",
       " '1204.5703',\n",
       " '1406.7486',\n",
       " '1710.10772',\n",
       " '1801.01260',\n",
       " '1708.01155',\n",
       " '1701.04724',\n",
       " '1809.04720',\n",
       " '1804.08198',\n",
       " '1811.08048',\n",
       " '1703.08837',\n",
       " '1712.05138',\n",
       " '1810.01218',\n",
       " '1811.00416',\n",
       " '1711.01567',\n",
       " '1807.01425',\n",
       " '1807.11293',\n",
       " '1811.01741',\n",
       " '0712.3327',\n",
       " '1707.01183',\n",
       " '1803.08586',\n",
       " '1708.03152',\n",
       " '1808.07604',\n",
       " '1412.2196',\n",
       " '1001.2190',\n",
       " '1603.07849',\n",
       " '1804.06137',\n",
       " '1806.07688',\n",
       " '1404.2520',\n",
       " '1709.02349',\n",
       " '1812.02253',\n",
       " '1508.00964',\n",
       " '1111.4555',\n",
       " '1607.06583',\n",
       " '1408.6824',\n",
       " '1704.02079',\n",
       " '1711.07956',\n",
       " '1811.03862',\n",
       " '1809.10243',\n",
       " '1801.07243',\n",
       " '1708.09401',\n",
       " '1510.04455',\n",
       " '1811.10315',\n",
       " '1310.2632',\n",
       " '1810.09202',\n",
       " '1405.0947',\n",
       " '1607.03025',\n",
       " '1901.00828',\n",
       " '1801.00708',\n",
       " '1703.00377',\n",
       " '1612.01189',\n",
       " '1402.5836',\n",
       " '1803.08910',\n",
       " 'cs/0008004',\n",
       " '1710.04234',\n",
       " '1710.00478',\n",
       " 'cs/0610079',\n",
       " '1807.11632',\n",
       " '0810.3442',\n",
       " '1806.01267',\n",
       " '1805.08493',\n",
       " '1506.02897',\n",
       " '1704.00623',\n",
       " '1704.01975',\n",
       " '1512.06429',\n",
       " '1812.09449',\n",
       " '1705.00002',\n",
       " '1602.05307',\n",
       " '1502.03167',\n",
       " '1702.06230',\n",
       " '1812.00797',\n",
       " '1508.01880',\n",
       " '1506.08891',\n",
       " '1708.05221',\n",
       " '1703.00035',\n",
       " '1312.6064',\n",
       " '1511.06241',\n",
       " '1606.02467',\n",
       " '1410.5557',\n",
       " '1901.09532',\n",
       " '1812.02288',\n",
       " '1811.00613',\n",
       " '1802.03499',\n",
       " '1804.00775',\n",
       " '1701.05013',\n",
       " '1705.02627',\n",
       " '1809.04624',\n",
       " '1810.05237',\n",
       " '1811.02545',\n",
       " '1804.10752',\n",
       " '1809.04185',\n",
       " 'cs/0605006',\n",
       " '1803.02392',\n",
       " '1810.10875',\n",
       " '1502.00743',\n",
       " '1506.03662',\n",
       " '1808.03314',\n",
       " '1406.6959',\n",
       " '1804.06609',\n",
       " '1602.01921',\n",
       " '1609.09869',\n",
       " '1612.07360',\n",
       " '1703.04247',\n",
       " '1901.02220',\n",
       " '1210.0100',\n",
       " '1709.02016',\n",
       " '1808.07048',\n",
       " '1705.07972',\n",
       " '1306.1031',\n",
       " '1802.06398',\n",
       " '1412.7024',\n",
       " '1803.03474',\n",
       " '1805.10604',\n",
       " '1803.10470',\n",
       " '1805.10973',\n",
       " '1808.01462',\n",
       " '1608.02902',\n",
       " '1511.01065',\n",
       " '1803.09203',\n",
       " '1805.00249',\n",
       " '1102.2787',\n",
       " '1503.07455',\n",
       " '1810.09302',\n",
       " '1805.00743',\n",
       " '1409.7779',\n",
       " '0908.0898',\n",
       " '1810.10656',\n",
       " '1309.4111',\n",
       " '1602.00749',\n",
       " '1709.05522',\n",
       " '1901.01365',\n",
       " '1110.4613',\n",
       " '1806.05666',\n",
       " '1505.01858',\n",
       " '1807.00392',\n",
       " '1812.10179',\n",
       " '1611.01423',\n",
       " '1706.02888',\n",
       " '1211.7012',\n",
       " '0902.2917',\n",
       " '1706.10198',\n",
       " '1807.10589',\n",
       " '1410.1784',\n",
       " '1705.02949',\n",
       " '1709.00616',\n",
       " '1410.5107',\n",
       " '1810.07278',\n",
       " '1812.00312',\n",
       " '1811.12064',\n",
       " '1607.01092',\n",
       " '1407.6560',\n",
       " '1802.05155',\n",
       " '1612.03217',\n",
       " '1407.5754',\n",
       " '1804.10822',\n",
       " '1701.09135',\n",
       " '1901.04112',\n",
       " '1408.1664',\n",
       " '1402.0556',\n",
       " '1805.12009',\n",
       " '1709.03698',\n",
       " '1303.3934',\n",
       " '1804.06003',\n",
       " '1707.07397',\n",
       " '1607.07959',\n",
       " '1211.2304',\n",
       " '1606.02407',\n",
       " '1507.02407',\n",
       " '1812.02391',\n",
       " '1601.07091',\n",
       " '1810.12482',\n",
       " '1705.00673',\n",
       " '1901.03149',\n",
       " '1204.2611',\n",
       " '1709.08025',\n",
       " '1505.00066',\n",
       " '1310.2053',\n",
       " '1207.3994',\n",
       " '1805.04623',\n",
       " '1801.09383',\n",
       " '1511.07409',\n",
       " '1001.3193',\n",
       " '1406.2616',\n",
       " '1506.06558',\n",
       " '1610.09996',\n",
       " '1107.3253',\n",
       " '1411.7632',\n",
       " '1801.05104',\n",
       " '1101.5317',\n",
       " '1805.09045',\n",
       " '1511.07404',\n",
       " '1804.05296',\n",
       " '1511.00418',\n",
       " '1411.1045',\n",
       " '1808.05054',\n",
       " '1806.04009',\n",
       " '1505.03581',\n",
       " '1901.02404',\n",
       " '1312.7557',\n",
       " '1807.04093',\n",
       " '1304.2694',\n",
       " '1703.02921',\n",
       " 'cs/0701050',\n",
       " '1707.05807',\n",
       " '1811.11222',\n",
       " '1007.3858',\n",
       " '1301.4730',\n",
       " '1802.00868',\n",
       " '1802.04791',\n",
       " '1803.10158',\n",
       " '1807.10965',\n",
       " '1901.06560',\n",
       " '1709.04090',\n",
       " '1506.01929',\n",
       " '1804.10992',\n",
       " '1408.2303',\n",
       " '1809.05786',\n",
       " '1810.07433',\n",
       " '1806.03578',\n",
       " '1811.07988',\n",
       " '1408.2584',\n",
       " '1106.4221',\n",
       " '1811.10790',\n",
       " '1808.02932',\n",
       " '1702.07463',\n",
       " '1306.1520',\n",
       " '1501.04704',\n",
       " '1812.00893',\n",
       " '1609.02200',\n",
       " '1605.08671',\n",
       " '1804.06252',\n",
       " '1604.00326',\n",
       " '1811.04136',\n",
       " '1611.05088',\n",
       " '1711.05795',\n",
       " '1602.07726',\n",
       " '1611.07174',\n",
       " '1811.00287',\n",
       " '1212.5316',\n",
       " '1407.5234',\n",
       " '1401.1974',\n",
       " '1505.04657',\n",
       " '1509.00539',\n",
       " '1710.10164',\n",
       " '1608.00641',\n",
       " '1708.05256',\n",
       " '1206.4602',\n",
       " '1510.02822',\n",
       " '1612.08326',\n",
       " '1709.09770',\n",
       " '1703.08289',\n",
       " '1606.00625',\n",
       " '1811.07078',\n",
       " '1804.00779',\n",
       " '1201.0715',\n",
       " '1506.02632',\n",
       " '1807.05118',\n",
       " '1712.05134',\n",
       " '1204.6725',\n",
       " 'cmp-lg/9406010',\n",
       " '1710.10749',\n",
       " '1608.07636',\n",
       " '1406.4852',\n",
       " '1107.4623',\n",
       " '1711.04268',\n",
       " '1511.02954',\n",
       " '1303.1354',\n",
       " '1606.09184',\n",
       " '1410.7550',\n",
       " '1606.04289',\n",
       " '1802.06897',\n",
       " '0903.0548',\n",
       " '1710.06425',\n",
       " '1511.04508',\n",
       " 'cs/0606052',\n",
       " '1512.09080',\n",
       " '1802.05883',\n",
       " '1609.07132',\n",
       " '1610.05556',\n",
       " '1310.3697',\n",
       " '1611.10152',\n",
       " '1401.6330',\n",
       " '1009.3083',\n",
       " '1312.0482',\n",
       " '1710.10577',\n",
       " '1803.07617',\n",
       " '1803.02007',\n",
       " '1805.08777',\n",
       " '1807.01511',\n",
       " '1812.02224',\n",
       " '1705.07522',\n",
       " '1806.02705',\n",
       " '1002.1531',\n",
       " '1810.13105',\n",
       " '1704.06497',\n",
       " '0710.1325',\n",
       " '1806.01261',\n",
       " '1706.02823',\n",
       " '1901.08469',\n",
       " '1105.2631',\n",
       " '1709.07814',\n",
       " '1710.01766',\n",
       " '1408.4073',\n",
       " '1406.5614',\n",
       " '1708.00154',\n",
       " '1807.02632',\n",
       " '1503.01404',\n",
       " '1612.04318',\n",
       " '1602.00639',\n",
       " '1803.08134',\n",
       " '1310.3438',\n",
       " '0805.3799',\n",
       " '1502.04434',\n",
       " '1704.06962',\n",
       " '1611.05995',\n",
       " '1804.00401',\n",
       " '1603.08233',\n",
       " '1706.09278',\n",
       " '1610.09322',\n",
       " '1707.01212',\n",
       " '1807.06677',\n",
       " '0712.4209',\n",
       " '1409.3870',\n",
       " '1304.6487',\n",
       " '1204.2134',\n",
       " '1105.2865',\n",
       " '1805.03911',\n",
       " 'cs/0308003',\n",
       " '1810.00434',\n",
       " '1608.08940',\n",
       " '1606.04695',\n",
       " '1810.11730',\n",
       " '1901.06486',\n",
       " '1206.4646',\n",
       " '1701.07405',\n",
       " '1807.10744',\n",
       " '1608.06417',\n",
       " '1711.10331',\n",
       " '1812.08685',\n",
       " '1808.01119',\n",
       " '1705.08435',\n",
       " '1609.09226',\n",
       " '1503.01445',\n",
       " '0904.1840',\n",
       " '1605.04598',\n",
       " '1608.08852',\n",
       " '1603.08318',\n",
       " '1604.06743',\n",
       " '1606.06900',\n",
       " '1605.02260',\n",
       " '1704.03718',\n",
       " '1801.07386',\n",
       " '1805.07732',\n",
       " ...}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1809.01604': 'FAILED',\n",
       " 'cmp-lg/9406023': 'FAILED',\n",
       " '1307.1630': 'FAILED',\n",
       " 'cs/0511028': 'FAILED',\n",
       " '1507.05122': 'FAILED',\n",
       " '1709.01305': 'FAILED',\n",
       " '1811.01721': 'FAILED',\n",
       " '1307.6458': 'FAILED',\n",
       " '1807.07247': 'FAILED',\n",
       " '1812.10924': 'FAILED',\n",
       " '1502.06895': 'FAILED',\n",
       " '1605.02401': 'FAILED',\n",
       " '1206.5253': 'FAILED',\n",
       " '1711.04731': 'FAILED',\n",
       " '1811.08764': 'FAILED',\n",
       " '1703.08580': 'FAILED',\n",
       " '1806.03332': 'FAILED',\n",
       " '1808.07733': 'FAILED',\n",
       " '1605.06492': 'FAILED',\n",
       " '1901.03775': 'FAILED',\n",
       " '1812.02207': 'FAILED',\n",
       " '1803.00384': 'FAILED',\n",
       " '1405.5864': 'FAILED',\n",
       " '1806.06237': 'FAILED',\n",
       " '1812.07858': 'FAILED',\n",
       " '1504.02141': 'FAILED',\n",
       " '1603.05359': 'FAILED',\n",
       " '1803.06077': 'FAILED',\n",
       " '1803.08554': 'FAILED',\n",
       " '1604.04879': 'FAILED',\n",
       " '0711.1056': 'FAILED',\n",
       " '1804.02508': 'FAILED',\n",
       " '1802.05581': 'FAILED',\n",
       " '1808.06645': 'FAILED',\n",
       " '1402.2224': 'FAILED',\n",
       " '1509.01951': 'FAILED',\n",
       " '1510.08583': 'FAILED',\n",
       " '1805.01220': 'FAILED',\n",
       " '1501.06206': 'FAILED',\n",
       " '1809.06065': 'FAILED',\n",
       " '0911.4530': 'FAILED',\n",
       " '1704.01523': 'FAILED',\n",
       " '1809.08343': 'FAILED',\n",
       " '1811.09678': 'FAILED',\n",
       " '1002.2780': 'FAILED',\n",
       " '1204.4249': 'FAILED',\n",
       " '1610.00843': 'FAILED',\n",
       " '1511.09180': 'FAILED',\n",
       " '1808.04816': 'FAILED',\n",
       " '1710.08167': 'FAILED',\n",
       " '1511.06566': 'FAILED',\n",
       " '1809.00970': 'FAILED',\n",
       " '1808.07456': 'FAILED',\n",
       " '1901.06086': 'FAILED',\n",
       " '1309.5843': 'FAILED',\n",
       " '1705.09407': 'FAILED',\n",
       " '0801.3272': 'FAILED',\n",
       " '1605.09519': 'FAILED',\n",
       " '1303.4085': 'FAILED',\n",
       " '1809.01733': 'FAILED',\n",
       " '1809.10934': 'FAILED',\n",
       " '1707.01825': 'FAILED',\n",
       " '1603.02366': 'FAILED',\n",
       " '1806.08698': 'FAILED',\n",
       " '1504.00353': 'FAILED',\n",
       " '1801.01627': 'FAILED',\n",
       " '1804.07942': 'FAILED',\n",
       " '1502.07802': 'FAILED',\n",
       " '1204.0867': 'FAILED',\n",
       " '1711.05408': 'FAILED',\n",
       " '1509.08880': 'FAILED',\n",
       " '1808.09955': 'FAILED',\n",
       " '1511.06388': 'FAILED',\n",
       " '1803.06852': 'FAILED',\n",
       " '1206.2248': 'FAILED',\n",
       " '1808.07967': 'FAILED',\n",
       " '1609.08017': 'FAILED',\n",
       " '1705.11175': 'FAILED',\n",
       " '1809.06260': 'FAILED',\n",
       " '1706.06681': 'FAILED',\n",
       " '1707.05246': 'FAILED',\n",
       " '1402.2011': 'FAILED',\n",
       " '1709.00149': 'FAILED',\n",
       " '1611.09345': 'FAILED',\n",
       " '1809.09170': 'FAILED',\n",
       " '1709.01779': 'FAILED',\n",
       " '1602.07630': 'FAILED',\n",
       " '1610.06283': 'FAILED',\n",
       " '1802.10171': 'FAILED',\n",
       " '1405.2982': 'FAILED',\n",
       " '1411.4617': 'FAILED',\n",
       " '1712.01600': 'FAILED',\n",
       " 'cs/0509032': 'FAILED',\n",
       " '1711.02488': 'FAILED',\n",
       " '1509.01774': 'FAILED',\n",
       " '1806.09351': 'FAILED',\n",
       " '1802.00420': 'FAILED',\n",
       " '1808.08460': 'FAILED',\n",
       " '1102.0522': 'FAILED',\n",
       " '1506.05855': 'FAILED',\n",
       " '1708.06959': 'FAILED',\n",
       " '1802.10264': 'FAILED',\n",
       " '1803.02852': 'FAILED',\n",
       " '1402.2447': 'FAILED',\n",
       " '1703.00512': 'FAILED',\n",
       " '1506.06216': 'FAILED',\n",
       " '1712.07686': 'FAILED',\n",
       " '1710.04019': 'FAILED',\n",
       " '1407.7390': 'FAILED',\n",
       " '1710.10898': 'FAILED',\n",
       " '1707.06892': 'FAILED',\n",
       " '1808.07528': 'FAILED',\n",
       " '1511.06645': 'FAILED',\n",
       " '1604.05668': 'FAILED',\n",
       " '1606.03504': 'FAILED',\n",
       " '1704.08063': 'FAILED',\n",
       " '1312.6197': 'FAILED',\n",
       " '1803.11366': 'FAILED',\n",
       " '1805.00979': 'FAILED',\n",
       " '1806.09771': 'FAILED',\n",
       " '1002.1436': 'FAILED',\n",
       " '1703.00978': 'FAILED',\n",
       " '1710.07797': 'FAILED',\n",
       " '0712.3277': 'FAILED',\n",
       " '1702.08536': 'FAILED',\n",
       " '1810.03944': 'FAILED',\n",
       " '1012.3476': 'FAILED',\n",
       " '1602.08877': 'FAILED',\n",
       " '1001.2738': 'FAILED',\n",
       " '1805.10367': 'FAILED',\n",
       " '1609.01962': 'FAILED',\n",
       " '1604.04795': 'FAILED',\n",
       " '1702.02526': 'FAILED',\n",
       " '1812.00117': 'FAILED',\n",
       " '1711.01062': 'FAILED',\n",
       " '1412.0980': 'FAILED',\n",
       " '1707.03069': 'FAILED',\n",
       " '1707.01009': 'FAILED',\n",
       " '1703.07051': 'FAILED',\n",
       " '1805.08443': 'FAILED',\n",
       " '1810.12558': 'FAILED',\n",
       " '1701.05544': 'FAILED',\n",
       " '1607.06792': 'FAILED',\n",
       " '1210.3312': 'FAILED',\n",
       " '1706.03148': 'FAILED',\n",
       " '1503.01910': 'FAILED',\n",
       " '1708.00667': 'FAILED',\n",
       " '1804.00521': 'FAILED',\n",
       " '1502.05556': 'FAILED',\n",
       " '1611.09464': 'FAILED',\n",
       " '1309.5823': 'FAILED',\n",
       " '1807.09289': 'FAILED',\n",
       " '1811.07945': 'FAILED',\n",
       " '1901.08770': 'FAILED',\n",
       " '1705.06196': 'FAILED',\n",
       " '1705.05394': 'FAILED',\n",
       " '1701.05973': 'FAILED',\n",
       " '1803.08624': 'FAILED',\n",
       " '1208.6231': 'FAILED',\n",
       " '1805.11183': 'FAILED',\n",
       " 'cs/0204026': 'FAILED',\n",
       " '1708.02901': 'FAILED',\n",
       " '1711.04141': 'FAILED',\n",
       " '1504.06165': 'FAILED',\n",
       " '1708.01641': 'FAILED',\n",
       " '1211.3169': 'FAILED',\n",
       " '1710.04142': 'FAILED',\n",
       " '1007.3622': 'FAILED',\n",
       " '1810.04632': 'FAILED',\n",
       " '1805.06641': 'FAILED',\n",
       " '1812.01662': 'FAILED',\n",
       " '1812.02099': 'FAILED',\n",
       " '1707.05697': 'FAILED',\n",
       " '1204.2435': 'FAILED',\n",
       " '1702.06354': 'FAILED',\n",
       " '1807.03257': 'FAILED',\n",
       " '1702.07108': 'FAILED',\n",
       " '1712.00202': 'FAILED',\n",
       " '1508.04306': 'FAILED',\n",
       " '1611.05384': 'FAILED',\n",
       " '1803.00773': 'FAILED',\n",
       " '1707.04610': 'FAILED',\n",
       " '1708.02637': 'FAILED',\n",
       " '1401.6432': 'FAILED',\n",
       " '1812.06515': 'FAILED',\n",
       " '1403.1023': 'FAILED',\n",
       " '1807.02371': 'FAILED',\n",
       " '1812.03230': 'FAILED',\n",
       " '0806.2682': 'FAILED',\n",
       " '0904.1812': 'FAILED',\n",
       " '1806.05241': 'FAILED',\n",
       " '1710.10689': 'FAILED',\n",
       " '1705.10470': 'FAILED',\n",
       " '1512.08103': 'FAILED',\n",
       " 'cs/9906002': 'FAILED',\n",
       " '1803.08071': 'FAILED',\n",
       " '1901.03674': 'FAILED',\n",
       " '1705.06400': 'FAILED',\n",
       " '0711.4175': 'FAILED',\n",
       " '1802.00917': 'FAILED',\n",
       " '1808.09907': 'FAILED',\n",
       " '1804.11239': 'FAILED',\n",
       " '1807.07803': 'FAILED',\n",
       " '1005.2770': 'FAILED',\n",
       " '1308.3558': 'FAILED',\n",
       " '1511.08887': 'FAILED',\n",
       " '1503.05667': 'FAILED',\n",
       " '1511.04777': 'FAILED',\n",
       " '1707.01450': 'FAILED',\n",
       " '1901.10674': 'FAILED',\n",
       " '1409.2905': 'FAILED',\n",
       " '1811.04026': 'FAILED',\n",
       " '1410.6558': 'FAILED',\n",
       " '1802.04592': 'FAILED',\n",
       " '1007.3808': 'FAILED',\n",
       " '1707.00189': 'FAILED',\n",
       " '1804.01640': 'FAILED',\n",
       " '1711.10789': 'FAILED',\n",
       " '1010.5416': 'FAILED',\n",
       " '1805.05487': 'FAILED',\n",
       " '1811.04784': 'FAILED',\n",
       " '1802.07412': 'FAILED',\n",
       " '1901.10170': 'FAILED',\n",
       " '1612.00583': 'FAILED',\n",
       " '1806.04728': 'FAILED',\n",
       " '1712.03660': 'FAILED',\n",
       " '1805.03829': 'FAILED',\n",
       " '1811.08039': 'FAILED',\n",
       " '1707.05373': 'FAILED',\n",
       " '1809.02147': 'FAILED',\n",
       " '1509.00244': 'FAILED',\n",
       " '1406.0053': 'FAILED',\n",
       " '1707.08063': 'FAILED',\n",
       " '0903.2226': 'FAILED',\n",
       " '1806.08514': 'FAILED',\n",
       " '1804.08144': 'FAILED',\n",
       " '1806.00194': 'FAILED',\n",
       " '1811.05381': 'FAILED',\n",
       " '1412.6618': 'FAILED',\n",
       " '0908.0358': 'FAILED',\n",
       " '1101.3354': 'FAILED',\n",
       " '1812.10784': 'FAILED',\n",
       " '1409.6911': 'FAILED',\n",
       " '1706.08476': 'FAILED',\n",
       " '1604.04333': 'FAILED',\n",
       " '1709.05256': 'FAILED',\n",
       " '1703.04730': 'FAILED',\n",
       " '1310.1177': 'FAILED',\n",
       " '1810.01733': 'FAILED',\n",
       " '1812.02171': 'FAILED',\n",
       " '1401.0978': 'FAILED',\n",
       " '1511.07356': 'FAILED',\n",
       " '1802.02488': 'FAILED',\n",
       " '1708.07455': 'FAILED',\n",
       " '1806.03547': 'FAILED',\n",
       " '1811.01057': 'FAILED',\n",
       " '1901.05574': 'FAILED',\n",
       " '1609.02646': 'FAILED',\n",
       " '1710.03839': 'FAILED',\n",
       " '1808.01124': 'FAILED',\n",
       " '1809.10097': 'FAILED',\n",
       " '1411.7666': 'FAILED',\n",
       " '1412.7056': 'FAILED',\n",
       " '1505.00670': 'FAILED',\n",
       " '1202.3775': 'FAILED',\n",
       " '1803.04687': 'FAILED',\n",
       " '1503.03438': 'FAILED',\n",
       " '1610.08871': 'FAILED',\n",
       " '1308.0870': 'FAILED',\n",
       " '1711.11543': 'FAILED',\n",
       " '1711.00811': 'FAILED',\n",
       " '1809.08993': 'FAILED',\n",
       " '1708.06819': 'FAILED',\n",
       " '1706.01824': 'FAILED',\n",
       " '1706.05721': 'FAILED',\n",
       " '1711.04951': 'FAILED',\n",
       " '1807.06722': 'FAILED',\n",
       " '1811.10105': 'FAILED',\n",
       " '1203.4867': 'FAILED',\n",
       " '1808.04189': 'FAILED',\n",
       " '1703.00099': 'FAILED',\n",
       " '1510.01032': 'FAILED',\n",
       " '1804.07274': 'FAILED',\n",
       " '1504.07339': 'FAILED',\n",
       " '1807.11622': 'FAILED',\n",
       " '1309.6301': 'FAILED',\n",
       " 'cs/0509044': 'FAILED',\n",
       " '1711.10337': 'FAILED',\n",
       " '1411.3229': 'FAILED',\n",
       " '1203.5602': 'FAILED',\n",
       " '1710.02909': 'FAILED',\n",
       " '1808.03246': 'FAILED',\n",
       " '1812.07484': 'FAILED',\n",
       " '1503.04371': 'FAILED',\n",
       " '1203.2936': 'FAILED',\n",
       " '1309.7109': 'FAILED',\n",
       " '1404.4108': 'FAILED',\n",
       " '1801.00406': 'FAILED',\n",
       " '1801.02101': 'FAILED',\n",
       " '1105.3416': 'FAILED',\n",
       " '1708.00187': 'FAILED',\n",
       " '1809.05375': 'FAILED',\n",
       " '1710.00555': 'FAILED',\n",
       " '1112.6384': 'FAILED',\n",
       " '1212.6643': 'FAILED',\n",
       " '1307.2482': 'FAILED',\n",
       " '1708.02863': 'FAILED',\n",
       " '1510.00252': 'FAILED',\n",
       " '1712.00846': 'FAILED',\n",
       " '1403.1497': 'FAILED',\n",
       " '1812.01593': 'FAILED',\n",
       " '1102.3493': 'FAILED',\n",
       " '1611.03473': 'FAILED',\n",
       " '1403.3378': 'FAILED',\n",
       " '1708.02973': 'FAILED',\n",
       " '1612.00576': 'FAILED',\n",
       " '1606.05681': 'FAILED',\n",
       " '1711.09357': 'FAILED',\n",
       " '1706.08564': 'FAILED',\n",
       " '1712.02743': 'FAILED',\n",
       " '1702.04858': 'FAILED',\n",
       " '1611.05720': 'FAILED',\n",
       " '1711.03985': 'FAILED',\n",
       " '1805.09927': 'FAILED',\n",
       " '1804.03635': 'FAILED',\n",
       " '1603.06598': 'FAILED',\n",
       " '1405.3224': 'FAILED',\n",
       " '1806.08730': 'FAILED',\n",
       " '1506.02222': 'FAILED',\n",
       " '1602.06979': 'FAILED',\n",
       " '1701.08118': 'FAILED',\n",
       " '1808.03114': 'FAILED',\n",
       " '0807.2724': 'FAILED',\n",
       " '1806.02514': 'FAILED',\n",
       " '1103.0999': 'FAILED',\n",
       " '1901.07441': 'FAILED',\n",
       " '1802.00434': 'FAILED',\n",
       " '1611.05923': 'FAILED',\n",
       " '1612.04065': 'FAILED',\n",
       " '1311.3534': 'FAILED',\n",
       " '1703.01256': 'FAILED',\n",
       " '1807.09358': 'FAILED',\n",
       " '1711.06606': 'FAILED',\n",
       " '1304.5850': 'FAILED',\n",
       " '1811.01249': 'FAILED',\n",
       " '1810.09660': 'FAILED',\n",
       " '1407.2921': 'FAILED',\n",
       " '1810.13098': 'FAILED',\n",
       " '1709.01472': 'FAILED',\n",
       " '1703.08524': 'FAILED',\n",
       " '1503.08155': 'FAILED',\n",
       " '1612.00410': 'FAILED',\n",
       " '1105.5853': 'FAILED',\n",
       " '1507.07267': 'FAILED',\n",
       " '1710.05941': 'FAILED',\n",
       " '1112.5309': 'FAILED',\n",
       " '1709.07417': 'FAILED',\n",
       " '1802.09431': 'FAILED',\n",
       " '1301.2030': 'FAILED',\n",
       " '1601.07576': 'FAILED',\n",
       " '1802.08760': 'FAILED',\n",
       " '1808.06560': 'FAILED',\n",
       " '1612.00628': 'FAILED',\n",
       " '1807.10584': 'FAILED',\n",
       " '1807.06962': 'FAILED',\n",
       " '1302.2855': 'FAILED',\n",
       " '1511.07236': 'FAILED',\n",
       " '1810.01398': 'FAILED',\n",
       " '1901.10124': 'FAILED',\n",
       " '1709.01434': 'FAILED',\n",
       " '1511.06457': 'FAILED',\n",
       " '1003.1354': 'FAILED',\n",
       " '0803.1733': 'FAILED',\n",
       " '1803.06417': 'FAILED',\n",
       " '1810.06999': 'FAILED',\n",
       " '1701.06532': 'FAILED',\n",
       " '0704.0304': 'FAILED',\n",
       " '1807.05195': 'FAILED',\n",
       " '1807.11637': 'FAILED',\n",
       " '1703.02930': 'FAILED',\n",
       " '1311.6091': 'FAILED',\n",
       " '1212.0248': 'FAILED',\n",
       " '1608.08306': 'FAILED',\n",
       " '1606.02348': 'FAILED',\n",
       " '1505.06807': 'FAILED',\n",
       " '1702.00932': 'FAILED',\n",
       " '1803.07544': 'FAILED',\n",
       " '1208.0645': 'FAILED',\n",
       " '1608.03902': 'FAILED',\n",
       " '1505.05899': 'FAILED',\n",
       " '1406.5311': 'FAILED',\n",
       " '1109.4994': 'FAILED',\n",
       " '1505.02186': 'FAILED',\n",
       " '1505.02417': 'FAILED',\n",
       " '1309.0790': 'FAILED',\n",
       " '1611.05162': 'FAILED',\n",
       " '0911.5703': 'FAILED',\n",
       " '1804.08597': 'FAILED',\n",
       " '1701.07717': 'FAILED',\n",
       " '1704.05753': 'FAILED',\n",
       " '1708.04968': 'FAILED',\n",
       " '1709.02082': 'FAILED',\n",
       " '1812.10617': 'FAILED',\n",
       " '1806.09792': 'FAILED',\n",
       " '1707.03377': 'FAILED',\n",
       " '1710.07990': 'FAILED',\n",
       " '1709.06662': 'FAILED',\n",
       " '1803.02999': 'FAILED',\n",
       " '1703.09470': 'FAILED',\n",
       " '1809.00357': 'FAILED',\n",
       " '1809.03368': 'FAILED',\n",
       " '1208.4423': 'FAILED',\n",
       " '1502.07523': 'FAILED',\n",
       " '1712.02466': 'FAILED',\n",
       " '1810.06208': 'FAILED',\n",
       " '1801.04063': 'FAILED',\n",
       " '1803.05428': 'FAILED',\n",
       " '1412.0035': 'FAILED',\n",
       " '1708.06297': 'FAILED',\n",
       " '1802.09030': 'FAILED',\n",
       " '1607.03474': 'FAILED',\n",
       " '1608.06111': 'FAILED',\n",
       " '1111.4580': 'FAILED',\n",
       " '1806.10714': 'FAILED',\n",
       " '1605.06523': 'FAILED',\n",
       " '0903.0666': 'FAILED',\n",
       " 'cs/0407060': 'FAILED',\n",
       " '1803.00057': 'FAILED',\n",
       " '1711.02637': 'FAILED',\n",
       " '1702.03040': 'FAILED',\n",
       " '1809.10374': 'FAILED',\n",
       " '1304.1018': 'FAILED',\n",
       " '1711.02348': 'FAILED',\n",
       " '1302.4405': 'FAILED',\n",
       " '1412.0823': 'FAILED',\n",
       " '1703.04977': 'FAILED',\n",
       " '1608.00778': 'FAILED',\n",
       " '1410.6264': 'FAILED',\n",
       " '1702.02779': 'FAILED',\n",
       " '1602.00223': 'FAILED',\n",
       " '1810.11027': 'FAILED',\n",
       " '1612.04799': 'FAILED',\n",
       " '1607.06641': 'FAILED',\n",
       " '1603.04042': 'FAILED',\n",
       " '1804.09398': 'FAILED',\n",
       " '1805.10796': 'FAILED',\n",
       " '1809.09910': 'FAILED',\n",
       " '1812.02900': 'FAILED',\n",
       " '1308.3513': 'FAILED',\n",
       " '1708.02550': 'FAILED',\n",
       " '1811.04064': 'FAILED',\n",
       " '1509.00825': 'FAILED',\n",
       " '1705.00652': 'FAILED',\n",
       " '1704.06369': 'FAILED',\n",
       " '1708.03816': 'FAILED',\n",
       " '1701.06181': 'FAILED',\n",
       " '1701.01212': 'FAILED',\n",
       " '1706.03692': 'FAILED',\n",
       " '1708.03447': 'FAILED',\n",
       " '1606.07548': 'FAILED',\n",
       " '1810.03644': 'FAILED',\n",
       " '1811.10984': 'FAILED',\n",
       " '1811.12704': 'FAILED',\n",
       " '1604.04888': 'FAILED',\n",
       " '1804.00891': 'FAILED',\n",
       " '1711.10317': 'FAILED',\n",
       " '1803.11303': 'FAILED',\n",
       " '1410.5509': 'FAILED',\n",
       " '1801.00443': 'FAILED',\n",
       " '1508.00092': 'FAILED',\n",
       " '1811.04437': 'FAILED',\n",
       " '1310.7001': 'FAILED',\n",
       " '1610.09289': 'FAILED',\n",
       " '1605.08283': 'FAILED',\n",
       " '1607.00455': 'FAILED',\n",
       " '1704.07056': 'FAILED',\n",
       " '1812.03640': 'FAILED',\n",
       " '1810.01185': 'FAILED',\n",
       " '1707.09183': 'FAILED',\n",
       " '1708.00065': 'FAILED',\n",
       " '1809.01791': 'FAILED',\n",
       " '1804.08042': 'FAILED',\n",
       " '1806.02246': 'FAILED',\n",
       " '1507.08711': 'FAILED',\n",
       " '1804.06439': 'FAILED',\n",
       " '1111.1051': 'FAILED',\n",
       " '1712.01496': 'FAILED',\n",
       " '1504.01452': 'FAILED',\n",
       " '1704.02201': 'FAILED',\n",
       " '1812.07394': 'FAILED',\n",
       " '1409.1411': 'FAILED',\n",
       " '1811.05187': 'FAILED',\n",
       " '1812.10761': 'FAILED',\n",
       " '1406.1943': 'FAILED',\n",
       " '1808.01265': 'FAILED',\n",
       " '1803.00657': 'FAILED',\n",
       " '1708.06425': 'FAILED',\n",
       " '1801.08186': 'FAILED',\n",
       " '1712.02250': 'FAILED',\n",
       " '1812.05313': 'FAILED',\n",
       " '1511.04103': 'FAILED',\n",
       " '1003.1266': 'FAILED',\n",
       " '1812.10366': 'FAILED',\n",
       " '1805.04625': 'FAILED',\n",
       " '1610.09028': 'FAILED',\n",
       " '1511.06147': 'FAILED',\n",
       " '1812.09818': 'FAILED',\n",
       " '1712.00371': 'FAILED',\n",
       " '1811.04151': 'FAILED',\n",
       " '1408.5601': 'FAILED',\n",
       " '0812.4487': 'FAILED',\n",
       " '1805.06956': 'FAILED',\n",
       " '1808.08558': 'FAILED',\n",
       " '1809.05884': 'FAILED',\n",
       " '1711.08267': 'FAILED',\n",
       " '1811.01926': 'FAILED',\n",
       " '1608.03638': 'FAILED',\n",
       " '1512.02949': 'FAILED',\n",
       " '1101.0064': 'FAILED',\n",
       " '1807.01279': 'FAILED',\n",
       " '1611.05128': 'FAILED',\n",
       " '1206.6682': 'FAILED',\n",
       " '1706.06802': 'FAILED',\n",
       " '1709.05480': 'FAILED',\n",
       " '1611.08991': 'FAILED',\n",
       " '1812.04920': 'FAILED',\n",
       " '1101.4450': 'FAILED',\n",
       " '1506.05187': 'FAILED',\n",
       " '1803.05768': 'FAILED',\n",
       " '1808.06289': 'FAILED',\n",
       " '1802.01666': 'FAILED',\n",
       " '1712.08467': 'FAILED',\n",
       " '1512.06492': 'FAILED',\n",
       " '1811.11881': 'FAILED',\n",
       " '1812.08972': 'FAILED',\n",
       " '1412.8060': 'FAILED',\n",
       " '1106.4507': 'FAILED',\n",
       " '1802.02568': 'FAILED',\n",
       " '1808.00931': 'FAILED',\n",
       " '1001.2596': 'FAILED',\n",
       " '1612.05001': 'FAILED',\n",
       " '1704.05120': 'FAILED',\n",
       " '1707.00995': 'FAILED',\n",
       " '1611.06788': 'FAILED',\n",
       " '1708.05478': 'FAILED',\n",
       " '1812.03031': 'FAILED',\n",
       " '1807.04067': 'FAILED',\n",
       " '1511.06939': 'FAILED',\n",
       " '1505.01740': 'FAILED',\n",
       " '1111.6278': 'FAILED',\n",
       " '1603.08631': 'FAILED',\n",
       " '1901.09671': 'FAILED',\n",
       " '1310.8487': 'FAILED',\n",
       " '1502.05680': 'FAILED',\n",
       " '1512.00142': 'FAILED',\n",
       " '1503.01102': 'FAILED',\n",
       " '1711.05165': 'FAILED',\n",
       " '1811.02539': 'FAILED',\n",
       " '1210.2440': 'FAILED',\n",
       " '1501.07867': 'FAILED',\n",
       " '1510.04935': 'FAILED',\n",
       " '1806.01313': 'FAILED',\n",
       " '1210.2159': 'FAILED',\n",
       " '1810.11957': 'FAILED',\n",
       " '1603.06141': 'FAILED',\n",
       " '1801.09500': 'FAILED',\n",
       " '1203.3887': 'FAILED',\n",
       " '1512.06789': 'FAILED',\n",
       " '1805.01167': 'FAILED',\n",
       " '1804.08333': 'FAILED',\n",
       " '1805.08019': 'FAILED',\n",
       " '1804.02322': 'FAILED',\n",
       " '1212.4093': 'FAILED',\n",
       " '1709.02975': 'FAILED',\n",
       " '1503.03163': 'FAILED',\n",
       " '1501.02917': 'FAILED',\n",
       " '1412.1587': 'FAILED',\n",
       " '1011.3516': 'FAILED',\n",
       " '1801.06700': 'FAILED',\n",
       " '1806.01337': 'FAILED',\n",
       " '1805.10528': 'FAILED',\n",
       " '1807.08333': 'FAILED',\n",
       " '1808.07931': 'FAILED',\n",
       " '0708.4311': 'FAILED',\n",
       " '1407.0088': 'FAILED',\n",
       " '1612.04759': 'FAILED',\n",
       " '1802.09405': 'FAILED',\n",
       " '1707.06480': 'FAILED',\n",
       " '1307.1960': 'FAILED',\n",
       " '1401.3737': 'FAILED',\n",
       " '1806.09202': 'FAILED',\n",
       " '1801.05931': 'FAILED',\n",
       " '1711.11556': 'FAILED',\n",
       " '1611.06241': 'FAILED',\n",
       " '1410.8349': 'FAILED',\n",
       " '1502.06644': 'FAILED',\n",
       " '1806.09445': 'FAILED',\n",
       " '1807.11648': 'FAILED',\n",
       " '1805.10572': 'FAILED',\n",
       " '1703.01842': 'FAILED',\n",
       " '1405.0203': 'FAILED',\n",
       " '0903.4443': 'FAILED',\n",
       " '1207.3790': 'FAILED',\n",
       " '1707.09074': 'FAILED',\n",
       " '0807.1267': 'FAILED',\n",
       " '1708.04299': 'FAILED',\n",
       " '1711.08819': 'FAILED',\n",
       " '1804.02692': 'FAILED',\n",
       " '1803.06975': 'FAILED',\n",
       " '1704.07352': 'FAILED',\n",
       " '1807.11254': 'FAILED',\n",
       " '1810.09390': 'FAILED',\n",
       " '1502.05742': 'FAILED',\n",
       " '1702.02034': 'FAILED',\n",
       " '1704.04613': 'FAILED',\n",
       " '1711.01941': 'FAILED',\n",
       " '1004.3692': 'FAILED',\n",
       " '1804.08228': 'FAILED',\n",
       " '1811.11103': 'FAILED',\n",
       " '1804.08229': 'FAILED',\n",
       " '1610.05735': 'FAILED',\n",
       " '1804.00815': 'FAILED',\n",
       " '1808.07118': 'FAILED',\n",
       " '1507.03641': 'FAILED',\n",
       " '1708.05123': 'FAILED',\n",
       " '1105.0286': 'FAILED',\n",
       " '1602.04567': 'FAILED',\n",
       " '1812.00477': 'FAILED',\n",
       " '1810.09150': 'FAILED',\n",
       " '1110.2417': 'FAILED',\n",
       " '1603.07252': 'FAILED',\n",
       " '1606.01455': 'FAILED',\n",
       " '1610.05551': 'FAILED',\n",
       " '1303.7454': 'FAILED',\n",
       " '1708.00111': 'FAILED',\n",
       " '1801.01803': 'FAILED',\n",
       " '1505.00880': 'FAILED',\n",
       " '1802.07442': 'FAILED',\n",
       " '1801.04354': 'FAILED',\n",
       " '1809.07941': 'FAILED',\n",
       " '1812.00602': 'FAILED',\n",
       " '1710.09318': 'FAILED',\n",
       " '1802.00469': 'FAILED',\n",
       " '1005.1524': 'FAILED',\n",
       " '1808.10442': 'FAILED',\n",
       " '1705.08395': 'FAILED',\n",
       " '1705.07565': 'FAILED',\n",
       " '1707.03195': 'FAILED',\n",
       " '1204.5703': 'FAILED',\n",
       " '1406.7486': 'FAILED',\n",
       " '1710.10772': 'FAILED',\n",
       " '1801.01260': 'FAILED',\n",
       " '1708.01155': 'FAILED',\n",
       " '1701.04724': 'FAILED',\n",
       " '1809.04720': 'FAILED',\n",
       " '1804.08198': 'FAILED',\n",
       " '1811.08048': 'FAILED',\n",
       " '1703.08837': 'FAILED',\n",
       " '1712.05138': 'FAILED',\n",
       " '1810.01218': 'FAILED',\n",
       " '1811.00416': 'FAILED',\n",
       " '1711.01567': 'FAILED',\n",
       " '1807.01425': 'FAILED',\n",
       " '1807.11293': 'FAILED',\n",
       " '1811.01741': 'FAILED',\n",
       " '0712.3327': 'FAILED',\n",
       " '1707.01183': 'FAILED',\n",
       " '1803.08586': 'FAILED',\n",
       " '1708.03152': 'FAILED',\n",
       " '1808.07604': 'FAILED',\n",
       " '1412.2196': 'FAILED',\n",
       " '1001.2190': 'FAILED',\n",
       " '1603.07849': 'FAILED',\n",
       " '1804.06137': 'FAILED',\n",
       " '1806.07688': 'FAILED',\n",
       " '1404.2520': 'FAILED',\n",
       " '1709.02349': 'FAILED',\n",
       " '1812.02253': 'FAILED',\n",
       " '1508.00964': 'FAILED',\n",
       " '1111.4555': 'FAILED',\n",
       " '1607.06583': 'FAILED',\n",
       " '1408.6824': 'FAILED',\n",
       " '1704.02079': 'FAILED',\n",
       " '1711.07956': 'FAILED',\n",
       " '1811.03862': 'FAILED',\n",
       " '1809.10243': 'FAILED',\n",
       " '1801.07243': 'FAILED',\n",
       " '1708.09401': 'FAILED',\n",
       " '1510.04455': 'FAILED',\n",
       " '1811.10315': 'FAILED',\n",
       " '1310.2632': 'FAILED',\n",
       " '1810.09202': 'FAILED',\n",
       " '1405.0947': 'FAILED',\n",
       " '1607.03025': 'FAILED',\n",
       " '1901.00828': 'FAILED',\n",
       " '1801.00708': 'FAILED',\n",
       " '1703.00377': 'FAILED',\n",
       " '1612.01189': 'FAILED',\n",
       " '1402.5836': 'FAILED',\n",
       " '1803.08910': 'FAILED',\n",
       " 'cs/0008004': 'FAILED',\n",
       " '1710.04234': 'FAILED',\n",
       " '1710.00478': 'FAILED',\n",
       " 'cs/0610079': 'FAILED',\n",
       " '1807.11632': 'FAILED',\n",
       " '0810.3442': 'FAILED',\n",
       " '1806.01267': 'FAILED',\n",
       " '1805.08493': 'FAILED',\n",
       " '1506.02897': 'FAILED',\n",
       " '1704.00623': 'FAILED',\n",
       " '1704.01975': 'FAILED',\n",
       " '1512.06429': 'FAILED',\n",
       " '1812.09449': 'FAILED',\n",
       " '1705.00002': 'FAILED',\n",
       " '1602.05307': 'FAILED',\n",
       " '1502.03167': 'FAILED',\n",
       " '1702.06230': 'FAILED',\n",
       " '1812.00797': 'FAILED',\n",
       " '1508.01880': 'FAILED',\n",
       " '1506.08891': 'FAILED',\n",
       " '1708.05221': 'FAILED',\n",
       " '1703.00035': 'FAILED',\n",
       " '1312.6064': 'FAILED',\n",
       " '1511.06241': 'FAILED',\n",
       " '1606.02467': 'FAILED',\n",
       " '1410.5557': 'FAILED',\n",
       " '1901.09532': 'FAILED',\n",
       " '1812.02288': 'FAILED',\n",
       " '1811.00613': 'FAILED',\n",
       " '1802.03499': 'FAILED',\n",
       " '1804.00775': 'FAILED',\n",
       " '1701.05013': 'FAILED',\n",
       " '1705.02627': 'FAILED',\n",
       " '1809.04624': 'FAILED',\n",
       " '1810.05237': 'FAILED',\n",
       " '1811.02545': 'FAILED',\n",
       " '1804.10752': 'FAILED',\n",
       " '1809.04185': 'FAILED',\n",
       " 'cs/0605006': 'FAILED',\n",
       " '1803.02392': 'FAILED',\n",
       " '1810.10875': 'FAILED',\n",
       " '1502.00743': 'FAILED',\n",
       " '1506.03662': 'FAILED',\n",
       " '1808.03314': 'FAILED',\n",
       " '1406.6959': 'FAILED',\n",
       " '1804.06609': 'FAILED',\n",
       " '1602.01921': 'FAILED',\n",
       " '1609.09869': 'FAILED',\n",
       " '1612.07360': 'FAILED',\n",
       " '1703.04247': 'FAILED',\n",
       " '1901.02220': 'FAILED',\n",
       " '1210.0100': 'FAILED',\n",
       " '1709.02016': 'FAILED',\n",
       " '1808.07048': 'FAILED',\n",
       " '1705.07972': 'FAILED',\n",
       " '1306.1031': 'FAILED',\n",
       " '1802.06398': 'FAILED',\n",
       " '1412.7024': 'FAILED',\n",
       " '1803.03474': 'FAILED',\n",
       " '1805.10604': 'FAILED',\n",
       " '1803.10470': 'FAILED',\n",
       " '1805.10973': 'FAILED',\n",
       " '1808.01462': 'FAILED',\n",
       " '1608.02902': 'FAILED',\n",
       " '1511.01065': 'FAILED',\n",
       " '1803.09203': 'FAILED',\n",
       " '1805.00249': 'FAILED',\n",
       " '1102.2787': 'FAILED',\n",
       " '1503.07455': 'FAILED',\n",
       " '1810.09302': 'FAILED',\n",
       " '1805.00743': 'FAILED',\n",
       " '1409.7779': 'FAILED',\n",
       " '0908.0898': 'FAILED',\n",
       " '1810.10656': 'FAILED',\n",
       " '1309.4111': 'FAILED',\n",
       " '1602.00749': 'FAILED',\n",
       " '1709.05522': 'FAILED',\n",
       " '1901.01365': 'FAILED',\n",
       " '1110.4613': 'FAILED',\n",
       " '1806.05666': 'FAILED',\n",
       " '1505.01858': 'FAILED',\n",
       " '1807.00392': 'FAILED',\n",
       " '1812.10179': 'FAILED',\n",
       " '1611.01423': 'FAILED',\n",
       " '1706.02888': 'FAILED',\n",
       " '1211.7012': 'FAILED',\n",
       " '0902.2917': 'FAILED',\n",
       " '1706.10198': 'FAILED',\n",
       " '1807.10589': 'FAILED',\n",
       " '1410.1784': 'FAILED',\n",
       " '1705.02949': 'FAILED',\n",
       " '1709.00616': 'FAILED',\n",
       " '1410.5107': 'FAILED',\n",
       " '1810.07278': 'FAILED',\n",
       " '1812.00312': 'FAILED',\n",
       " '1811.12064': 'FAILED',\n",
       " '1607.01092': 'FAILED',\n",
       " '1407.6560': 'FAILED',\n",
       " '1802.05155': 'FAILED',\n",
       " '1612.03217': 'FAILED',\n",
       " '1407.5754': 'FAILED',\n",
       " '1804.10822': 'FAILED',\n",
       " '1701.09135': 'FAILED',\n",
       " '1901.04112': 'FAILED',\n",
       " '1408.1664': 'FAILED',\n",
       " '1402.0556': 'FAILED',\n",
       " '1805.12009': 'FAILED',\n",
       " '1709.03698': 'FAILED',\n",
       " '1303.3934': 'FAILED',\n",
       " '1804.06003': 'FAILED',\n",
       " '1707.07397': 'FAILED',\n",
       " '1607.07959': 'FAILED',\n",
       " '1211.2304': 'FAILED',\n",
       " '1606.02407': 'FAILED',\n",
       " '1507.02407': 'FAILED',\n",
       " '1812.02391': 'FAILED',\n",
       " '1601.07091': 'FAILED',\n",
       " '1810.12482': 'FAILED',\n",
       " '1705.00673': 'FAILED',\n",
       " '1901.03149': 'FAILED',\n",
       " '1204.2611': 'FAILED',\n",
       " '1709.08025': 'FAILED',\n",
       " '1505.00066': 'FAILED',\n",
       " '1310.2053': 'FAILED',\n",
       " '1207.3994': 'FAILED',\n",
       " '1805.04623': 'FAILED',\n",
       " '1801.09383': 'FAILED',\n",
       " '1511.07409': 'FAILED',\n",
       " '1001.3193': 'FAILED',\n",
       " '1406.2616': 'FAILED',\n",
       " '1506.06558': 'FAILED',\n",
       " '1610.09996': 'FAILED',\n",
       " '1107.3253': 'FAILED',\n",
       " '1411.7632': 'FAILED',\n",
       " '1801.05104': 'FAILED',\n",
       " '1101.5317': 'FAILED',\n",
       " '1805.09045': 'FAILED',\n",
       " '1511.07404': 'FAILED',\n",
       " '1804.05296': 'FAILED',\n",
       " '1511.00418': 'FAILED',\n",
       " '1411.1045': 'FAILED',\n",
       " '1808.05054': 'FAILED',\n",
       " '1806.04009': 'FAILED',\n",
       " '1505.03581': 'FAILED',\n",
       " '1901.02404': 'FAILED',\n",
       " '1312.7557': 'FAILED',\n",
       " '1807.04093': 'FAILED',\n",
       " '1304.2694': 'FAILED',\n",
       " '1703.02921': 'FAILED',\n",
       " 'cs/0701050': 'FAILED',\n",
       " '1707.05807': 'FAILED',\n",
       " '1811.11222': 'FAILED',\n",
       " '1007.3858': 'FAILED',\n",
       " '1301.4730': 'FAILED',\n",
       " '1802.00868': 'FAILED',\n",
       " '1802.04791': 'FAILED',\n",
       " '1803.10158': 'FAILED',\n",
       " '1807.10965': 'FAILED',\n",
       " '1901.06560': 'FAILED',\n",
       " '1709.04090': 'FAILED',\n",
       " '1506.01929': 'FAILED',\n",
       " '1804.10992': 'FAILED',\n",
       " '1408.2303': 'FAILED',\n",
       " '1809.05786': 'FAILED',\n",
       " '1810.07433': 'FAILED',\n",
       " '1806.03578': 'FAILED',\n",
       " '1811.07988': 'FAILED',\n",
       " '1408.2584': 'FAILED',\n",
       " '1106.4221': 'FAILED',\n",
       " '1811.10790': 'FAILED',\n",
       " '1808.02932': 'FAILED',\n",
       " '1702.07463': 'FAILED',\n",
       " '1306.1520': 'FAILED',\n",
       " '1501.04704': 'FAILED',\n",
       " '1812.00893': 'FAILED',\n",
       " '1609.02200': 'FAILED',\n",
       " '1605.08671': 'FAILED',\n",
       " '1804.06252': 'FAILED',\n",
       " '1604.00326': 'FAILED',\n",
       " '1811.04136': 'FAILED',\n",
       " '1611.05088': 'FAILED',\n",
       " '1711.05795': 'FAILED',\n",
       " '1602.07726': 'FAILED',\n",
       " '1611.07174': 'FAILED',\n",
       " '1811.00287': 'FAILED',\n",
       " '1212.5316': 'FAILED',\n",
       " '1407.5234': 'FAILED',\n",
       " '1401.1974': 'FAILED',\n",
       " '1505.04657': 'FAILED',\n",
       " '1509.00539': 'FAILED',\n",
       " '1710.10164': 'FAILED',\n",
       " '1608.00641': 'FAILED',\n",
       " '1708.05256': 'FAILED',\n",
       " '1206.4602': 'FAILED',\n",
       " '1510.02822': 'FAILED',\n",
       " '1612.08326': 'FAILED',\n",
       " '1709.09770': 'FAILED',\n",
       " '1703.08289': 'FAILED',\n",
       " '1606.00625': 'FAILED',\n",
       " '1811.07078': 'FAILED',\n",
       " '1804.00779': 'FAILED',\n",
       " '1201.0715': 'FAILED',\n",
       " '1506.02632': 'FAILED',\n",
       " '1807.05118': 'FAILED',\n",
       " '1712.05134': 'FAILED',\n",
       " '1204.6725': 'FAILED',\n",
       " 'cmp-lg/9406010': 'FAILED',\n",
       " '1710.10749': 'FAILED',\n",
       " '1608.07636': 'FAILED',\n",
       " '1406.4852': 'FAILED',\n",
       " '1107.4623': 'FAILED',\n",
       " '1711.04268': 'FAILED',\n",
       " '1511.02954': 'FAILED',\n",
       " '1303.1354': 'FAILED',\n",
       " '1606.09184': 'FAILED',\n",
       " '1410.7550': 'FAILED',\n",
       " '1606.04289': 'FAILED',\n",
       " '1802.06897': 'FAILED',\n",
       " '0903.0548': 'FAILED',\n",
       " '1710.06425': 'FAILED',\n",
       " '1511.04508': 'FAILED',\n",
       " 'cs/0606052': 'FAILED',\n",
       " '1512.09080': 'FAILED',\n",
       " '1802.05883': 'FAILED',\n",
       " '1609.07132': 'FAILED',\n",
       " '1610.05556': 'FAILED',\n",
       " '1310.3697': 'FAILED',\n",
       " '1611.10152': 'FAILED',\n",
       " '1401.6330': 'FAILED',\n",
       " '1009.3083': 'FAILED',\n",
       " '1312.0482': 'FAILED',\n",
       " '1710.10577': 'FAILED',\n",
       " '1803.07617': 'FAILED',\n",
       " '1803.02007': 'FAILED',\n",
       " '1805.08777': 'FAILED',\n",
       " '1807.01511': 'FAILED',\n",
       " '1812.02224': 'FAILED',\n",
       " '1705.07522': 'FAILED',\n",
       " '1806.02705': 'FAILED',\n",
       " '1002.1531': 'FAILED',\n",
       " '1810.13105': 'FAILED',\n",
       " '1704.06497': 'FAILED',\n",
       " '0710.1325': 'FAILED',\n",
       " '1806.01261': 'FAILED',\n",
       " '1706.02823': 'FAILED',\n",
       " '1901.08469': 'FAILED',\n",
       " '1105.2631': 'FAILED',\n",
       " '1709.07814': 'FAILED',\n",
       " '1710.01766': 'FAILED',\n",
       " '1408.4073': 'FAILED',\n",
       " '1406.5614': 'FAILED',\n",
       " '1708.00154': 'FAILED',\n",
       " '1807.02632': 'FAILED',\n",
       " '1503.01404': 'FAILED',\n",
       " '1612.04318': 'FAILED',\n",
       " '1602.00639': 'FAILED',\n",
       " '1803.08134': 'FAILED',\n",
       " '1310.3438': 'FAILED',\n",
       " '0805.3799': 'FAILED',\n",
       " '1502.04434': 'FAILED',\n",
       " '1704.06962': 'FAILED',\n",
       " '1611.05995': 'FAILED',\n",
       " '1804.00401': 'FAILED',\n",
       " '1603.08233': 'FAILED',\n",
       " '1706.09278': 'FAILED',\n",
       " '1610.09322': 'FAILED',\n",
       " '1707.01212': 'FAILED',\n",
       " '1807.06677': 'FAILED',\n",
       " '0712.4209': 'FAILED',\n",
       " '1409.3870': 'FAILED',\n",
       " '1304.6487': 'FAILED',\n",
       " '1204.2134': 'FAILED',\n",
       " '1105.2865': 'FAILED',\n",
       " '1805.03911': 'FAILED',\n",
       " 'cs/0308003': 'FAILED',\n",
       " '1810.00434': 'FAILED',\n",
       " '1608.08940': 'FAILED',\n",
       " '1606.04695': 'FAILED',\n",
       " '1810.11730': 'FAILED',\n",
       " '1901.06486': 'FAILED',\n",
       " '1206.4646': 'FAILED',\n",
       " '1701.07405': 'FAILED',\n",
       " '1807.10744': 'FAILED',\n",
       " '1608.06417': 'FAILED',\n",
       " '1711.10331': 'FAILED',\n",
       " '1812.08685': 'FAILED',\n",
       " '1808.01119': 'FAILED',\n",
       " '1705.08435': 'FAILED',\n",
       " '1609.09226': 'FAILED',\n",
       " '1503.01445': 'FAILED',\n",
       " '0904.1840': 'FAILED',\n",
       " '1605.04598': 'FAILED',\n",
       " '1608.08852': 'FAILED',\n",
       " '1603.08318': 'FAILED',\n",
       " '1604.06743': 'FAILED',\n",
       " '1606.06900': 'FAILED',\n",
       " '1605.02260': 'FAILED',\n",
       " '1704.03718': 'FAILED',\n",
       " '1801.07386': 'FAILED',\n",
       " '1805.07732': 'FAILED',\n",
       " ...}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52596\n",
      "52596\n"
     ]
    }
   ],
   "source": [
    "print(len(paper_ids))\n",
    "print(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:   2%|▏         | 215/9557 [00:19<19:42,  7.90file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (275 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (392 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (694 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (1005 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (1440 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:   6%|▌         | 587/9557 [00:49<08:54, 16.79file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (427 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (660 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (834 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (855 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (875 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 9557/9557 [12:27<00:00, 12.79file/s]  \n",
      "Processing files:   5%|▌         | 455/8952 [00:31<09:23, 15.08file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: unknown keyword: 'pagesize'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'width'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '597.50787pt'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'height'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '845.04684pt'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:   9%|▊         | 778/8952 [00:52<08:10, 16.66file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (382 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  10%|█         | 918/8952 [01:07<14:14,  9.40file/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (134 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  16%|█▌        | 1398/8952 [01:41<09:56, 12.67file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (101 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (260 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (605 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  16%|█▋        | 1470/8952 [01:46<08:50, 14.10file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: cannot find ExtGState resource 'a0'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  21%|██▏       | 1919/8952 [02:20<07:15, 16.16file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: unknown keyword: 'pagesize'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'width'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '614.295pt'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'height'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '794.96999pt'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  22%|██▏       | 1938/8952 [02:21<07:18, 16.00file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: unknown keyword: 'pagesize'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'width'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '597.50787pt'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'height'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '845.04675pt'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  28%|██▊       | 2546/8952 [03:35<10:01, 10.65file/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (334 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (430 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (685 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  34%|███▎      | 3017/8952 [04:10<05:31, 17.89file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (490 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  41%|████      | 3690/8952 [04:59<04:02, 21.68file/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: unknown keyword: 'pagesize'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'width'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '597.50787pt'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'height'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '845.04684pt'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  47%|████▋     | 4170/8952 [05:32<04:40, 17.02file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (499 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (555 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  48%|████▊     | 4265/8952 [05:39<05:00, 15.58file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (604 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  48%|████▊     | 4308/8952 [05:42<06:44, 11.48file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (335 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  48%|████▊     | 4310/8952 [05:43<07:09, 10.80file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (176 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  51%|█████     | 4561/8952 [06:00<04:29, 16.27file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (270 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (556 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  51%|█████▏    | 4599/8952 [06:04<08:40,  8.36file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (64 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  53%|█████▎    | 4711/8952 [06:14<06:15, 11.30file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  54%|█████▍    | 4877/8952 [06:26<04:16, 15.86file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (634 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  56%|█████▌    | 5026/8952 [06:37<04:08, 15.83file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  57%|█████▋    | 5111/8952 [06:43<03:30, 18.22file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: unknown keyword: 'pagesize'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'width'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '614.295pt'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'height'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '794.96999pt'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  58%|█████▊    | 5182/8952 [06:47<03:02, 20.68file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: unknown keyword: 'pagesize'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'width'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '415.41023pt'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'height'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '617.42479pt'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  60%|█████▉    | 5348/8952 [07:02<03:08, 19.14file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: unknown keyword: 'pagesize'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'width'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '614.295pt'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'height'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '794.96999pt'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  61%|██████    | 5419/8952 [07:07<03:23, 17.37file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: library error: FT_New_Memory_Face(Times): unknown file format\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  61%|██████▏   | 5493/8952 [07:12<04:14, 13.58file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (302 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (437 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (529 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (667 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  68%|██████▊   | 6059/8952 [07:51<02:44, 17.59file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (555 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  68%|██████▊   | 6118/8952 [07:55<02:44, 17.18file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.75'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.75'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA1.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca1.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.75'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.75'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA1.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca1.0'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  72%|███████▏  | 6422/8952 [08:19<02:10, 19.44file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: unknown keyword: 'pagesize'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'width'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '614.295pt'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'height'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '794.96999pt'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  81%|████████  | 7247/8952 [09:24<01:23, 20.54file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  82%|████████▏ | 7319/8952 [09:29<02:05, 12.98file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (1083 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  87%|████████▋ | 7760/8952 [10:03<01:20, 14.74file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (807 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  91%|█████████▏| 8182/8952 [10:38<00:35, 21.58file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (252 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  92%|█████████▏| 8259/8952 [10:46<00:56, 12.31file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  95%|█████████▌| 8509/8952 [11:03<00:28, 15.42file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  96%|█████████▌| 8603/8952 [11:12<00:22, 15.53file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: unknown keyword: 'pagesize'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'width'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '614.295pt'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'height'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '794.96999pt'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'epdf'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bbox'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'clip'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'width'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '433.62pt'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'image'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'width'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '296.30743pt'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'epdf'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bbox'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'clip'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'width'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '325.215pt'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'image'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'width'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '383.03122pt'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'image'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'width'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '224.03743pt'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'epdf'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bbox'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'clip'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'width'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '224.03743pt'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'epdf'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bbox'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'clip'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'width'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '224.03743pt'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'image'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'width'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '411.93877pt'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'btrans'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'rotate'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'etrans'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'btrans'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'rotate'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'etrans'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 8952/8952 [11:37<00:00, 12.84file/s]\n",
      "Processing files:   5%|▍         | 402/8904 [00:31<06:34, 21.56file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: format error: cmsOpenProfileFromMem failed\n",
      "\n",
      "MuPDF error: format error: cmsOpenProfileFromMem failed\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:   5%|▍         | 439/8904 [00:33<09:25, 14.97file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (81 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (368 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:   6%|▋         | 560/8904 [00:41<08:37, 16.13file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (1078 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:   8%|▊         | 681/8904 [00:50<10:16, 13.33file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (235 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:   8%|▊         | 686/8904 [00:50<08:59, 15.24file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (159 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  10%|█         | 929/8904 [01:07<11:21, 11.70file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: unknown keyword: 'pagesize'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'width'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '614.295pt'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'height'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '794.96999pt'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  15%|█▌        | 1379/8904 [01:39<10:02, 12.49file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (245 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  18%|█▊        | 1566/8904 [01:51<05:51, 20.89file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  20%|█▉        | 1777/8904 [02:06<06:10, 19.26file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  20%|██        | 1806/8904 [02:08<06:58, 16.95file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (1000 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  22%|██▏       | 1991/8904 [02:24<06:03, 19.04file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (272 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  27%|██▋       | 2372/8904 [02:50<05:19, 20.41file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (135 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  30%|██▉       | 2628/8904 [03:10<06:21, 16.47file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: unknown keyword: 'pagesize'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'width'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '614.295pt'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'height'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '794.96999pt'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  32%|███▏      | 2879/8904 [03:33<07:39, 13.13file/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (245 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (341 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (567 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (2851 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  36%|███▋      | 3249/8904 [03:58<05:26, 17.33file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: unknown keyword: 'pagesize'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'width'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '614.295pt'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'height'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '794.96999pt'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  38%|███▊      | 3397/8904 [04:08<09:06, 10.07file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (191 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  39%|███▊      | 3431/8904 [04:10<04:12, 21.65file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  40%|████      | 3599/8904 [04:24<04:56, 17.90file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (243 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  43%|████▎     | 3813/8904 [04:42<06:00, 14.11file/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (317 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  48%|████▊     | 4280/8904 [05:23<05:35, 13.80file/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: cannot find XObject resource 'arial-minus'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'arial-minus'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'arial-minus'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'arial-minus'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'arial-minus'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'arial-minus'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'arial-minus'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'arial-minus'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'arial-minus'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  51%|█████     | 4528/8904 [05:44<03:52, 18.82file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: unknown keyword: 'pagesize'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'width'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '614.295pt'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'height'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '794.96999pt'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  54%|█████▎    | 4779/8904 [06:01<04:00, 17.15file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (509 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  54%|█████▍    | 4819/8904 [06:08<07:14,  9.41file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: unknown keyword: 'pagesize'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'width'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '415.41023pt'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'height'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '617.42479pt'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  55%|█████▍    | 4860/8904 [06:10<04:43, 14.25file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (360 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (483 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  58%|█████▊    | 5161/8904 [07:03<03:47, 16.48file/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (173 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (296 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  62%|██████▏   | 5492/8904 [07:26<03:40, 15.46file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.5'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  66%|██████▌   | 5879/8904 [08:00<03:23, 14.87file/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  67%|██████▋   | 5988/8904 [08:08<03:00, 16.19file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (199 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (427 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  78%|███████▊  | 6950/8904 [09:18<03:23,  9.59file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (408 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  78%|███████▊  | 6976/8904 [09:20<02:20, 13.75file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (618 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (670 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  80%|███████▉  | 7112/8904 [09:33<01:39, 17.99file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (409 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  83%|████████▎ | 7418/8904 [09:53<01:16, 19.45file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (454 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (3740 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (3740 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (4165 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (4265 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (4265 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (4558 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (4650 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (4650 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (5058 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (5058 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (5293 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (5293 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  84%|████████▍ | 7519/8904 [10:00<01:14, 18.63file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (597 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (662 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  86%|████████▋ | 7698/8904 [10:11<01:34, 12.80file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: unknown keyword: 'pagesize'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'width'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '614.295pt'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'height'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '794.96999pt'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  92%|█████████▏| 8204/8904 [11:04<00:30, 22.93file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: format error: cmsOpenProfileFromMem failed\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 8904/8904 [11:52<00:00, 12.50file/s]\n",
      "Processing files:  13%|█▎        | 1185/8892 [01:36<22:03,  5.82file/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  16%|█▌        | 1400/8892 [01:53<08:29, 14.70file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: unknown keyword: 'pagesize'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'width'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '597.50787pt'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'height'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '845.04675pt'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  16%|█▋        | 1462/8892 [01:58<07:47, 15.89file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (576 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  17%|█▋        | 1492/8892 [02:00<07:31, 16.37file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: unknown keyword: 'pagesize'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'width'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '614.295pt'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'height'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '794.96999pt'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  25%|██▌       | 2252/8892 [02:59<07:51, 14.08file/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: cannot find ExtGState resource 'A1'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  28%|██▊       | 2482/8892 [03:23<08:03, 13.27file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (365 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (540 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  31%|███       | 2733/8892 [03:41<05:48, 17.68file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (363 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (466 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (876 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  32%|███▏      | 2803/8892 [03:45<06:15, 16.22file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (133 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  32%|███▏      | 2830/8892 [03:46<07:11, 14.05file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: unknown keyword: 'pagesize'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'width'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '614.295pt'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'height'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '794.96999pt'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  32%|███▏      | 2833/8892 [03:47<06:20, 15.92file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (493 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (657 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (703 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (799 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (908 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  37%|███▋      | 3307/8892 [04:26<11:11,  8.32file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (345 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (734 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (792 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (828 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (924 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (995 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (1125 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (1332 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (1392 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (1524 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  43%|████▎     | 3781/8892 [04:58<05:46, 14.76file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (607 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  45%|████▌     | 4023/8892 [05:17<04:44, 17.13file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (75 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (138 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  49%|████▉     | 4365/8892 [05:41<05:33, 13.57file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: cannot find XObject resource 'arial-minus'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'arial-minus'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'arial-minus'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'arial-minus'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'arial-minus'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  50%|█████     | 4449/8892 [05:47<05:10, 14.29file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (427 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (674 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (427 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (1036 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  51%|█████     | 4498/8892 [05:50<05:01, 14.59file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (533 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (803 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (890 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (979 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (1064 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  54%|█████▎    | 4764/8892 [06:39<03:29, 19.70file/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  56%|█████▌    | 5001/8892 [06:53<03:51, 16.80file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (86 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (208 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  57%|█████▋    | 5065/8892 [06:57<03:14, 19.65file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (329 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (356 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (481 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (577 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  59%|█████▉    | 5285/8892 [07:12<03:37, 16.58file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (319 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  60%|█████▉    | 5323/8892 [07:15<03:55, 15.17file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: unknown keyword: 'pagesize'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'width'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '597.50787pt'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'height'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '845.04675pt'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'bcolor'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ecolor'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  67%|██████▋   | 5937/8892 [07:59<02:51, 17.22file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca1.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca1.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca1.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca1.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca1.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca1.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca1.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca1.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca1.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca1.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca1.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca1.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca1.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca1.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca1.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca1.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca1.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca1.0'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  76%|███████▌  | 6756/8892 [09:07<03:49,  9.29file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.4'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.4'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.4'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.4'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.4'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.4'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.4'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.4'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  80%|███████▉  | 7111/8892 [09:54<01:52, 15.90file/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (466 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (905 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  81%|████████  | 7162/8892 [09:59<02:35, 11.13file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: format error: invalid code in 2d faxd\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '9411.5827.93'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'h7.457'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '28.297252.677'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '785.797100.96'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '214..59'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '18.001785.076'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'h74.859'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '2.67.507'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '6252.94163110.73'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '2.67.50741631.43044.304'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '693.5430443.46'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '4124.348.539'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '4l'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '44.24149.687.73'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '2.674149.687.73'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '47.4149.68'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '10079c46'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '808.9.811'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '2.677m'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'c7'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '549.98l'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '5493.97223.25c'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '825.609253.195'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '39.6879451.617'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'c3547.1'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '4191.19238.773'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '54.0l309'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '28.297250243.47617297257.5239'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '9411.5h'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'c416'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '78.25484.'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'l9.988549.1'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '429.98l'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '621.1l48'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '429.98l42.578'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'l32.49213.70148'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '596.9.21'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '596.90290.062938.25480l'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '246.10290.5.512'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '41.2810290.5.51420.109'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '.l2.7426'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '804.7.6875'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '4194297.7.6875'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '100.c75'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '865.l2.742670.5'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '78.25c54'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '6..507'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '6..507'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '78.25480619.9'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '7853.9290619.9'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '865.c9290619.'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '421862938.5.54'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '225.92938.5.5007'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '38.5.5'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '903.92942.229328'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '99.932942.22909'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '865.l2.942.22907853.92942.457'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '78.254827.687'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '78.25c54827.687'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '6..507'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '6..507'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'ch'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '805.770.9188801.29451..918884.649451..967'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '646.9451..9187796.38.770.9187796.38.71'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '94.6187796.38213.70'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '64798.439918884.6'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '798.4399c9188801.298.4399189.9'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '429.27.2'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '796.38.67.5087'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '636.908884.6'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '636.9c9188801.28'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '636.9089.27.2'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '49.27.2'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'c45'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'l4c'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '628l'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '621.1l48'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '628l42.578'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'l58293'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '596.90539.6477'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '596.9.2137'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '596.905658.5393'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '630.7.2137'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '596.90314.8837'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '9.14938.254l'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '101.3l82'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '4306477.7.687l882'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '48.867.7.68752'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '100.c752'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '865.l2.2'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '4805407853.92531.8.'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '78.25c543720.664'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '6..507'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'c3409.94.9655301'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '6..507'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'c3537054'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'l3'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'l3'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '865.c925'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '613.19238.656'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  82%|████████▏ | 7267/8892 [10:07<02:06, 12.86file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (203 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  87%|████████▋ | 7778/8892 [10:46<06:42,  2.77file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: cannot find XObject resource 'arial-minus'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'arial-minus'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'arial-minus'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'arial-minus'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'arial-minus'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'arial-minus'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'arial-minus'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'arial-minus'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'arial-minus'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'arial-minus'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'arial-minus'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'arial-minus'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  88%|████████▊ | 7856/8892 [10:53<01:59,  8.66file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (205 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  90%|█████████ | 8034/8892 [11:10<01:27,  9.86file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (842 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  92%|█████████▏| 8160/8892 [11:20<00:47, 15.36file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (1845 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  92%|█████████▏| 8172/8892 [11:21<00:42, 16.91file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: syntax error in content stream\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '@pgfcolorspaces'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'put'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '@resources'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'put'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '@pgfcolorspaces'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'put'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '@resources'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'put'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '@resources'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'put'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '@resources'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'put'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '@resources'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  96%|█████████▌| 8523/8892 [11:49<00:27, 13.48file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: unknown keyword: 'pagesize'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'width'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '614.295pt'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'height'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '794.96999pt'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 8892/8892 [12:14<00:00, 12.11file/s]\n",
      "Processing files:  11%|█         | 945/8824 [01:18<12:46, 10.28file/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: unknown keyword: 'pagesize'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'width'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '614.295pt'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'height'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '794.96999pt'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  13%|█▎        | 1119/8824 [01:31<09:56, 12.91file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (2923 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (6643 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (9671 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  13%|█▎        | 1139/8824 [01:33<08:54, 14.37file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: cannot find XObject resource 'arial-minus'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'arial-minus'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'arial-minus'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'arial-minus'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'arial-minus'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'arial-minus'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'arial-minus'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'arial-minus'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'arial-minus'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  17%|█▋        | 1542/8824 [02:02<07:30, 16.18file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: syntax error in content stream\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '@pgfcolorspaces'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'put'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '@resources'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'put'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '@pgfcolorspaces'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'pagesize'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'width'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '614.295pt'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'height'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '794.96999pt'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'put'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '@resources'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'put'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '@resources'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'put'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '@resources'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'put'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '@resources'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'put'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '@resources'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'put'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '@resources'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'put'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '@resources'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'put'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '@resources'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'put'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '@resources'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'put'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '@resources'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'put'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '@resources'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'put'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '@resources'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'put'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '@resources'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'put'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '@resources'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'put'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '@resources'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'put'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '@resources'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  18%|█▊        | 1610/8824 [02:08<13:53,  8.65file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: library error: FT_New_Memory_Face(Times): unknown file format\n",
      "\n",
      "MuPDF error: library error: FT_New_Memory_Face(Times,Bold): unknown file format\n",
      "\n",
      "MuPDF error: library error: FT_New_Memory_Face(Times,Italic): unknown file format\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  26%|██▌       | 2259/8824 [02:58<07:09, 15.29file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (425 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  29%|██▉       | 2572/8824 [03:22<06:09, 16.92file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: unknown keyword: 'pagesize'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'width'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '597.50787pt'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'height'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '845.04675pt'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  30%|██▉       | 2606/8824 [03:25<09:07, 11.35file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: unknown keyword: 'pagesize'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'width'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '614.295pt'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'height'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '794.96999pt'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  30%|███       | 2677/8824 [03:30<09:22, 10.93file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (203 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  34%|███▍      | 3040/8824 [03:54<05:30, 17.51file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (418 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (716 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (1036 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (1107 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (1185 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  43%|████▎     | 3836/8824 [05:03<04:22, 18.98file/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (402 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  46%|████▌     | 4027/8824 [05:16<06:41, 11.94file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (717 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  47%|████▋     | 4120/8824 [05:21<06:06, 12.82file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (635 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  48%|████▊     | 4217/8824 [05:27<04:41, 16.38file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.3'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.3'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.3'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.3'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.3'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.3'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.3'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.3'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.3'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.3'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.3'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.3'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.3'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.3'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.3'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.3'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.3'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.3'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.3'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.3'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.3'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.3'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.3'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.3'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  50%|████▉     | 4409/8824 [05:41<04:52, 15.09file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: unknown keyword: 'pagesize'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'width'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '597.50787pt'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'height'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '845.04684pt'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  51%|█████     | 4473/8824 [05:46<04:31, 16.01file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  51%|█████     | 4498/8824 [05:49<17:30,  4.12file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: unknown keyword: 'pagesize'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'width'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '614.295pt'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'height'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '794.96999pt'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  51%|█████▏    | 4525/8824 [05:51<05:44, 12.46file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  53%|█████▎    | 4712/8824 [06:08<03:20, 20.49file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (1035 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (1099 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (1193 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (5794 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  54%|█████▍    | 4761/8824 [06:12<03:00, 22.45file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (821 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (1539 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (1603 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (1666 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (1937 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (2037 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (2147 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  55%|█████▍    | 4813/8824 [06:16<03:41, 18.12file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (285 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  55%|█████▌    | 4872/8824 [06:20<04:21, 15.09file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (453 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (503 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (713 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (734 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (754 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  56%|█████▌    | 4938/8824 [06:24<02:30, 25.88file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (379 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (4509 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  58%|█████▊    | 5120/8824 [06:39<03:36, 17.11file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.0'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  61%|██████    | 5387/8824 [07:03<04:36, 12.44file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (56 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (207 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (342 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (406 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (483 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (513 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (596 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (723 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (872 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  64%|██████▍   | 5642/8824 [07:22<04:39, 11.37file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  71%|███████   | 6264/8824 [08:10<03:21, 12.70file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: format error: No default Layer config\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  72%|███████▏  | 6336/8824 [08:16<03:05, 13.43file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (682 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  76%|███████▌  | 6668/8824 [08:37<02:04, 17.34file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  76%|███████▋  | 6734/8824 [08:42<02:00, 17.39file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (292 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  78%|███████▊  | 6908/8824 [08:55<01:47, 17.84file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: format error: No default Layer config\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  83%|████████▎ | 7282/8824 [09:23<01:12, 21.25file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: unknown keyword: 'pagesize'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'width'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '614.295pt'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'height'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '794.96999pt'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  84%|████████▍ | 7434/8824 [09:33<02:37,  8.85file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (1676 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (1750 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (2484 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (4625 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (6933 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (9636 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (14592 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  86%|████████▌ | 7607/8824 [09:45<00:59, 20.51file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (418 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  87%|████████▋ | 7705/8824 [09:52<01:11, 15.65file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: unknown keyword: 'pagesize'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'width'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '614.295pt'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'height'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '794.96999pt'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  88%|████████▊ | 7772/8824 [09:56<00:49, 21.11file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: unknown keyword: 'pagesize'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'width'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '614.295pt'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'height'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '794.96999pt'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  89%|████████▉ | 7847/8824 [10:01<01:19, 12.30file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: unknown keyword: 'pagesize'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'width'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '597.50787pt'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'height'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '845.04684pt'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  90%|█████████ | 7956/8824 [10:08<00:42, 20.56file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@CA0.5'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.5'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  90%|█████████ | 7965/8824 [10:09<01:04, 13.25file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  98%|█████████▊| 8634/8824 [10:59<00:14, 13.37file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (307 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  99%|█████████▉| 8732/8824 [11:05<00:05, 17.67file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: cannot find XObject resource 'R13'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R13'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R13'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R13'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R13'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R13'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R13'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R13'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R13'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R13'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R13'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R13'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R13'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R13'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R13'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R13'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R18'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R18'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R18'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R18'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R18'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R18'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R18'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R18'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R18'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R18'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R18'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R18'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R66'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R80'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R80'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R80'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R80'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R87'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R87'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R87'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R87'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R13'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R13'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R13'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R13'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R13'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R13'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R13'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R13'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R13'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R13'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R13'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R13'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R13'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R13'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R13'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R13'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R18'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R18'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R18'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R18'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R18'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R18'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R18'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R18'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R18'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R18'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R18'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R18'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R66'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R80'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R80'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R80'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R80'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R87'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R87'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R87'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R87'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R17'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R23'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R28'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R33'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R38'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R43'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R48'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R53'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R58'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R63'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R68'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R73'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R78'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R83'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R88'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R93'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R98'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R103'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R108'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R113'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R118'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R123'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R128'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R133'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R138'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R143'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R148'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R153'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R201'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R215'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R215'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R215'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R215'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R222'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R222'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R222'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'R222'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 8824/8824 [11:11<00:00, 13.15file/s]\n",
      "Processing files:   9%|▉         | 629/7143 [00:48<06:03, 17.92file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.8'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.8'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.8'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.8'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.8'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.8'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.8'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.8'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.8'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.8'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.8'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'pgf@ca0.8'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  16%|█▋        | 1167/7143 [01:28<09:58,  9.99file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: cannot find ExtGState resource 'A1'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A1'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A1'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A1'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A1'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A1'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A1'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A1'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A1'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A1'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A1'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A1'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A1'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A1'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A1'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A1'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A1'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A1'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'A2'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  17%|█▋        | 1225/7143 [01:32<07:23, 13.34file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (192 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  22%|██▏       | 1575/7143 [02:09<06:30, 14.26file/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  23%|██▎       | 1651/7143 [02:15<05:39, 16.19file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (93 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (325 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  23%|██▎       | 1663/7143 [02:16<07:36, 12.02file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: unknown keyword: 'pagesize'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'width'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '614.295pt'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'height'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '794.96999pt'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  26%|██▌       | 1845/7143 [02:31<04:15, 20.77file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: unknown keyword: 'pagesize'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'width'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '614.295pt'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'height'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '794.96999pt'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  28%|██▊       | 2019/7143 [02:43<07:56, 10.74file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  33%|███▎      | 2364/7143 [03:11<06:58, 11.42file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: syntax error in content stream\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '@pgfcolorspaces'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'put'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '@resources'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'put'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '@pgfcolorspaces'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'pagesize'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'width'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '614.295pt'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'height'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '794.96999pt'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'put'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '@resources'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'put'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '@resources'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'put'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '@resources'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'put'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '@resources'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'put'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '@resources'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'put'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '@resources'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  35%|███▌      | 2504/7143 [03:22<13:23,  5.78file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (456 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  44%|████▍     | 3138/7143 [04:10<03:01, 22.09file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (1015 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (1159 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  45%|████▌     | 3221/7143 [04:16<04:44, 13.81file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: unknown keyword: 'pagesize'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'width'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '614.295pt'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'height'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '794.96999pt'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  50%|████▉     | 3556/7143 [04:44<03:13, 18.51file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (264 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (634 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (726 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  50%|████▉     | 3564/7143 [04:44<04:45, 12.52file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (175 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  54%|█████▎    | 3829/7143 [05:04<06:14,  8.84file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (65 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  56%|█████▌    | 3993/7143 [05:18<04:39, 11.26file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (3210 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  67%|██████▋   | 4807/7143 [06:17<02:36, 14.91file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: cannot find XObject resource 'arial-minus'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'arial-minus'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'arial-minus'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'arial-minus'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'arial-minus'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'arial-minus'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'arial-minus'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'arial-minus'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  69%|██████▉   | 4947/7143 [06:28<01:49, 20.11file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  71%|███████▏  | 5096/7143 [06:38<01:43, 19.83file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'Black'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  73%|███████▎  | 5181/7143 [06:44<02:51, 11.45file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (161 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  74%|███████▍  | 5292/7143 [06:54<01:35, 19.41file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (437 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  79%|███████▉  | 5674/7143 [07:19<01:13, 19.96file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: unknown keyword: 'pagesize'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'width'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '597.50787pt'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'height'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: '845.04684pt'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  86%|████████▋ | 6167/7143 [07:55<00:59, 16.44file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (65 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (194 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  88%|████████▊ | 6270/7143 [08:02<01:03, 13.75file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (328 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (372 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (575 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (596 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  91%|█████████ | 6470/7143 [08:15<00:49, 13.49file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (334 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (712 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (744 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  92%|█████████▏| 6538/7143 [08:20<00:53, 11.28file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'cmyk'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  96%|█████████▌| 6829/7143 [08:40<00:21, 14.50file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  97%|█████████▋| 6917/7143 [08:46<00:12, 17.92file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: cannot find XObject resource 'arial-minus'\n",
      "\n",
      "MuPDF error: syntax error: cannot find XObject resource 'arial-minus'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 7143/7143 [09:02<00:00, 13.18file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successes: 50004. Failures: 2268. Node IDs: 52596.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results, successes, failures = process_pdfs(pdf_dirs, results)\n",
    "\n",
    "print(f'Successes: {successes}. Failures: {len(failures)}. Node IDs: {len(paper_ids)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Successes: 50004. Failures: 2268. Node IDs: 52596.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1809.01604': 'Merging datasets is a key operation for data analytics. A frequent requirement for merging is joining across columns that have different surface forms for the same entity. For instance, the name of a person might be represented as Douglas Adams, Douglas Noel Adams, D. Adams or Adams, Douglas. Similarly, ontology alignment can require recognizing distinct surface forms of the same entity, especially when ontologies are independently developed. This problem occurs for many entity types such as people’s names, company names, addresses, product descriptions, conference venues, or even people’s faces. Data management systems have however, largely focussed solely on equi-joins, where string or numeric equality determines which rows should be joined, because such joins are efﬁcient. We propose a different approach to joining different surface representations of the same entity, inspired by recent advances in deep learning. Our approach depends on (a) mapping surface forms into sets of vectors such that forms for the same entity are closest in vector space, (b) indexing these vectors to ﬁnd the forms that can be potentially joined together. The approach is general, in the sense that once a model has been built for a speciﬁc semantic type (e.g. people, companies or faces) it can be used for joining any two datasets which share that semantic type. It is also efﬁcient because indexing uses space partitioning algorithms (such as approximate nearest neighbor) to ﬁnd surface forms that are potentially joinable, thus eliminating large parts of the vector space from consideration. Further, nearest neighbor algorithms have been applied to billions of vectors (Johnson, Douze, and J´egou 2017), so the approach is practical for most datasets. To test the feasibility of these ideas, we used Wikidata as ground truth to build models for datasets with 1.1M people’s names (about 200K identities) and 130K company names (70K identities). The problem of mapping vectors for the same entity closer in vector space than vectors for other entities is known in the literature as deep metric learning. Deep metric learning is known to be a difﬁcult problem as studied in the space of face recognition and person-re-identiﬁcation (Schroff, Kalenichenko, and Philbin 2015), (Yang, Zhou, and Wang 2018), (Chen et al. 2018). As a result, there is a signiﬁcant amount of research on two aspects of training these networks: (a) how to choose samples for efﬁcient learning, and (b) what constitutes a good loss function. In building models for entity names, we had to adapt these techniques for triplet selection and loss functions because matching entity names has different characteristics, as we describe below. As in face recognition, our system for metric learning is built by training a so-called triplet based ‘siamese triplet’ network to learn to produce a small distance estimate for two surface forms for the same entity (between an arbitrarily chosen anchor and positive), and a large distance estimate for surface forms of different entities',\n",
       " 'cmp-lg/9406023': 'This document contains the second version of the Spanish tagset for the CRATER project. It has been extensively changed with respect to the ﬁrst draft of the tagset, dated January 281. The major motivations for changes are pointed out in section 2. For a more comprehensive exposition of the changes, refer to [S´anchez 1994]. Section 3 contains the tagset with an English description of each tag. 2 Design motivations In its origins, this tagset was inspired by the English tagset used in the ET10/63 project, which, in turn, was derived from the one used by CLAWS [Garside et al. 1987]. The kind of information tackled by the English tagset was conveniently adapted to Spanish. Major morphosyntactic categories were contemplated, but also some syntactic and semantic distinctions beyond the level of morphosyntax were taken into account. For instance, semantic classes for temporal, measure or locative nouns have their own tags. The naming conventions of the English tagset, though, were modiﬁed as to produce mnemonic tags, as far as possible. The ﬁrst version contained a set of errors and inconsistencies that needed a correction. Other decisions had to be reviewed on the light of two major issues: the recommendations of both TEI and EAGLES on text annotation and the idea that the tagset was to be used by an automatic tagging system. The objectives of CRATER include the development of a public domain POS tagger for Spanish and the production of a (sample) tagged corpus of over one million words. This goal will contribute to the creation of valuable corpus and linguistic resources for Spanish. One of the major concerns of the computational linguistics community in the last years has been the reusability of resources of varied types. Consequently, in order to deﬁne the characteristics for future resources to be reusable, a set of initiatives and working groups has been set up to produce guidelines and recommendations aiming at the standardization of the type and form of the information to be included in these linguistic resources. 1I am indebted to Flora Ram´ırez Bustamante, who has taken active part in the reﬁnement of the ﬁrst draft of this document. 1  One of these groups is the Text Encoding Initiative. TEI produced a ﬁrst draft of its Guidelines [TEI P1 1990] in 1990 and, since then, has delivered a set of draft documents related to the annotation of texts [Simons 1991], [Langendoen & Fahmy 1991], [TEI AI1W2 1991], that will conform the relevant chapters of the second version of its guidelines, known as TEI P2. Other working groups, like EAGLES (Expert Advisory Groups on Language Engineering Standards), are also working on its own recommendations for morphosyntactic annotation. For the moment, only a draft document for sections 4.6 and 4.7 has been produced [Leech & Wilson 1994]. Therefore, if linguistic resources for CRATER are to be considered reusable, it has to be guaranteed that they follow these recommendations —at least concerning the type of information to be included in the annotations, since the syntax can be produced with the appropriate mappings. This is particularly',\n",
       " '1307.1630': 'Low cost mobile devices have been recognized as crucial components of various wireless networks with important applications. A typical example is wireless sensor networks which have been developed for a variety of applications, including surveillance, environmental monitoring and health care. Such low cost devices are typically equipped with ﬁxed energy supplies, such as batteries with limited operation life. Replacing batteries for such devices is either impossible or expensive, particularly in the case in which sensors are deployed in hostile environments. Therefore energy harvesting, a technique to collect energy from the surrounding environment, has recently received considerable attention as a sustainable solution to overcome the bottleneck of energy constrained wireless networks [1]. Conventional energy harvesting techniques rely on external energy sources that are not part of communication networks, such as those based on solar power, wind energy, etc. [1], [2]. Recently a new concept of energy harvesting has been proposed which involves collecting energy from ambient radio frequency signals [3], [4], so that wireless signals can be used as a means for the delivery of information and power simultaneously. In addition, such an approach can also reduce the cost of communication networks, since peripheral equipment to The material in this papers was presented in part at the 8-th International Conference on Communications and Networking in China, Guilin, China, August, 2013. The authors are with Department of Electrical Engineering, Princeton University, Princeton, NJ 08544, USA. Zhiguo Ding is also with School of Electrical, Electronic, and Computer Engineering Newcastle University, NE1 7RU, UK. take advantage of external energy sources can be avoided. The concept of simultaneous power and information delivery was ﬁrst proposed in [3], where the fundamental tradeoff between the energy and information rate is characterized for pointto-point communication scenarios. The extension of such a concept to frequency selective channels is considered in [4]. In [5] the authors study energy harvesting for communication scenarios with co-channel interference, where such interference is identiﬁed as a potential energy source. The simultaneous transfer of power and information is also studied in multipleinput multiple-output systems in [6], and its extension to the scenario with imperfect channel information at the transmitter was considered in [7]. To ensure such a new concept of energy harvesting implemented in practical systems, it is important to address the difﬁculty that practical circuits cannot realize energy harvesting and data detection from wireless signals at the same time. This challenge has motivated a few recent works deviating from the ideal assumption that a receiver can detect signals and harvest energy simultaneously. In [8], the authors introduced a general receiver architecture, in which the circuits for energy harvesting and signal detection are operated in a time sharing or power splitting manner. This approach is naturally applied to a cooperative network with one sourcedestination pair in [9], where amplify-and-forward (AF) is considered and exact expressions for outage probability and throughput are developed. In this paper, a general wireless cooperative network is considered, in which multiple pairs of sources and destinations',\n",
       " 'cs/0511028': 'Recent rapid advances in multiple-input multiple-output (MIMO) communication theory and growing cognizance of the tremendous performance gains achieved by MIMO techniques [1]–[9] have spurred efforts to integrate this technology into future wireless systems such as wireless local area networks (WLANs) and 4G cellular systems. One of the approaches to exploiting diversity capability of MIMO channels is the use of orthogonal space–time block codes (OSTBCs), which have drawn considerable attention because they attain full diversity with scalar maximumlikelihood (ML) decoding [7]–[9].1 1However, OSTBCs with arbitrary complex constellation cannot provide the full diversity and full transmission rate simultaneously for more than two transmit antennas [8, Theorem 5.4.2] (see also [10]–[13]). A new class of quasi-orthogonal codes has been proposed in [14]–[16] with the tradeoff between the decoding complexity, transmission rate and/or diversity. July 5, 2006 DRAFT  2 REVISED FOR PUBLICATION IN THE IEEE TRANSACTIONS ON INFORMATION THEORY In general, the potential beneﬁts of multiple-antenna systems may be limited by rank deﬁciency of the channel due to double scattering or the keyhole effect, for example, as well as spatial fading correlation due, for instance, to insufﬁcient spacing between antenna elements [17]–[30]. Some mechanism rendering a MIMO channel rank deﬁcient cannot be explained by the archetypal model based on single-scattering processes [26], [27]. To address this issue, a double-scattering MIMO model has been proposed recently in [24] wherein the channel matrix is characterized by a product of two statistically independent complex Gaussian matrices, in contrast to the common single complex Gaussian matrix characterization for wireless MIMO channels.2 This doublescattering model can capture both rank-deﬁcient and spatial correlation effects of MIMO channels and encompass a variety of propagation environments, bridging the gap between an independent and identically distributed (i.i.d.) Rayleigh case and a degenerate one-rank channel known as a keyhole or pinhole channel. There are other recent attempts to modeling MIMO channels for more realistic scattering environments (e.g., double or multibounce diffuse scattering) beyond single scattering [31]–[34]. The effects of rank deﬁciency and spatial correlation on the capacity of MIMO channels are relatively well understood (see, e.g., [17]–[30]). From a capacity point of view, it has been known that at high signal-to-noise ratio (SNR), the spatial fading correlation reduces the diversity advantage—a parallel shift of the capacity curve over SNR in decibels (dB)—offered by multiple antennas, whereas the rank deﬁciency decreases the spatial multiplexing beneﬁt—a slope of the capacity curve over SNR—of multiple-antenna channels [21]. Previously, the performance of space–time coding in the presence of spatial fading correlation has been extensively studied for the most popular Rayleigh, Rician, and Nakagami-m fading [35]–[40]. Also, the effect of rank deﬁciency has been investigated in [41]–[44] for a special case of the keyhole channel. The objective of this paper is to assess the effects of double scattering on the diversity performance of MIMO systmes in a communication link with nT transmit antennas, nR receive',\n",
       " '1507.05122': 'FAILED',\n",
       " '1709.01305': 'S INCE the early 1990s how to retrieve unlabeled images by textual queries has been a grand challenge in multimedia retrieval, and remains hot to this day [1]–[4]. In order to understand and exploit the interplay between visual content, textual query and user behaviors, web image retrieval demands multi-modal approaches [5]–[7] and thus makes it right at the heart of the multimedia ﬁeld. As image and query are two distinct modalities, a cross-media similarity metric that effectively reﬂects image-query relevance is essential. The key to cross-media similarity computation is to represent both images and queries in a common space [9]–[14]. While the idea is simple, constructing a proper common space Manuscript received September 28, 2016; revised May 1, 2017 and November 25, 2017; accepted January 2, 2018. This work was supported by the National Science Foundation of China (No. 61672523) and the Key Scientiﬁc Research Base for Digital Conservation of Cave Temples (Zhejiang University), State Administration for Cultural Heritage. The associate editor coordinating the review of this manuscript and approving it for publication was Prof. Benoit HUET (Corresponding author: Xirong Li). J. Dong and D. Xu are with the College of Computer Science and Technology, Zhejiang University, Hangzhou 310027, China (e-mail: danieljf24@zju.edu.cn; xdq@zju.edu.cn). X. Li is with the Key Lab of Data Engineering and Knowledge Engineering, School of Information, Renmin University of China, Beijing 100872, China (e-mail: xirong.li@gmail.com). w olf    200  g re y  w o lf    1 3 s n o w  w o lf   1 0 g ra y  w o lf   9 w o lf in  th e  w ild   9 th e  g ra y  w o lf    4 s n o w  fo r w a llp a p e r   3 click count q u o te  a n d  s a y in g     3 3 8 life quote 144 q u o te   1 4 0 q u o te  a b o u t life   1 0 7 S a yin g  a n d  q u o te    6 6 life  q u o te  a n d  sa yin g     6 5 fu n n y q u o te    4 0 im age query        Fig. 1. Image, query and their user-click count, sampled from query log data of a web image search engine [8]. is non-trivial. A desirable property is to let each of the many queries stay closer to images relevant w.r.t. the queries than irrelevant images. In [12] for instance, Yu et al. employ deep neural network to embed images and queries into a joint latent space using large scale click-through logs. Deng et al. [13] ﬁrstly perform dictionary learning to learn sparse and discriminative codes for images and queries respectively, and then map them into a common label space by linear transformation. Depending on the choice of the common space, we',\n",
       " '1811.01721': 'Reducing the computational complexity of neural networks (NNs) while maintaining accuracy encompasses a long line of research in NN design, training and inference. Different computer arithmetic primitives have been considered, including ﬁxed-point [21], uniform quantization via 8 bit integer [15], ternary [20] and binary/low-bit representations [29, 3, 1]. Some implementations are efﬁciently implemented on CPU/GPU ISAs [35, 33], while others demand custom hardware [10]. Instead of developing quantization techniques increasingly divorced from the original implementation, we seek to improve ﬂoating point itself, and let word size reduction yield efﬁciency for us. It is historically known to be up to 10× less energy efﬁcient in hardware implementations than integer math [14]. Typical implementation is encumbered with IEEE 754 standard compliance [37], demanding speciﬁc forms such as fused multiply-add (FMA) that we will show as being inefﬁcient and imprecise. Memory movement (SRAM/DRAM/ﬂip-ﬂops) dominates power consumption; word bit length reduction thus provides obvious advantages beyond just reducing adder and multiplier area. We explore encodings to better capture dynamic range with acceptable precision in smaller word sizes, and more efﬁcient summation and multiplication (Sections 3-5), for a reduction in chip power and area. Signiﬁcant inspiration for our work is found in logarithmic number systems (LNS) [2] and the work of Miyashita et al. [24] that ﬁnds logarithmic quantizers better suited to data distributions in NNs, and alternative visions of ﬂoating point from Gustafson [11, 12] and Kulisch [19]. We sidestep prior LNS design issues with numerical approximation and repurpose ideas from Gustafson and Preprint. Work in progress.  Table 1: Dynamic range and signiﬁcand fractional precision of math types considered Word Encoding Range in decibels Fraction bits type 20 log10(fmax/fmin) bits (max) 8 symmetric integer [−27 + 1, 27 −1] 42.1 — 8 (8, 0) posit or (8, 0, α, β, γ) log 72.2 5 8 (4, 3) ﬂoat (w/o denormals) 83.7 3 16 symmetric integer [−215 + 1, 215 −1] 90.3 — 8 (4, 3) ﬂoat (w/ denormals) 101.8 3 8 (8, 1) posit or (8, 1, α, β, γ) log 144.5 4 16 (5, 10) ﬂoat16 (w/o denormals) 180.6 10 16 (5, 10) ﬂoat16 (w/ denormals) 240.8 10 12 (12, 1) posit or (12, 1, α, β, γ) log 240.8 8 8 (8, 2) posit or (8, 2, α, β, γ) log 289.0 3 16 (16, 1) posit or (16, 1, α, β, γ) log 337.2 12 Kulisch, producing a general-purpose arithmetic that is effective on CNNs [13] without quantization tinkering or re-training (Section 7), and can be as efﬁcient as integer math in hardware (Section 8). 2 Floating point variants for NNs There are few studies on NNs for ﬂoating point variants beyond those provided for in CPU/GPU ISAs. [4] shows a kind of 8 bit ﬂoating point for communicating gradients, but this is not used for general computation. Flexpoint [17] and the Brainwave NPU',\n",
       " '1307.6458': 'The ﬁrst cryptographic scheme using generalized Reed-Solomon codes was proposed in 1986 by Niederreiter [Nie86] but it was shown to be insecure in [SS92]. The attack recovers the underlying Reed-Solomon code allowing the decoding of any encrypted data. However during the past years ∗GRACE Project, INRIA Saclay & LIX, CNRS UMR 7161 - ´Ecole Polytechnique, 91120 Palaiseau Cedex, France. alain.couvreur@lix.polytechnique.fr †XLIM, CNRS UMR 7252 - Universit´e de Limoges, 123 avenue Albert Thomas, 87060 Limoges Cedex, France. philippe.gaborit@unilim.fr ‡Faculty of Natural Sciences and Mathematics, Department of Mathematics, Universidad del Rosario, Bogot´a, Colombia. gauthier.valerie@ursario.edu.co §Normandie Univ, France; UR, LITIS, F-76821 Mont-Saint-Aignan, France. ayoub.otmani@univ-rouen.fr ¶SECRET Project - INRIA Rocquencourt, 78153 Le Chesnay Cedex, France. jean-pierre.tillich@inria.fr 1  there were several attempts to repair this scheme. In the present article, we focus on three modiﬁed McEliece schemes using generalized Reed Solomon codes. The ﬁrst one was proposed by Wieschebrink [Wie06] and consists in choosing a generator matrix of a generalized Reed-Solomon code and adding to it a few random columns. It was advocated that this modiﬁcation avoids the SidelnikovShestakov attack [SS92]. More recently, some of the nice algebraic properties of the Reed-Solomon codes were also used to devise the ﬁrst public-key homomorphic encryption scheme [BL11] based on coding theory. The third one is another variant of the McEliece cryptosystem [McE78] proposed in [BBC+11] which uses this time a generator matrix of a generalized Reed-Solomon but hides its structure diﬀerently than in the McEliece cryptosystem: instead of multiplying by a permutation matrix, the generator matrix is multiplied by a matrix whose inverse is of the form Π+R where Π is a sparse matrix with row density m ⩾1 and R is a matrix of rank z ⩾1. The key point of this modiﬁcation is that the public code obtained with this method is not anymore a generalized ReedSolomon code and this seems to thwart the Sidelnikov and Shestakov attack completely. In the present article, we propose polynomial time attacks of these three schemes. Notice that for Baldi et al.’s scheme [BBC+11], our attack only considers the case when the matrix Π is a permutation matrix i.e. the case m = 1, and R is of rank z = 1. We focus on these speciﬁc cases because all the parameters proposed in [BBC+11] were of this form. A good reason for these choices (m = 1 and z = 1) stems from the fact that the resulting schemes have the smallest public key sizes and the smallest deciphering complexity among this class of encryption schemes. Contrarily to the Niederreiter’s proposal [Nie86] based on generalized Reed-Solomon codes, the original McEliece cryptosystem [McE78] which uses Goppa codes, has withstood many key-recovery attacks and after more than thirty years now, it still belongs to the very few unbroken public-key cryptosystems. No signiﬁcant breakthrough has been',\n",
       " '1807.07247': 'Chest X-ray is one of the most common radiology exams used for screening of lung diseases. X-ray is econonimical and can be performed with minimal procedural steps. Moroever, each scan can detect multiple suspected pathologies such as tuberculosis and pneumonia, etc. Computer-Aided Detection (CADe) and Diagnosis (CADx) has been a major research focus in medicine. CAD for chest X-ray could potentially become a cost-eﬀective assistive tool for radiologists. Recent advances in artiﬁcial intelligence and machine learning have demonstrated that deep learning technologies have superiority in solving various X-ray analysis tasks involving image classiﬁcation [1,2,3], NLP based analysis [4] and localisation [5]. The data-driven nature of deep learning beneﬁts from the increasing volume of publicly accessible medical imaging dataset, such as CT, MRI, X-ray [6,1]. Wang et al. [1] introduced a large scale collection of chest arXiv:1807.07247v3  [cs.CV]  24 Jul 2018  2 X-ray which contains the absence or presence of 14 lung diseases. Several methods explored the use of ResNet [1] and DenseNet [3,2], that were pre-trained on ImageNet [7], to classify 14 chest related diseases. However, there are a few challenges which may obstruct the improvement gained from the usage of direct transfer learning from general image classiﬁcation tasks to detecting lung diseases in chest x-ray and, more generally, in wider medical imaging domain. First unlike categories in ImageNet where many of them are from diﬀerent branches of WordNet, the high visual similarity among a wealth of pathologies in lung X-rays can be diﬃcult to interpret and distinguish. Second, presence of patterns from various potential pathologies in one medical scan mandates the model learn a huge number of possible label sets for prediction, which is exponential to the size of label space (2C for C labels). Third, issues like the class-imbalance among disease labels and overwhelming normal samples, cannot be fully taken into consideration by just using sigmoid with binary cross-entropy loss [1,3] as in done in standard transfer learning based methodologies. These challenges drive a need for innovative learning mechanisms which consider both subtle diﬀerences among various classes, as well as multilabel nature of the task. This paper introduces two contributions to detect lung diseases from chest x-ray. 1. First, we provide a ﬁne-grained perspective into this problem, where ﬁnegrained image classiﬁcation is deﬁned as a problem to categorise visually similar sub-categories [8]. Thus, this motivates us to explore and re-adapt bilinear pooling method [9] from ﬁne-grained classiﬁcation ﬁeld. 2. Second, a neural network loss named Multi-label SoftMax Loss (MSML), is proposed, that captures the characteristics of multi-label learning. We further combine the idea of MSML with bilinear pooling to propose a novel mecahnism for multi-label learning in a deep learning context. 2 Methods Formally speaking, let Y = {1, 2, ..., C} be the ﬁnite set of labels and Train = {(inputn, yn',\n",
       " '1812.10924': 'Despite Deep Neural Networks’ (DNN) superior discrimination power in many ﬁelds, the logics of each hidden feature representations before the output layer still remain to be blackbox. Understanding why a speciﬁc prediction is made is of utmost importance for the end-users to trust and adopt the model, and for the system designers to reﬁne the model by performing feature engineering and parameter tuning. This is especially true for high stakes domains such as clinical decision support, disaster response and recidivism prediction. For instance, decision trees are preferred over DNN in the health care domain for disease diagnosis due to their ease of interpretation [1] [2] [3]. However, decision trees overﬁt easily and performs bad on large heterogeneous electronic health records (EHR) datasets [4]. It is therefore desirable to develop models to ﬁnd a spot where both interpretability and performance could be ultimately optimized. In recent years, we found resurgent interest in designing interpretable machine learning models. It should be noted that interpretability or transparency of a model is still not clearly deﬁned in the literature [5] [6]. An intuitive and natural way to interpret neural networks is through visualization. There is a number of works done in this area [7]. In [8] two tools are introduced: one plots the activations produced on each layer of a trained neural network; the other visualizes the learned features computed by each neurons at each layer of a neural network. A review of visualization methods for interpreting deep convolutional neural nets is provided in [9]. However, recent research [10] shows that it is space, not the individual units, that contains the semantic information in the higher layers of neural networks , which means that the common approach: activation maximization [7] [11] [12] [13] [14] applied previously for interpretation has ﬂaws. A related suggestion was given in [15] to abandon the idea of inspecting individual hidden units. Thus alternative solutions for interpretation are required. Network diagnosis [16] is another approach. Earlier research in this area focuses on designing inherently interpretable models such as decision lists [17], decision sets [18], additive models [19], sparse linear models [20], etc. However, this approach presents a severe constraint on the selection of algorithms. Besides, although human can comprehend these models, they fail to model more complex problems with good accuracy performance. In this paper, we apply the most recent model-agnostic approach [21] which performs post-hoc explanations on the trained models. Past research focus on either global interpretations [22] [23] or local explanations [24] [25] [26]. We concentrate on the global interpretations. In this paper, we adopt knowledge distillation to improve the global interpretation results. Knowledge distillation refers to the process of transferring the dark knowledge learned by a teacher model (usually sophisticated and large) to a student model (usually shallow and small). Dark Knowledge [27] [28] is the salient information hidden in the “soft targets”: predicted probabilities for all classes, which are more informative than the “hard targets”: predicted classes. Maybe',\n",
       " '1502.06895': 'The rapidly growing data dimension has brought new challenges to statistical variable selection, a crucial technique for identifying important variables to facilitate interpretation and improve prediction accuracy. Recent decades have witnessed an explosion of research in variable selection and related ﬁelds such as compressed sensing [1, 2], with a core focus on regularized methods [3, 4, 5, 6, 7]. Regularized methods can consistently recover the support of coeﬃcients, i.e., the non-zero signals, via optimizing regularized loss functions under 1  certain conditions [8, 9, 10]. However, in the big data era when p far exceeds n, such regularized methods might fail due to two reasons. First, the conditions that guarantee variable selection consistency for convex regularized methods such as lasso might fail to hold when p >> n; Second, the computational expense of both convex and non-convex regularized methods increases dramatically with large p. Bearing these concerns in mind, [11] propose the concept of “variable screening”, a fast technique that reduces data dimensionality from p to a size comparable to n, with all predictors having non-zero coeﬃcients preserved. They propose a marginal correlation based fast screening technique “Sure Independence Screening” (SIS) that can preserve signals with large probability. However, this method relies on a strong assumption that the marginal correlations between the response and the important predictors are high [11], which is easily violated in the practice. [12] extends the marginal correlation to the Spearman’s rank correlation, which is shown to gain certain robustness but is still limited by the same strong assumption. [13] and [14] take a diﬀerent approach to attack the screening problem. They both adopt variants of a forward selection type algorithm that includes one variable at a time for constructing a candidate variable set for further reﬁning. These methods eliminate the strong marginal assumption in [11] and have been shown to achieve better empirical performance. However, such improvement is limited by the extra computational burden caused by their iterative framework, which is reported to be high when p is large [15]. To ameliorate concerns in both screening performance and computational eﬃciency, [15] develop a new type of screening method termed “High-dimensional ordinary least-square projection” (HOLP). This new screener relaxes the strong marginal assumption required by SIS and can be computed eﬃciently (complexity is O(n2p)), thus scalable to ultra-high dimensionality. This article focuses on linear models for tractability. As computation is one vital concern for designing a good screening method, we primarily focus on a class of linear screeners that can be eﬃciently computed, and study their theoretical properties. The main contributions of this article lie in three aspects. 1. We deﬁne the notion of strong screening consistency to provide a uniﬁed framework for analyzing screening methods. In particular, we show a necessary and suﬃcient condition for a screening method to be strong screening consistent is that the screening matrix is restricted diagonally dominant (RDD). This condition gives insights into the design of screening',\n",
       " '1605.02401': 'The amount of consumer-generated multimedia data on the internet has grown almost exponentially in recent times. One popular multimedia upload site, YouTube, reported about a year ago that 300 hours of multimedia recordings are uploaded on it every minute [2]. There are several such sites on the internet today, each of which attracts similarly large amounts of data. The recordings are largely unannotated; descriptions if any are limited to simple high-level metadata such as the author, or a brief legend indicating the overall content. Often the legends themselves are cryptic and uninformative to the uninformed, e.g. “My favorite clip”. In order to be able to organize, categorize, summarize and index these recordings such that they can be retrieved through meaningful queries, one requires analysis of their content. Given the rather spotty nature of the metadata, the description of the content must usually be automatically derived. This naturally requires automatic identiﬁcation of the objects and events that occur in the recording. Multimedia recordings have both video and audio components. Often, the sounds in the recordings carry information that the video itself may not. Thus, not only the visual objects in the recordings be automatically detected, it is also important to detect the sounds that occur in them. Automatic sound event detection also ﬁnds application in other scenarios, such as monitoring traﬃc for sounds of accidents or impact, surveillance, where one may “listen” for sounds of gunshots [31], screams [25] etc., which might indicate unusual noteworthy activity. It is also useful in cases such as wildlife monitoring [8], context recognition [13] and several health and life style monitoring system. In all cases, the detectors themselves must be “trained” from examples of the sound to be detected. In general for learning such detectors, one requires annotated data, where the segments of audio containing the desired event are clearly indicated (as well as data in which the events are distinctly not present). We will refer to this type of labeling as strongly labeled data. This is fundamentally limiting, since such well-annotated data are generally scarce. A solution to the scarcity is to use the consumer-produced videos themselves to train the detectors. This immediately raises several challenges, however. Firstly, of course, the recording conditions, styles, and sophistication vary greatly among such recordings, resulting in large within-category variations between diﬀerent instances of events, making the fundamental learning problem challenging. Much more important however, is the nature of annotations, if any, that they may carry. As mentioned earlier, the vast majority of consumer-produced videos carry little or no content annotation (which is what necessitates the development of automated concept detectors in the ﬁrst place). Nevertheless, a signiﬁcant number of these recordings do carry some weak information about their content, in the form of title, tags, etc. By “weak” annotation, we mean that while they may provide information about the presence or absence of particular events in the video, they will not provide',\n",
       " '1206.5253': 'In this paper we study a new type of inference problem where the goal is to ﬁnd the most reliable path from a given source to a given sink through a network where edges within the network may fail according to certain probabilities. Finding minimum cost or most reliable paths in a network is a classic computer science problem; in this paper, we consider a novel but natural variant where edge failure probabilities may depend on the state of a hidden random variable. The introduction of hidden state adds complexities to the problem of ﬁnding most reliable paths not present in previous variants; in particular, hidden state can be used to model correlations between edge failures that cannot be modeled by previous variants. In this paper, we give a number of theoretical results characterizing the presented problem including an NP-hardness proof which shows that computing an exact solution is impractical in the general case. We also give an exact algorithm and a faster approximation algorithm for solving the presented problem. We believe algorithms which tackle this problem will ﬁnd useful applications in computer network QoS (quality-of-service) routing. Existing techniques for QoS routing generally do not model any hidden state of the network, and furthermore, edge failures are assumed to be independent [Orda, 1999, F. A. Kuipers and Mieghem, 2002]. By considering hidden states as well as allowing for correlations between failures, we believe our problem formulation can be used to produce more realistic models of networks which may lead to improved routing performance. For example, hidden state variables could be used to model network hardware or software, where failures between nodes or links running on similar systems are often correlated (as they may share vulnerabilities). We also believe algorithms for tackling the problem we introduce will ﬁnd useful applications involving weighted ﬁnite state automata. Weighted ﬁnite state automata are currently used in pattern recognition and parsing applications [Smith and Eisner, 2005, Thollard et al., 2005a, Thollard et al., 2005b], where inference procedures typically involve ﬁnding mostlikely sequences of states or parses of a given automaton. In prior applications utilizing weighted ﬁnite state automata, it has been assumed that transitions between states are not correlated and that there is no hidden state. Again, by introducing hidden variables, we believe richer models may be built which may lead to improved performance in applications using these automata. There has been a substantial amount of theoretical algorithms and operations research that has tackled problems similar in ﬂavor to the problem we propose in this paper. This research includes work on restricted shortest-path problems [Ergun et al., 2002, Hassin, 1992, Lorenz and Raz, 1999], bicriteria netCHANG & AMIR 41  s t e1 e2 e5 e8 e9 e7 e3 e 6 e 4 Figure 1: An example network. work design problems [Marathe et al., 1998], and other similar shortest-path problem formulations [Nikolova et al., 2006, Loui, 1983]. This previous',\n",
       " '1711.04731': 'Written prose is one way in which we communicate our thoughts to each other. Given a ‘message’, there are many ways to write a sentence capable of conveying the embedded information, even when they are all written in the same language. Sentences can communicate essentially the same information but do so using different ‘styles’. That is, the various versions may have essentially the same meaning or semantic content, and insofar as they use different words are each ‘paraphrases’ of each other. These paraphrases, while sharing the same semantic content, are not necessarily interchangeable. When writing a sentence we frequently consider not only the semantic content we wish to communicate, but also the manner, or style, in which we express it. Different wording may convey different levels of politeness or familiarity with the reader, display different cultural information about the writer, be easier to understand for certain populations, & 2018 The Authors. Published by the Royal Society under the terms of the Creative Commons Attribution License http://creativecommons.org/licenses/by/4.0/, which permits unrestricted use, provided the original author and source are credited.  etc., Style transfer, or stylistic paraphrasing, is the task of rewriting a sentence such that we preserve the meaning but alter the style. The problem of style transfer is clearly relevant for the creation of natural language generation systems. The translations, paraphrases, summarizations, and other language generated by a natural language system are only useful if the outputs are understood and accepted by the intended audience. This may require us to target certain levels of simplicity, formality, or other characteristics of style in the language produced. There are many features of the prose which contribute to the perceived style of a text including sentence length, use of passive or active voice, vocabulary level, tone and level of formality. Analysis and classification of style focusing on sentiment, usage of stop-words, formality, etc., have all been the subject of study [1–4]. Similarly, generation of language targeting one aspect of style such as simplicity, formality, length and use of active voice have received attention [5–8], and some work has even been done to try to control several of these properties simultaneously [9]. Fewer results exist which do not consider any of these aspects explicitly, but instead use a more general view of style. These systems generally require parallel data for training and testing their results and parallel style transfer corpora are in short supply. A few recent exceptions use a corpus of Shakespearean plays and their modernizations for the task [10,11]. Even more recently, researchers have published results of targeting a style using only unlabelled training data. Some of these systems generate text not conditioned on an input and cannot be applied to this problem [12], and others only show results on a sentiment transfer task [13,14]. Generally, unsupervised systems still need parallel data for evaluation and may benefit from some amount of parallel data during training. We believe that one of the major barriers',\n",
       " '1811.08764': 'We propose a novel regularization technique that is applied before the activation of all neurons in the neural network. The new regularization term encourages the distribution of the individual activations to have a few distinct modes. This property is achieved implicitly by computing the variance of the activation of each neuron in each minibatch and by penalizing for variations of this variance, i.e., we encourage the variances to be the same across the mini-batches. We provide a theoretical link between the variance-based regularization term and the resulting peaked activation distributions, which we also observe experimentally, see Fig. 1. In addition, we also provide experimental evidence that the new term leads to improved accuracy and can replace, during training, normalization techniques such as the batch-norm technique. The link between the new regularization term and batch-norm is further explored theoretically. A distribution with few modes would lead to more stable batches and, for example, the representation of a given sample would not vary along different batches. In other words, it is desirable that a sample, if repeated twice in multiple batches, would produce the same network activations postnormalization. This is an indirect way in which batchnorm beneﬁts from few-modes. In our method it is encouraged more explicitly. The new regularization term is adaptive, in the sense that it can lead to a few distinct outcomes. When applied to a mixture of two Gaussians, the regularization leads, in an unsupervised way, to one of two possible projections: either the LDA projection that maximally separates between the two Gaussians, or the orthogonal projection that is least sensitive to their differences. Interestingly, the amount of variance in each activation is controlled by a parameter β. In order to avoid searching over a wide range of hyper-parameters, we optimize for this term during training and allow each neuron to adapt to a different level of variance. 32nd Conference on Neural Information Processing Systems (NIPS 2018), Montr´eal, Canada. arXiv:1811.08764v1  [cs.LG]  21 Nov 2018  (a) (b) Figure 1: Histograms of activations in a network trained on the UCI adult dataset. (a) Random neurons trained with batchnorm. (b) Random neurons trained with our VCL method. Each row corresponds to a different hidden layer. 2 The Variance Constancy Loss The distribution of the activations of each neuron depends on both the distribution of network inputs and the weight of the network upstream from that neuron. Let ρ be a random variable denoting the activations of a single neuron and denote the underlying distribution as p. The variance of ρ is given by σ2 = E[(ρ −µρ)2], where µρ = E[ρ]. For a ﬁnite sample s = {ρ1...ρn} randomly drawn from p, the unbiased sample variance of p over s is given by σ2 s = 1 n−1 Pn i=1(ρsi −1 n Pn i=1 ρsi)2. The variance of the sample variances is given by: E[(σ2 −σ2 s)2] = m4 n −σ4(n −3) n(n −1',\n",
       " '1703.08580': 'Robot-assisted Minimally Invasive Surgery (RMIS) overcomes many of the limitations of traditional laparoscopic Minimally Invasive Surgery (MIS), providing the surgeon with improved control over the anatomy with articulated instruments and dexterous master manipulators. In addition to this, 3D-HD visualization on systems such as da Vinci enhances the surgeon’s depth perception and operating precision [3]. However, complications due to the reduced ﬁeld-of-view provided by the surgical camera limit the surgeon’s ability to self-localize. Traditional haptic cues on tissue composition are lost through the robotic control system [11]. Overlaying preand intra-operative imaging with the surgical console can provide the surgeon with valuable information which can improve decision making during complex procedures [14]. However, integrating this data is a complex task and involves understanding spatial relationships between the surgical camera, operating instruments and patient anatomy. A critical component of this process is segmentation of the instruments in the camera images which can be used to prevent rendered overlays from occluding the instruments while providing crucial input to instrument tracking frameworks [12,2]. 1 https://github.com/warmspringwinds/tf-image-segmentation arXiv:1703.08580v1  [cs.CV]  24 Mar 2017  2 Fig. 1: Example frames from RMIS procedures demonstrating the complex lighting and color distributions which make instrument segmentation an extremely challenging problem. Input Convolution ReLU Convolution Addition ReLU Output ReLU Convolution Residual Block Fig. 2: Architecture of a ”bottleneck” residual block which is composed of three convolution layers. The ﬁrst convolutional layer performs dimensionality reduction, leaving the middle layer with smaller input/output dimensions and the third convolutional layer expands the dimension back to the original size. The output of the third convolutional layer is the residual, which is added to the input features. Batch normalization was omitted for simplicity. Segmentation of surgical tools from tissue backgrounds is an extremely difﬁcult task due to lighting challenges such as shadows and specular reﬂections, visual occlusions such as smoke and blood, and due to complex background textures (see Fig. 1). Early methods attempted to simplify the problem by modifying the appearance of the instruments [15]. However, this complicates clinical application of the technique as sterilization can become an issue. Segmentation of the instruments using natural appearance is a more desirable approach as it can be applied directly to pre-existing clinical setups. However, this deﬁnes a more challenging problem. To solve it, previous work has relied on machine learning techniques to model the complex discriminative boundary. The instrumentbackground segmentation can be modeled as a binary segmentation problem to which discriminative models, such as Random Forests [4], maximum likelihood Gaussian Mixture Models [12] and Naive Bayesian classiﬁers [13], all trained on color features, have been applied. A more recent work, showing state-of-the-art performance [7], applies Fully Convolutional Networks (FCNs), more speciﬁcally FCN-8s model [10] for the task of binary segmentation of robotic tools. Although most approaches',\n",
       " '1806.03332': 'Information leakage metrics seek to quantify an adversary’s ability of inferring information about one quantity from another. Mutual information (MI) is a classic measure for quantifying information and often used to measure information secrecy [1] or leakage in data publishing settings [2], [3]. More recently, Issa et al. introduced a measure, called maximal leakage (MaxL), for a guessing adversary that quantiﬁes the maximal multiplicative gain of an adversary, with access to a disclosed dataset, to guess any (possible random) function of the original dataset [4]. Information leakage measures can be viewed through the lens of adversarial inference capabilities, and therefore, quantiﬁed via a loss function that the adversary seeks to minimize. The choice of a loss function provides a concrete measure of the gain in adversarial inference capability. For example, the deﬁnition of MaxL can be interpreted in terms of an adversary seeking to minimize the 0-1 loss function, which induces the adversary towards a hard decision, i.e., a maximum likelihood estimator. On the other hand, when MI is used as a leakage measure, the underlying loss function is the logarithmic loss (log-loss) function [5]–[7], which models a (soft decision) belief-reﬁning adversary. These two models capture two extremal actions of adversaries. Can these measures be viewed through the same framework? In this paper, we introduce a tunable measure, called maximal α-leakage, for information leakages, which encompasses MI (for α = 1) and MaxL (for α = ∞) and allows continuous interpolation between the two extremes. The parameter α can be viewed as a tunable This material is based upon work supported by the National Science Foundation under Grant No. CCF-1350914. parameter that determines how much weight the adversary gives to its posterior belief. In this paper, we deﬁne two tunable measures for information leakages in Section III: α-leakage (Deﬁnition 4) and maximal α-leakage (Deﬁnition 5). In Section III, we prove that the α-leakage can be expressed as Arimoto mutual information (A-MI) (Theorem 1), and the maximal α-leakage is equivalent to the supremum of A-MI and Sibson mutual information (SMI) (Theorem 2) over all distributions of the original dataset. In Section IV, we prove several important properties of the maximal α-leakage. II. PRELIMINARIES We begin by reviewing R´enyi entropy and divergence [8]. Deﬁnition 1. Given a discrete distribution PX over a ﬁnite alphabet X, the R´enyi entropy of order α ∈(0, 1) ∪(1, ∞) is deﬁned as Hα(PX) = α 1 −α log ∥PX∥α. (1) Let QX be a discrete distribution over X. The R´enyi divergence (between PX and QX) of order α ∈(0, 1) ∪(1, ∞) is deﬁned as Dα(PX∥QX) = 1 α −1 log  X x PX(x)α QX(x)α−1 ! . (2) Both of the two quantities are deﬁned by their continuous extension for α = 1 or ∞. The α-leakage and max α-leakage metrics can be expressed in terms of Sibson mutual information (S-MI',\n",
       " '1808.07733': 'In this paper, we explore the effectiveness of methods designed to improve sentiment classiﬁcation (positive vs. negative) of sentences that contain complex syntactic structures. While simple bag-of-words or lexicon-based methods (Pang and Lee, 2005; Wang and Manning, 2012; Iyyer et al., 2015) achieve good performance on this task, they are unequipped to deal with syntactic structures that affect sentiment, such as contrastive conjunctions (i.e., sentences of the form “A-but-B”) or negations. Neural models that explicitly encode word order (Kim, 2014), syntax (Socher et al., 2013; Tai et al., 2015) and semantic features (Li et al., 2017) have been proposed with the aim of improving performance on these more complicated sentences. Recently, Hu et al. (2016) incorporate logical rules into a neural model and show that these rules increase the model’s accuracy on sentences containing contrastive conjunctions, while Peters et al. (2018a) demonstrate increased overall accuracy on sentiment analysis by initializing a model with representations from a language model trained on millions of sentences. In this work, we carry out an in-depth study of the effectiveness of the techniques in Hu et al. (2016) and Peters et al. (2018a) for sentiment classiﬁcation of complex sentences. Part of our contribution is to identify an important gap in the methodology used in Hu et al. (2016) for performance measurement, which is addressed by averaging the experiments over several executions. With the averaging in place, we obtain three key ﬁndings: (1) the improvements in Hu et al. (2016) can almost entirely be attributed to just one of their two proposed mechanisms and are also less pronounced than previously reported; (2) contextualized word embeddings (Peters et al., 2018a) incorporate the “A-but-B” rules more effectively without explicitly programming for them; and (3) an analysis using crowdsourcing reveals a bigger picture where the errors in the automated systems have a striking correlation with the inherent sentiment-ambiguity in the data. 2 Logic Rules in Sentiment Classiﬁcation Here we brieﬂy review background from Hu et al. (2016) to provide a foundation for our reanalysis in the next section. We focus on a logic rule for sentences containing an “A-but-B” structure (the only rule for which Hu et al. (2016) provide experimental results). Intuitively, the logic rule for such sentences is that the sentiment associated with the whole sentence should be the same as the sentiment associated with phrase “B”.1 1The rule is vacuously true if the sentence does not have this structure. arXiv:1808.07733v1  [cs.CL]  23 Aug 2018  More formally, let pθ(y|x) denote the probability assigned to the label y ∈{+, −} for an input x by the baseline model using parameters θ. A logic rule is (softly) encoded as a variable rθ(x, y) ∈[0, 1] indicating how well labeling x with y satisﬁes the rule. For the case of A-but-B sentences',\n",
       " '1605.06492': 'The eﬃcient reduction of a constrained convex optimization problem to a constrained linear optimization problem is an appealing algorithmic concept, in particular for large-scale problems. The reason is that for many feasible sets of interest, the problem of minimizing a linear function over the set admits much more eﬃcient methods than its non-linear convex counterpart. Prime examples for this phenomenon include various structured polytopes that arise in combinatorial optimization, such as the path polytope of a graph (aka the unit ﬂow polytope), the perfect matching polytope of a bipartite graph, and the base polyhedron of a matroid, for which we have highly eﬃcient combinatorial algorithms for linear minimization that rely heavily on the speciﬁc rich structure of the polytope [22]. At the same time, minimizing a non-linear convex function over these sets usually requires the use of generic interior point solvers that are oblivious to the speciﬁc combinatorial structure of the underlying set, and as a result, are often 1 arXiv:1605.06492v1  [math.OC]  20 May 2016  much less eﬃcient. Another important example includes structured sets of matrices such as the spectrahedron, i.e., convex-hull of unit-trace positive semideﬁnite matrices, or the nuclear ball that are central to many machine learning problems, such as matrix completion, for which linear optimization amounts to computing the leading eigenvector or leading pair of singular vectors, whereas, algorithms for non-linear convex optimization over these sets often rely on very expensive singular value decompositions. Indeed, it is for this reason, that the conditional gradient (CG) method (aka Frank-Wolfe algorithm), a method for constrained convex optimization that is based on solving linear subproblems over the feasible domain, has regained much interest in recent years in the machine learning, signal processing and optimization communities. It has been recently shown that the method delivers state-of-the-art performance on many problems of interest, see for instance [13, 17, 4, 9, 10, 23, 19, 26, 11, 14]. As part of the regained interest in the conditional gradient method, there is also a recent eﬀort to understand the convergence rates and associated complexities of conditional gradientbased methods, which is in general far less understood than other ﬁrst-order methods, e.g., the projected gradient method. It is known, already from the ﬁrst introduction of the method by Frank and Wolfe in the 1950’s [5], and the somewhat later work of Polyak and Levitin [20], that the method converges with a rate of roughly O(1/t) for minimizing a smooth convex function over a convex and compact set, which matches the rate of the standard projected gradient method for the same setting. However, it is not clear if this convergence rate improves under an additional standard strong-convexity assumption. In fact, certain lower bounds, such as in [18, 6], suggest that such improvement, even if possible, should come with a worse dependence on the problem’s parameters (e.g., the dimension), which is a phenomena that',\n",
       " '1901.03775': 'FAILED',\n",
       " '1812.02207': \"As a consequence of the growing concerns regarding the development of responsible and ethical Artificial Intelligence (AI) solutions and the attendance of the requirements of new AI-related legislation, such as the General Data Protection Regulation (GDPR) (European Commission, 2016), model interpretability has become an essential issue in the AI research agenda. Thus, when selecting a Machine Learning (ML) algorithm for a new classification task, good predictive performance coupled with easy model interpretation favors the Decision Tree (DT) induction algorithms (Rokach and Maimon, 2014). These algorithms induce a model represented by a set of rules in a tree-like structure (as illustrated in Figure 1). This structure elucidates how the induced model predicts the class of a new instance, more interpretable than many other model representations, such as an Artificial Neural Network (ANN) (Haykin, 2007) or  Better Trees 3 Support Vector Machines (SVMs) (Abe, 2005). As a result, DT induction algorithms are among the most frequently used ML algorithms for classification tasks (Jankowski and Jackowski, 2014; Wu and Kumar, 2009). Fig. 1: Example of a decision tree classification. When unlabeled data is provided to the tree, conditions are applied starting from the root node and following the appropriate branch until a leaf is reached. The class is recommended based on the leaf pointed out. Adapted from Tan et al (2005). DT algorithms have several other advantages over many ML algorithms, such as robustness to noise, tolerance against missing information, capability to handle various types of attributes, treatment of irrelevant and redundant attributes, and low computational cost (Rokach and Maimon, 2014). Their importance is attested by the wide range of well-known algorithms proposed in the literature, such as Breiman et al.'s Classification and Regression Tree (CART) (Breiman et al, 1984) and Quinlan's C4.5 algorithm (Quinlan, 1993), as well as some hybrid-variants of them, like Na¨ıve-Bayes Tree (NBTree) (Kohavi, 1996), Logistic Model Tree (LMT) (Landwehr et al, 2005) and Conditional Inference Trees (CTree) (Hothorn et al, 2006), to name a few. Similarly to most ML algorithms, DT induction algorithms might improve their performance through hyperparameters setup. Due to the high number of possible configurations and their significant influence on the predictive performance of the induced models, hyperparameter tuning is often warranted (Bergstra et al, 2011; Massimo et al, 2016; Pil´at and Neruda, 2013; Padierna et al, 2017). Moreover, highly accurate DT induction algorithms grounded on pre-prune (e.g., CTree and CHAID) or post-prune (e.g., C4.5,  4 Better Trees J48 and CART) strategies demand setting up appropriate hyperparameter settings since inaccurate ones lead to under-fitting or over-fitting problems (Loh, 2014). The tuning task is usually performed to “black-box” algorithms, such as ANNs and SVMs, but not for DTs. There are some prior studies investigating the evolutionary design of new DT induction algorithms (Barros et al, 2012, 2015), but only a few on hyperparameter\",\n",
       " '1803.00384': 'In recent years the interest in transparent, interpretable and explainable models in machine learning has grown dramatically, with dedicated workshops at NIPS 2016(Wilson et al., 2016), NIPS 2017 (Tosi et al., 2017; Wilson et al., 2017) and ICML 2017 (Varshney et al., 2017) as well as attention from grant agencies (Gunning, 2016). The approaches to interpretable models go in several distinct directions – producing sparse models (Hara & Maehara, 2016; Wisdom et al., 2016; Hayete et al., 2016; Tansey et al., 2017), visualization techniques (Smilkov et al., 2016; Selvaraju et al., 2016; Thiagarajan et al., 2016; Gallego-Ortiz & Martel, 2016; Krause et al., 2016; Zrihem et al., 2016; Handler et al., 2016), hybrid models (Krakovna & DoshiVelez, 2016; Reing et al., 2016), input data segmentation (Samek et al., 2016; Hechtlinger, 2016; Thiagarajan et al., 2016), and model diagnostics with or without blackbox interpretation layers (Lundberg & Lee, 2016; Vidovic et al., 1KTH Royal Institute of Technology 2Ayasdi Inc. 3Stanford University 4CUNY College of Staten Island. Correspondence to: Leo Carlsson <leoc@kth.se>, Mikael Vejdemo-Johansson <mvj@math.csi.cuny.edu>. Preliminary work. Under review. Copyright 2018 by the author(s). 2016; Whitmore et al., 2016; Ribeiro et al., 2016b; Singh et al., 2016; Phillips et al., 2017; Ribeiro et al., 2016a;c) to name a few prominent directions. In this paper, we present a method, Fibres of Failure that draws on topological data analysis to produce model diagnostics through a classiﬁcation of prediction failure modes in feature space. Our method relates to both the input data segmentation and the model diagnostics directions of research by ﬁnding and classifying input regions that behave unexpectedly or erroneously as compared to what the model is designed to predict. Noisy input as well as adversarial learning has been used to motivate and to generate examples and insights for interpretability (Kindermans et al., 2016). We will use the same basic idea to illustrate our method – by studying prediction failures on MNIST images with added noise. 2. Related work One interpretability method with a large impact on the ﬁeld, LIME (Ribeiro et al., 2016c), inspects single instances by perturbing the input and tracing how predictions change with the perturbation. Other interpretability methods focus closer on aggregates of inputs, such as TreeView (Thiagarajan et al., 2016), which visualizes deep neural networks by ﬁrst clustering neurons by activation patterns, then clusters these groups by prediction labels, and ﬁnally trains a predictor to predict the meta-clusters from the input data directly. The FIFA method builds on MAPPER, an algorithm from Topological Data Analysis that constructs a graph (or simplicial complex) model of arbitrary data. MAPPER has had success in a wide range of application areas, from medical research studying cancer, diabetes, asthma and many more topics (Nicolau et al., 2011; Li et al., 2015; Hinks et al., 2016; Schneider et al., 2016), genetics and phenotype studies (Romano et al., 2014; Carlsson, 2017; C´amara, 2017; Savir et',\n",
       " '1405.5864': 'Demand for video content over wireless networks has grown signiﬁcantly in recent years and shows no sign of letting up. According to the Cisco Visual Networking Index mobile forecast for 2012-2017 [1], mobile video data is expected to grow at a compound annual growth rate of 75 percent to 7.4 exabyes (one million gigabytes) by 2017. By this time, it is expected to be 66.5 percent of global mobile trafﬁc data (11.2 exabytes), up from 51 percent in 2012 (see Fig. 1). We expect both broadcast and on-demand services will continue to expand, including traditional services like streaming TV content (e.g., sporting events) and newer services like video Twitter, video blogging, cloud-based live video broadcasting, and mobile-tomobile video conferencing and sharing. Meanwhile, hardware platforms (smart phones, tablets, notebooks, television/set-top boxes, in-vehicle infotainment systems) continue to push the envelope in performance and graphical quality. More capable processors, better performing graphics, increased storage 1 Department of Electrical Engineering, University of Southern California, Los Angeles, CA; 2 Intel Corporate Research capacities, and larger displays make devices more powerful and intelligent than ever before. And with this increase in device capability comes a corresponding increase in demand for high-quality video data; for example, increasing demand for high-deﬁnition (HD) and 3D data types.\\r \\xa0 Fig. 1. Demand for video trafﬁc will continue to grow signiﬁcantly and QoE has clear ﬁnancial implications according to industry sources Cisco [1] and Conviva [2] The implications of these trends for future wireless networks are signiﬁcant. While continued evolution in spectral efﬁciency is to be expected, the maturity of MIMO, air interfaces using OFDM/OFMDA, and Shannon capacity-approaching codes mean that such spectral efﬁciency improvements will not deliver the increased capacity needed to support future demand for video data. Additional measures like the brute force expansion of wireless infrastructure (number of cells) and the licensing of more spectrum, while clearly addressing the problem of network capacity, may be prohibitively expensive, require signiﬁcant time to implement, or be infeasible due to prior spectrum allocations which are not easily modiﬁed. Recognizing these challenges, Intel and several industry partners jointly developed a program to explore nonincremental, systems-level solutions through university research. Known as Video-aware Wireless Networks or simply VAWN, the program considers various approaches to enabling a higher capacity in future wireless networks, and in enabling a higher quality of user experience for video and video-based services delivered over wireless networks to intelligent mobile devices. Broad strategies explored in the program include unconventional optimizations in video transport within the network, optimizations in video processing to reduce network transmission requirements and improve user experience, and novel network architectures better suited to address future capacity and quality of service challenges speciﬁc to video. arXiv:1405.5864v1  [cs.IT]  22 May 2014  The approach taken by the group at the University of Southern California (including several of the authors), exploits a unique feature of',\n",
       " '1806.06237': 'Peer review is the backbone of academia. In order to provide high-quality peer reviews, it is of utmost importance to assign papers to the right reviewers (Thurner and Hanel, 2011; Black et al., 1998; Bianchi and Squazzoni, 2015). Even a small fraction of incorrect reviews can have signiﬁcant adverse eﬀects on the quality of the published scientiﬁc standard (Thurner and Hanel, 2011) and dominate the beneﬁts yielded by the peer-review process that may have high standards otherwise (Squazzoni and Gandelli, 2012). Indeed, researchers unhappy with the peer review process are somewhat more likely to link their objections to the quality or choice of reviewers (Travis and Collins, 1991). We focus on peer-review in conferences where a number of papers are submitted at once. These papers must simultaneously be assigned to multiple reviewers who have load constraints. The importance of the reviewer-assignment stage of the peer-review process cannot be overestimated; quoting Rodriguez et al. (2007): “one of the ﬁrst and potentially most important stage is the one that attempts to distribute submitted manuscripts to competent referees.” Given the massive scale of many conferences such as NeurIPS and ICML, these reviewer assignments are largely performed in an automated manner. For instance, NeurIPS 2016 assigned 5 out of 6 reviewers per paper using an automated process (Shah et al., 2017). This problem of automated reviewer assignments forms the focus of this paper. 1 arXiv:1806.06237v2  [stat.ML]  15 Nov 2019  Various past studies show that small changes in peer review quality can have far reaching consequences (Thorngate and Chowdhury, 2014; Squazzoni and Gandelli, 2012) not just for the papers under consideration but more generally also for the career trajectories of the researchers. These long term eﬀects arise due to the widespread prevalence of the Matthew eﬀect (“rich get richer”) in academia (Merton, 1968). It is also known (Travis and Collins, 1991; Lamont, 2009) that works that are novel or not mainstream, particularly those interdisciplinary in nature, face signiﬁcantly higher diﬃculty in gaining acceptance. A primary reason for this undesirable state of aﬀairs is the absence of suﬃciently many good “peers” to aptly review interdisciplinary research (Porter and Rossini, 1985). These issues strongly motivate the dual goals of the reviewer assignment procedure we consider in this paper — fairness and accuracy. By fairness, we speciﬁcally consider the notion of max-min fairness which is studied in various branches of science and engineering (Rawls, 1971; Lenstra et al., 1990; Hahne, 1991; Lavi et al., 2003; Bonald et al., 2006; Asadpour and Saberi, 2010). In our context of reviewer assignments, max-min fairness posits maximizing the review-quality of the paper with the least qualiﬁed reviewers. The max-min fair assignment guarantees that no paper is discriminated against in favor of more lucky counterparts. That is, even the most ambivalent paper with a small number of reviewers being competent enough to evaluate its merits will receive as good treatment as possible. The max-min',\n",
       " '1812.07858': 'Cyber-security is an important area in which machine learning is becoming increasingly signiﬁcant. Many machine learning algorithms such as convolutional neural networks (David and Netanyahu 2015), LSTM (Woodbridge et al. 2016) and others (Khorshidpour, Hashemi, and Hamzeh 2017; McLaughlin et al. 2017; Hu and Tan 2017a; Villegas 2017; Patri, Wojnowicz, and Wolﬀ2017) were applied to cyber-security problems. It is important to note that machine learning in cyber-security is far more than merely applying established machine learning methods to data sets of cyber entities. Cyber-security involves machine learning challenges that require elegant methodological and theoretical handling. We believe that such challenges are of interest to people with passion for machine learning, without necessarily requiring cyber domain expertise or prior knowledge. The machine learning community is usually unaware of these challenges. We are not the ﬁrst to discuss security and AI challenges (Stoica et al. 2017) or alert on the lack of data sets (Kumar, Wicker, and Swann 2017). The novelty of our work is the presentation of new cyber-security problems, the machine learning challenges involved in them and the publication of data sets that enable investigating them. We hope it will lead to new methods in both machine learning and cyber-security. Cyber-Security Problems Malware Classiﬁcation And Detection : Identifying Malicious Programs Malware is a program or a ﬁle that is harmful to a computer system. As part of the arms race, the attacker tries to avoid detection. Some evasion techniques are polymorphism, impersonation, compression and obfuscation (You and Yim 2010). For example, in malware coloring the attacker slightly change the malware, leading to polymorphism (many variants). Since many threat intelligence repositories are based on signatures of the malware (e.g., SHA1, MD5), a slight modiﬁcation enables to a signature-based detection. Current detection systems use various algorithms: Naive Bayes Classiﬁer(Luo 2016), SVM (Kuriakose and Vinod 2015), Random Forest (Hu and Tan 2017b), DNN (Xie, Girshick, and Farhadi 2015), CNN (David and Netanyahu 2015) and LSTM (Woodbridge et al. 2016; Saxe and Berlin 2017). Labeling Malware Via Opertor Domain Pivoting Historically, malware classiﬁcation was based on signatures and domain experts. However, domain experts are limited in the number of cases they analyze, and signatures lead to labeling errors. The large number of malware and their population rapid growth make the problem even more severe. For these reasons, we have constructed a malware data set and grouped malware contacting the same malicious site. Let m1, m2 be malware. Let OperatorDomains(m) be the unique domains with which the malware communicates. The speciﬁc deﬁnition of OperatorDomains(m) is use case speciﬁc and requires domain knowledge. For example, many malware communicate with benign domains (e.g., google.com) in order to check Internet connectivity. So, communication with Google is not an indication of the operator or maliciousness. A good deﬁnition of OperatorDomains(m) should focus in malicious (or at least not known',\n",
       " '1504.02141': 'Identiﬁcation of normal Activities of Daily Living (ADL), for e.g., walking, hand washing, making breakfast, etc., is important to understand a person’s behaviour, goals and actions [1]. However, in certain situations, a more challenging, useful and interesting research problem is to identify cases when an abnormal activity occurs, as it can have direct implications on the health and safety of an individual. An important abnormal activity is the occurrence of a fall. However, falls occur rarely, infrequently and unexpectedly w.r.t. the other normal ADLs and this leads to either little or no training data for them [2]. The Centers for Disease Control and Prevention, USA [3], suggests that on average, patients incur 2.6 falls per person per year. Recent studies also suggest that even in a long term experimental set up only a few real falls may be captured [4, 5]. In these situations with highly skewed fall data, a typical supervised activity recognition system may misclassify ‘fall’ as one of the already existing normal activity as ‘fall’ may not be included in the classiﬁer training set. An alternative strategy is to build fall detection speciﬁc classiﬁers that assume abundant training data for falls, which is hard to obtain in practice. Another challenge is the data collection for falls, as it may require a person to actually undergo falling which may be harmful, ethically questionable, and the falling incidences collected in controlled laboratory settings may not be the true representative of falls in naturalistic settings [6]. The research question we address in this paper is: Can we recognise falls by observing only normal ADL with no training data for falls in a person independent manner?. We use the HMMs for the present task as they are very well-suited for sequential data and can model human motions with high accuracy [7]. Typically, an HMM can be trained on normal activities and the maximum of negative of log-likelihood on the training data is set as a threshold to identify a fall as an outlier. However, choosing such a threshold may severely effect classiﬁer’s performance due to spurious artifacts present in the sensor data and most of the falls may be classiﬁed as normal activities. In this paper, we use the outlier detection approach to identify falls and present three X-Factor HMM based approaches for detecting short-term fall events. The ﬁrst and second method models individual normal activities by separate HMMs or all normal 2  activities together by a single HMM, by explicitly modelling the poses of a movement by each HMM state. An alternative HMM is constructed whose model parameters are the averages of the normal activity models, while the averaged covariance matrix is artiﬁcially ‘inﬂated’ to model unseen falls. In the third method, an HMM is trained to model the transitions between normal activities, where each hidden state represents a normal activity, and adds a single hidden state (for unseen falls) with an inﬂated covariance based',\n",
       " '1603.05359': 'Most recommender systems recommended a list of K items, such as restaurants, songs, or movies. The user examines the recommended list from the ﬁrst item to the last, and typically clicks on the ﬁrst item that attracts the user. The cascade model [10] is a popular model to formulate this kind of user behavior. The items before the ﬁrst clicked item are not attractive, because the user examines these items but does not click on them. The items after the ﬁrst attractive item are unobserved, because the user never examines these items. The key assumption in the cascade model is that each item attracts the user independently of the other items. Under this assumption, the optimal solution in the cascade model, the list of K items that maximizes the probability that the user ﬁnds an attractive item, are K most attractive items. The cascade model is simple, intuitive, and surprisingly effective in explaining user behavior [7]. In this paper, we study on an online learning variant of the cascade model, which is known as cascading bandits [15]. In this model, the learning agent does not know the preferences of the user over recommended items and the goal is to learn them by interacting with the user. At time t, the agent recommends to the user a list of K items out of L candidate items and observes the click of the user. If the user clicks on an item, the agent receives a reward of one. If the user does not click on any item, the agent receives a reward of zero. The performance of the learning agent is evaluated by its cumulative reward in n steps, which is the total number of clicks in n steps. The goal of the agent is to maximize it. Kveton et al. [15] proposed two computationally and sample efﬁcient algorithms for cascading bandits. They also proved a Ω(L −K) lower bound on the regret in cascading bandits, which shows that the regret grows linearly with the  number of candidate items L. Therefore, cascading bandits are impractical for learning when L is large. Unfortunately, this setting is common practice. For instance, consider the problem of learning a personalized recommender system for K = 10 movies from the ground set of L = 100k movies. In this setting, each movie would have to be shown to the user at least once, which means at least 10k interactions with the recommender system, before the system starts behaving intelligently. Such a system would clearly be impractical. The main contribution of our work is that we propose linear cascading bandits, an online learning framework that makes learning in cascading bandits practical at scale. The key step in our approach is that we assume that the attraction probabilities of items can be predicted from the features of items. Features are often available in practice or can be easily derived. To the best of our knowledge, this is the ﬁrst work that studies',\n",
       " '1803.06077': 'Autonomous cars are currently primed for mass adoption by the consumer market. The recent slew of announcements by several car makers and automotive suppliers indicate that we continue on the path to having autonomous vehicles cohabiting our streets with other objects. Some examples of these objects include pedestrians, vehicles, strollers and shopping carts to name a few. As opposed to most other consumer technologies, autonomous vehicles behaving erroneously can result in signiﬁcant harm to humans and property. Therefore, the ability to detect and recognize various objects around the car is paramount to ensuring safe operation of the vehicle. In this paper, we present a solution to detect and classify several moving objects around the vehicle in real time. This solution was developed for use in Carnegie Mellon University’s autonomous driving research vehicle, Cadillac SRX [1]. A. Related work Several approaches to detecting obstacles around the car have been explored. The information about objects around the car can be obtained through various sensors. These include LIDAR and RADAR-based approaches used by [2]. Others include stereo camera-based approaches to make use of the additional depth information available [3]. Bertozzi et al. [4] use images from 4 ﬁsheye cameras to detect and *Both authors contributed equally to this manuscript. Iljoo Baek and Albert Davies are with the Department of Electrical and Computer Engineering, Carnegie Mellon University, Pittsburgh, PA 15213, USA ibaek, albertd@andrew.cmu.edu Geng Yan is with Robotics Institute, Carnegie Mellon University, Pittsburgh, PA 15213, USA gyan@andrew.cmu.edu Raj Rajkumar is with the faculty of the Department of Electrical and Computer Engineering and Robotics Institute, Carnegie Mellon University, Pittsburgh, PA 15213, USA 1The video demos of our algorithm have been uploaded to Youtube: https://youtu.be/vpoCfC724iA, https://youtu. be/2X4aqH2bMBs 1 2 3 4 5 6 7 8 9 10 11 12 Fig. 1. Left: Input image conﬁguration, Anti-Clockwise from top leftfront, back, left and right cameras respectively. The rectangle boxes indicate the 12 regions of interest. Right: Mapping of the ROIs to regions around the vehicle track objects. Another approach is to combine the data from various sensors to arrive at a more accurate estimate. This sensor fusion-based approach has also been explored for Carnegie Mellon University’s autonomous driving research vehicle [1][5]. Once the information about the environment has been obtained, the detection of objects can be done by processing one single frame at a time or by comparing the images from adjacent frames. Detection using processing from a single frame can be done using feature-based methods or machine learning. These methods analyze a single frame to ﬁnd various object classes like pedestrians and cyclists. The disadvantage of this approach is that they impose high computational demand and they can also miss objects that can be of potential danger but were not known a priori while training the model. Detection using processing of adjacent frames takes advantage of object motion to reduce the search space',\n",
       " '1803.08554': 'Through natural evolution, the nervous system of the nematode, C. elegans, structured a near optimal wiring diagram (White et al., 1986). Its stereotypic brain composed of 302 neurons connected through approximately 8000 chemical and electrical synapses (Chen et al., 2006). C. elegans exhibits distinct behavioral mechanisms to process complex chemical stimulations (Bargmann, 2006), avoid osmotic regions (Culotti & Russell, 1978), sleep (Nichols et al., 2017), show adaptive behavior (Ardiel & Rankin, 2010), perform mechanosensation (Chalﬁe et al., 1985b), and to control muscles (Wen et al., 2012). The functions of many neural circuits within its brain have been identiﬁed (Wicks & Rankin, 1995; Chalﬁe et al., 1985a; Li et al., 2012; Nichols et al., 2017). In particular, a neural circuit which is responsible for inducing a forward/backward locomotion reﬂex when the worm is *Equal contribution 1Cyber Physical Systems, TU Wien, Austria. Correspondence to: Mathias Lechner <mlechner@tuwien.ac.at>, Ramin Hasani <ramin.hasani@tuwien.ac.at>. mechanically exposed to touch stimulus on its body, has been well-characterized (Chalﬁe et al., 1985a). The circuit is called tap-withdrawal (TW) and it comprises 9 neuron classes which are wired together by means of chemical and electrical synapses. Synaptic polarities (either being excitatory or inhibitory) of the circuit have then been predicted, suggesting that the circuit realizes a competitive behavior between forward and backward reﬂexes, in presence of touch stimulations (Wicks & Rankin, 1995; Wicks et al., 1996). Behavior of the tap-withdrawal (TW) reﬂexive response is substantially similar to the control agent’s reaction in some standard control settings such as the impulse response of a controller operating on an Inverted Pendulum (Widrow, 1964; Doya, 2000; Russell & Norvig, 2010), a controller acting on driving an under-powered car, to go up on a steep hill, known as the Mountain Car (Moore, 1990; Singh & Sutton, 1996), and a controller acting on the navigation of a rover robot that plans to go from point A to B, on a planned trajectory, with two control commands of angular and linear velocity. We intend to take advantage of the similarity and reconﬁgure the synaptic and neuronal parameters of a deterministic dynamic model of the TW neural circuit, in each of the mentioned control settings. We use publicly available reinforcement learning toolkits, to evaluate the performance of our neuronal circuit policies. The environments include the inverted pendulum (Schulman et al., 2017), the continuous mountain car of OpenAI Gym1 and rllab 2, and the Cart-pole of rllab (Duan et al., 2016). In a real robotic setting, We also determine a control task for a rover robot to park autonomously in a speciﬁc parking spot, by a learned TW neuronal policy. For all three control challenges, we preserve the near-optimal wiring structure of the TW circuit and adopt a search-based reinforcement learning (RL) algorithm for synaptic parametrization of the network. The approach is named as neuronal circuit policies. Our principle contribution in this work is to demonstrate',\n",
       " '1604.04879': 'In recent years there has been a great development in the information technology and communications, which has changed the data collection and processing methods [1], [2]. This phenomenon, coupled with the fact that the traditional batch learning has limitations to deal with issues of data stream environments, leads to other data processing techniques. One approach is the instance-based data stream classiﬁcation algorithms. Under this scheme, each new instance is compared with existing ones using a distance function, and the closest existing instances are used to assign the class to the new one. However the performance of these methods depends on the quality of the distance function. It is necessary that the function is able to identify the instances that are semantically similar. Likewise, it should also identify as dissimilar those that are semantically different [3]. The general-purpose function does not take into account any statistical regularities that might be estimated from a large training set of labeled examples. However, the best results are obtained when the metric is designed speciﬁcally for the task at hand, issue that has received much interest from researchers in the last decade [3], [4]. Distance metric learning consists in adapting some pairwise real-valued metric function such as Mahalanobis to the problem of interest using side information as supervision, brought by training examples. Most of methods learn the metric in a supervised manner from similarity, dissimilarity and/or relative distance constraints, being formulated as an optimization problem [3]. Metric learning algorithms have key properties. Each algorithm has properties that deﬁne their applicability and suitability for the application at hand. These properties are: Learning paradigm, form of metric, scalability, optimality of the solution and dimensionality reduction. Some studies [5], [6], [7] have shown that good design metric learning can signiﬁcantly improve the k-NN classiﬁcation accuracy in batch learning. This, with the scalability property of the online distance metric learning, has motivated us to implement a new instance-based data stream classiﬁcation algorithm, learning a Mahalanobis distance metric. One solution could be to learn the metric in an online way. This approach leads to complex convex optimization problems so it is unable to address well the computational resources restrictions of data stream environments. For that reason we choose KISS Metric Learning algorithm [8], a simple statistical proposal of distance metric learning. We implement a KISSME-based variant (Keep It Simple and Straightforward MEtric) in an online setting for hybridizing it with a k-NN algorithm, being our Online-KISSME-Stream the main contribution of this paper. Then, to evaluate its performance we use streaming evaluation methodologies and implement some well comparison metrics for online learning, taking into account aspects such as concept drift detection. The rest of the paper is organized as follows. In Section II we brieﬂy review the background and related work on Mahalanobis metric learning. In Section III we describe and present the above Online-KISSME-Stream. In Section IV we report and discuss the results of our experiments',\n",
       " '0711.1056': 'During the last decade, there have been many developments in the construction and analysis of low-complexity error-correcting codes which closely approach the Shannon capacity limit of many standard communication channels with feasible complexity. These codes are understood to be codes deﬁned on graphs, together with the associated iterative decoding algorithms. Graphs serve not only to describe the codes themselves, but more importantly, they structure the operation of their eﬃcient sub-optimal iterative decoding algorithms. Proper design of codes deﬁned on graphs enables to asymptotically achieve the capacity of the binary erasure channel (BEC) under iterative message-passing decoding. Capacity-achieving sequences of ensembles of low-density parity-check (LDPC) codes were originally introduced by Shokrollahi [28] and by Luby et al. [13], and a systematic study of capacity-achieving sequences of LDPC ensembles was presented by Oswald and Shokrollahi [18] for the BEC. Analytical bounds on the maximal achievable rates of LDPC ensembles were derived by Barak et al. [6] for the asymptotic case where the block length tends to inﬁnity; this analysis provides a lower bound on 1  the gap between the channel capacity and the achievable rates of LDPC ensembles under iterative decoding. The decoding complexity of LDPC codes under iterative message-passing decoding scales linearly with the block length, though their encoding complexity is in general super-linear with the block length; this motivated the introduction of repeat-accumulate codes and their more recent variants (see, e.g., [1], [10] and [20]) whose encoding and decoding complexities under iterative message-passing decoding are both inherently linear with the block length. Due to the simplicity of the density evolution analysis for the BEC, suitable constructions of capacity-achieving ensembles of variants of repeat-accumulate codes were devised in [10], [19], [20] and [25]. All these works rely on the density evolution analysis of codes deﬁned on graphs for the BEC, and provide an asymptotic analysis which refers to the case where we let the block length of these code ensembles tend to inﬁnity. Another innovative coding technique, introduced by Shokrollahi [29], enables to achieve the capacity of the BEC with encoding and decoding complexities which scale linearly with the block length, and it has the additional pleasing property of achieving the capacity without the knowledge of the erasure probability of the channel. The performance analysis of ﬁnite-length LDPC code ensembles whose transmission takes place over the BEC was introduced by Di et al. [8]. This analysis considers sub-optimal iterative messagepassing decoding as well as optimal maximum-likelihood decoding. In [2], an eﬃcient approach to the design of LDPC codes of ﬁnite length was introduced by Amraoui et al.; this approach is specialized for the BEC, and it enables to design such code ensembles which perform well under iterative decoding with a practical constraint on the block length. In [22], Richardson and Urbanke initiated the analysis of the distribution of the number of iterations needed for the decoding of LDPC ensembles of ﬁnite block',\n",
       " '1804.02508': 'One of the most astonishing aspects of life is the overwhelming amount of diversity that has existed throughout life’s history. Ever since Charles Darwin published On the Origin of Species, evolutionary biologists have tried to understand the processes that lead to biological diversity (Darwin, 1959). On the micro scale, the question of how genetic diversity is maintained within a population has been of interest to population geneticists (Kimura and Crow, 1964; Lewontin and Hubby, 1966; Sved et al., 1967; Ayala and Campbell, 1974) for decades; work on this topic still continues to this day (Good et al., 2017). In a similar fashion, ecologists have long been interested in the ecological and evolutionary processes that lead to the origins (Rainey et al., 2000; Nosil, 2012) and maintenance (Rosenzweig, 1995; Chesson, 2000) of species diversity. The rise of cheap sequencing technologies in recent years has led to the recognition of another characteristic of biological diversity, molecular diversity (Tenaillon et al., 2012), or diversity in the sense that multiple genotypes can lead to the same phenotype (Gonz´alez-Gonz´alez et al., 2017). In other words, evolution can lead to a diversity of genetic circuits across species (Tsong et al., 2003). The evolutionary principles that lead to molecular diversity in genetic systems has been well-explored. The relationship between genotype and phenotype must be many-to-one to allow for the existence of neutral evolutionary trajectories between genotypes. Computational studies of metabolic networks, gene regulatory networks, and RNA-structure networks [reviewed in (Wagner, 2011)] all show evidence of neutral paths that conserve phenotypes between different genotypes. Many-to-one genotype-phenotype mappings are even present in artiﬁcial digital evolution systems [e.g., (LaBar et al., 2016; Fortuna et al., 2017; LaBar and Adami, 2017)] and evolutionary simulations of digital logic circuits (Raman and Wagner, 2010). Empirical studies of biological systems suggest the existence of multiple genotypes encoding similar phenotypes, either through genetic analysis (Tsong et al., 2006; Taylor et al., 2016), comparative genomics (Cross et al., 2011), or experimental evolution (Lind et al., 2015; Hope et al., 2017). However, the evolutionary reasons why populations evolve one genotype instead of another genotype, or which evolutionary processes lead to the evolution of different genotypes, are largely unexplored in biological systems due to the difﬁculty of deciphering every possible evolutionary trajectory and process, and the waiting time required for many of these evolutionary events to occur [but see (Lind et al., 2015)]. This difﬁculty presents a prime opportunity for artiﬁcial life and digital evolution studies to perform “digital genetics” and test hypotheses for why some populations, but not others, evolve certain genotypic characteristics (Adami, 2006). Genetic circuits are not the only biological network shaped by evolution. Neuronal circuits are also shaped by selective pressures, and much work has been devoted to understand those. Much of the literature',\n",
       " '1802.05581': 'In this paper we consider the following general convex optimization problem min {f (X, Y) := g (X + Y) + RX (X) + RY (Y) : X, Y ∈E} , (1) where E is a ﬁnite-dimensional normed vector space over the reals, g : E →R is assumed to be continuously diﬀerentiable and strongly convex, while RX : E →(−∞, +∞] and RY : E →(−∞, +∞] are proper, lower semicontinuous and convex functions which can be thought of either as regularization functions, or indicator functions1 of certain closed and convex feasible sets X and Y. Problem (1) captures several important problems of interest, perhaps the most wellstudied is that of Robust Principal Component Analysis (PCA) [3, 14, 11], in which the goal is to (approximately) decompose an m×n input matrix M into the sum of a low-rank matrix X and a sparse matrix Y. The underlying optimization problem for Robust PCA can be written as (see for instance [11]) min \\x1a1 2 ∥X + Y −M∥2 F : ∥X∥nuc ≤τ, ∥Y∥1 ≤s, X, Y ∈Rm×n \\x1b , (2) 1An indicator function of a set is deﬁned to be 0 in the set and +∞outside. 1 arXiv:1802.05581v3  [cs.LG]  15 Nov 2019  where ∥·∥F denotes the Frobenius norm, ∥·∥nuc denotes the nuclear norm, i.e., the sum of singular values, which is a highly popular convex surrogate for low-rank penalty, and ∥·∥1 is the entry-wise ℓ1-norm, which is a well-known convex surrogate for entry-wise sparsity. Other variants of interest of Problem (2) are when the data matrix M is a corrupted covariance matrix, in which case it is reasonable to further constrain X to be positive semideﬁnite, i.e., use the constraints X ⪰0 and Tr(X) ≤τ. In the case that M is assumed to have several fully corrupted rows or columns, a popular alternative to the ℓ1-norm regularizer on the variable Y is to use either the norm ∥·∥1,2 (sum of ℓ2-norm of rows) in case of corrupted rows, or the norm ∥·∥2,1 (sum of ℓ2-norm of columns) in case of corrupted columns, as a regularizer/constraint [15]. Finally, moving beyond Robust PCA, a diﬀerent choice of interest for the loss g (·) could be g (Z) := (1/2) ∥AZ −M∥2 F , where A is a linear sensing operator such that AT A is positive deﬁnite (so g (·) is strongly convex). In this paper we present an algorithm and analyses that build on the special structure of Problem (1), which improve upon state-of-the-art complexity bounds, under several diﬀerent assumptions. A common key to all of our results is the ability to exploit the strong convexity of g(·) to obtain improved complexity bounds. Here it should be noted that while g (·) is assumed to be strongly convex, Problem (1) is in general not strongly convex in (X, Y). This can already be observed when choosing g (z) := 1 2 ∥z∥2 2, and RX (·) = RY (·) = 0, where x, y ∈Rd. In this',\n",
       " '1808.06645': 'Deep Neural Networks (DNNs) perform impressively well in classic machine learning areas such as image classiﬁcation, segmentation, speech recognition and language translation [1, 2, 3]. These results have lead to DNNs being increasingly deployed in production settings, including self-driving cars, on-the-ﬂy speech translation, and facial recognition for identiﬁcation. However, like previous machine learning approaches, DNNs have been shown to be vulnerable to adversarial attacks during test time [4]. The existence of such adversarial examples suggests that DNNs lack robustness, and might not be learning the higher level concepts we hope they would learn. Increasingly, it seems that the attackers are winning, especially when it comes to white box attacks where access to network architecture and parameters is granted. Several approaches have been proposed to protect against adversarial attacks. Traditional defense mechanisms are designed with the goal of maximizing the perturbation necessary to trick the network, and making it more obvious to a human eye. However, iterative optimization of adversarial examples by computing gradients in a white box environment or estimating gradients using a surrogate model Preprint. Work in progress. arXiv:1808.06645v2  [cs.LG]  8 Sep 2018  in a black-box setting have been shown to successfully break such defenses. While these methods are theoretically interesting as they can shed light on the nature of potential adversarial attacks, there are many practical applications in which being perceptible to a human is not a reasonable defense against an adversary. For example, in a self-driving car setting, any deep CNN applied to analyzing data originating from a non-visible light spectrum (e.g. LIDAR), could not be protected even by an attentive human observer. It is necessary to generate ‘complete’ defenses which preclude the existence of adversarial attacks against the model. This requires deeper understanding of the mechanisms which make ﬁnding adversarial examples against deep learning models so simple. In this paper, we review characteristics of such mechanisms and propose a novel defense method inspired by our understanding of the problem. In a nutshell, the method makes use of the depth of neural networks to create an exponential population of defenses for the attacker to overcome, and employs randomness to increase the difﬁculty of successfully ﬁnding an attack against the population. 2 Related Work Adversarial examples in the context of DNNs have come into the spotlight after Szegedy et al. [4], showed the imperceptibility of the perturbations which could fool state-of-the-art computer vision systems. Since then, adversarial examples have been demonstrated in many other domains, notably including speech recognition [5], and malware detection[6]. Nevertheless, Deep Convolutional Neural Networks (CNNs) in computer vision provide a convenient domain to explore adversarial attacks and defenses, both due to the existence of standardized test datasets, high performing CNN models reaching human or super-human accuracy on clean data, and the marked deterioration of their performance when subjected to adversarial examples to which human vision is robust. In order to construct effective defenses against adversarial attacks, it is important',\n",
       " '1402.2224': '1 1.1 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 1.2 Our Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2 2 Preliminaries 4 2.1 Preliminaries from Privacy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 2.2 Preliminaries from Learning Theory . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 2.3 Private Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 2.4 The Exponential Mechanism . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 2.5 Concentration Bounds . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 3 The Sample Complexity of Private Learners 6 3.1 Equivalence of (α, β)-Probabilistic Representation and Private Learning . . . . . . . 7 4 From a Probabilistic Representation to a Deterministic Representation 14 5 Probabilistic Representation for Privately Solving Optimization Problems 17 5.1 Exact 3SAT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21 6 Extensions 21 6.1 (ǫ, δ)-Diﬀerential Privacy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21 6.2 Probabilistic Representation Using a Hypothesis Class . . . . . . . . . . . . . . . . . 22 7 A Probabilistic Representation for Points 24  1 Introduction Motivated by the observation that learning generalizes many of the analyses applied to large collections of data, Kasiviswanathan el al. [17] deﬁned in 2008 private learning as a combination of probably approximately correct (PAC) learning [20] and diﬀerential privacy [12]. A PAC learner is given a collection of labeled examples (sampled according to an unknown probability distribution and labeled according to an unknown concept) and generalizes the labeled examples into a hypothesis h that should predict with high accuracy the labeling of fresh examples taken from the same unknown distribution and labeled with the same unknown concept. The privacy requirement is that the choice of h preserves diﬀerential privacy of sample points. Intuitively this means that this choice should not be signiﬁcantly aﬀected by any particular sample. Diﬀerential privacy is increasingly accepted as a standard for rigorous privacy and recent research has shown that diﬀerentially private variants exists to many analyses. We refer the reader to surveys of Dwork [10, 11]. The sample complexity required for learning a concept class C determines the amount of labeled data needed for learning a concept c ∈C. It is well known that the sample complexity of learning a concept class C (non-privately) is proportional to a complexity measure of the class C knowns as the VC-dimension [21, 7, 14]. Kasiviswanathan et al. [17] proved that a private learner exists for every ﬁnite concept class. The proof is via a generic construction that exhibits sample complexity logarithmic in the size of the concept class. The VC-dimension of a concept class is bounded by this quantity (and signiﬁcantly lower for some interesting concept classes), and hence the results of [17] left open the possibility that the sample complexity of private learning may be signiﬁcantly higher than that of non-private learning. In analogy to the characterization of the sample complexity of (non-private) PAC learners via the VC-dimension, we give a combinatorial characterization of the sample size suﬃcient and necessary for private PAC learners. Towards obtaining this characterization, we introduce the notion of probabilistic representation of a concept class. We note that our characterization, as the VC-dimension characterization, ignores the computation required by the learner. Some of our algorithms are, however, computationally eﬃcient. 1.1 Related Work We start with a short description',\n",
       " '1509.01951': 'Deep learning based vision architectures learn to extract & represent visual features with model  architectures that are composed of layers of non-linear transformations stacked on top of each  other [1]. They learn high level abstractions from low level features extracted from images  utilizing supervised or unsupervised learning algorithms. Recent advances in training CNNs  with gradient descent based backpropagation algorithm have shown very accurate results due to  inclusion of rectified linear units as nonlinear transformation [2]. Also extension of  unsupervised learning algorithms that train deep belief networks towards training convolutional  networks have exhibited promise to scale it to realistic image sizes [4]. Both the supervised and  unsupervised learning approaches have matured and have provided architectures that can   successfully classify objects in 1000 & 100 categories respectively. Yet both the approaches  cannot be scaled realistically to classify objects from 10K categories.     The need for large scale object recognition is ever relevant today with the explosion of the  number of individual objects that are supposed to be comprehended by artificial vision based  solutions. This requirement is more pronounced in use case scenarios as drone vision,  augmented reality, retail, image search & retrieval, industrial robotic navigation, targeted  advertisements etc. The large scale object recognition will enable the recognition engines to  cater to wider spectrum of object categories. Also the mission critical use cases demand higher  level of accuracy simultaneously with the large scale of objects to be recognized.    In this paper, we propose a two level hierarchical deep learning architecture that achieves  compelling results to classify objects in 10K categories. To the best of our knowledge the  proposed method is the first attempt to classify 10K objects utilizing a two level hierarchical  deep learning architecture. Also a blend of supervised & unsupervised learning based leaf level  models is proposed to overcome labelled data scarcity problem. The proposed architecture  provides us with the dual benefit in the form of providing the solution for large scale object  recognition and at the same time achieving this challenge with greater accuracy than being  possible with a 1-level deep learning architecture.    2. RELATED WORKS  We have not come across any work that uses 2-level hierarchical deep learning architecture to  classify 10K objects in images. But object recognition on this large scale using shallow  architectures utilizing SVMs is discussed in [5]. This effort presents a study of large scale  categorization with more than 10K image classes using multi-scale spatial pyramids (SPM) [14]  on bag of visual words (BOW) [13] for feature extraction & Support Vector Machines (SVM)  for classification.     This work creates ten different datasets derived from ImageNet each with 200 to 10,000  categories. Based on these datasets it outlines the influence on classification accuracy due to  different factors like number of labels in a dataset, density of the dataset and the hierarchy of  labels in a dataset. The methods are proposed which provide extended information to the  classifier on the relationship between different labels by defining a hierarchical cost. This cost is  calculated as the height of the lowest',\n",
       " '1510.08583': 'The rapid increase in multi-media sharing through social networking sites such as Facebook, Flickr, and Instagram can cause potential threats to users’ privacy. Many users are quick to share private images about themselves, their family and friends, without thinking much about the consequences of an unwanted disclosure of these images. Moreover, social networking sites such as Facebook, allow users to tag other people, which can reveal private information of the users in a particular image (Ahern et al. 2007). Gross and Acquisti (2005) analyzed more than 4,000 Carnegie Mellon University students’ Facebook proﬁles and outlined potential threats to privacy. Users often provide personal information generously on online social networking websites, but hardly make use of limiting privacy preferences. Additionally, they rarely change default privacy settings, which could jeopardize their privacy (Zerr et al. 2012). Current social networking sites do not assist users in making privacy decisions for images that they upload online. Manually assigning privacy settings to each image each time can be cumbersome. To avoid a possible loss of a user’s privacy, it has become critical to develop automated approaches that can accurately predict the privacy settings for images that are shared online. Several studies have started to explore classiﬁcation models of image privacy using image tags and image content features such as SIFT (or Scale Invariant Feature Transform) or RGB (or Red Green Blue) (Zerr et al. 2012; Squicciarini, Caragea, and Balakavi 2014) and found that image tags are very informative for the task of classifying images as public or private. However, given large collections of image training data available these days (e.g., the ILSVRC-2012 subset of the ImageNet dataset (Russakovsky et al. 2015) that has 1.2M+ images labeled with 1000 categories), recent deep neural networks are now able to learn powerful features that go beyond SIFT and RGB (Donahue et al. 2013; Donahue et al. 2014) and work remarkably well in many image analysis tasks such as generating short sentence descriptions of images and videos (Venugopalan et al. 2015). In this paper, we explore an approach to privacy prediction that uses deep visual features and deep tags for predicting the class of an image as public or private. Speciﬁcally, we use three deep feature representations corresponding to the output of three layers of an eight-layer deep neural network pre-trained on the above ILSVRC-2012 (Russakovsky et al. 2015), as well as the probability distribution over categories obtained from the last layer of the network via softmax. We further investigate deep tags, which correspond to the top ranked probabilities from the probability distribution over categories. We analyze image tags with respect to privacy settings and use information gain and tag frequency to identify informative tags. Our Contributions. • We show that models trained using traditional visual features such as “SIFT” and “GIST” yield very low performance with respect to the private class. • We explore deep visual features and deep tags for privacy',\n",
       " '1805.01220': 'Multicolor ﬂuorescence in situ hybridization (mFISH) is a cytogenetic methodology that allows the simultaneous visualization of each chromosome pair in a diﬀerent color, providing a genome-wide picture of cytogenetic abnormalities in a single experiment (Speicher et al., 1996; Schrock et al., 1996). It was introduced in 1996 as spectral karyotyping (SKY) (Schrock et al., 1996) and multiplex-FISH (M-FISH) (Speicher et al., 1996), similar methodologies in terms of labeling but diﬀering in terms of imaging system requirements and image acquisition and analysis process. After the mFISH spectral information has been acquired, diﬀerent features can be Preprint submitted to Cytometry Part A May 4, 2018  analyzed to assign a chromosome label to each pixel. Manual interpretation of mFISH images is a time-consuming task where not only the intensity of each pixel is compared across channels but also the shape, size and centromere position. Many attempts were made to automate the task, being the most notable approaches pixel and region based classiﬁers. These classiﬁers usually build a feature vector using pixel or patch based intensity information and use that information to train a classiﬁer, which is later used to classify pixels from the same image (Wang et al., 2017; Li et al., 2012), or from a diﬀerent one (Choi et al., 2004, 2008). Multiple pixel based classiﬁers have been developed for the analysis of mFISH images, showing that the spectral information present in a pixel can be successfully used to train machine learning classiﬁers. (Schwartzkopf et al., 2005; Choi et al., 2008). In the other hand, region based classiﬁcation has also been studied, showing that it generally outperforms pixel based classiﬁcation approaches.(Li et al., 2012; Wang et al., 2017), underlining the importance of using spatial information to improve the performance of mFISH analysis algorithms. Despite the relative success of the above mentioned approaches, none of them take into account spatial information about the shape, size, or texture of the objects being analyzed. This limits the performance of the algorithms in challenging scenarios where the identiﬁcation of the chromosome is not clear based only on the spectral information. Some important features typically used in manual analysis, but not incorporated into classiﬁcation algorithms, are the relative length of a chromosome, the arm ratio, or the centromeric index (Lejeune et al., 1960). Such features can be automatically learned running the input images through a network of convolutions and resampling operations, comparing the resulting image to the expected segmentation map, and backpropagating the error to learn the network parameter. This approach is usually called “end to end semantic segmentation”. End to end semantic segmentation using convolutional networks has been shown to achieve state of the art results by automatically learning features based on spatial and intensity information (Ronneberger et al., 2015; Badrinarayanan et al., 2015; Chen et al., 2016). The convolutional network approach shifts the focus from feature engineering to network architecture engineering, searching for the best network layout for a given problem. In',\n",
       " '1501.06206': 'We live in a constantly changing world, and consequently our beliefs have to be revised whenever there is new information. When we encounter a new piece of information that contradicts our current beliefs, we revise our beliefs rationally. arXiv:1501.06206v2  [cs.LO]  27 Jan 2015  In the last three decades, the ﬁeld of computer science has grown substantially beyond mere number crunching, and aspires to imitate rational thinking of human beings. A separate branch of study, artiﬁcial intelligence (AI) has evolved, with a number of researchers attempting to represent and manipulate knowledge in a computer system. Much work has been devoted to study the statics of the knowledge, i.e. representing and deducting from ﬁxed knowledge, resulting in the development of expert systems. The ﬁeld of logic programming, conceived in last seventies, has proved to be an important tool for handling static knowledge. However, such ﬁxed Horn knowledge based systems can not imitate human thinking, unless they are accomplish revising their knowledge in the light of new information. As mentioned before, this revision has to take place rationally. This has led to a completely new line of research, the dynamics of belief. Studies in dynamics of belief are twofold: What does it mean to rationally revise a belief state? How can a belief state be represented in a computer and revised? The ﬁrst question is more philosophical theory, and a lot of works have been carried out from epistemological perspective to formalize belief dynamics. The second question is computation oriented, and has been addressed diﬀerently from various perspectives of application. For example, a lot of algorithms have been proposed in logic programming to revise a Horn knowledge base or a database represented as a logic program; number of algorithms are there to carry out a view update in a rational database; algorithm to carry out diagnosis; algorithm for abduction reasoning and so on. We need the concept of ”change” in some form or other and thus need some axiomatic characterization to ensure that the algorithms are rational. Unfortunately, till this date, these two tracks remain separate, with minimal sharing of concepts and results. The primary purpose of the paper is to study these two developments and integrate them. When a new piece of information is added to a Horn knowledge base (Delgrande 2008 and Delgrande & Peppas 2011), (Papini 2000) it may become inconsistent. Revision means modifying the Horn knowledge base in order to maintain consistency, by keeping the new information and removing the least possible previous information. In our case, update means revision and contraction, that is insertion and deletion in database perspective. Previous works (Aravindan & Dung 1994), (Aravindan 1995) have explained connections between contraction and knowledge base dynamics. Our Horn knowledge base dynamics is deﬁned in two parts: an immutable part (Horn formulae) and updatable part (literals) (for deﬁnition and properties see the works of Nebel 1998, Segerberg 1998, Hansson et al 2001 and Ferm´e & Hansson 2001). Knowledge bases have a set',\n",
       " '1809.06065': 'O BJECT detection in 3D is still challenging in robotics perception, the applied scenes of which widely include urban and suburban roads, highways, bridges and indoor settings. Robots recognize and localize key objects from data in the 3D form and predict their locations, sizes and orientations, which provides both semantic and spatial information for high-level decision making. The point cloud is one of the most commonly used 3D data forms, and can be gathered by range cameras, like LiDAR and RGB-D cameras. Since the coordinate information of point clouds is not inﬂuenced by appearance changes, point clouds are also robust in extreme weather and various seasons. In addition, it is naturally scaleinvariant. The scale of an object is invariant anywhere in a point cloud, while it always changes in an image due to foreshortening effects. Moreover, the increasing perception distance and decreasing price of 3D LiDARs make them a promising direction for autonomous driving researchers [1]. Current image-based detectors beneﬁt from translation invariance from convolution operations and can perform with human-comparable accuracy. However, the successful imagebased architectures cannot be directly applied in 3D space. Point-cloud-based object detection consumes point clouds which are sparse point lists instead of dense arrays. If drawing arXiv:1809.06065v3  [cs.CV]  16 Jan 2019  2 on the success of image-based detectors and conducting dense convolution operation to acquire translation invariance, preprocessing must be implemented to convert the sparse point clouds into dense arrays. Otherwise, special layers should be carefully designed to extract meaningful features from the sparse inputs. Additionally, the fore-background imbalance is much more serious than in 2D scenarios, since the new zaxis further enlarges the searching space and the extent of imbalance is different for each different z value. Lin et al.[2] proposed focal loss to tackle the forebackground imbalance in image-based object detection, so that one-stage detectors could achieve state-of-the-art accuracy as two-stage detectors. As a hard-mining improvement of binary cross entropy, it helps the network focus on hard classiﬁed objects, in case they are overwhelmed by a large number of easily classiﬁed objects. Similar to image-based detection methods, point-cloudbased detection methods can also be classiﬁed into twostage [3], [4], [5] and one-stage detectors [6], [7]. In this paper, inspired by [2], we aim to solve the fore-background imbalance for 3D object detection through the focal loss. We claim the following contributions: • We extend focal loss to 3D object detection to solve the huge fore-background imbalance in one-stage detectors, and conduct experiments on two different one-stage 3D object detectors, 3D-FCN [6] and VoxelNet [7]. The experiment results demonstrate up to 11.2AP gains from the focal loss in a wide range of hyperparameters. • To further understand focal loss in 3D object detection, we analyze its effect towards foreground and background estimations, and validate that it plays a role similar',\n",
       " '0911.4530': 'Determining the capacity of a multiple-input multipleoutput (MIMO) interference channel (IC) is a long standing open problem. Recently, by assuming that some channel matrices are invertible, [1] derived the capacity region of MIMO ICs with average power constraints under strong interference, and sum-rate capacities under noisy interference and mixed interference. Those results were extended to MIMO ICs with average covariance constraints in [2]. Later, the noisy interference sum-rate capacity of a MIMO IC with an average power constraint was also considered in [3]. While the corresponding result in [1] requires that all the input covariance matrices satisfy a closed-form condition, [3] requires that the optimal solution of a non-convex optimization problem be non-singular and satisfy a complex condition. We note that neither [1] nor [3] includes the other as a special case. In this paper, we consider the capacity of a MIMO Zinterference channel (ZIC) in which the received signals are deﬁned as yyy1 = H1xxx1 + Fxxx2 + zzz1 and yyy2 = H2xxx2 + zzz2, (1) where xxxi is the transmitted signal of user i, i = 1, 2; Hi and F are channel matrices known at both transmitters and receivers; and zzzi is a zero-mean circularly symmetric complex Gaussian random vector with identity covariance matrix, i.e., zzzi ∼CN (0, I). Transmitter i and receiver i have ti and ri antennas, respectively. The transmitted signal xxxi is subject to a power constraint, denoted as P, that takes a form from any one of the following: n X j=1 E h xxxijxxx† ij i ⪯n¯Si, (2) This work was supported in part by the National Science Foundation under Grants CNS-09-05398, CCF-09-05320 and CCF-09-05235. n X j=1 tr \\x10 E h xxxijxxx† ij i\\x11 ≤n ¯Pi, (3) tr \\x10 E h xxxijxxx† ij i\\x11 ≤Pi, j = 1, · · · , n, or (4) n X j=1 \\x10 E h xxxijxxx† ij i\\x11 k ≤n ¯Pik, k = 1, · · · , ti, (5) where the channel is assumed to be used n times and xxxij is the transmitted signal of user i at time j. Here, E[·] denotes expectation; (·)† denotes the Hermitian of a matrix; A ⪰B means that A and B are both semi-positive deﬁnite Hermitian matrices and A−B is also semi-positive deﬁnite; tr(·) denotes the trace of a matrix; and (·)k denotes the kth diagonal element of a square matrix. Constraints (2)-(5) are referred to respectively as the expected block covariance constraint, the expected block power constraint, the expected per-symbol power constraint, and the expected per-antenna block power constraint. In this paper, we generalize the results of [1] and [2] to the cases in which the channel matrices can be arbitrary, and the constraint can be any one from (2)-(5). Speciﬁcally, we derive the capacity regions under very strong and aligned strong interference which are achieved by fully decoding the interference; and the sum-rate capacity under noisy interference which is achieved by treating the',\n",
       " '1704.01523': 'FAILED',\n",
       " '1809.08343': 'Concerns about the ways in which cyber-physical and/or autonomous decision making systems behave when deployed in the real world are growing: what various stakeholder are worried about is that the systems achieves its goal in ways that are not considered acceptable according to values and norms of the impacted community, also called “speciﬁcation gaming” behaviors. Thus, there is a growing need to ∗On leave from the University of Padova. understand how to constrain the actions of an AI system by providing boundaries within which the system must operate. To tackle this problem, we may take inspiration from humans, who often constrain the decisions and actions they take according to a number of exogenous priorities, be they moral, ethical, religious, or business values (Sen 1974), and we may want the systems we build to be restricted in their actions by similar principles (Arnold et al. 2017). The overriding concern is that the autonomous agents we construct may not obey these values on their way to maximizing some objective function (Simonite 2018). The idea of teaching machines right from wrong has become an important research topic in both AI (Yu et al. 2018) and farther aﬁeld (Wallach and Allen 2008). Much of the research at the intersection of artiﬁcial intelligence and ethics falls under the heading of machine ethics, i.e., adding ethics and/or constraints to a particular system’s decision making process (Anderson and Anderson 2011). One popular technique to handle these issues is called value alignment, i.e., the idea that an agent can only pursue goals that follow values that are aligned to the human values and thus beneﬁcial to humans (Russell, Dewey, and Tegmark 2015). Another important notion for these autonomous decision making systems is the idea of transparency or interpretability, i.e., being able to see why the system made the choices it did. Theodorou, Wortham, and Bryson (2016) observe that the Engineering and Physical Science Research Council (EPSRC) Principles of Robotics dictates the implementation of transparency in robotic systems. The authors go on to deﬁne transparency in a robotic or autonomous decision making system as, “... a mechanism to expose the decision making of the robot”. This still leaves open the question of how to provide the behavioral constraints to the agent. A popular technique is called the bottom-up approach, i.e., teaching a machine what is right and wrong by example (Allen, Smit, and Wallach 2005). In this paper, we adopt this approach as we consider the case where only examples of the correct behavior are available to the agent, and it must therefore learn from only arXiv:1809.08343v1  [cs.LG]  21 Sep 2018  these examples. We propose a framework which enables an agent to learn two policies: (1) πR which is a reward maximizing policy obtained through direct interaction with the world and (2) πC which is obtained via inverse reinforcement learning over demonstrations by humans or other',\n",
       " '1811.09678': 'During the last decade, deep neural networks (DNN) have encountered a wide success in automatic speech recognition. Many architectures such as recurrent (RNN) [34, 15, 1, 31, 13], time-delay (TDNN) [39, 28], or convolutional neural networks (CNN) [42] have been proposed and achieved better performances than traditional hidden Markov models (HMM) combined with gaussian mixtures models (GMM) in different speech recognition tasks. However, despite such evolution of models and paradigms, the acoustic feature representation remains almost the same. The acoustic signal is commonly split into time-frames, for which Mel-ﬁlter banks energies, or Mel frequency scaled cepstral coefﬁcients (MFCC) [8] are extracted, alongside with the ﬁrst and second order derivatives. In fact, time-frames are characterized by 3-dimensional features that are related by representing three different views of the same basic element. Consequently an efﬁcient neural networks-based 32nd Conference on Neural Information Processing Systems (NIPS 2018), Montréal, Canada. arXiv:1811.09678v1  [eess.AS]  21 Nov 2018  model has to learn both external dependencies between time-frames, and internal relations within the features. Traditional real-valued architectures deal with both dependencies at the same level, due to the lack of a dedicated mechanism to learn the internal and external relations separately. Quaternions are hypercomplex numbers that contain a real and three separate imaginary components, ﬁtting perfectly to three and four dimensional feature vectors, such as for image processing and robot kinematics [35, 29, 4]. The idea of bundling groups of numbers into separate entities is also exploited by the recent capsule network [33]. Contrary to traditional homogeneous representations, capsule and quaternion neural networks bundle sets of features together. Thereby, quaternion numbers allow neural models to code latent inter-dependencies between groups of input features during the learning process with up to four times less parameters than real-valued neural networks, by taking advantage of the Hamilton product as the equivalent of the dot product between quaternions. Early applications of quaternion-valued backpropagation algorithms [3, 2] have efﬁciently solved quaternion functions approximation tasks. More recently, neural networks of complex and hypercomplex numbers have received an increasing attention [16, 38, 7, 40], and some efforts have shown promising results in different applications. In particular, a deep quaternion network [24, 25, 37], and a deep quaternion convolutional network [5, 27] have been successfully employed for challenging tasks such as images and language processing. Contributions: This paper proposes to evaluate previously investigated quaternion-valued models in two different realistic conditions of speech recognition, to see whether the quaternion encoding of the signal, alongside with the quaternion algebra and the important parameter reduction help to better capture the acoustic signal nature, leading to a more expressive representation of the information. Based on the TIMIT [10] phoneme recognition task, a quaternion convolutional neural network (QCNN) is compared to a real-valued CNN in a end-to-end framework, and a quaternion recurrent neural network (QRNN) is compared to an RNN within a more traditional HMM-based system. In the end-to-end approach',\n",
       " '1002.2780': 'Trace-norm regularization is a popular approach for matrix completion and collaborative ﬁltering, motivated both as a convex surrogate to the rank (Fazel et al., 2001; Candes & Tao, 2009) and in terms of a regularized inﬁnite factor model with connections to large-margin norm-regularized learning (Srebro et al., 2005b; Bach, 2008; Abernethy et al., 2009; Salakhutdinov & Mnih, 2008). Current theoretical guarantees on using the tracenorm for matrix completion all assume a uniform sampling distribution over entries of the matrix (Srebro & Shraibman, 2005; Candes & Tao, 2009; Candes & Recht, 2009; Candes & Tao, 2009; Recht, 2009). In a collaborative ﬁltering setting, where rows of the matrix represent e.g. users and columns represent e.g. movies, this corresponds to assuming all users are equally likely to rate movies and all movies are equally likely to be rated. This of course cannot be further from the truth, as in any actual collaborative ﬁltering application, some users are much more active then others and some movies are rated by many people while others are much less likely to be rated. In Section 3 we show, both analytically and through simulations, that this is not a deﬁciency of the proof techniques used to establish the above guarantees. Indeed, a non-uniform sampling distribution can lead to a signiﬁcant deterioration in prediction quality and an increase in the sample complexity. Under non-uniform sampling, as many as Ω(n4/3) samples might be needed for learning even a simple (e.g. orthogonal low rank) n × n matrix. This is in sharp contrast to the uniform sampling case, in which ˜O(n) samples are enough. It is important to note that if the rank could be minimized directly, which is in general not computationally tractable, ˜O(n) samples would be enough to learn a low-rank model even under an arbitrary non-uniform distribution. In Section 4 we suggest a correction to the tracenorm regularizer, which we call the weighted tracenorm, that takes into account the sampling distribution. This correction is motivated by our analytic analysis and we discuss how it corrects the problems that the unweighted trace-norm has with non-uniform sampling. We then show how the weighted trace-norm indeed yields a signiﬁcant improvement on the (highly non-uniformly sampled) Netﬂix dataset. 2. Complexity Control in terms of Matrix Factorizations Consider the problem of predicting the entries of some unknown target matrix Y ∈Rn×m based on a random subset S of observed entries YS. For example, n and m may represent the number of users and the number of movies, and Y may represent a matrix of partially observed rating values. Predicting elements of Y can be done by ﬁnding a matrix X minimizing the training error, here measured as a squared error, and some measure c(X) of complexity. That is, minimizing either: min X ∥XS −YS∥2 F + λc(X) (1)  Learning with the',\n",
       " '1204.4249': 'In his early work [9], Shannon proved that feedback could not increase the capacity of a point-to-point memoryless channel. However, feedback could improve error performance and simplify the transmission scheme for this kind of channel. In [10], Horstein proposed a simple sequential transmission scheme, which achieves the capacity of Binary Symmetric Channel (BSC) and provides larger error exponents than traditional ﬁxed length block coding. Besides, Schalkwijk and Kailath also showed that feedback could improve error performance and/or simplify the transmission scheme for the point-to-point Gaussian channel [7], [8]. For Gaussian multiuser channels, the situation is more interesting. In [12], Gaarder and Wolf proved that feedback can enlarge the capacity region of the multiple access channel, and Ozarow [3] successfully constructed a simple coding scheme for the two user Gaussian MAC with feedback and reafﬁrmed that feedback could increase the capacity of the channel. Furthermore, Kramer devised a code for complex Gaussian channel based on a beautiful property of the circulant matrix that has all columns of the DFT (Discrete Fourier Transform) matrix as its eigenvectors [14]. This code was proved to obtain the linear-feedback sum-capacity of the symmetric Gaussian channel with feedback in [16]. By using the control-theoretic approach to communications with feedback, Ardestanizadeh and Fraceschetii [17] also proposed a linear code that has the same performance as Kramer’s code for symmetric Gaussian complex channels. Recently, Shayevitz and Feder [1], [2], and [4] have discovered an underlying principle between the Horstein and Schalkwijk-Kailth schemes in a simple encoding scheme called posterior matching scheme for general point-to-point memoryless channels. The idea of posterior matching is that the transmitter encapsulates the information the receiver does not know up to present time in one random variable and then transmits that random variable to the receiver in the next transmission to reﬁne the receiver’s knowledge. The distribution of that variable will be selected in a way such that the input constraint is satisﬁed. Later, Bae and Anastasopolous extended this scheme for the ﬁnite-state channel with feedback by using another approach [11]. Ma and Coleman provided a viewpoint on posterior matching from stochastic control perspectives [18] and generalized this encoding scheme to higher dimension via optimal transportation [19]. One interesting open problem is to extend the Shayevitz and Feder posterior matching scheme for multiuser cases. In this paper, using the same approach as Shayevitz and Feder used for point-to-point memoryless channels, we propose a posterior matching based encoding and decoding strategy for real Gaussian MACs, referred to as a timevarying posterior matching scheme, and analyze the error probabilities for all encoding-decoding schemes designed by using these strategies. We analyze the achievable rate region and error performance of encoding and decoding schemes using these strategies by deﬁning a generalized iterated function systems (GIFS) which has the generalized average contractive property (asymptotically average contractive). Refer to our Theorem I for more details',\n",
       " '1610.00843': 'Mixture models denote the statistical setting where observed samples can come from one of several distinct underlying populations – each typically with its own probability distribution – but are not labeled as separate in the data presented. They have been used to model a wide variety of phenomena, and have seen great success in practice, going back as far as Pearson [1894]. In this paper we consider (what we call) the search problem in the mixture model setting: given some special side information about one of the mixture components, is it possible to eﬃciently learn the parameters of that component only? Given that there are known methods for learning the entire set of parameters of various mixture models, “eﬃcient” here means more eﬃcient (statistically and/or computationally) than existing methods for learning all the parameters. As an example, we consider the “latent Dirichlet allocation” model for document generation. In this model, “underlying population” means the set of topics in a document, which determines the frequencies of diﬀerent words in the document. “Side information” could be a word that is more common in the topic of interest than it is in any other topic: for example, the word “semi-supervised” might work if the topic of interest is machine learning. ∗avik@utexas.edu †neeman@iam.uni-bonn.de ‡sanghavi@mail.utexas.edu §shakkott@austin.utexas.edu 1  Side information could also consist of a small number of labelled examples. We might have a small collection of documents about machine learning and also a much larger corpus that includes documents from many topics. Our methods will allow us to leverage the large, unlabelled corpus to obtain good estimates for word frequencies in machine learning articles – and these estimates will be much better than anything that could be learned from the small labelled sample. Main contributions: We propose a general setting for side information in mixture models, and show how to solve the search problem by estimating certain matrices of moments. We prove error bounds on the resulting estimates; our rates have a sharp dependence on the sample size (although they are possibly not sharp in the other parameters). We then specialize our approach to four popular families of mixture models: Gaussian mixture models with spherical covariances, latent Dirichlet allocation for topic models, mixed linear regression, and subspace clustering. We give concrete algorithms for these four families. Our results also include new moment derivations for mixed linear regression and subspace clustering models. Finally, we simulate our algorithm on both real and synthetic data sets for the Gaussian mixture model, topic model, and subspace clustering applications. For synthetic data set we compare its performance to the tensor decomposition methods discussed by Anandkumar et al. [2014] in both GMM and LDA models, and k-means for subspace clustering. We show that our methods outperform the baseline when the side information is informative. We also demonstrate the practical applicability of our algorithms on three real data sets – the NY Times data set of news articles, Yelp data set',\n",
       " '1511.09180': 'Adaptive networks consist of a collection of agents with learning abilities. The agents interact with each other on a local level and diffuse information across the network to solve inference and optimization tasks in a decentralized manner. Such networks are scalable, robust to node and link failures, and are particularly suitable for learning from big data sets by tapping into the power of collaboration among distributed agents. The networks are also endowed with cognitive abilities due to the sensing abilities of their agents, their interactions with their neighbors, and the embedded feedback mechanisms for acquiring and reﬁning information. Each agent is not only capable of sensing data and experiencing the environment directly, but it also receives information through interactions with its neighbors and processes and analyzes this information to drive its learning process. As already indicated in [1], [5], there are many good reasons for the peaked interest in networked solutions, especially in this day and age when the word “network” has become commonplace whether one is referring to social networks, power networks, transportation networks, biological networks, or other networks. Some of these reasons have to do with the beneﬁts of cooperation over networks in terms of improved performance and improved robustness and resilience to failure. Other reasons deal with privacy and secrecy considerations where agents may not be comfortable sharing their data with remote fusion centers. In other situations, the data may already be available in dispersed locations, as happens with cloud computing. One may also be interested in learning and extracting information through data mining from large data sets. Decentralized learning procedures offer an attractive approach to dealing with such data sets. Decentralized mechanisms can also serve as important enablers for the design of robotic swarms, which can assist in the exploration of disaster areas. A. Asynchronous Behavior The survey article [1] and monograph [5] focused on the case of synchronous networks where data arrive at all agents in a synchronous manner and updates by the agents are also performed in a synchronous manner. The network topology was assumed to remain largely static during the adaptation process. Under these conditions, the limits of performance and stability of these networks were identiﬁed in some detail for two main classes of distributed strategies: consensus and diffusion constructions. In this chapter, we extend the overview from [1] to cover asynchronous environments. In such environments, the operation of the network can suffer from the occurrence of various random events including randomly changing topologies, random link failures, random data arrival times, and agents turning on and off randomly. Agents may also stop updating their solutions or may stop sending or receiving information in a random manner and without coordination with other agents. Results in [2]–[4] examined the implications of such asynchronous events on network performance in some detail and under a fairly To appear as book chapter in Cooperative and Graph Signal Processing, P. Djuric and C. Richard, editors, Elsevier, 2018. The work in this book chapter was supported in part by',\n",
       " '1808.04816': 'Information Extraction (IE) systems read text to extract entities, and relations and create beliefs represented in a knowledge graph. Current systems though are far from perfect: e.g., in the 2017 Text Analysis Conference (TAC) Knowledge Base Population task, participants created knowledge graphs with relations like cause of death and city of headquarters from news corpora (Dang, 2017). When manually evaluated, no system had achieved an F1 score above 0.3 (Rajput, 2017). One reason for such low scores is inconsistency between the text and the extracted beliefs. We consider a belief to be consistent if the text from which it was extracted linguistically supports it (regardless of any logical or real-world factual truth). We show the difference between consistent and inconsistent readings, along with a potential correction, in Fig. 1. In Fig. 1a, the system considered Harry Reid was charged with an assault, which is not ∗*This work was done while the ﬁrst author was doing his Ph.D. at the University of Maryland, Baltimore County and before joining Philips Research North America. consistent with the provenance sentence. In Fig. 1b the system is consistent in constructing its belief. Belief learned by IE system: per:charges(Harry Reid, assault) Provenance identiﬁed by IE system: Nevada’s Harry Reid switches longtime stance to support assault weapon ban Analysis output: Is reading consistent: Inconsistent Suggested relation: no repair (a) An inconsistent reading with no correction. Belief learned by IE system: per:cause_of_death(Edward Hardman, Typhoid fever) Provenance identiﬁed by IE system: The Western Australian government agreed to offer the Government Geologist post to Hardman shortly before news of his death reached them . Early in April , he contracted typhoid fever , and died a few days later in a Dublin hospital on 6 April Analysis output: Is reading consistent: Consistent Suggested relation: per:cause_of_death (b) A consistent reading not requiring a correction. Notice the relation is unchanged. Figure 1: Examples of beliefs extracted from real IE systems on the TAC 2015 English news corpus, demonstrating the consistency and repair tasks. Multiple sentences can contribute to a belief (1b). We study two problems: (i) whether an extracted belief is consistent with its text (called consistency), and (ii) correcting it if not (called repair). We believe we are the ﬁrst to study these problems jointly. We model these problems jointly, arguing that addressing both of these is important and can beneﬁt one another. Our use of consistency here refers to a language-based sense that text supports the belief even if its contradicts world knowledge. We are concerned with methods that can be standalone—that is, reliant on neither a precise schema (Ojha and Talukdar, 2017) nor an ensemble of IE systems, e.g., Yu et al. (2014); Viswanathan et al. (2015). Previous work on determining the arXiv:1808.04816v3  [cs.CL]  27 Jan 2023  consistency of an IE extraction was not standalone. We want a standalone approach because the results from non-standalone',\n",
       " '1710.08167': 'Ever since Tukey’s pioneering work on exploratory data analysis (EDA) [1], effective exploration of data has remained an art as much as a science. Indeed, while human analysts are remarkably skilled in spotting patterns and relations in adequately visualized data, coming up with insightful visualizations is hard task to formalize, let alone to automate. As a result, EDA systems require signiﬁcant expertise to use effectively. However, with the increasing availability and importance of data, data analysts with sufﬁcient expertise are becoming a scarce resource. Thus, further research into automating the search for insightful data visualizations is becoming increasingly critical. Modern computational methods for dimensionality reduction, such as Projection Pursuit and manifold learning, allow one to spot complex relations from the data automatically and to present them visually. Their drawback is however that the criteria by which the views are found are deﬁned by static objective functions. The resulting visualizations may or may not be informative for the user and task at hand. Often such visualizations show the most prominent features of the data, while the user might be interested in other subtler structures. It would therefore be of a great help if the user could efﬁciently tell the system what she already knows and the system could utilize this when deciding what to show the user next. Achieving this is the main objective of this paper. We present a novel interaction system based on solid theoretical principles. The main idea of the system is shown in Fig. 1. The computer maintains a distribution, called the background distribution (1a), modelling the belief state of the user. The system shows the user projections in which the data and the background distribution differ the most (1b,c). The user marks in the projection the patterns she has observed (1d,e) and the computer then uses these to update the background distribution (1f). The process is iterated until the user is satisﬁed, i.e., typically when there are no notable differences between the data and the background distribution. Example. Speciﬁcally, the data considered in this work is a set of d-dimensional (d-D) data points. To illustrate the envisioned data exploration process, we synthesized a 3-D dataset with 150 points such that there are two clusters of 50 points and two of 25 points. The smaller clusters are partially overlapping in the third dimension. Looking at the ﬁrst two principal components, one can only observe three clusters with 50 points each (similarly to the black points in Fig. 2a). In our interactive approach, the data analyst will learn not only that there are actually four clusters, but also that two of the four clusters correspond to a single cluster in the ﬁrst view of the data. The visualizations considered are scatter plots of the data points after projection onto a 2-D subspace, as in Projection Pursuit [2], [3]. The projection chosen for visualization arXiv:1710.08167v1  [stat.ML]  23 Oct 2017  Fig. 1. Overview of the interaction',\n",
       " '1511.06566': 'Let G : X →R and F ∗: Y →R be convex, proper, and lower semicontinuous functionals on Hilbert spaces X and Y , possibly inﬁnite-dimensional. Also let K ∈L(X; Y ) be a bounded linear operator. We then wish to solve the minimax problem min x∈X max y∈Y G(x) + ⟨Kx, y⟩−F ∗(y). One possibility is the primal-dual algorithm of Chambolle and Pock [11], a type of proximal point or extragradient method, also classiﬁed as the “modiﬁed primal-dual hybrid gradient method” or PDHGM by Esser [18]. If either G of F ∗is strongly convex, the method can be accelerated to produce Nesterov’s [25] optimal O(1/N2) rates. But what if we have only partial strong convexity? For example, what if G(x) = G0(Px) ∗ Department of Applied Mathematics and Theoretical Physics, University of Cambridge, United Kingdom. tuomo.valkonen@iki.fi † Department of Mathematical Sciences, University of Liverpool, United Kingdom ‡ Institute for Computer Graphics and Vision, Graz University of Technology, 8010 Graz, Austria. Digital Safety & Security Department, AIT Austrian Institute of Technology GmbH, 1220 Vienna, Austria. pock@icg.tugraz.at 1 arXiv:1511.06566v2  [math.OC]  10 Feb 2016  for a projection operator P to a subspace X0 ⊂X, and strongly convex G0 : X0 →R? This kind of structure is common in many applications in image processing and the data sciences, as we will more closely review in Section 5. Under such partial strong convexity, can we obtain a method that would give an accelerated rate of convergence at least for Px? We provide a partially positive answer: we can obtain mixed rates, O(1/N2) with respect to initialisation, and O(1/N) with respect to bounds on the “residual variables” y and (I −P)x. In this, our results are similar to the “optimal” algorithm of Chen et al. [15]. Instead of strong convexity, they assume smoothness of G to derive a primal-dual algorithm based on backward–forward steps, instead of the backward–backward steps of [11]. The derivation of our algorithms is based, ﬁrstly, on replacing simple step length parameters by a variety of abstract step length operators and, secondly, a type of abstract partial strong monotonicity property ⟨∂G(x′) −∂G(x), eT −1(x′ −x)⟩≥∥x′ −x∥2 eT −1,∗Γ′ −ψ eT −1,∗(Γ′−Γ)(x′ −x), (1.1) the full details of which we provide in Section 2. In this, we make the monotonicity dependent on the step length operator eT. Secondly, our factor of strong convexity is the operator Γ, which is however shifted in (1.1) into a penalty term ψ through the introduction of additional strong monotonicity in terms of Γ′ ≥Γ. This exact procedure can be seen as a type of smoothing, famously studied by Nesterov [26], and more recently, for instance, by Beck and Teboulle [4]. In these approaches, one computes a priori a level of smoothing—comparable to Γ′—needed to achieve certain quality of solution, and then',\n",
       " '1809.00970': 'At its core, semantic segmentation is tasked with associating pixels, or voxels, of an image with a label that corresponds to a meaningful category. As a fundamental problem in medical image computing, an impressive amount of research on the topic has been conducted in recent years, spanning methods that segment tumors in MRI volumes (Zikic et al., 2014; Menze, 2014), airways from chest CT scans (Miyawaki et al., 2017), vessels in retinal scans (Pilch et al., 2012) or mitochondria in electron microscopes (Seyedhosseini et al., 2013) to name a few. To this day, the vast majority of state-of-the-art segmentation approaches rely heavily on supervised machine learning frameworks (Sweeney et al., 2014; Menze, 2014), and in particular deep learning (GarciaGarcia et al., 2017), to produce excellent segmentation results. In general, these methods depend on large amounts of training examples to learn complex prediction models. Critically, most of these models are trained using pixel-wise annotations associated with training examples. While highly eﬀective, the cost of acquiring such pixel-wise annotations for training machine learning methods is often overlooked and yet a central limiting factor for aggregating extremely large training datasets. This is particularly the case for video and 3D image data where annotations are extremely costly (i.e. days per video sequence). This in turn negatively impacts the capacity to train high-performing segmentation models, as the number of training samples remains relatively small. ∗Corresponding author Email address: laurent.lejeune@artorg.unibe.ch (Laurent Lejeune) Preprint submitted to ArXiv September 5, 2018 arXiv:1809.00970v1  [cs.CV]  27 Aug 2018  To reduce the burden of producing pixel-wise annotations, a number of semi-supervised concepts have been proposed such as active learning (Konyushkova et al., 2015), domain adaption (Tzeng et al., 2017) and crowd-sourcing (Mavandadi et al., 2012). Alternatively, a number of recent methods propose to infer pixel-wise segmentation directly from image labels (i.e. the image contains a tumor) by leveraging strong object or shape priors (Menze et al., 2010). In eﬀect these methods attempt to reﬁne segmentations from pre-trained neural networks for generic object classes (Su et al., 2015) or trained attention models (Kingma et al., 2014). While extremely promising, such methods still only produce coarse segmentations and remain ill suited for training complex prediction models. At the same time, the method by which annotations are provided has important practical implications in terms of convenience for the annotator and can also greatly speed-up the annotation process (Ferreira et al., 2012). For example, providing tumor pixel segmentations in volumetric data would be infeasible if each pixel were to be speciﬁed individually. Instead, there is an important body of work that has considered alternative user-interaction mechanisms. For instance, (Konyushkova et al., 2015) used 3D image planes to specify the boundary between image backgrounds and objects in 3D modalities. Scribbles of positive and negative image regions were also shown to be eﬀective in speeding up annotation generation (Roberts et al., 2011). Even more',\n",
       " '1808.07456': 'Crowd counting has been widely studied for decades of years because of a great many practical demands such as public safety and city planning. While, crowd counting still remains challenging and researchers seek to address it by focusing on aspects of severe occlusions, perspective distortions, and diverse crowd distributions. In this work, we explore an important feature in crowd counting scenario, i.e., cross-scale visual similarity. Fig. 1 shows two examples of the cross-scale visual similarity within crowd images. In each image, it is not difﬁcult to ﬁnd two regions which are visually similar when they are resized to the same scale. The cross-scale visual similarity is quite universal in crowd counting, not only within an individual image, but also among different images of various scenes. In contrast, this feature is not typical for the natural images such as Cifar-10 (Krizhevsky and Hinton 2009) and ImageNet (Deng et al. 2009). Therefore, the vision model designed for crowd counting especially requires the capability of scale invariance. This work was done when Siyu Huang and Zhi-Qi Cheng visited Carnegie Mellon University. Figure 1: In crowd images, regions of different scales exhibit high visual similarity if we resize them to certain sizes. This feature is common for regions within an image and also for regions among different images. It indicates the importance of scale invariance in crowd counting. A common solution for augmenting scale invariance of convolutional neural networks (CNNs) would be to make CNNs larger (Krizhevsky, Sutskever, and Hinton 2012; Simonyan and Zisserman 2015; Huang et al. 2017) and deeper (Szegedy et al. 2015; He et al. 2016) by introducing more learnable parameters to improve their representation performances. Another solution is to manually build branches in CNNs for visual concepts of different scales (Xu et al. 2014; Cai et al. 2016). Speciﬁcally in crowd counting, researchers explore various variants (Zeng et al. 2017; Sam, Surya, and Babu 2017) of multi-sized convolutions (Zhang et al. 2016) to deal with the scale variation in people size. Different from these approaches, we focus on the pooling module to boost the scale invariance of CNNs. As studied by existing literature (Huang et al. 2007; Boureau, Ponce, and LeCun 2010; Scherer, M¨uller, and Behnke 2010), the scale invariance of CNNs is in general brought by the pooling layer. However, it is evident that the conventional pooling can only deal with slight scale change (Gong et al. 2014), thus cannot well cope with the signiﬁcant scale variation in crowd counting scenarios, e.g., the examples shown in Fig.1. Motivated by this, we propose to employ a larger pooling range to adapt the network to such a severe scale variation. Fig. 2 illustrates how a larger pooling range enables an inarXiv:1808.07456v1  [cs.CV]  22 Aug 2018  input map pool 2×2 pool 4×4 input map pool 2×2 pool 4×4 Figure 2: An intuitive illustration of the',\n",
       " '1901.06086': 'Overall, reinforcement learning (RL) involves an agent interacting with an environment through repeatedly running a policy π, collecting experience from each iteration and using that experience to update its policy for maximal reward (Fig 1). Figure 1: RL ﬂow chart Thanks to advancements in big data, computing power, and other machine learning discipline, reinforcement learning has emerged as the pinnacle ﬁeld in pushing humanity closer to true artiﬁcial intelligence. Model-based reinforcement learning, for example, aims to build an accurate model (such as a MDP) of the environment dynamics and train the agent on said model, giving model learning capabilities as well as ease of reward learning. On the other hand, in model-free reinforcement learning, the agent does not have explicit information regarding state transitions and must continuously explore and generate experience to ﬁnd the optimal policy. In recent years, major problems have arisen in the ﬁeld of reinforcement learning, such as planning and how to balance exploration and exploitation. Of particular interest, however, is the problem of knowledge gathering, namely how to eﬃciently and quickly sample trajectories to gain experience and update the policy without adversely aﬀecting average return. 3 Architecture Our work, dubbed WALL-E, utilizes multiple rollout samplers running in parallel to rapidly generate experience. For starters, the agent processor runs asynchronously and updates the policy based on experience from the experience queue when ready, sending policy parameters to the policy queue. In turn, the N sampler processors, concurrently generate experience based on the updated policy read from the primed policy queue and sends experience back to the experience queue (Fig 2). 1 arXiv:1901.06086v2  [cs.LG]  28 Jan 2019  Figure 2: Parallel Sampler RL Architecture 4 Results Due to our parallel samplers, we experience not only faster convergence times, but also higher average reward thresholds. For example, on the MuJoCo HalfCheetah-v2 task, with N = 10 parallel sampler processes, we are able to achieve much higher average return than those from using only a single process architecture (Fig 3). Figure 3: Comparison of N = 10 vs N = 1 By testing other values of N on 20000 samples per iteration, we notice a signiﬁcant decrease in rollout time w.r.t. processor count (Fig 4) that surprisingly does not negatively impact the average return in a non-trivial fashion. Figure 4: Rollout time decrease Furthermore, by plotting the speedup from 20000 samples per iteration (Fig 5), we see that the running time is highly fast with a variance from the asynchronous nature and the queue I/O. Thus, based on our results, we conclude that the experience collection speedup w.r.t. to CPU numbers is near-linear (while not over-linear). 2  Figure 5: Speedup comparison As we can see from Fig.6, with the near-linear decrease of experience collection time w.r.t. the number of CPUs, the data collection is no longer the bottleneck while the percentage of policy learning time increases to become the next bottleneck, though',\n",
       " '1309.5843': 'Many approaches to sentiment analysis make use of lexical resources – i.e. lists of positive and negative words – often deployed as baselines or as features for other methods (usually machine learning based) for sentiment analysis research (Liu and Zhang, 2012). In these lexica, words are associated with their prior polarity, i.e. if that word out of context evokes something positive or something negative. For example, wonderful has a positive connotation – prior polarity – while horrible has a negative one. These approaches have the advantage of not needing deep semantic analysis or word sense disambiguation to assign an affective score to a word and are domain independent (they are thus less precise but more portable). SentiWordNet (henceforth SWN) is one of these resources and has been widely adopted since it provides a broad-coverage lexicon – built in a semi-automatic manner – for English (Esuli and Sebastiani, 2006). Given that SWN provides polarities scores for each word sense (also called ‘posterior polarities’), it is necessary to derive prior polarities from the posteriors. For example, the word cold has a posterior polarity for the meaning “having a low temperature” – like in “cold beer” – that is different from the one in “cold person” which refers to “being emotionless”. This information must be considered when reconstructing the prior polarity of cold. Several formulae to compute prior polarities starting from posterior polarities scores have been used in the literature. However, their performance varies signiﬁcantly depending on the adopted variant. We show that researchers have not paid sufﬁcient attention to this posterior-to-prior polarity issue. Indeed, we show that some variants outperform others on different datasets and can represent a fairer state-ofthe-art approach using SWN. On top of this, we attempt to outperform the state-of-the-art formula using a learning framework that combines the various formulae together. In detail, we will address ﬁve main research questions: (i) is there any relevant difference in the posterior-to-prior polarity formulae performance  (both in regression and classiﬁcation tasks), (ii) is there any relevant variation in prior polarity values if we use different releases of SWN (i.e. SWN1 or SWN3), (iii) can a learning framework boost performance of such formulae, (iv) considering word Part of Speech (PoS), is there any relevant difference in formulae performance, (v) considering the gender dimension of the annotators (male/female) and the sentiment dimension (positive/negative), is there any relevant difference in SWN performance. In Section 2 we brieﬂy describe our approach and how it differentiates from similar sentiment analysis tasks. Then, in Sections 3 and 4, we present SentiWordNet and overview various posterior-to-prior polarity formulae based on this resource that appeared in the literature (included some new ones we identiﬁed as potentially relevant). In Section 5 we describe the learning approach adopted on priorpolarity formulae. In Section 6 we introduce the ANEW and General Inquirer resources that will be used as gold standards. Finally, in the two last sec',\n",
       " '1705.09407': 'FAILED',\n",
       " '0801.3272': 'Despite the lack of precise knowledge of its basic theoretical behavior and limits, relaying is beginning to ﬁnd practical application in standards such as IEEE 802.16j [1]. By deploying relatively inexpensive relays, service providers can reduce the number of base stations required to serve a given area, or increase capacity at the cell edge. Relaying research efforts have also increased recently [2]–[7]. Capacity bounds for the full-duplex MIMO relay channel were derived in [2], [3]. The authors of [6] derive the optimal inﬁnite-SNR diversity-multiplexing tradeoff for the half duplex MIMO relay channel and ﬁnd that a compress-andforward strategy is optimal in this sense. Recently, practical strategies have been developed for MIMO relaying. Both [4] and [7] derive the mutual-information-maximizing nonregenerative linear relay for spatial multiplexing when the direct link is ignored. This letter derives the optimal transmit antenna selection criteria at both source and relay; i.e., all transmissions occur using the transmit antenna that will give the destination the highest post-processing signal-to-noise ratio. We consider the case where only a single spatial stream is to be sent from source The authors are with the Wireless Networking and Communications Group, Department of Electrical and Computer Engineering, 1 University Station C0803, University of Texas at Austin, Austin, TX, 78712-0240 (email: {peters, rheath}@ece.utexas.edu, phone: (512) 471-1190, fax: (512) 471-6512). EDICS: COM-{ESTI,MIMO,NETW} This work was supported by the Semiconductor Research Corporation under contract 2007-HJ-1648. October 9, 2018 DRAFT  ACCEPTED TO IEEE SIGNAL PROCESSING LETTERS, JANUARY 2008 2 to destination. This scenario arises when the channel is ill-conditioned (i.e., there is a dominant path of propagation in the source-destination channel), or if robustness via diversity is preferred over throughput (i.e., near the cell edge). Unlike most previous practial MIMO relay results (e.g., [4], [5], [7]), the strategy derived here is the optimal transmit antenna selection strategy when the direct link from source to relay is not ignored. We prove that transmit antenna selection, combined with an MMSE receiver at the destination, achieves the full diversity order of the MIMO single relay channel. That is, at high SNR the probability of outage decays with SNR as quickly as is possible in such a model. Further, antenna selection requires less feedback than beamforming. Distributed space-time codes, which may also achieve the full diversity gain, not only require their own level of overhead for coordination and synchronization, but also require the relay to be able to decode the message transmitted by the source. Compared to recent results using limited feedback beamforming [8], under the tested parameters given in the aforementioned paper, antenna selection at both source and destination is about twice as likely to cause bit errors as a Grassmannian codebook with 16 codes, which is a loss of about 1 dB at high SNR. In return, antenna selection requires only log2 NSNR bits of feedback versus',\n",
       " '1605.09519': 'The recent spread of wireless devices has brought heavy data trafﬁc which video-streaming requests, such as YouTube, occupy a dominant portion of. Unfortunately, however, current wireless systems have limitations of resources to accommodate this tremendous video trafﬁc. Discovering new but inexpensive resources is considered a solution to cope with the explosive trafﬁc. In the same vein, memory for data caching arises as a new resource to exploit in wireless communications [2]. The characteristic of video trafﬁc facilitates utilization of memory to handle huge video trafﬁc; a few popular videos account for the majority of video trafﬁc [3] and hence network trafﬁc to carry the videos to the end users can be signiﬁcantly reduced by storing the top-ranked video ﬁles near the users who are likely to request them. Although caching has been intensively studied in wired networks, also known as content delivery network (CDN), it is transparent to wireless segments. Without consideration of wireless aspects, CDN is not enough to provide sufﬁcient data rate to wireless end users. In this context, there have been recent studies ﬁguring out wireless caching. For a given caching placement, several transmission schemes to exploit the given memory contents have been studied in [4]– [6]. Based on appropriate user grouping, when each user requests multiple ﬁles, a groupcasting scheme was proposed in [7]. With practical Zipf popularity distribution, [8] characterized the regimes with different coded multicasting gains. Preﬁx caching for wireless video streaming was proposed and optimized in [11]. Caching was exploited in cooperative multi-point MIMO transmission (CoMP) to reduce backhaul cost in [12]–[14]. Because where and what to cache determines the performance of wireless caching, caching placement has also attracted research interests, namely femto-caching and device-to-device (D2D) caching. In [9], proactive caching for femto-caching and D2D caching was studied. A caching scheme based on prediction of future demands was proposed in [10]. Optimal caching placement is able to minimize the access distance  3 and inter-cell interference in wireless cache networks. In [15], [16], an optimization problem in terms of the average delay, a function of caching placement, was formulated and proved to be NP-complete when each user can access to a different set of femto base stations. With random caching placement for D2D communication, optimal cluster size and the parameter characterizing the random caching distribution were studied in [17], [18], where a square cell was composed of square clusters and D2D communication was activated if the ﬁle requested by user in a cluster was cached in any device inside the cluster. For D2D coded caching placement, optimal portion of ﬁles to store and density of nodes caching the requested ﬁle were investigated in [19], [20], respectively. Combining coded multicasting with D2D communication, [21] proposed caching and delivery schemes which can exploit spatial reuse gain as well as coded multicasting gain. Caching placement optimizing a tradeoff between throughput and outage was explored in [22], [23]. When Maximum-distance separable coding is used, optimal storage allocation',\n",
       " '1303.4085': 'Localization is an important and extensively studied topic in wireless sensor networks (WSNs) [1]. Localization can be performed using a plethora of algorithms [1] (and references therein), which exploit inter-node measurements like time-ofarrival (TOA), time-difference-of-arrival (TDOA), angle-ofarrival (AOA), or received signal strength (RSS). The performance of any location estimator depends not only on the algorithm but also on the placement of the anchors (nodes with known locations). Anchor placement is a key challenge in localization system design, as certain anchor positions not only deteriorate the performance but also result in ambiguities or identiﬁability issues. In [2], the effect of anchor placement is studied using the geometric dilution of precision (GDOP). The idea of GDOP is borrowed from the global positioning system (GPS) and it is obtained from the Cram´er-Rao lower bound (CRB) with simplifying assumptions on the noise model, i.e., equal variances on all the range estimates. This assumption is valid for GPS due to the approximately equal distances between the anchors (the satelThis work was supported in part by STW under the FASTCOM project (10551) and in part by NWO-STW under the VICI program (10382). lites) and the nodes, but it does not translate well to WSNs where the noise variance is proportional to the distance (typically different) between the anchors and the sensor. In [3], the effect of the anchor positions has been studied by empirically identifying the ambiguity issues. However, they do not provide any algorithm for anchor placement. The anchor placement problem can be interpreted as the problem where we divide a speciﬁc anchor area A into M grid points and select the positions of the K anchors as the best K grid points out of M grid points, where K ≪M. Here, the K selected anchors are deemed the best, if they guarantee a certain minimal accuracy on the location estimates within a speciﬁc sensor area S. In practice, K is not known, and this makes anchor selection a combinatorial problem involving an exhaustive search over all the 2M possible anchor positions, and the computation over S is even more cumbersome. In this paper, we consider TOA-based ranging, however, we do not restrict ourselves to a particular localization algorithm. Instead, we use the CRB as a performance constraint. The anchor placement problem is studied for the following two cases of TOA-based one-way ranging: a) the anchors send the ranging signals (OW-A) and b) the sensor sends the ranging signals (OW-S). The anchor placement problem is formulated as the design of a sparse selection vector. For the OW-A case, the sparse solution yields the ranging energies1 that the anchors should adopt leading to a solution for the joint ranging energy optimization and anchor placement problem, and for the OW-S case the sparse solution yields the optimal anchor positions. Using the CRB as a performance constraint, we can formulate the',\n",
       " '1809.01733': 'Modern communication systems employ a two step encoding process for the transmission of image/video data (see Fig. 1a for an illustration): (i) the image/video data is ﬁrst compressed with a source coding algorithm in order to get rid of the inherent redundancy, and to reduce the amount of transferred information; and (ii) the compressed bitstream is ﬁrst encoded with an error correcting code, which enables resilient transmission against errors, and then modulated. Shannon’s separation theorem proves that this two-step source and channel coding approach is optimal theoretically in the asymptotic limit of inﬁnitely E. Bourtsoulatze is with the Communications and Information Systems Group, Department of Electronic and Electrical Engineering, University College London, London, UK. D. Burth Kurka and D. G¨und¨uz are with the Information Processing and Communications Laboratory, Department of Electrical and Electronic Engineering, Imperial College London, London, UK. Part of this work was done while the ﬁrst author was with the Information Processing and Communications Laboratory, Imperial College London. E-mails: e.bourtsoulatze@ucl.ac.uk, d.kurka@imperial.ac.uk, d.gunduz@imperial.ac.uk This work has been funded by the European Union’s Horizon 2020 research and innovation programme under the Marie Sk lodowskaCurie fellowship (grant agreement No. 750254) and by the European Research Council (ERC) through the Starting Grant BEACON (grant agreement No. 677854). long source and channel blocks [1]. While in practical applications joint source and channel coding (JSCC) is known to outperform the separate approach [2], separate architecture is attractive for practical communication systems thanks to the modularity it provides. Moreover, highly eﬃcient compression algorithms (e.g. JPEG, JPEG2000, WebP [3]) and near-optimal channel codes (e.g. LDPC, Turbo codes) are employed in practice to approach the theoretical limits. However, many emerging applications from the Internet-of-things to autonomous driving and to tactile Internet require transmission of image/video data under extreme latency, bandwidth and/or energy constraints, which preclude computationally demanding long-blocklength source and channel coding techniques. We propose a JSCC technique for wireless image transmission that directly maps the image pixel values to the complex-valued channel input symbols. Inspired by the success of unsupervised deep learning (DL) methods, in particular, the autoencoder architectures [4], [5], we design an end-to-end communication system, where the encoding and decoding functions are parameterized by two convolutional neural networks (CNNs) and the communication channel is incorporated in the neural network (NN) architecture as a non-trainable layer; hence, the name deep JSCC. Two channel models, the additive white Gaussian noise (AWGN) channel and the slow Rayleigh fading channel, are considered in this work due to their widespread adoption in representing realistic channel conditions. The proposed solution is readily extendable to other channel models, as long as they can be represented as a nontrainable NN layer with a diﬀerentiable transfer function. DL-based methods, and, particularly, autoencoders, have recently shown remarkable results',\n",
       " '1809.10934': 'While communication networks have traditionally been designed to reliably convey information, modern decentralized networks are introducing new challenges. More than communication by itself, what is crucial for the next generation of networks is to ensure the cooperation and coordination of the constituent devices, viewed as autonomous decision makers. The devices have to adapt their behavior to the state of the environment and to the actions of other devices, which may not be known by all players, creating information asymmetries; coordination is meant in the broad sense of enforcing a joint behavior of the devices through communication to resolve such asymmetries. More speciﬁcally, we quantify coordination in terms of how well we can approximate a target joint distribution between the actions and signals of the devices. In particular, empirical coordination requires the joint histogram of actions and signals to approach a target distribution, while strong coordination requires their joint distribution to converge in total variation to an i.i.d. target distribution [1]. In this work, we consider a two-node network with an information source and a noisy channel in which the input and output signals should be strongly coordinated with the source and the reconstruction. This scenario presents two conﬂicting goals: the encoder needs to convey a message to the decoder to coordinate the actions, while simultaneously coordinating the signals coding the message. The two nodes are assisted in their task by a shared source of randomness. The case in which the encoder and the decoder are both noncausal has already been considered in [2, 3] but the problem of ﬁnding the coordination region is still open. We focus here Ma¨el Le Treust gratefully acknowledges the supports of DIM-RFSI under grant EX032965, and of Labex MME-DII (ANR11-LBX-0023-01). The authors thank SRV ENSEA for ﬁnancial support for the visit of M. R. Bloch in 2017. on the setting in which the encoder is strictly causal, which has the beneﬁt of shortening the transmission delay. In [4] the authors provide a characterization of the empirical coordination region when the encoder is strictly causal. In [5], we proposed an explicit polar coding scheme that achieves this region. In this paper, we provide an inner and an outer bound for the strong coordination region and show that the inner bound is achievable with polar codes. Although the achievability techniques are similar to the ones used in [3], the strictly causal nature of the encoder requires a more subtle random coding scheme with a block-Markov structure. The remainder of the paper is organized as follows. Section II introduces the notation, Section III describes the model under investigation and states the main result. Section IV proves an inner bound by proposing a random binning scheme and a random coding scheme that have the same statistics and Section V proves an outer bound. The two bounds match, except for the bound on the minimal rate of common randomness, and closing the gap between the two regions remains an open problem. Finally, we provide',\n",
       " '1707.01825': 'Data-mining competitions such as those as oﬀered by Kaggle, KDD Cup, and other organizations, have become a mainstay of machine learning. By establishing common rules of participation as well as training and testing datasets that are shared by all contestants, these competitions can help to advance the state-of-the-art of machine learning practice in a variety of application domains. In order for the scientiﬁc results of these contests to have value, however, it is imperative that the methods by which candidates are evaluated be sound. The importance of fair evaluation is made more pressing by the availability of oracles, often provided by the organizers of the competitions themselves, that return the accuracy or loss value of the contestant’s guesses with respect to the test labels. The purpose of such oracles is to help participants to pursue more promising algorithmic strategies and to improve the overall quality of contestants’ submissions. But they also open up the possibility of systematic overﬁtting, either inadvertently or maliciously. In this paper, we consider how an oracle that returns the log loss of a contestant’s guesses w.r.t. the ground-truth labels of a test set, can be exploited by an attacker to infer the test set’s true labels. The log-loss is mathematically convenient because, unlike other metrics such as the AUC [8, 1], which is calculated over pairs of examples, the log-loss can be computed for each example separately. Moreover, unlike the 0-1 loss that conveys only the number of correctly labeled examples, the log-loss measures how “close” the contestant’s guesses are to ground-truth. The attack proposed in our paper can be eﬀective despite limited ﬂoating-point resolution in the oracle’s return values, and can be applied even if the oracle only computes the log-loss on an unknown (but ﬁxed) subset of the test set. In a case study we performed for this paper, we applied the attack to achieve a perfect score on a recent Kaggle competition (Intel & MobileODT Cervical Cancer Screening), thereby attaining a rank on the ﬁrst-stage competition leaderboard of #4 out of 848. To be fair, Kaggle had structured their competition rules such that the ﬁrst stage was mostly for informational purposes to let contestants know how their algorithmic approachs were faring compared to their contestants’. However, even a temporary high ranking in a data-mining contest could conceivably hold ancillary value, e.g., by inducing a potential employer or recruiter to take a look at a particular person’s curriculum vitae. In any case, the potential of exploiting a competition oracle underlines the importance of employing commonsense safeguards to preserve the integrity of contestant rankings. In particular, the results in this paper suggest that evaluation of contestants’ performance should be done strictly on test examples on which the oracle never reported accuracy. 1 arXiv:1707.01825v1  [cs.LG]  6 Jul 2017  1.1 Related work Both intentional hacking [9, 2, 10] and',\n",
       " '1603.02366': 'Index coding is a multiuser communication problem in which the broadcaster reduces the total number of transmissions by taking advantage of the fact that a user may have side information about other user’s data. We consider the index coding problem formulation of [3]. Suppose, a set of users are assigned bijectively to a set of vectors that they want to know. However, instead of knowing the assigned vector, each knows a subset of other vectors. This scenario can be depicted by a so-called side-information graph where each vertex represents a user and there is an edge from user A to user B, if A knows the vector assigned to B. Given this graph, how much information should a broadcaster transmit, such that each vertex can deduce its assigned vector? Consider a group of n users with the side information represented by the directed graph G, such that the out-neighbors of vertex vi ∈V (G) = {v1, v2, . . . , vn} denote the nodes whose data is available to vi. The data requested by node vi is represented by a vector xi ∈Fℓ q. Let N(v, G) ⊆V (G) \\\\ {v} denote the out-neighbors of vertex v (v ∈N(v, G)). For example, an index coding scenario has been depicted in ﬁg. 1. The side information graph for this scenario is given in ﬁg. 2. In the graph G of Abhishek Agarwal is with the Department of Electrical and Computer Engineering, University of Minnesota, Minneapolis, MN 55455. Arya Mazumdar is with the Computer Science Department of University of Massachusetts, Amherst, MA 01003, and was with the University of Minnesota. email: abhiag@umn.edu, arya@cs.umass.edu. Research supported by NSF grants CCF 1318093 and CAREER CCF 1453121. arXiv:1603.02366v2  [cs.IT]  29 Apr 2016  2 User\\t\\r \\xa0A\\t\\r \\xa0 Wants\\t\\r \\xa0xA\\t\\r \\xa0 Has\\t\\r \\xa0xC,\\t\\r \\xa0xE,\\t\\r \\xa0xF\\t\\r \\xa0 User\\t\\r \\xa0B\\t\\r \\xa0 Wants\\t\\r \\xa0xB\\t\\r \\xa0 Has\\t\\r \\xa0xA,\\t\\r \\xa0xE\\t\\r \\xa0 User\\t\\r \\xa0E\\t\\r \\xa0 Wants\\t\\r \\xa0xE\\t\\r \\xa0 Has\\t\\r \\xa0xA,\\t\\r \\xa0xD,\\t\\r \\xa0xF\\t\\r \\xa0 User\\t\\r \\xa0F\\t\\r \\xa0 Wants\\t\\r \\xa0xF\\t\\r \\xa0 Has\\t\\r \\xa0xD,\\t\\r \\xa0xE\\t\\r \\xa0 User\\t\\r \\xa0C\\t\\r \\xa0 Wants\\t\\r \\xa0xC\\t\\r \\xa0 Has\\t\\r \\xa0xB\\t\\r \\xa0 User\\t\\r \\xa0D\\t\\r \\xa0 Wants\\t\\r \\xa0xD\\t\\r \\xa0 Has\\t\\r \\xa0xC,\\t\\r \\xa0xF\\t\\r \\xa0 Fig. 1: Example of an Index Coding problem. The corresponding side-information graph is depicted in ﬁg. 2 ﬁg. 2, N(A, G) = {C, E, F}, N(B, G) = {A, E}, N(C, G) = {B}, N(D, G) = {C, F}, N(E, G) = {A, D, F}, N(F, G) = {D, E}. The aim is to broadcast the minimum amount of data (in-terms of Fℓ qsymbols) such that vertex vi is able to reconstruct xi from xN(vi,G) (vectors assigned to the neighbors) and the broadcast for all i ∈{1, . . . , n}. The amount of broadcasted data is referred to as the broadcast rate of the index coding problem. This simple formulation attracted substantial attention recently [1], [5], [12]. In particular, it has been shown that any network coding problem can be cast as an index coding problem [6], [7]. Furthermore, index coding has been identiﬁed as the hardest instance of all of network coding [11]. For up',\n",
       " '1806.08698': 'Enabled by the proliferation of ubiquitous sensing devices and the pervasive wireless data connectivity, real-time monitoring has become a reality in large-scale cyber-physical systems, such as power grids, manufacturing facilities, and smart transportation systems. However, the unprecedented high-dimensionality and generation rate of the sensing data also impose critical challenges on its timely delivery. In order to measure and ensure the freshness of information available to the central controller, a metric called Age of Information (AoI) has been introduced and analyzed in various networks [1]. Speciﬁcally, at time t, the AoI in the system is deﬁned as t −u(t), where u(t) is the time stamp of the latest received update at the destination. Since AoI depends on data generation as well as queueing and transmission, it exhibits fundamental differences between traditional network performance metrics, such as throughput and delay. Modeling the status updating process as a queueing process, time average AoI has been analyzed in systems with a single server [1]–[8], and multiple servers [9]–[11]. Peak Age of This work was supported in part by the US National Science Foundation (NSF) under Grant ECCS-1650299. Information (PAoI) has been introduced and studied in [12]– [14]. The optimality properties of a preemptive Last Generated First Served service discipline are identiﬁed in [15]. AoI minimization has also been investigated, either by controlling the generation process of the updates [16]–[26], or by scheduling the transmission of updates that have already been generated [27]–[31]. Optimal status updating policy with knowledge of the server state has been studied in [16]. AoIoptimal sampling of a Wiener process is investigated in [17]. Under an energy harvesting setting, optimal status updating have been studied in [18]–[26]. Transmission scheduling in a broadcast channel has been studied in [27]–[29]. Reference [27] shows that a greedy policy which always tries to update the most outdated client is optimal in a symmetric setting. Reference [28] formulates the problem as a Markov Decision Process (MDP), and show that the optimal policy is a switchtype. It also proposes a sequence of ﬁnite-state approximations for the inﬁnite-state MDP and proves its convergence. A restless bandits based formulation and a Whittle’s index based scheduling have been studied in [29]. Different transmission scheduling policies for AoI minimization in a multiple access channel under throughput constraints on individual nodes have been analyzed in [30]. Age-optimal link scheduling in a multiple-source system with conﬂicting links is studied in [31], and the problem is shown to be NP-complete in general. Headof-line age-based scheduling algorithms have been shown to be throughput optimal in wireless networks in [32]. In this paper, we investigate the optimal online transmission scheduling for a single link under the assumption that the link capacity is limited and each update takes multiple time slots to transmit. During the transmission of an update, new updates may arrive. Therefore, the source has to decide whether to',\n",
       " '1504.00353': 'I N software-deﬁned radio (SDR) applications, researchers and engineers have yet to fully harness the error-correction capability of modern codes due to their high computational complexity. Many are still using classical codes [1], [2] as implementing low-latency high-throughput—exceeding 10 Mbps of information throughput—software decoders for turbo or low-density parity-check (LDPC) codes is very challenging. The irregular data access patterns featured in decoders of modern error-correction codes make eﬃcient use of singleinstruction multiple-data (SIMD) extensions present on today’s central processing units (CPUs) diﬃcult. To overcome this diﬃculty and still achieve a good throughput, software decoders resorting to inter-frame parallelism (decoding multiple independent frames at the same time) are often proposed [3]– [5]. Inter-frame parallelism comes at the cost of higher latency, as many frames have to be buﬀered before decoding can be started. Even with a split layer approach to LDPC decoding where intra-frame parallelism can be applied, the latency remains high at multiple milliseconds on a recent desktop processor [6]. This work presents software polar decoders that enable SDR systems to utilize powerful and fast errorcorrection. Polar codes provably achieve the symmetric capacity of memoryless channels [7]. Moreover they are well suited P. Giard, G. Sarkis and W. J. Gross are with the Department of Electrical and Computer Engineering, McGill University, Montréal, Québec, Canada (email: {pascal.giard,gabi.sarkis}@mail.mcgill.ca, warren.gross@mcgill.ca). C. Leroux is with the IMS Lab, Bordeaux-INP, Bordeaux, France (e-mail: camille.leroux@ims-bordeaux.fr). C. Thibeault is with the Department of Electrical Engineering, École de technologie supérieure, Montréal, Québec, Canada (e-mail: claude.thibeault@etsmtl.ca). for software implementation, due to regular memory access patterns, on both x86 and embedded processors [8]–[10]. To achieve higher throughput and lower latency on processors, software polar decoders can also exploit SIMD vector extensions present on today’s CPUs. Vectorization can be performed intra-frame [8] or inter-frame [9], [10], with the former having lower decoding latency as it does not require multiple frames to start decoding. In this work, we explore intra-frame vectorized polar decoders. We propose architectures and optimization strategies that lead to the implementation of high-performance software polar decoders tailored to diﬀerent processor architectures with decoding latency of 26 µs for a (32768, 29492) polar code, a signiﬁcant performance improvement compared to that of our previous work [8]. We start Section II with a review of the construction and decoding of polar codes. We then present two diﬀerent software decoder architectures with varying degrees of specialization in Section III. Implementation and results on an embedded processor are discussed in Section IV. We also adapt the decoder to suit graphical processing units (GPUs), an interesting target for applications where many hundreds of frames have to be decoded simultaneously, and present the results in Section V. Finally, Section VI compares the energy consumption of the diﬀerent decoders and Section',\n",
       " '1801.01627': 'Optical character recognition (OCR) has always been a challenging ﬁeld in pattern recognition. OCR techniques are used to convert handwritten or machine printed scanned document images to machine-encoded texts. These OCR techniques are script dependent. Therefore, script identiﬁcation is considered as a precursor to OCR. In particular, in case of a multilingual country like India script identiﬁcation is the must since a single document, such as postal documents and business forms, contains several diﬀerent scripts (see Fig. 1). Indic handwritten script identiﬁcation has a rich state-of-the-art literature [1–4]. More often, previous works have been focusing on word-level script identiﬁcation [5]. Not stopping there, in a recent work [6], authors introduced page-level script identiﬁcation performance to see whether we can expedite the processing time. In general, in their works, hand-crafted features that are based on structural and/or visual appearances (morphology-based) were used. The question is, are we just relying on what we see and use apply features accordingly or can we just let machine to select features that are required for optimal identiﬁcation rate? This inspires to use deep learning, where CNNs can be used for extracting and/or selecting features for identiﬁcation task(s). Needless to say, CNNs have stood well with their immense contribution in the ﬁeld of OCR. Their onset has ben marked by the ground-breaking performance of CNNs on MNIST dataset [7]. Very recently, the use CNN for Indic script (Bangla character recognition) has arXiv:1801.01627v1  [cs.CV]  5 Jan 2018  Fig. 1. Two multi-script postal document images, where Bangla, Roman and Devanagari scripts are used. been reported [8]. Not to be confused, the primary of goal of this paper is to use deep learning concept to identify 11 diﬀerent handwritten Indic scripts: Bangla, Devnagari, Gujarati, Gurumukhi, Kannada, Malayalam, Oriya, Roman, Tamil, Telugu and Urdu. Inspired from deep learning-based concept, we use CNNs to select features from handwritten document images (scanned), where we use multilevel 2D discrete Haar wavelet transform (in addition to conventional spatial domain representation) and image representations are scaled to a variety of diﬀerent sizes. With these representation, several diﬀerent CNNs are used to select features. In short, the primary idea behind this is to avoid using hand-crafted features for identiﬁcation. Using multi-layer perceptron (MLP), 11 diﬀerent handwritten scripts (as mentioned earlier) are identiﬁed with satisfactory performance. The remainder of the paper can be summarized as follows. Section 2 provides a quick overview of our contribution, where it includes CNN architecture and feature extraction process. In Section 3, experimental results are provided. It also includes a quick comparison study. Section 4 concludes our paper. 2 Contribution outline As mentioned earlier, in stead of using hand-crafted features for document image representation, our goal is to let deep learning to select distinguishing features for optimal script identiﬁcation. For a few but recent works, where CNNs have used with successful classiﬁcation, we refer to [7,9',\n",
       " '1804.07942': 'Question answering (QA) has been a long-standing research problem in natural language processing (NLP) since 1960s. In this paper, we focus on a sub-type of QA tasks: answering stock related questions. Our goal is to automatically generate convincing natural language answers to stock related questions, just like the answers given by the professional stock analysts. Table 1 shows two representative StockQA examples. Although fundamentally a QA problem, StockQA is quite different from those well studied in previous research due to the following two characteristics. First, StockQA is different from traditional QA tasks in obtaining answers. In previous QA tasks, the answers are typically selected from a knowledge base (e.g., entities) (Berant et al. 2013; Yin et al. 2016) or question-answer pairs *Zhaopeng Tu is the corresponding author. Work was done when Yong Jiang and Lei Shu were interning at Tencent AI Lab. 1The data is publicly available at http://ai.tencent. com/ailab/nlp/data/stockQA.tar.gz. Q: I bought TSLA at $349, how to handle it? A: TSLA is in a weakening trend. I suggest you to sell some shares to reduce your risk. Sell all if it could not rise above the 50-day MA $330. Q: What is the support level of MSFT? I invested 30% of my money in it. A: MSFT is trying to break the previous high point. Hold it if it can stay steady on $79.15. Table 1: Two representative StockQA examples. collected from web forums (e.g., sentences) (Bian et al. 2008; Cong et al. 2008). In contrast, due to the dynamic nature of stock related QA, we generate answers based on the question and the knowledge of the referred stock. In our task, the answers to a given question may vary according to the time when the questions are asked, as well as the stock referred to. Accordingly, the retrieval-based approaches cannot be applied in this task. Second, number understanding and generation is critical in StockQA for generating reasonable answers. In previous knowledge-base QA tasks (Berant et al. 2013; Bordes et al. 2015), numerical values are either not involved or simply treated as attribute values of entities (just like other types of attribute values). For example, in answering questions about the elevation of a mountain, the numerical answer is generally selected from a knowledge base like other entities (e.g., mountain names). In StockQA, however, reasonable answers often contain numbers, which are generated by analyzing relations between numbers in question and stock numerical knowledge (e.g., the numeric value of cost price in question and close price in knowledge base), as well as text words in question and numbers in stock knowledge (e.g., the words “resistance level” in question and “high price” in knowledge base). In addition, numbers in answers generally refer to an estimated price of support level or resistance level, which cannot be generated with an arithmetic operation (e.g., subtraction',\n",
       " '1502.07802': 'Fine-grained image classiﬁcation refers to the task of recognising the class or subcategory (for instance the particular ﬁsh species) under the same basic category such as bird or ﬁsh species [1, 17]. This is a challenging task for two reasons. First, some classes (species) from the same category, such as ﬁsh, can appear to be very similar in terms of appearance leading to low inter-class variation. Second, there is a high degree of variability in the instances of the same classes due to environmental and illumination variations leading to high intra-class variation. Fig. 1 shows examples of both issues. An approach to tackling these two issues is to extract local region descriptors and to model them. Such an approach has previously been popular for recognition of faces [11, 16] and ﬁsh [1]. These approaches typically divide the image into patches (or blocks), with each patch considered to be an independent (and partial) observation of the object. Each patch is then represented by a feature vector and the distribution of all of these features vectors, from an image, is then modelled using a Gaussian mixture model (GMM). The feature vector to represent each patch has usually been obtained from a transform such as the 2D discrete cosine transform [16]. Thalassoma Trilobatum Thalassoma Quinquevittatum Thalassoma Purporeum Thalassoma Hardwicke Fried Rice Chicken Rice Ramen Beef Noodle Fig. 1: First two rows show example images of four ﬁsh species, which have low inter-class variation: similar visual appearance despite being distinct species. (Images taken by J.E. Randall). The last two rows show images of four food dishes, with each dish type having high intra-class variation. Recently, feature learning through the use of deep convolutional neural networks (CNNs) has led to considerable improvements for object recognition [10]. These deep CNN feature representations are trained on large datasets such as ImageNet [5] which has 1, 000 general object categories. It has been shown that these learnt features can be used to obtain impressive results for other recognition tasks when used as a global image representation [14]. However, to the best of our knowledge no work has examined how to use these learnt features as a local feature extractor for use with well known statistical modelling approaches such as GMMs. To use these deep CNN features as a local feature extractor two issues need to be addressed. First, deep CNNs such as [10] generally have an internal representation which is high dimensional, leading to the curse of dimensionality [3] for local modelling techniques such as GMMs. Second, we need to develop an efﬁcient and effective method to retrain a deep CNN containing millions of weights using a relatively small arXiv:1502.07802v1  [cs.CV]  27 Feb 2015  set of images speciﬁc to a ﬁne-grained class. In this paper we address both of these issues. Inspired by recent work that has shown how to optimise deep CNN features for small datasets using',\n",
       " '1204.0867': 'A. Background Consider the following communication problem of broadcasting with receiver side information. A single sender wishes to send a set of m messages M = {x1, x2, . . . , xm} to a set of n receivers R = {R1, R2 . . . , Rn}. Each receiver is deﬁned as Ri ≜(Wi, Ki), i.e., it knows some messages Ki ⊆M a priori, and it wants to obtain some messages Wi ⊆M. This is known as the index coding problem [1], and any index coding problem can be completely speciﬁed by (M, R). In this paper, we consider only binary messages1, i.e., xi ∈{0, 1} for all i ∈{1, 2, . . . , m}, where xi are each uniformly distributed on {0, 1} and are mutually independent. An index code for the index coding problem is deﬁned as: Deﬁnition 1 (Index Code): An index code for the index coding problem (M, R) consists of 1) An encoding function for the sender, E : {0, 1}m → {0, 1}ℓ, and 2) A decoding function for each receiver, Di : {0, 1}ℓ+|Ki| →{0, 1}|Wi| such that Di(E(M), Ki) = Wi, for each i ∈{1, 2, . . . , n}. In words, the sender encodes its m-bit message word into an ℓ-bit codeword which is given to all receivers. Using the codeword and its known messages, each receiver decodes the messages that it wants. The integer ℓis referred to as the length of the index code. Let ℓ∗(M, R) be the smallest integer ℓfor which the above conditions hold. Our objective is to determine ℓ∗(M, R) and construct an optimal index code that has length ℓ∗(M, R). In practice, this leads to the optimal use of transmission energy and resources. 1The results here also apply to messages of equal size that are non-binary. Without loss of generality, we assume that |Wi| ≥1 and |Ki| ≥1 for each i ∈{1, 2, . . . , n}, meaning that each receiver knows at least one bit and requests for at least one bit. This is because (i) any receiver that does not requests for any message bit can be removed from the system, and so we do not need to consider the case where Wi = 0, and (ii) if a receiver i knows no message bit, we can arbitrarily assign a new dummy bit x′ to it and to the sender (of course, that bit will never be sent by the sender), and so we do not consider the case where Ki = 0. B. Classiﬁcation A few classes of index coding problems have been studied. We propose to categorize these and other index coding problems as follows. We ﬁrst classify different types of information ﬂow from the sender to the receivers. We say that an index coding problem is unicast if Wi ∩Wj = ∅, ∀i ̸= j, (1) meaning that each message bit can be requested by at most one receiver. In addition, we say that the problem is single-unicast if, in addition to (1), we also have that |Wi| = 1 for',\n",
       " '1711.05408': 'Recurrent neural networks (RNNs) are an attractive apparatus for probabilistic language modeling (Mikolov and Zweig, 2012). Recent experiments show that RNNs signiﬁcantly outperform other methods in assigning high probability to held-out English text (Jozefowicz et al., 2016). Roughly speaking, an RNN works as follows. At each time step, it consumes one input token, updates its hidden state vector, and predicts the next token by generating a probability distribution over all permissible tokens. The probability of an input string is simply obtained as the product of the predictions of the tokens constituting the string followed by a terminating token. In this manner, each RNN deﬁnes a weighted language; i.e. a total function from strings to weights. Siegelmann and Sontag (1995) showed that single-layer rational-weight RNNs with saturated linear activation can compute any computable function. To this end, a speciﬁc architecture with 886 hidden units can simulate any Turing machine in real-time (i.e., each Turing machine step is simulated in a single time step). However, their RNN encodes the whole input in its internal state, performs the actual computation of the Turing machine when reading the terminating token, and then encodes the output (provided an output is produced) in a particular hidden unit. In this way, their RNN allows “thinking” time (equivalent to the computation time of the Turing machine) after the input has been encoded. We consider a different variant of RNNs that is commonly used in natural language processing applications. It uses ReLU activations, consumes an input token at each time step, and produces softmax predictions for the next token. It thus immediately halts after reading the last input token and the weight assigned to the input is simply the product of the input token predictions in each step. Other formal models that are currently used to implement probabilistic language models such as ﬁnite-state automata and context-free grammars are by now well-understood. A fair share of their utility directly derives from their nice algorithmic properties. For example, the weighted languages computed by weighted ﬁnite-state automata are closed under intersection (pointwise product) and union (pointwise sum), and the corresponding unweighted languages are closed under intersection, union, difference, and complementation (Droste et al., 2013). Moreover, toolkits like OpenFST (Allauzen et al., 2007) and Carmel1 implement efﬁcient algorithms on automata like minimization, intersection, ﬁnding the highestweighted path and the highest-weighted string. RNN practitioners naturally face many of these same problems. For example, an RNN1https://www.isi.edu/licensed-sw/carmel/ arXiv:1711.05408v2  [cs.FL]  4 Mar 2018  based machine translation system should extract the highest-weighted output string (i.e., the most likely translation) generated by an RNN, (Sutskever et al., 2014; Bahdanau et al., 2014). Currently this task is solved by approximation techniques like heuristic greedy and beam searches. To facilitate the deployment of large RNNs onto limited memory',\n",
       " '1509.08880': 'Classic methods of linear dimensionality reduction assume that data approximately follows some low-dimensional linear subspace and aim at ﬁnding an optimal projection onto Copyright 2015 by the authors. that subspace, i.e. Principle Component Analysis (PCA) [Pearson, 1901] and Random Projection [Hegde et al., 2008]. Nonlinear dimensionality reduction, also referred to as manifold learning, is a generalization of those linear techniques that aims at ﬁtting a nonlinear low dimensional structure. Such manifold learning methods as Isometric Feature Mapping [Tenenbaum et al., 2000], Locally Linear Embedding [Roweis and Saul, 2000], and Laplacian Eigenmap [Belkin and Niyogi, 2001] are widely used as methods of nonlinear dimensionality reduction in machine learning, either to reduce the computational cost of working in higher-dimensional spaces, or to learn or approximate a manifold more favourable to subsequent learning tasks such as classiﬁcation or regression. These algorithms seek to determine a nonlinear lower dimensional space by preserving various geometric properties of the input. However, it is not clear which of these properties would be more beneﬁcial to the later discrimination stage. Since they are typically unsupervised techniques, they present a certain risk for the later classiﬁcation or regression task: the lowerdimensional space found may not be the most helpful one for the second supervised learning stage and, in fact, in some cases could be harmful. How should we design manifold construction techniques to beneﬁt most the subsequent supervised learning stage? As shown by Figure 1, simply optimizing geometric properties may be detrimental the subsequent learning stage. To solve this problem, we consider an alternative scenario where the manifold construction step is not carried out blindly. We couple the task of nonlinear dimensionality reduction with the subsequent supervised learning stage. To do so, we make use of the known remarkable result that all of the manifold learning techniques already mentioned and many others are speciﬁc instances of the generic Kernel PCA (KPCA) algorithm for different choices of the kernel function [Ham et al., 2004]. More generally, all these methods can be thought of ﬁrst mapping input vectors into a reproducing kernel Hilbert space and then conducting a low-rank projection within that space. Thus, our goal is to both learn a mapping as well as a projection taken from a parametric family as well as a hypothesis which is found in the low-dimensional space. The main purpose of this paper is precisely to derive learnFoundations of Coupled Nonlinear Dimensionality Reduction ing guarantees for this scenario, which we coin as Coupled Nonlinear Dimensionality Reduction, and to use those guaranteed as guidelines in the design of algorithms. In practice, a user will often use a handful of different kernel functions and choose the one that is most effective according to measurements on a validation dataset. Instead, in this work, we argue that a more effective method is to allow a learning algorithm itself to choose a kernel function from a parametrized class. The idea',\n",
       " '1808.09955': 'The scientiﬁc exploitation of spectroscopic astrophysical data requires high-conﬁdence spectral classiﬁcation and a precise determination of the redshift. The volume of data that current and upcoming astrophysical surveys are collecting prohibits comprehensive visual inspection campaigns and the development of automatic methods achieving human-expert performance becomes essential (Pˆaris et al. 2012, 2017). Standard automatic methods and human experts approach these tasks very diﬀerently. Automatic methods generically consist in comparing each spectrum with a database of spectral archetypes (Hutchinson et al. 2016) to ﬁnd the best matching class, or comparing the principalcomponent decompositions along diﬀerent spectral classes (Bolton et al. 2012; Pˆaris et al. 2017) to ﬁnd a best ﬁt solution. These methods perform signiﬁcantly worse than humanexperts, which motivated the inclusion of a comprehensive program of human-expert visual inspection of quasar targets to large astrophysical surveys such as the Baryon Oscillations Spectroscopic Survey survey (Smee et al. 2013; Gunn ⋆E-mail: nbusca@lpnhe.in2p3.fr et al. 2006; Eisenstein et al. 2011; Dawson et al. 2013 and Pˆaris et al. (2017) for the description of the visual inspection). Human-experts intervened to validate or correct misclassiﬁcations (where the automatically-determined spectral class is incorrect) and catastrophic redshifts (where emission lines are classiﬁed incorrectly). Human experts approach the task in a very diﬀerent way from the automatic methods described above. They more or less immediately recognize spectral features (emission lines, spectral breaks, absorptions, etc.) and use them for spectral classiﬁcation. This classiﬁcation and an eyeball redshift based on the identiﬁed features can be used as a prior for a more precise automatic redshift ﬁtter. Needless to say, the process of visually inspecting hundreds of thousands of spectra is tedious and requires a signiﬁcant investment of human-expert time. To limit the number of visually inspected quasar spectra in the extended Baryon Oscillation Spectroscopic Survey (eBOSS, Dawson et al. 2016), early data was used to develop a decision tree (Pˆaris et al. 2018) based on the quality ﬂags and the ﬁrst ﬁve best-ﬁt solutions found by the automatic redshift ﬁtter from Bolton et al. (2012). Spectra with bad quality ﬂags or having inconsistent solutions among the top ﬁve best-ﬁts would be automatically tagged as either nonquasar or as requiring a visual inspection. This procedure © 2018 The Authors arXiv:1808.09955v1  [astro-ph.IM]  29 Aug 2018  2 N. G. Busca et al. signiﬁcantly reduces the fraction of spectra requiring a visual inspection down to less than about 5% of the quasar targets, but a few tens of thousands still require it. The increase of data expected with upcoming large-scale-structure surveys such as DESI (Aghamousa et al. 2016a,b) turns visual inspection of a signiﬁcant fraction of the spectra into a titanic eﬀort. The situation described above, where human-expert level performance is required and a large library of humanexpert inspected data is available, constitutes a perfect setup for exploring the',\n",
       " '1511.06388': 'NLP systems seek to automate the extraction of information from human language. A key challenge in this task is the complexity and sparsity in natural language, which leads to a phenomenon known as the curse of dimensionality. To overcome this, recent work has learned real valued, distributed representations for words using neural networks (G.E. Hinton, 1986; Bengio et al., 2003; Morin & Bengio, 2005; Mnih & Hinton, 2009). These ”neural language models” embed a vocabulary into a smaller dimensional linear space that models ”the probability function for word sequences, expressed in terms of these representations” (Bengio et al., 2003). The result is a vector-space model (VSM) that represents word meanings with vectors that capture the semantic and syntactic information of words (Maas & Ng, 2010). These distributed representations model shades of meaning across their dimensions, allowing for multiple words to have multiple real-valued relationships encoded in a single vector (Liang & Potts, 2015). Various forms of distributed representations have shown to be useful for a wide variety of NLP tasks including Part-of-Speech tagging, Named Entity Recognition, Analogy/Similarity Querying, Transliteration, and Dependency Parsing (Al-Rfou et al., 2013; Al-Rfou et al., 2015; Mikolov et al., 2013a;b; Chen & Manning, 2014). Extensive research has been done to tune these embeddings to various tasks by incorporating features such as character (compositional) information, word order information, and multi-word (phrase) information (Ling et al., 2015; Mikolov et al., 2013c; Zhang et al., 2015; Trask et al., 2015). Despite these advancements, most word embedding techniques share a common problem in that each word must encode all of its potential meanings into a single vector (Huang et al., 2012). For words with multiple meanings (or ”senses”), this creates a superposition in vector space where a vector takes on a mixture of its individual meanings. In this work, we will show that this superposition 1 arXiv:1511.06388v1  [cs.CL]  19 Nov 2015  Under review as a conference paper at ICLR 2016 obfuscates the context speciﬁc meaning of a word and can have a negative effect on NLP classiﬁers leveraging the superposition as input data. Furthermore, we will show that disambiguating multiple word senses into separate embeddings alleviates this problem and the corresponding confusion to an NLP model. 2 RELATED WORK 2.1 WORD2VEC Mikolov et al. (2013a) proposed two simple methods for learning continuous word embeddings using neural networks based on Skip-gram or Continuous-Bag-of-Word (CBOW) models and named it word2vec. Word vectors built from these methods map words to points in space that effectively encode semantic and syntactic meaning despite ignoring word order information. Furthermore, the word vectors exhibited certain algebraic relations, as exempliﬁed by example: ”v[man] - v[king] + v[queen] ≈v[woman]”. Subsequent work leveraging such neural word embeddings has proven to be effective on a variety of natural language modeling tasks (Al-Rfou et al., 2013; Al-Rfou et al., 2015; Chen & Manning, 2014). 2.2 WANG2VEC Because word embeddings in word2vec are insensitive',\n",
       " '1803.06852': 'In many real world applications, we often face the problems of estimating the causal effects of a set of sources Xn = (x1, ..., xn)T on one target variable Y . To achieve this, one can build a linear regression model given their observations [2, 4, 15, 16, 3], and check the coefﬁcients. For variables that are statistically dependent, we would, in  most of the cases, get non-zero regression coefﬁcients between the observations1. If xj has a signiﬁcant regression coefﬁcient, it is believed to have a large causal inﬂuence on Y . However, the correctness of this is based on the causal sufﬁciency assumption that there is no hidden confounder of Xn and Y , which cannot be veriﬁed from the regression procedure. Simply checking the coefﬁcient vector cannot give us enough information for identifying confounder. Given the correctness of the causal sufﬁciency assumption unveriﬁed, estimating the causal effects by regression could be problematic: one never knows if the coefﬁcients purely describe the inﬂuence of Xn on Y , or it is signiﬁcant because they share a hidden common driving force. Thus, confounder detection is important. It basically acts as a veriﬁcation procedure of the causal sufﬁciency assumption. For further analysis, we write a mathematical model, and denote the non-observable confounder as Z. Directly following the paper [6], we assume that the Z is a one dimensional variable, and consider the model Xn = bnZ + En, (1) Y = aT nXn + cZ + F, (2) where an, bn are n dimensional vectors and En is the n dimensional noise. F is the one dimensional noise, and c is a scalar. When ∥bn∥and c are both non-zero2, Z is a confounder of Xn and Y [6]. Consider a least square regression of Y on Xn to get the regression coefﬁcient as ˜an = Σ−1 XnΣXnY , (3) The covariance matrices are ΣXnY = (ΣEn + bnbT n)an + cbn, ΣXn = ΣEn + bnbT n. Notice that we assume the variance of variable Z is 1 here. We consider this assumption justiﬁed since we can always make this true by rescaling bn and c. Then we get ˜an = an + c(ΣEn + bnbT n)−1bn. (4) The regression coefﬁcient basically consists of two parts. One is the part describing the causal inﬂuences of Xn on Y , and the other is the part describing confounding effects. As this decomposition reveals, the regression coefﬁcient in confounding and non-confounding cases could be clearly different. Consider the following points. 1The regression coefﬁcient here refers to the correlation coefﬁcient between variables. It is known that dependent variables could also be uncorrelated, and in that case the regression coefﬁcient is 0. 2By default, ∥· ∥stands for the L2 norm ∥· ∥2 2  1. Purely causal cases: ∥bn∥or c should be 0. In this case, ˜an = an. 2. Confounding cases: ∥bn∥and c are not 0. In this case, ˜an = an + c(ΣEn + bnbT n)−1bn. For ease of explanation, we denote ˜an as the composition of causal part and confounding part ˜an = an |{z} causal',\n",
       " '1206.2248': 'Model selection by cross-validation is a de-facto standard in applied machine learning to tune parameter conﬁgurations of machine learning methods in supervised learning settings (see Mosteller and Tukey 1968; Stone 1974; Geisser 1975 and also Arlot et al. 2010 for a recent and extensive review of the method). Part of the data is held back and used as a test set to get a less biased estimate of the true generalization error. Cross-validation is computationally quite demanding, though. Doing a full grid search on all possible combinations of parameter candidates quickly takes a lot of time, even if one exploits the obvious potential for parallelization. Therefore, cross-validation is seldom executed in full in practice, but diﬀerent heuristics are usually employed to speed up the computation. For example, instead of using the full grid, local search heuristics may be used to ﬁnd local minima in the test error (see for instance Kohavi and John 1995; Bengio 2000; Keerthi et al. 2006). However, in general, as with all local search methods, no guarantees can be given as to the quality of the found local minima. Another frequently used heuristic is to perform the cross-validation on a subset of the data, and then train on the full data set to get the most accurate predictions. The problem here is to ﬁnd the right size of the subset: If the subset is too small and cannot reﬂect the true complexity of the learning problem, the conﬁgurations selected by c⃝— Tammo Krueger, Danny Panknin and Mikio Braun. arXiv:1206.2248v6  [cs.LG]  3 Feb 2016  Krueger, Panknin and Braun cross-validation will lead to underﬁtted models. On the other hand, a too large subset will take longer for the cross-validation to ﬁnish. Eﬀective use of model selection heuristics requires both an experienced practitioner and familiarity with the data set. However, as we will discuss in more depth below, the eﬀect of taking subsets on the estimated generalization error is more manageable: Given increasing subsets of the data, the test errors converge to the values on the full data set for each parameter conﬁguration, but the parameter conﬁguration achieving the minimum test error will converge much faster. Thus, using subsets in a systematic way opens up a promising way to speed up the model selection process, since training models on smaller subsets of the data is much more time-eﬃcient. During this process care has to be taken when an increase in available data suddenly reveals more structure in the data, leading to a change of the optimal parameter conﬁguration. Still, as we will discuss in more depth, there are ways to guard against such change points, making the heuristic of taking subsets a more promising candidate for an automated procedure. In this paper we will propose a method which speeds up cross-validation by considering subsets of increasing size. By removing clearly underperforming parameter conﬁgurations on the way this leads to a substantial saving in total computation time',\n",
       " '1808.07967': 'In 2015, around 17.7 million people died worldwide due to heart diseases. Left ventricle (LV) quantiﬁcation is a key factor for the identiﬁcation and diagnosis of such pathologies [2]. However, the estimation of cardiac indices remains a very complex task due to its intricated temporal dynamics and the inter-subject variability of the cardiac structures. Indices such as cavity and myocardium area, regional wall thickness, cavity dimensions, among others, provide useful information to diagnose various types of cardiac pathologies. Cardiovascular magnetic resonance (CMR) is one of the preferred modalities for LV related studies since it is non invasive, presents high spatio-temporal resolution, has a good signalto-noise ratio and allows to clearly identify the tissues and muscles of interest [6]. The classical approach to LV quantiﬁcation consists in estimating such indices by means of automatic segmentation [3,4,5,6,7,9]. Segmentation is usually performed following supervised learning approaches, which require expert manual annotations contouring the edges of the myocardium for training. Once the arXiv:1808.07967v1  [cs.CV]  23 Aug 2018  2 Fig. 1: Illustration of indices of the left cardiac ventricle (based on Fig. 1 from [10]). (a) Cavity area (brown) and myocardial area (orange). (b) Directional dimensions of cavity (white arrows). (c) Regional wall thicknesses. A: anterior; AS: anterospetal; IS: inferoseptal; I: inferior; IL: inferolateral; AL: anterolateral. (d) Cardiac phase (systole or diastole) segmentation is performed, the indices are computed from the resulting mask. Therefore, the accuracy of the predicted indices is conditioned on the quality of the segmentation. In this work, we follow an alternative strategy that directly estimates the indices of interest from the input image sequence. Inspired by the work of [11,10,12], our model is based on a convolutional neural network directly operating on images and regressing the target indices. Diﬀerent from previous approaches like [10] where the temporal dynamics of cardiac sequences is incorporated using recurrent neural networks (RNNs), we propose a simple but eﬀective strategy based on the use of spatio-temporal convolutions [8]. In the context of video analysis, spatio-temporal convolutions are standard 3D convolutions that operate on spatio-temporal video volumes [7]. Here we employ them to process subsets of temporally contiguous CMR slices, leveraging temporal information towards improving prediction accuracy. We investigate the use of spatio-temporal convolutions for estimating cardiac phase, directional dimensions of the cavity, regional wall thicknesses and area of cavity and myocardium under the hypothesis that such indices may be better explained when taking into account the temporal dynamics of the heart. We benchmark the proposed architecture using the LVQuan Challenge 20181 dataset, which provides CMR sequences with annotations for the aforementioned indices, and provide empirical evidence that incorporating the temporal dynamics of the heart through 3D spatio-temporal convolutions improves prediction accuracy when compared with single-slice models. 2 Materials and methods 2.1 Architecture An overview of the proposed CNN architecture is presented in Figure 2. The network',\n",
       " '1609.08017': 'Deep neural networks (DNNs, e.g., LeCun et al., 2015; Schmidhuber, 2015), if trained properly, have been demonstrated to signiﬁcantly improve the benchmark performances in a wide range of application domains. As neural networks go deeper and deeper, naturally, its model complexity also increases quickly, hence the pressing need to reduce overﬁtting in training DNNs. A number of techniques have emerged over the years to address this challenge, among which dropout (Hinton et al., 2012; Srivastava, 2013) has stood out for its simplicity and effectiveness. In a nutshell, dropout randomly “drops” neural units during training as a means to prevent feature co-adaptation—a sign of overﬁtting (Hinton et al., 2012). Simple as it appears to be, dropout has led to several record-breaking performances (Hinton et al., 2012; Ma & Hovy, 2016), and thus spawned a lot of recent interests in analyzing and justifying dropout from the theoretical perspective, and also in further improving dropout from the algorithmic and practical perspective. In their pioneering work, Hinton et al. (2012) and Srivastava et al. (2014) interpreted dropout as an extreme form of model combination (aka. model ensemble) with extensive parameter/weight sharing, and they proposed to learn the combination through minimizing an appropriate expected loss. Interestingly, they also pointed out that for a single logistic neural unit, the output of dropout is in fact the geometric mean of the outputs of the model ensemble with shared parameters. Subsequently, many theoretical justiﬁcations of dropout have been explored, and we can only mention a few here due to space limits. Building on the weight sharing perspective, Baldi & Sadowski (2013; 2014) analyzed the ensemble averaging property of dropout in deep non-linear logistic networks, and supported the view that dropout is equivalent to applying stochastic gradient descent on some regularized 1 arXiv:1609.08017v3  [cs.LG]  15 Feb 2017  Published as a conference paper at ICLR 2017 loss function. Wager et al. (2013) treated dropout as an adaptive regularizer for generalized linear models (GLMs). Helmbold & Long (2016) discussed the differences between dropout and traditional weight decay regularization. In terms of statistical learning theory, Gao & Zhou (2014) studied the Rademacher complexity of different types of dropout, showing that dropout is able to reduce the Rademacher complexity polynomially for shallow neural networks (with one or no hidden layers) and exponentially for deep neural networks. This latter work (Gao & Zhou, 2014) formally demonstrated that dropout, due to its regularizing effect, contributes to reducing the inherent model complexity, in particular the variance component in the generalization error. Seen as a model combination technique, it is intuitive that dropout contributes to reducing the variance of the model performance. Surprisingly, dropout has also been shown to play some role in reducing the model bias. For instance, Jain et al. (2015) studied the ability of dropout training to escape local minima, hence leading to reduced model bias. Other studies (Chen et al., 2014; Helmbold & Long, 2014; Wager et al., 2014) focus on the effect of the dropout noise on models with',\n",
       " '1705.11175': 'Visual target tracking is one of the most important and active research areas in computer vision with a wide range of applications like surveillance, robotics and human-computer interaction (HCI). Although it has been studied extensively during past decades as recently surveyed in [1] [2], object tracking is still a difﬁcult problem due to many challenges that cause signiﬁcant appearance changes of targets such as varying illumination, occlusion, pose variations, deformation, abrupt motion, background clutter, and high target densities (in crowded environments). Robust representation of target appearance is important to overcome these challenges. Recently, convolutional neural network (CNN) features have demonstrated outstanding results on various recognition tasks [3], [4]. Motivated by this, a few deep learning N. L. Baisa and A. Wallace are with the Department of Electrical, Electronic and Computer Engineering, Heriot Watt University, Edinburgh EH14 4AS, United Kingdom. (e-mail: {nb30, a.m.wallace}@hw.ac.uk). D. Bhowmik is with the Department of Computing, Shefﬁeld Hallam University, Shefﬁeld S1 1WB, United Kingdom.(e-mail: deepayan.bhowmik@shu.ac.uk) based trackers [5], [6] have been developed. In addition, discriminative correlation ﬁlter-based trackers have achieved state-of-the-art results as surveyed in [7] in terms of both efﬁciency and robustness due to three reasons. First, efﬁcient correlation operations are performed by replacing exhausted circular convolutions with element-wise multiplications in the frequency domain which can be computed using the fast Fourier transform (FFT) with very high speed. Second, thousands of negative samples around the target’s environment can be efﬁciently incorporated through circular-shifting with the help of a circulant matrix. Third, training samples are regressed to soft labels of a Gaussian function (Gaussianweighted labels) instead of binary labels alleviating sampling ambiguity. In fact, regression with class labels can be seen as classiﬁcation. However, correlation ﬁlter-based trackers are susceptible to long-term occlusions. In addition, the Gaussian mixture probability hypothesis density (GM-PHD) ﬁlter [8] has an in-built capability of removing clutter while ﬁltering targets with very efﬁcient speed without the need for explicit data association. Though this ﬁlter is designed for multi-target ﬁltering, it is even preferable for single target ﬁltering in scenes with challenging background clutter as well as clutter that comes from other targets not of current concern. This ﬁltering approach is ﬂexible, for instance, it has been extended for multiple targets of different types in [9] [10]. In this work, we mainly focus on long-term tracking of a target of interest in sparse as well as crowded environments where the unknown target is initialized by a bounding box and then tracked in subsequent frames. Without making any constraint on the video scene, we develop a novel long-term online tracking algorithm that can close the research gap between sparse and crowded scenes tracking problems using the advantages of the correlation ﬁlters, a hybrid of multilayer CNN and hand-crafted features, an incremental (online) support vector machine (SVM) classiﬁer and a Gaussian mixture probability hypothesis',\n",
       " '1809.06260': 'Nowadays, most large-scale online platforms or mobile Apps have multiple scenarios that may involve services such as search, advertising, and recommendation. There are some well-known platforms of different kinds. Taobao is an E-commerce platform where users can search for and buy products through querying, bookmarking, or recommendation. Yahoo! is a comprehensive web site where users can read news, watch movies, make shopping, and more. One of the common features of these services is that ranking strategy serves as a fundamental function to provide a list of ranked items to users. Machine learning techniques have been widely applied in optimizing these ranking strategies [8, 28, 32, 50] to facilitate better services for search, advertising, or recommendation. However, ranking strategy in one scenario only optimizes its own metric, without considering the correlation between scenarios (or applications). In these platforms, strategies in different scenarios may be developed by different teams, and optimized by different methods with different metrics. Such metrics may include Click Through Rate (CTR), Conversion Rate (CVR), and Gross Merchandise Volume (GMV). However, separate optimization of single scenario cannot guarantee the globally optimal performance of the entire platform. Instead, if the strategies in different scenarios can work collaboratively, we can expect a better overall performance. Let’s illustrate this with a toy example. In a long beach, as shown in Figure 1, there are two sellers (denoted by A and B), located at different positions for selling their snacks. The top figure indicates the initial location, where people on the left side of the beach buy snacks at A and people on the right at B. The middle figure shows that when A moves right, he can sell more snacks (A can cover more people than B). Similar cases to B. The bottom figure indicates an optimal solution to this non-cooperative game, where the two sellers compete with each other and they are both at the center arXiv:1809.06260v1  [cs.AI]  17 Sep 2018  Figure 1: A competitive game for two sellers (A and B) selling snacks in a long beach. The top figure shows the initial location, the middle one shows the competing process, and the bottom one shows a solution when the two sellers are competitors. People in red are likely to buy snacks at A, and people in blue at B. People in grey are those beyond the scope of A and B. of the beach. However, this is a definitely sub-optimal solution if we want to optimize the total income of the two sellers, as some people(in grey) are beyond the scope of them. This simple example demonstrates that collaboration between scenarios in a system is extremely important if the objective is to optimize the total return of the system. This is also the case for E-commerce platforms which have many different scenarios in service. In a large E-commerce platform, we indeed observed competitor behaviors: increasing CTR in product search drops that in search advertisement systems, and increasing GMV in main',\n",
       " '1706.06681': 'Document summarization aims to produce ﬂuent and coherent summaries covering salient information in the documents. Many previous summarization systems employ an extractive approach by identifying and concatenating the most salient text units (often whole sentences) in the document. Traditional extractive summarizers produce the summary in two steps: sentence ranking and sentence selection. First, they utilize humanengineered features such as sentence position and length (Radev et al., 2004a), word frequency and importance (Nenkova et al., 2006; Hong and Nenkova, 2014), among others, to rank sentence salience. Then, they select summary-worthy sentences using a range of algorithms, such as graph centrality (Erkan and Radev, 2004), constraint optimization via Integer Linear Programming (McDonald, 2007; Gillick and Favre, 2009; Li et al., 2013), or Support Vector Regression (Li et al., 2007) algorithms. Optionally, sentence reordering (Lapata, 2003; Barzilay et al., 2001) can follow to improve coherence of the summary. Recently, thanks to their strong representation power, neural approaches have become popular in text summarization, especially in sentence compression (Rush et al., 2015) and single-document summarization (Cheng and Lapata, 2016). Despite their popularity, neural networks still have issues when dealing with multi-document summarization (MDS). In previous neural multi-document summarizers (Cao et al., 2015, 2017), all the sentences in the same document cluster are processed independently. Hence, the relationships between sentences and thus the relationships between different documents are ignored. However, Christensen et al. (2013) demonstrates the importance of considering discourse relations among sentences in multi-document summarization. This work proposes a multi-document summarization system that exploits the representational power of deep neural networks and the sentence relation information encoded in graph representations of document clusters. Speciﬁcally, we apply Graph Convolutional Networks (Kipf and Welling, 2017) on sentence relation graphs. First, we discuss three different techniques to produce sentence relation graphs, where nodes represent sentences in a cluster and edges capture the connections between sentences. Given a relation graph, our summarization model applies a Graph Convolutional Network (GCN), which takes in sentence embeddings from Recurrent Neural Networks as input node features. Through multiple layer-wise proparXiv:1706.06681v3  [cs.CL]  23 Aug 2017  agation, the GCN generates high-level hidden features for each sentence that incorporate the graph information. We then obtain sentence salience estimations via a regression on top, and extract salient sentences in a greedy manner while avoiding redundancy. We evaluate our model on the DUC 2004 multidocument summarization (MDS) task. Our model shows a clear advantage over traditional graphbased extractive summarizers, as well as a baseline GRU model that does not use any graph, and achieves competitive results with other state-ofthe-art MDS systems. This work provides a new gateway to incorporating graph-based techniques into neural summarization. 2 Related Work 2.1 Graph-based MDS Graph-based MDS models have traditionally employed surface level (Erkan and Radev, 2004; Mihalcea',\n",
       " '1707.05246': 'Natural Language Processing (NLP) models suffer considerably when applied in the wild. The distribution of the test data is typically very different from the data used during training, causing a model’s performance to deteriorate substantially. Domain adaptation is a prominent approach to transfer learning that can help to bridge this gap; many approaches were suggested so far (Blitzer et al., 2007; Daumé III, 2007; Jiang and Zhai, 2007; Ma et al., 2014; Schnabel and Schütze, 2014). However, most work focused on one-toone scenarios. Only recently research considered using multiple sources. Such studies are rare and typically rely on speciﬁc model transfer approaches (Mansour, 2009; Wu and Huang, 2016). Inspired by work on curriculum learning (Bengio et al., 2009; Tsvetkov et al., 2016), we instead propose—to the best of our knowledge—the ﬁrst model-agnostic data selection approach to transfer learning. Contrary to curriculum learning that aims at speeding up learning (see §6), we aim at learning to select the most relevant data from multiple sources using data metrics. While several measures have been proposed in the past (Moore and Lewis, 2010; Axelrod et al., 2011; Van Asch and Daelemans, 2010; Plank and van Noord, 2011; Remus, 2012), prior work is limited in studying metrics mostly in isolation, using only the notion of similarity (Ben-David et al., 2007) and focusing on a single task (see §6). Our hypothesis is that different tasks or even different domains demand different notions of similarity. In this paper we go beyond prior work by i) studying a range of similarity metrics, including diversity; and ii) testing the robustness of the learned weights across models (e.g., whether a more complex model can be approximated with a simpler surrogate), domains and tasks (to delimit the transferability of the learned weights). The contributions of this work are threefold. First, we present the ﬁrst model-independent approach to learn a data selection measure for transfer learning. It outperforms baselines across three tasks and multiple domains and is competitive with state-of-the-art domain adaptation approaches. Second, prior work on transfer learning mostly focused on similarity. We demonstrate empirically that diversity is as important as— and complements—domain similarity for transfer learning. Finally, we show—for the ﬁrst time— to what degree learned measures transfer across models, domains and tasks. 2 Background: Transfer learning Transfer learning generally involves the concepts of a domain and a task (Pan and Yang, 2010). A domain D consists of a feature space X and a marginal probability distribution P(X) over X, arXiv:1707.05246v1  [cs.CL]  17 Jul 2017  where X = {x1, · · · , xn} ∈X. For document classiﬁcation with a bag-of-words, X is the space of all document vectors, xi is the i-th document vector, and X is a sample of documents. Given a domain D = {X, P(X)}, a task T consists of a',\n",
       " '1402.2011': 'The simplest way of introducing redundancy in distributed storage systems is 3-replication, where three replicas of each data block are created. This makes it possible for three parallel reads for each data block. In this paper we introduce a new property that we call availability that ensures t + 1 parallel reads for each data block. We are also concerned with the locality r of each read, which measures how many blocks must be read before the desired block can be reconstructed. In this language, 3-replication allows t+1 = 3 parallel reads for each block, each with locality r = 1. However, as we increase the availability t by increasing the replication factor, the rate vanishes like 1 t+1. We show that it is possible to construct codes that can support a scaling number of parallel reads while keeping the rate to be an arbitrarily high constant. Speciﬁcally, one of our constructions results in codes of dimension k with availability t = Θ(k1/3−ϵ) where each read has locality r = Θ(k1/3) for any rate. We further show that this is possible while keeping the minimum distance arbitrarily close to the Singleton bound. The main motivation for this new property is the application of erasure codes for hot data. Current distributed storage systems use various forms of redundancy ranging from block replication to traditional and modern storage codes. It is now well understood that classical codes (such as Reed-Solomon) are highly suboptimal for distributed settings due to the repair problem [1]. Several storage codes have been recently The authors are with the Dept. of ECE, The University of Texas at Austin, Austin, TX 78751 USA. E-mail: {ankitsr, dimitris}@utexas.edu, {dimakis, sriram}@austin.utexas.edu. The authors would like to thank Arya Mazumdar and Natalia Silberstein for valuable discussions. developed, each optimized for a different repair cost metric. Codes that optimize the number of bits communicated during repairs (a quantity called repair bandwidth) were developed, for example, in [1]–[6] and references therein. Codes with small disk-I/O were studied in [3], [7]. Finally, codes that minimize the number of nodes that participate in the repair process, a quantity called locality, were studied in [8]–[19]. Some of these results have found their way into practice: codes with small locality were recently deployed in Azure production clusters [20], while others have been tested in Facebook clusters [6], [21]. Code designs with small repair bandwidth and locality are attractive for archival and cold data. This is information that is rarely accessed or modiﬁed, usually involving back-end systems that store massive logs for analytics or backups. It turns out that in these applications there are very large volumes of cold data that must be safely retained. Another signiﬁcant family of storage problems involves the management of hot data. This is frequently accessed information, often in front-end systems facing end-users. For these applications data blocks are frequently accessed, in some cases concurrently by multiple',\n",
       " '1709.00149': 'The millions of academic papers in the biomedical domain contain a vast amount of information that may lead to new hypotheses for disease treatment. However, scientists are faced with a problem of “undiscovered public knowledge,” as they struggle to read and assimilate all of this information (Swanson, 1986). Furthermore, the literature is growing at an exponential rate (Pautasso, 2012); PubMed1 has been adding more than a million papers per year since 2011. We have surpassed our 1http://www.ncbi.nlm.nih.gov/pubmed ability to keep up with and integrate these ﬁndings through manual reading alone. Large ongoing efforts, such as the BioNLP task community (N´edellec et al., 2013; Kim et al., 2012, 2009) and the DARPA Big Mechanism Program (Cohen, 2015), are making progress in advancing methods for machine reading and assembly of extracted biochemical interactions into large-scale models. However, to date, these methods rely either on the manual selection of relevant documents, or on the processing of large batches of documents that may or may not be relevant to the model being constructed. Batch machine reading of literature at this scale poses a new, growing set of problems. First, access to some documents is costly. The PubMedCentral (PMC) Open Access Subset2 (OA) is estimated3 to comprise 20%4 of the total literature; the remaining full-text documents are only available through paid access. Second, while there have been great advances in quality, machine reading is still not solved. Updates to our readers requires reprocessing the documents. For large document corpora, this quickly becomes the chief bottleneck in information extraction for model construction and analysis. Finally, even if we could cache all reading results, the search for connections between concepts within the extracted results should not be done blindly. At least in the biology domain, the many connections between biological entities and processes leads to a very high branching factor, making blind search for paths intractable. To effectively read at this scale, we need to incorporate methods for focused reading: develop the ability to pose queries about concepts of interest and perform targeted, incremental search 2https://www.ncbi.nlm.nih.gov/pmc/ tools/openftlist/ 3https://tinyurl.com/bachman-oa 4This includes 5% from PMC author manuscripts. arXiv:1709.00149v1  [cs.AI]  1 Sep 2017  through the literature for connections between concepts while minimizing reading documents that are likely irrelevant. In this paper we present what we believe is the ﬁrst algorithm for focused reading. We make the following contributions: (1) Present a general framework for a family of possible focused reading algorithms along with a baseline instance. (2) Cast the design of focused reading algorithms in a reinforcement learning (RL) setting, where the machine decides if it should explore (i.e., cast a wider net) or exploit (i.e., focus reading on a speciﬁc topic). (3) Evaluate our focused reading policies in terms of search efﬁciency and quality of information',\n",
       " '1611.09345': 'The multi-domain setting arises when there is data about a task in several different but related domains. For example in visual recognition of an object when viewed with different camera types. Multi-domain learning (MDL) models [Dredze et al., 2010, Daum´e III, 2007, Yang and Hospedales, 2015] aim to learn a cross-domain parameter sharing strategy that reﬂects the domains’ similarities and differences. Such selective parameter sharing aims to be robust to the differences in statistics across domains, while exploiting data from multiple domains to improve performance compared to learning each domain separately. In this chapter we derive a general framework that encompasses MDL and MTL from both neural network and tensor-factorisation perspectives. Many classic and recent MDL/MTL algorithms can be understood by the assumptions about the cross domain/task sharing structure encoded in their designs. E.g., the assumption that each task/domain’s model is a linear combination of a global and a task-speciﬁc parameter vector [Evgeniou and Pontil, 2004, Daum´e III, 2007]. Our framework includes these as special cases corresponding to speciﬁc settings of a semantic descriptor vector parametrising tasks/domains [Yang and Hospedales, 2015]. This vector can be used to recover existing models from our framework, but more generally it allows one to relax the often implicit assumption that domains are atomic/categorical entities, and exploit available metadata about tasks/domains to guide sharing structure for better MDL/MTL [Yang and Hospedales, 2015, Yang and Hospedales, 2016b]. For example, in surveillance video analysis, exploiting the knowledge of the time of day and day of week corresponding to each domain for better MDL. Finally, the idea of a semantic task/domain descriptor, allows our framework to go beyond the conventional MDL/MTL setting, and address both zero-shot learning [Yang and Hospedales, 2015] and zero-shot domain adaptation [Yang and Hospedales, 2015, Yang and Hospedales, 2016b] – where a model can be deployed for a new task/domain without any training data, solely by specifying the task/domain’s semantic descriptor metadata. Multi-Domain versus Multi-Task Learning The difference between domains and tasks can be subtle, and some multi-domain learning problems can be addressed by methods proposed for multi-task learning and vice-versa. However, to better understand this work, it is useful to distinguish them clearly. Domains refer to multiple datasets addressing the same task, but with differing statistical bias. For example camera type for object recognition; time of day or year for surveillance video analysis; or more subtle human biases in data collection [Torralba and Efros, 2011]. Tasks, on the other hand would refer to different object categories to recognise. In other words, a task change affects the output label-space of a supervised learning problem, while a domain change does not. A classic benchmark with multiple domains is the Ofﬁce dataset [Saenko et al., 2010]. It contains images of the same set of categories (e.g., mug, laptop, keyboard) from three data',\n",
       " '1809.09170': 'Recently there has been a growing interest in discovering governing equations of certain physical problems using observational data. It is a result of the wide recognition that all physical laws, e.g., Newton’s law, Kepler’s law, etc., were established based on empirical observational data. Since all models and physical laws are approximations to the true physics, a numerically constructed law or governing equation, which albeit may not possess a concise analytical form, could serve as a good model, so long as it is reasonably accurate. Early work in this direction includes [3, 35], where symbolic regression was used to select physical laws and determine the structure of the underlying dynamical system. More recently, a sparsity-promoting method [7] was proposed to discover governing equations from noisy measurement data. It was based on a sparse regression method ([41]) and a Pareto analysis to construct parsimonious governing equations from a combinatorially large set of candidate models. This methodology was further applied to recovering partial diﬀerential equations [31, 34], as well as inferring structures of network models [25]. Conditions were provided in [42] for recovering the governing equations from possibly highly corrupted measurement data, along with a sparse convex optimization method to recover the coeﬃcients of the underlying equations in the space of multivariate polynomials. A nonconvex sparse regression approach was proposed in [32] for selection and identiﬁcation of a dynamical system directly from noisy data. A model selection approach was developed in [26] for dynamical systems via sparse regression and information criteria. Combining delay embedding and Koopman theory, a data-driven method was designed in [6] to decompose chaotic systems as an intermittently forced linear system. Very recently, three sampling strategies were developed in [33] for learning quadratic high-dimensional diﬀerential equations from under-sampled data. There are other techniques that address various aspects of dynamical system discovery problem. These include, but are not limited to, methods to reconstruct the equations of motion from a data series [12], artiﬁcial neural networks [19], nonlinear regression [43], equation-free modeling [21], normal form identiﬁcation [24], empirical dynamic modeling [40, 48], nonlinear Laplacian spectral analysis [18], modeling emergent behavior [30], and automated inference of dynamics [36, 14, 15]. The readers are also referred to the introduction in [5]. The focus of this paper is on the study of local recovery/approximation of general ﬁrst-order nonlinear ordinary diﬀerential/algebraic equations from the time-varying measurement data. The major new features of the proposed ∗Corresponding author Email addresses: wu.3423@osu.edu (Kailiang Wu), xiu.16@osu.edu (Dongbin Xiu) Preprint submitted to Elsevier September 26, 2018 arXiv:1809.09170v1  [math.NA]  24 Sep 2018  numerical framework include the following. First, our method seeks “accurate approximation” to the underlying governing equations. This is diﬀerent from many of the existing studies, where “exact recovery” of the equations is the goal. The justiﬁcation for “approximation”, rather than “recovery”, is that all governing equations will eventually be discretized and approximated by certain numerical schemes during implementation. As',\n",
       " '1709.01779': 'In the last decade, deep learning has made major advances in solving artiﬁcial intelligence problems in different domains such as speech recognition, visual object recognition, object detection and machine translation (Schmidhuber 2015). This success is often attributed to its ability to discover intricate structures in high-dimensional data (LeCun, Bengio, and Hinton 2015), thereby making it particularly well suited for tackling complex tasks that are often regarded as characteristic of humans, such as vision, speech and natural language understanding. However, typically, a key requirement for learning deep representations of complex high-dimensional data is large sets of labeled data. Unfortunately, in many situations this data is not readily available, and humans are required to manually label large collections of data. On the other hand, in recent years, crowdsourcing has established itself as a reliable solution to annotate large collections of data. Indeed, crowdsourcing platforms like Amazon Mechanical Turk1 and Crowdﬂower2 have proven to be an Copyright c⃝2018, Association for the Advancement of Artiﬁcial Intelligence (www.aaai.org). All rights reserved. 1http://www.mturk.com 2http://crowdﬂower.com efﬁcient and cost-effective way for obtaining labeled data (Snow et al. 2008; Buhrmester, Kwang, and Gosling 2011), especially for the kind of human-like tasks, such as vision, speech and natural language understanding, for which deep learning methods have been shown to excel. Even in ﬁelds like medical imaging, crowdsourcing is being used to collect the large sets of labeled data that modern data-savvy deep learning methods enjoy (Greenspan, van Ginneken, and Summers 2016; Albarqouni et al. 2016; Guan et al. 2017). However, while crowdsourcing is scalable enough to allow labeling datasets that would otherwise be impractical for a single annotator to handle, it is well known that the noise associated with the labels provided by the various annotators can compromise practical applications that make use of such type of data (Sheng, Provost, and Ipeirotis 2008; Donmez and Carbonell 2008). Thus, it is not surprising that a large body of the recent machine learning literature is dedicated to mitigating the effects of the noise and biases inherent to such heterogeneous sources of data (e.g. Yan et al. (2014); Albarqouni et al. (2016); Guan et al. (2017)). When learning deep neural networks from the labels of multiple annotators, typical approaches rely on some sort of label aggregation mechanisms prior to training. In classiﬁcation settings, the simplest and most common approach is to use majority voting, which naively assumes that all annotators are equally reliable. More advanced approaches, such as the one proposed in (Dawid and Skene 1979) and other variants (e.g. Ipeirotis, Provost, and Wang (2010); Whitehill et al. (2009)) jointly model the unknown biases of the annotators and their answers as noisy versions of some latent ground truth. Despite their improved ground truth estimates over majority voting, recent works have shown that jointly learning the classiﬁer model and the annotators noise model using EM-style algorithms',\n",
       " '1602.07630': 'FAILED',\n",
       " '1610.06283': 'In recent years, quadrotors have been widely used for civilian and law-enforcement purposes, such as providing aerial surveillance, carrying out rescue missions, transporting goods over distance, and performing surveying and inspection tasks [1]–[4]. In all these applications, the quadrotor is required to precisely track a desired trajectory in order to perform the task safely and effectively. Trajectory tracking for quadrotors poses a challenge on controller design. First, quadrotors are underactuated systems with nonlinear dynamics, making it a difﬁcult control problem. Second, trajectory tracking precision of quadrotors can be affected by many factors, including uncertainty in the turn-rate-to-thrust map, time delays that are difﬁcult to quantify, aerodynamic effects and other unpredictable factors such as friction in the actuators. Third, even in a perfect world, where the system dynamics are known exactly, a given classical controller cannot achieve perfect tracking for any arbitrary, feasible, desired trajectory. Our goal is to achieve improved trajectory tracking control for quadrotors while taking into account three features that The authors are with the Dynamic Systems Lab (www.dynsyslab.org) at the University of Toronto Institute for Aerospace Studies (UTIAS), Canada. Email: {qiyang.li, jingxing.qian, zining.zhu, xuchan.bao}@mail.utoronto.ca, mohamed.helwa@robotics.utias.utoronto.ca, schoellig@utias.utoronto.ca. Fig. 1. Block diagram of our interactive “ﬂy-as-you-draw” demo. The user draws an arbitrary trajectory on a mobile device. Upon receiving the new trajectory, the quadrotor immediately takes off and follows the signal, processed by the pre-trained Deep Neural Network (DNN) in the (x-z)-plane. The overhead camera system provides state feedback and also performance feedback to the user. A demo video can be found at http://tiny.cc/DNN-ImpromptuTracking. are crucial for most real-world trajectory tracking applications (Figure 1 shows our speciﬁc application): 1) Stability of the control system and robustness to reasonable disturbances must be guaranteed to ensure safety of the operation. 2) The system should be able to precisely track a new trajectory without adaptation. 3) The computational resources needed for the control system should be manageable such that the algorithm can be applied to small vehicles with limited computational power. Simple controllers such as typical proportional-integralderivative (PID) controllers can achieve adequate performance under certain conditions, for example low speeds and accelerations, while having all the crucial features mentioned above [5], [6]. However, PID controllers are difﬁcult to tune and they tend to behave poorly on more aggressive trajectories. There exist previous works on improving control for quadrotors or other robots, such as learning the dynamics or the inverse dynamics, iterative learning control and Gaussian Process learning. However, we show in Section II that these approaches have drawbacks with respect to the three crucial features we identiﬁed above, which are relevant for real-time trajectory tracking. In this paper, we propose a DNN-based control system which improves the trajectory tracking performance by utilizing past ﬂight experiences. After',\n",
       " '1802.10171': 'Weakly supervised learning [3, 26, 33, 35] has recently gained much attention as a popular solution to address labeled data scarcity in computer vision. Using only image level labels for example, one can obtain attention maps for a given input with back-propagation on a Convolutional Neural Network (CNN). These maps relate to the network’s response given speciﬁc patterns and tasks it was trained for. The value of each pixel on an attention map reveals to what extent the same pixel on the input image contributes to the ﬁnal output of the network. It has been shown that one can extract localization and segmentation information from such attention maps without extra labeling effort. However, supervised by only classiﬁcation loss, attenFigure 1. The proposed Guided Attention Inference Network (GAIN) makes the network’s attention on-line trainable and can plug in different kinds of supervision directly on attention maps in an end-to-end way. We explore the self-guided supervision from the network itself and propose GAINext when extra supervision are available. These guidance can optimize attention maps towards the task of interest. tion maps often only cover small and most discriminative regions of object of interest [11, 28, 38]. While these attention maps can still serve as reliable priors for tasks like segmentation [12], having attention maps covering the target foreground objects as complete as possible can further boost the performance. To this end, several recent works either rely on combining multiple attention maps from a network via iterative erasing steps [31] or consolidating attention maps from multiple networks [11]. Instead of passively exploiting trained network attention, we envision an end-toend framework with which task-speciﬁc supervision can be directly applied on attention maps during training stage. On the other hand, as an effective way to explain the network’s decision, attention maps can help to ﬁnd restrictions of the training network. For instance in an object categorization task with only image-level object class labels, we may encounter a pathological bias in the training data when the foreground object incidentally always correlates with the same background object (also pointed out in [24]). Figure 1 shows the example class ”boat” where 1 arXiv:1802.10171v1  [cs.CV]  27 Feb 2018  there may be bias towards water as a distractor with high correlation. In this case the training has no incentive to focus attention only on the foreground class and generalization performance may suffer when the testing data does not have the same correlation (”boats out of water”). While there have been attempts to remove this bias by re-balancing the training data, we instead propose to model the attention map explicitly as part of the training. As one beneﬁt of this we are able to control the attention explicitly and can put manual effort in providing minimal supervision of attention rather than re-balancing the data set. While it may not always',\n",
       " '1405.2982': 'Coordinated transmission has been recognized as a promising approach to improving the system performance of wireless cellular networks [2]. According to the level of cooperation, the coordinated transmission can be roughly classiﬁed into two categories, i.e., MIMO cooperation and interference coordination [3]. In MIMO cooperation, the transmitters, e.g., base stations (BSs), cooperate in data transmission by sharing all the channel state information (CSI) and data signals. In interference coordination, the BSs only coordinate in the transmission strategies for mitigating the inter-cell interference. Compared with MIMO cooperation, interference coordination requires the CSI to be shared only, and hence induces less overhead on the backhaul network [4]. A common model for studying interference coordination is the interference channel (IFC) [5], where multiple transmitters simultaneously communicate with their respective receivers over a common frequency band, and thus interfere with each other. Part of this work will be presented in IEEE ICASSP 2014 [1]. The work is supported by the National Science Council, R.O.C., under Grants NSC-1022221-E-007-019-MY3 and NSC 102-2221-E-011-005-MY3. Wei-Chiang Li and Chong-Yung Chi are with Institute of Communications Engineering & Department of Electrical Engineering, National Tsing Hua University, Hsinchu, Taiwan 30013, R.O.C. E-mail: weichiangli@gmail.com, cychi@ee.nthu.edu.tw Tsung-Hui Chang is with Department of Electronic and Computer Engineering, National Taiwan University of Science and Technology, Taipei, Taiwan 10607, R.O.C. E-mail: tsunghui.chang@ieee.org. In this paper, we consider a multiple-input single-output (MISO) IFC, wherein the transmitters are equipped with multiple antennas while the receivers are equipped with single antenna. Moreover, we are interested in the coordinated beamforming (CoBF) design problem; that is, the transmitters coordinate with each other to optimize their transmit beamforming vectors. A typical formulation of the CoBF design problem is to maximize a system utility function, e.g., the sum rate, proportional fairness rate, harmonic mean rate or the max-min-fairness (MMF) rate, assuming that the transmitters have perfect CSI. It turns out that the CoBF problems are in general difﬁcult optimization problems. Speciﬁcally, it has been shown in [6] that, except for the MMF rate [7], the CoBF problem for the sum rate, proportional fairness rate and harmonic mean rate are NP-hard in general, implying that they cannot be efﬁciently solved in general. Due to this fact, a signiﬁcant amount of research efforts has been devoted to the development of reliable and efﬁcient methods for handling the CoBF problems. For example, the works [8]–[11] characterize the optimal beamforming structure in order to reduce the dimension of exhaustive search. Global optimization algorithms were also developed in [12]–[15] but are only efﬁcient when the number of users is small. Another branch of works focus on suboptimal but computationally efﬁcient approximation algorithms; see [6], [10], [16]–[22]. The works mentioned above all have assumed that the transmitters have perfect CSI',\n",
       " '1411.4617': 'Write-Once-Memories (WOM) are a frequently used model for modern computer memories, such as ﬂash memories. For example, for Single-Level-Cell (SLC) type ﬂash memories, each memory cell may be turned from bit 1 to bit 0 by applying programming pulses. However, the memory cell can not be turned from bit 0 to bit 1 without using a block erasure operation. If no erasure operation is used, then the SLC type ﬂash memory is a perfect example of WOM. Modern NAND-type ﬂash memories usually can endure very limited numbers of erasure operations. The block erasure operations are also expensive in terms of time and power consumption and thus should be avoided as much as possible. Rewriting coding schemes for WOM are a type of coding schemes, where data can still be written into WOM, when some memory cells have already been written. Rewriting codes for ﬂash memories are thus preferred, due to the fact that data can be written into each memory block multiple times without using any erasure operation. The concept of rewriting codes for WOM was coined by Rivest and Shamir [2]. However, constructing capacityachieving WOM codes had been an open problem for almost three decades. Recently, several capacity-achieving WOM codes were proposed. One algebraic construction based capacity-achieving WOM coding scheme is proposed by Shipilka [3]. The coding scheme achieves zero encoding error probability, but have polynomial computational complexities. Another polar coding based capacity-achieving WOM coding scheme is proposed by Burshtein and Strugatski [4]. This coding scheme has asymptotic vanishing encoding error probability and linear coding complexities. However, the coding scheme needs a random dither signal shared by the encoder and decoder. For most data storage applications, the random dither signal is difﬁcult to implement. A third capacityachieving WOM code construction was proposed in [1], where the coding scheme is based on source polarization [5]. The WOM coding scheme in [1] has vanishing encoding error probabilities and linear coding complexities. One major advantage of this coding scheme is that no shared random dither signal is needed. Due to the fact that practical computer memory systems always contain noises, a nature question to ask next is how may we generalize the above coding schemes, such that they may also have the error-control capabilities. Some joint WOM and channel coding schemes have already been proposed in [6]. The coding schemes in [6] may be considered as generalizations of the WOM coding schemes in [4]. Recently, some new joint WOM and channel coding schemes were also proposed in [7]. In [7], two coding schemes were proposed including one basic coding scheme, and one chaining based coding scheme. The basic coding scheme may be considered as a certain generalization of the WOM coding scheme in [1] from the noiseless WOM case to the noisy WOM case. However, the paper [7] only showed that the basic coding scheme can be used for a speciﬁc channel model, where any memory cells with',\n",
       " '1712.01600': 'Automated land cover mapping based on satellite image analysis and classiﬁcation is a well-known challenge which is of a great interest for many ﬁelds, such as agriculture [1] and risk monitoring [2]. The recently launched Sentinel-2 satellite constellation provides a richer content in spatial, spectral and temporal domains, and produces a huge amount of images to process daily. In this context, Deep Learning (DL) appears as an appealing alternative to traditional shallow classiﬁcation approaches to deal with such a massive amount of data. A DL architecture is a deep artiﬁcial neural network composed of a hierarchical succession of neuron layers performing linear and non-linear processing. Mimicking the human brain behavior, the network tuning (typically millions of parameters) is automatically performed thanks to a supervised training process on large datasets that are generally associated to some “ground truth” knowledge. However, the ground truth quality is essential to reach satisfying performances. Some recent works already use deep neural nets to process remotely sensed images. In [3], the authors compared different well-established deep architectures (AlexNet, AlexNetsmall, VGG) for the classiﬁcation of SAT-4/SAT-6 dataset (from US National Agriculture Imagery Program, NAIP) using Convolutional Neural Networks (CNN). Pirotti et al. [4] benchmarked different machine learning methods (including multilayered perceptron) for classiﬁcation of Sentinel-2 images. In [5], we proposed a new 3D CNN architecture for hyperspectral data pixelwise classiﬁcation (semantic segmentation). In [6, 7], we adapted the SegNet architecture to achieve semantic segmentation of multimodal airborne imagery. In this paper, we rely on the recent DenseNet [8] and SegNet [9] architectures to perform land cover semantic segmentation of large multispectral Sentinel-2 images. These architectures are experimentally assessed through two different use cases, namely ﬁne and coarse resolution estimation. We also introduce a new 3D DenseNet network in order to jointly process both spatial and spectral dimensions. In addition, we suggest the use of a “noisy ground truth” (i.e. outdated and low spatial resolution labels) for both training and testing. The idea is to explore the feasibility of outdated low quality knowledge integration for modern image sensors and analysis methods. Experiments are conducted in a wide region between France, Switzerland and Italy relying on the reference areas of GlobCover (ESA 2009 Global Land Cover Map) annotation and 2016 ESA Sentinel-2 images. 2. SPECTRAL CHANNEL FUSION AND DEEP NEURAL NETWORKS When dealing with multispectral images, strategies for processing and fusing spectral channels are numerous. Deep neural networks enable a large variety of choices from the arXiv:1712.01600v1  [cs.CV]  5 Dec 2017  component operator to architectural levels. At the low component level, the classical approach is to use 2D convolution layers from the ﬁrst stages of the network. In such a conﬁguration, each neuron applies a speciﬁc ﬁlter to each channel and then fuses (sums) the resulting maps. Such an approach enables the early combination of',\n",
       " 'cs/0509032': 'Over the past ten years, the study of phase transition phenomena has been one of the most exciting areas in Computer Science and Artiﬁcial Intelligence. Numerous studies have established that for many NP-complete problems (e.g., SAT and CSP), the hardest random instances occur, while a control parameter is varied accordingly, between an under-constrained region where all instances are almost surely satisﬁable and an over-constrained region where all instances are almost surely unsatisﬁable. In the transition region, there is a threshold where half the instances are satisﬁable. Generating hard instances is important both for understanding the complexity of the problems and for providing challenging benchmarks [Cook and Mitchell, 1997]. Another remarkable progress in Artiﬁcial Intelligence has been the development of incomplete algorithms for various kinds of problems. And, since this progress, one important issue has been to produce hard satisﬁable instances in order to evaluate the efﬁciency of such algorithms, as the approach that involves exploiting a complete algorithm in order to keep random satisﬁable instances generated at the threshold can only be used for instances of limited size. Also, it has been shown that generating hard (forced) satisﬁable instances is related to some open problems in cryptography such as computing a one-way function [Impagliazzo et al., 1989; Cook and Mitchell, 1997]. In this paper, we mainly focus on random CSP (Constraint Satisfaction Problem) instances. Initially, four “standard” models, denoted A, B, C and D [Smith and Dyer, 1996; Gent et al., 2001], have been introduced to generate random binary CSP instances. However, [Achlioptas et al., 1997] have identiﬁed a shortcoming of all these models. Indeed, they prove that random instances generated using these models suffer from (trivial) unsatisﬁability as the number of variables increases. To overcome the deﬁciency of these standard models, several alternatives have been proposed. On the one hand, [Achlioptas et al., 1997] have proposed a model E and [Molloy, 2003] a generalized model. However, model E does not permit to tune the density of the instances and the generalized model requires an awkward exploitation of probability distributions. Also, other alternatives correspond to incorporating some “structure” in the generated random instances. Roughly speaking, it involves ensuring that the generated instances be arc consistent [Gent et al., 2001] or path consistent [Gao and Culberson, 2004]. The main drawback of all these approaches is that generating random instances is no more quite a natural and easy task. On the other hand, [Xu and Li, 2000; Xu and Li, 2003], [Frieze and Molloy, 2003] and [Smith, 2001] have revisited standard models by controlling the way parameters change as the problem size increases. The alternative model D scheme of [Smith, 2001] guarantees the occurrence of a phase transition when some parameters are controlled and when the constraint tightness is within a certain range. The two revised models, called RB and RD, of [Xu and Li, 2000; Xu and Li, 2003] provide the same',\n",
       " '1711.02488': 'There is no doubt that high-quality image plays a critical role in computer vision tasks such as object detection and scene understanding. Unfortunately, the images obtained in reality are often degraded in some cases. For example, when captured in low-light conditions, images always suffer from very low contrast and brightness, which increases the difﬁculty of subsequent high-level tasks in a great extent. Figure 1(a) provides one case, from which many details have been buried into the dark background. Due to the fact that in many cases only low-light images can be captured, several low-light image enhancement methods have been proposed to overcome this problem. In general, these methods can be categorized into two groups: histogrambased methods and Retinex-based methods. In this paper, a novel low-light image enhancement ∗Authors contributed equally. (a) Origional (b) MSRCR[16] (c) Dong[8] (d) LIME[11] (e) SRIE[10] (f) Ours Figure 1. An example result of our image enhancement method and others state-of-the-art methods. model based on convolutional neural network and Retinex theory is proposed. To the best of our knowledge, this is the ﬁrst work of using convolutional neural network and Retinex theory to solve low-light image enhancement. Firstly, we explain that multi-scale Retinex is equivalent to a feedforward convolutional neural network with different Gaussian convolution kernels. The main drawback of multiscale Retinex is that the parameters of kernels depend on artiﬁcial settings rather than learning from data, which makes the accuracy and ﬂexibility of the model reduce in some way. Motivated by this fact, we put forward a Convolutional Neural Network (MSR-net) that directly learns an end-toend mapping between dark and bright images. Our method differs fundamentally from existing approaches. We regard low-light image enhancement as a supervised learning problem. Furthermore, the surround functions in Retinex theory [19] are formulated as convolutional layers, which are arXiv:1711.02488v1  [cs.CV]  7 Nov 2017  involved in optimization by back-propagation. Overall, the contribution of our work can be boiled down to three aspects: First of all, we establish a relationship between multi-scale Retinex and feedforward convolutional neural network. Secondly, we consider low-light image enhancement as a supervised learning problem where dark and bright images are treated as input and output respectively. Last but not least, experiments on a number of challenging images reveal the advantages of our method in comparison with other state-of-the-art methods. Figure 1 gives an example. Our method achieves a brighter and more natural result with a clearer texture and richer details. 2. Related Work 2.1. Low-light Image Enhancement In general, low-light image enhancement can be categorized into two groups: histogram-based methods and Retinex-based methods. Directly amplifying the low-light image by histogram transformation is probably the most intuitive way to lighten the dark image. One of the simplest and',\n",
       " '1509.01774': 'We are currently in the phase of conceptualizing the requirements of the ﬁfth generation (5G) of mobile wireless systems. One of the major goals is to improve the areal capacity (bits/s/m2) by a factor of 1000 [2]. To this end, an extension to the already allocated spectrum is of paramount importance. Recently, the spectrum beyond 6 GHz, which largely entails the millimeter wave is envisaged as a powerful source of spectrum for 5G wireless systems. However, the millimeter wave technology is still in its initial stage and along with complex regulatory requirements in this regime, it has to address several challenges like propagation loss, low efﬁciency of radio frequency components such as power ampliﬁers, small ∗A. Kaushik and F. K. Jondral are with Communications Engineering Lab, Karlsruhe Institute of Technology (KIT), Germany. Email:{ankit.kaushik,friedrich.jondral}@kit.edu. †S.K. Sharma, S. Chatzinotas and B. Ottersten are with SnT - securityandtrust.lu, University of Luxembourg, Luxembourg. Email:{shree.sharma, symeon.chatzinotas, bjorn.ottersten}@uni.lu. The preliminary analysis of this paper has been presented at CROWNCOM 2015 in Doha, Qatar [1]. This work was partially supported by the National Research Fund, Luxembourg under the CORE projects “SeMIGod” and “SATSENT”. size of the antenna and link acquisition [3]. Therefore, in order to capture a deeper insight of its feasibility in 5G, it is essential to overcome the aforementioned challenges in the near future. Besides the spectrum beyond 6 GHz, an efﬁcient utilization of the spectrum below 6GHz presents an alternative solution. The use of the spectrum in this regime (below 6 GHz) is fragmented and statically allocated, leading to inefﬁciencies and the shortage in the availability of spectrum for new services. However, it is possible to overcome this scarcity if we manage to utilize this radio spectrum efﬁciently. In this perspective, cognitive radio (CR) is foreseen as one of the potential contenders that addresses the spectrum scarcity problem. Since its origin by Mitola et al. in 1999, this notion has evolved at a signiﬁcant pace, and consequently has acquired certain maturity. However, from a deployment perspective, this technology is still in its preliminary phase. In this view, it is necessary to make substantial efforts that enable the placement of this concept over a hardware platform. An access to the licensed spectrum is an outcome to the paradigm employed by the secondary user (SU). Based on the paradigms described in the literature, all CR systems that provide dynamic access to the spectrum mainly fall under three categories, namely, interweave, underlay and overlay systems [4]. In interweave systems (ISs), the SUs render an interference-free access to the licensed spectrum by exploiting spectral holes in different domains such as time, frequency, space and polarization, whereas underlay systems enable an interference-tolerant access under which the SUs are allowed to use the licensed spectrum (e.g. Ultra Wide Band) as long as they respect the interference constraints of the primary receivers (PRs). Besides that, overlay systems consider the participation',\n",
       " '1806.09351': 'Reinforcement Learning algorithms (RL) now allow artiﬁcial agents to learn to play many of the Atari 2600 games directly from pixels [28] or to beat the world’s best players at Go and chess with minimal human knowledge [41]. Unfortunately, these impressive successes rely on very long interaction times between the algorithm and the system: for example, 38 days of play (real time) for Atari 2600 games [28], 4.8 million games for Go [41], or about 100 hours of simulation time (much more for real time) for a 9-DOF mannequin that learns to walk [20]. This makes these algorithms well suited to simulated environments, but challenging to use with real robots, for which it is often not materially possible to perform more than few dozen of trials of a few seconds/minutes. At the other end of the spectrum, model-based policy search algorithms can learn policies in a few minutes of interaction time, at the expense of a signiﬁcant computation time between episodes. For instance, PILCO [11] and Black-DROPS [5, 4] can learn a policy to balance a cart-pole or a policy to control a 5-DOF manipulator in less than 40-60 seconds of interaction time. However, these algorithms implicitly assume that most states can be associated to a positive or negative reward, as this is the case when the objective is to balance a pole or to follow a trajectory with a manipulator. In other words, these algorithms are essentially greedy and mostly exploiting. While this assumption often holds in control tasks, rewards are much more sparse in many interesting learning scenarios: typically, we would like to reward the robot when it successfully achieves the 2nd Conference on Robot Learning (CoRL 2018), Z¨urich, Switzerland. arXiv:1806.09351v3  [cs.LG]  3 Mar 2020  Policy System 2.0 1.5 1.0 0.5 0.0 0.5 1.0 1.5 2.0 1.0 0.5 0.0 0.5 1.0 1.5 2.0 Model Max Novelty Max Reward Min model variance PARETO FRONT Pareto-Based Multi-Objective Policy Search Learn transition dynamics Choose policy with exploration parameter ε  State xt Controls ut Figure 1: Overview of the Multi-DEX algorithm: The robot interacts with the environment with a policy in an episodic scheme; after each episode, Multi-DEX learns a GP model of the dynamics of the system and then performs multi-objective policy search to obtain a set of Pareto-optimal policies based on novelty, cumulative reward, and model variance; last, a policy is selected from the Pareto set based on an exploration parameter ε and executed on the robot to collect new data. task, and not for all the intermediate steps that we think should lead to success. For example, a robot might need to open a drawer and get rewarded by how much the drawer is open: in most of the state space, the reward is zero because the robot does not even touch the handle',\n",
       " '1802.00420': 'In response to the susceptibility of neural networks to adversarial examples (Szegedy et al., 2013; Biggio et al., 2013), there has been signiﬁcant interest recently in constructing defenses to increase the robustness of neural networks. While progress has been made in understanding and defending against adversarial examples in the white-box setting, where the adversary has full access to the network, a complete solution has not yet been found. As benchmarking against iterative optimization-based attacks (e.g., Kurakin et al. (2016a); Madry et al. (2018); Carlini & Wagner (2017c)) has become standard practice in evaluating defenses, new defenses have arisen that appear to be robust against these powerful optimization-based attacks. We identify one common reason why many defenses provide *Equal contribution 1Massachusetts Institute of Technology 2University of California, Berkeley. Correspondence to: Anish Athalye <aathalye@mit.edu>, Nicholas Carlini <npc@berkeley.edu>. Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018 by the author(s). apparent robustness against iterative optimization attacks: obfuscated gradients, a term we deﬁne as a special case of gradient masking (Papernot et al., 2017). Without a good gradient, where following the gradient does not successfully optimize the loss, iterative optimization-based methods cannot succeed. We identify three types of obfuscated gradients: shattered gradients are nonexistent or incorrect gradients caused either intentionally through non-differentiable operations or unintentionally through numerical instability; stochastic gradients depend on test-time randomness; and vanishing/exploding gradients in very deep computation result in an unusable gradient. We propose new techniques to overcome obfuscated gradients caused by these three phenomena. We address gradient shattering with a new attack technique we call Backward Pass Differentiable Approximation, where we approximate derivatives by computing the forward pass normally and computing the backward pass using a differentiable approximation of the function. We compute gradients of randomized defenses by applying Expectation Over Transformation (Athalye et al., 2017). We solve vanishing/exploding gradients through reparameterization and optimize over a space where gradients do not explode/vanish. To investigate the prevalence of obfuscated gradients and understand the applicability of these attack techniques, we use as a case study the ICLR 2018 non-certiﬁed defenses that claim white-box robustness. We ﬁnd that obfuscated gradients are a common occurrence, with 7 of 9 defenses relying on this phenomenon. Applying the new attack techniques we develop, we overcome obfuscated gradients and circumvent 6 of them completely, and 1 partially, under the original threat model of each paper. Along with this, we offer an analysis of the evaluations performed in the papers. Additionally, we hope to provide researchers with a common baseline of knowledge, description of attack techniques, and common evaluation pitfalls, so that future defenses can avoid falling vulnerable to these same attack approaches. To promote reproducible research, we release our reimplementation of each of these defenses, along with implementations of our attacks for each. 1 1 https://github.com/anishathalye',\n",
       " '1808.08460': 'As machine learning increasingly supports consequential decision making, its vulnerability to manipulation and gaming is of growing concern. When individuals learn to adapt their behavior to the specifics of a statistical decision rule, its original predictive Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. FAT* ’19, January 29–31, 2019, Atlanta, GA, USA © 2019 Association for Computing Machinery. ACM ISBN 978-1-4503-6125-5/19/01...$15.00 https://doi.org/10.1145/3287560.3287576 power will deteriorate. This widely observed empirical phenomenon, known as Campbell’s Law or Goodhart’s Law, is often summarized as: “Once a measure becomes a target, it ceases to be a good measure” [24]. Institutions using machine learning to make high-stakes decisions naturally wish to make their classifiers robust to strategic behavior. A growing line of work has sought algorithms that achieve higher utility for the institution in settings where we anticipate a strategic response from the the classified individuals [4, 10, 13]. Broadly speaking, the resulting solution concepts correspond to more conservative decision boundaries that increase robustness to some form of distributional shift. But there is a flip side to strategic classification. As insitutional utility increases as a result of more cautious decision rules, honest individuals worthy of a positive classification outcome may face a higher bar for success. The costs incurred by individuals as a consequence of strategic classification are by no means hypothetical, as the example of lending shows. In the United States, credit scores are widely deployed to allocate credit. However, even creditworthy individuals routinely engage in artificial practices intended to improve their credit scores, such as opening up a certain number of credit lines in a certain time period [9]. In this work, we study the tension between accuracy to the institution and impact to the individuals being classified. We first introduce a general measure of the cost of strategic classification, which we call the social burden. Informally, the social burden measures the expected cost that a positive individual needs to incur to be correctly classified correctly. For a broad class of cost functions, we prove there exists an intrinsic trade-off between institutional accuracy and social burden: any increase in institutional accuracy comes at an increase in social burden. Moreover, we precisely characterize this trade-off and show the commonly considered Stackelberg equilibrium solution achieves maximal institutional accuracy at the expense of maximal social burden. Equipped with this generic trade',\n",
       " '1102.0522': 'FAILED',\n",
       " '1506.05855': 'Model selection is a central problem in statistics. In the information-based paradigm of inference, models are selected to maximize the expected predictive performance. The canonical implementation of information-based inference is the minimization of the Akaike Information Criterion (AIC), an estimate for the (minus) predictive performance (Akaike 1973; Burnham and Anderson 1998). Although it has enjoyed signiﬁcant success, AIC is biased in many important applications. Model singularity, i.e. the absence of a one-toone correspondence between model parameters and distribution functions, can make the bias extremely large and result in the catastrophic failure of model selection, as described below. There are three important and related mechanisms of failure: (i) ﬁnite-sample-size corrections, (ii) model singularity and (iii) model-training-algorithm dependence. In the course of our own analyses of biophysical and cell biology data, we frequently encounter all three phenomena. The goal of this paper is to propose a reﬁnement to the information-based approach that overcomes these limitations. We begin by studying the predictive complexity that plays a critical role in the mechanism of failure of AIC. We compute the exact predictive complexity of models to study its phenomenology and dependence on the parameters of the generative model. We discover that the AIC approximation for the complexity can signiﬁcantly under or over-estimate the complexity, leading to pathological over-ﬁtting or under-ﬁtting in model selection problems. We ﬁnd that parameter unidentiﬁability (i.e. model singularity), sample size, ﬁtting algorithm and parameter manifold geometry can all play a critical role in determining the model complexity. In real analyses, the true distribution is unknown and therefore the complexity must be approximated. Our exploration of the true complexity motiInformation-based inference for singular models and ﬁnite sample sizes 3 vates a new approximation for the complexity: the frequentist complexity. In this approximation, we assume the model of interest is the generative model at the estimated parameters. The frequentist complexity is not a universal function of model dimension and sample size. Instead it naturally adapts to the likelihood function, model training algorithm and sample size. We propose an improved information criterion based on this new frequentist complexity: the Frequentist Information Criterion (QIC). For regular models in the large-sample-size limit, QIC is equal to AIC. Away from this limit, there can be large mismatches between the QIC and AIC. For instance, for models with large multiplicity, QIC can be much larger than AIC. For sloppy models (Machta et al. 2013), QIC can be much smaller than AIC. It is essential to note that QIC is still biased (since the true distribution is not know) but this bias is nearly always much smaller than the AIC estimate of the complexity and, as a result, QIC outperforms AIC (and other information criteria). QIC also outperforms other predictive methods in many contexts. To demonstrate this improved performance, we present three example analyses in Section 5 that highlight speciﬁc advantages QIC over other methods. 2 Information-based inference',\n",
       " '1708.06959': 'Linear programming (LP) decoding was introduced by Feldman et al. in 2005 [1] as an efﬁcient, but (compared to maximum-likelihood (ML) decoding) suboptimal decoding approach for binary linear codes. Since then, LP decoding of low-density parity-check (LDPC) codes has been extensively studied by various authors, and, in particular, several lowcomplexity approaches have been proposed. See, for instance, [2]–[6]. The approach was later extended to nonbinary linear codes by Flanagan et al. [7], and several low-complexity approaches were proposed in [8]–[11]. Nonbinary LDPC codes are especially appealing because they in general exhibit a better performance than binary codes in the important ﬁnitelength regime. The underlying structure of LP decoding are the codeword polytopes (or convex hulls) whose vertices correspond to the codewords of a binary image of a (nonbinary) single paritycheck (SPC) code. By intersecting all those polytopes deﬁned by the rows of a speciﬁc parity-check matrix of a linear code, one obtains the so-called fundamental polytope, the domain of optimization of an LP decoder. While an explicit description for binary codes is well known (second formulation in [1]), all LP formulations for nonbinary codes known so far generalize the ﬁrst formulation in [1] and thus depend on auxiliary variables (one for each feasible conﬁguration) [7]. As recent results have shown [6], [12], LP decoding based on the alternating direction method of multipliers (ADMM) for convex optimization problems [13] is able to outperform (in terms of decoding complexity) other LP decoding approaches. The efﬁciency of the algorithm relies on an efﬁcient algorithm to do Euclidean projection onto the codeword polytope of a binary SPC code. In the binary case, the so-called “twoslice” lemma is the main result that enables efﬁcient Euclidean projections in time O(d log d) for a binary SPC code of length d. More recently, more efﬁcient projection algorithms have been proposed in [14] and [15]. While initial work has been done to apply ADMM to the nonbinary case [11], it is currently not known how this framework can be applied to codes over nonbinary ﬁelds with characteristic greater than two, one difﬁculty being that little is known about codeword polytopes of nonbinary codes over such ﬁelds which one would need to project on. In this work, we present several results on the codeword polytope and the fundamental polytope of a general nonbinary code over any ﬁnite ﬁeld Fq. We provide an explicit construction for valid (facet-deﬁning) inequalities for the socalled constant-weight embedding of a nonbinary SPC code  2 over any prime ﬁeld Fp without relying on auxiliary variables. The construction is based on what we call classes of building blocks. A building block is simply a vector of length p, while a class of building blocks is a set of such vectors. The vectors within a class are used to build an inequality in a block-wise manner (thus the name building block) where each block corresponds to a code',\n",
       " '1802.10264': 'Robotic grasping is one of the most fundamental robotic manipulation tasks: before interacting with objects in the world, a robot typically must begin by grasping them. Prior work in robotic manipulation has sought to address the grasping problem through a wide range of methods, from analytic grasp metrics [43], [36] to learning-based approaches [2]. Learning grasping directly from self-supervision offers considerable promise in this ﬁeld: if a robot can become progressively better at grasping through repeated experience, perhaps it can achieve a very high degree of proﬁciency with minimal human involvement. Indeed, learning-based methods inspired by techniques in computer vision have achieved good results in recent years [22]. However, these methods typically do not reason about the sequential aspect of the grasping task, either choosing a single grasp pose [33], or repeatedly choosing the next most promising grasp greedily [24]. While previous works have explored deep reinforcement learning (RL) as a framework for robotic grasping in a sequential decision making context, such studies have been limited to either single objects [34], or simple geometric shapes such as cubes [40]. In this work, we explore how RL can be used to automatically learn robotic grasping skills for diverse objects, with a focus on comparing a variety of RL methods in a * Equal contribution 1Accompanying video: https://goo.gl/pyMd6p realistic simulated benchmark. One of the most important challenges in learning-based grasping is generalization: can the system learn grasping patterns and cues that allow it to succeed at grasping new objects that were not seen during training? Successful generalization typically requires training on a large variety of objects and scenes, so as to acquire generalizeable perception and control. Prior work on supervised learning of grasping has used tens of thousands [33] to millions [24] of grasps, with hundreds of different objects. This regime poses a major challenge for RL: if the learning is conducted primarily on-policy, the robot must repeatedly revisit previously seen objects to avoid forgetting, making it difﬁcult to handle extremely diverse grasping scenarios. Off-policy reinforcement learning methods might therefore be preferred for tasks such as grasping, where the wide variety of previously seen objects is crucial for generalization. Indeed, the supervised learning methods explored in previous work [33], [24] can be formalized as special cases of off-policy reinforcement learning that do not consider the sequential nature of the grasping task. Our aim in this paper is to understand which off-policy RL algorithms are best suited for vision-based robotic grasping. A number of model-free, off-policy deep reinforcement learning methods have been proposed in recent years for solving tasks such as Atari games [28] and control of simple simulated robots [25]. However, these works do not explore the kinds of diverse and highly varied situations that arise in robotic grasping, and the focus is typically on ﬁnal performance (e.g., expected reward), rather than generalization to new objects and situations. Furthermore, training typically involves progressively collecting more and',\n",
       " '1803.02852': 'FAILED',\n",
       " '1402.2447': 'In our recent work on score calibration for speaker recognition, we employed linear score-to-log-likelihood-ratio transforms, the parameters of which were trained via generative [1, 2], or discriminative [3] methods. In both cases, we noticed that a linear transform could not calibrate well everywhere over a wide range of operating points. This meant we had to choose in which operating region we wanted calibration to work best, by tailoring the training objective function. In both generative and discriminative cases, this was achieved (essentially) by artiﬁcially weighting the importance of target and nontarget trials in the training data. In [1], we used a weighted maximum-likelihood criterion, while in [3], a variety of different calibration-sensitive discriminative objective functions were explored. While these strategies both resulted in good calibration in the targeted operating region, it also gave poorer calibration in other operating regions. In this paper, we explore the possibility of using more general, non-linear calibration transforms, with the hope that (i) they can give good calibration over a wider range of operating points and (ii) they can be trained without having to resort to specially tailored objective functions. In what follows, we recapitulate our generative and discriminative linear calibration strategies, and then introduce several non-linear strategies. All of these are compared experimentally on scores from SRE’12. 2. Calibration We brieﬂy summarize the calibration problem and some of its solutions. We consider a speaker recognizer that, when given speech input, outputs a raw score. The score should help to decide which of two hypotheses, known as target and non-target is true. The speech input has two parts, the enrollment speech and the test speech. The target hypothesis says the test speech is of the same speaker as the enrollment. The non-target hypothesis says the speakers are different. In order to be able to use the recognizer to make costeffective decisions, we can calibrate the recognizer scores, to give us log-likelihood-ratios (LLRs) [4]. Calibration transforms a score, s, as: s →log P(s|H1, B) P(s|H2, B) (1) where the likelihoods are conditioned on H1, the target hypothesis, or H2, the non-target hypothesis. The likelihoods are further conditioned on some background information, B, which may include generative or discriminative score modelling assumptions, model parameters, or data. If B includes model parameters rather than data, the calibration method is known as a plug-in method. If instead, B contains data rather than parameters, the method is known as fully Bayesian. In this paper, we shall work with plug-in methods, which perform well in situations where a large amount of training data is available, which is the case here. See [2] for an analysis of the relationship between plug-in and fully Bayesian solutions and [5] for an example where fully Bayesian calibration outperforms plug-in calibration when very little training is available. 2.1. Generative calibration For training',\n",
       " '1703.00512': 'The term benchmarking is used in machine learning (ML) to refer to the evaluation and comparison of ML methods regarding their ability to learn patterns in ‘benchmark’ datasets that have been applied as ‘standards’. Benchmarking could be thought of simply as a sanity check to conﬁrm that a new method successfully runs as expected and can reliably ﬁnd simple patterns that existing methods are known to identify Hastie et al. (2009). A more rigorous way to view benchmarking is as an approach to identify the respective strengths c⃝2017 Olson, La Cava, Orzechowski, Urbanowicz, and Moore. License: CC-BY 4.0, see https://creativecommons.org/licenses/by/4.0/. Attribution requirements are provided at http://jmlr.org/papers/vx/x.html. arXiv:1703.00512v1  [cs.LG]  1 Mar 2017  Olson, La Cava, Orzechowski, Urbanowicz, and Moore and weaknesses of a given methodology in contrast with others Caruana and NiculescuMizil (2006). Comparisons could be made over a range of evaluation metrics, e.g., power to detect signal, prediction accuracy, computational complexity, and model interpretability. This approach to benchmarking would be important for demonstrating new methodological abilities or simply to guide the selection of an appropriate ML method for a given problem. Benchmark datasets typically take one of three forms. The ﬁrst is accessible, well-studied real-world data, taken from diﬀerent real-world problem domains of interest. The second is simulated data, or data that has been artiﬁcially generated, often to ‘look’ like real-world data, but with known, underlying patterns. For example, the GAMETES genetic-data simulation software generates epistatic patterns of association in ‘mock’ single nucleotide polymorphism (SNP) data Urbanowicz et al. (2012b,a). The third form is toy data, which we will deﬁne here as data that is also artiﬁcially generated with a known embedded pattern but without an emphasis on representing real-world data, e.g., the parity or multiplexer problems Blum et al. (2003); Koza (1992). It is worth noting that the term ‘toy dataset’ has often been used to describe a small and simple dataset such as the examples included with algorithm software. While some benchmark repositories and datasets have emerged as more popular than others, ML still lacks a central, comprehensive, and concise set of benchmark datasets that accentuate the strengths and weaknesses of established ML methods. Individual studies often restrict their benchmarking eﬀorts for various reasons, for example based on comparing variants of the ML algorithm of interest. The genetic programming (GP) community has also previously discussed appropriate benchmarking when comparing GP methodologies O’Neill et al. (2010); McDermott et al. (2012); White et al. (2013). Benchmarking eﬀorts may focus on a speciﬁc application of interest, e.g. traﬃc sign detection Stallkamp et al. (2012), or a more narrowly deﬁned ML problem type, e.g. classiﬁcation of 2-way epistatic interactions Moore et al. (2006); Li et al. (2016). The scope of benchmarking may also be limited by practical computational requirements. There are currently a number of challenges that make it diﬃcult',\n",
       " '1506.06216': 'The Internet technology has undergone enormous changes since its early stages and it has become an important communication infrastructure targeting anywhere, anytime connectivity. Historically, human-to-human (H2H) communication, mainly voice communication, has been the center of importance. Therefore, the current network protocols and infrastructure are optimized for human-oriented trafﬁc characteristics. Lately, an entirely different paradigm of communication has emerged with the inclusion of \"machines\" in the communications landscape. In that sense, machines/devices that are typically wireless such as sensors, actuators, and smart meters are able to communicate with each other exchanging information and data without human intervention. Since the number of connected devices/machines is expected to surpass the human-centric communication devices by tenfold, machine-to-machine (M2M) communication is expected to A. Ali and W. Hamouda with the Dept. of Electrical and Computer Engineering, Concordia University, Montreal, Quebec, H3G 1M8, Canada, and M. Uysal with the Dept. of Electrical and Electronics Engineering, Ozyegin University, Istanbul, Turkey, 34794, e-mail:{(ali_abde,hamouda)@ece.concordia.ca}, murat.uysal@ozyegin.edu.tr.  be a key element in future networks [1]. With the introduction of M2M, the next generation Internet or the Internet-of-Things (IoT) has to offer the facilities to connect different objects together whether they belong to humans or not. The ultimate objective of M2M communications is to construct comprehensive connections among all machines distributed over an extensive coverage area. Recent reports show that the projected number of connected machines/devices to the IoT will reach approximately 50 billions by 2020 (Fig. 1). This massive introduction of communicating machines has to be planned for and accommodated with applications requiring wide range of requirements and characteristics such as mobility support, reliability, coverage, required data rate, power consumption, hardware complexity, and device cost. Other planning and design issues for M2M communications include the future network architecture, the massive growth in the number of users, and the various device requirements that enable the concept of IoT. In terms of M2M, the future network has to provide machine requirements as power and cost are critical aspects of M2M devices. For instance, a set-and-forget type of application in M2M devices such as smart meters require very long battery life where the device has to operate in an ultra low-power mode. Moreover, the future network should allow for low complex and low data rate communication technologies which provide low cost devices that encourage the large scale of the IoT. The network architecture, therefore, needs to be ﬂexible enough to provide these requirements and more. In this regard, a considerable amount of research has been directed towards available network technologies such as Zigbee (IEEE 802.15.4) or WiFi (IEEE 802.11b) by interconnecting devices in a form of large heterogeneous network [2]. Furthermore, solutions for the heterogeneous network architecture (connections, routing, congestion control, energy-efﬁcient transmission, etc.) have been presented to suit the new requirements of M2M communications. However, it is still not clear whether these sophisticated solutions can',\n",
       " '1712.07686': 'Reinforcement learning (RL) is a growing area of biologically inspired machine learning techniques. RL is used to train agents how to act in unknown environments with unknown optimal behavior. Agents know only the goals they have to reach. Training is based on numeric feedback to agent’s actions. The common practice is to give a positive reward when the ﬁnal goal is reached or a negative one when the ﬁnal goal became impossible to reach. When number of states recognizable by the agent is inﬁnite or too large to keep in memory—function approximations are used for state processing. One of common approximations used in RL is an artiﬁcial neural network (ANN). Neural networks are vulnerable to the problem known as catastrophic forgetting (CF) which causes information losses in network during retraining. In RL ANN retraining occurs often—from once per step to once per episode, and so CF has a signiﬁcant effect. Pseudorehearsal is one of the methods used to prevent CF, and we are going to use it to improve speed and quality of training. We conducted an experiment on a simulation of the pole balancing cart to prove that pseudorehearsal signiﬁcantly improves performance of actor-critic agent. II. BACKGROUND A. Reinforcement learning Reinforcement learning is a framework of machinelearning-based applications for action selection, policy improvement and state evaluation. RL is a natural concept used by living creatures. First researches on RL in nature appeared about century ago. Edward Thorndike found that learning is based on the ability of the animals to ﬁgure out results from the consequences of their behavior [1]. Later B.F.Skinner researched learning by reinforcement and punishment more deeply [2]. According to R.Sutton RL as a computer science concept was born in 1979 at the University of Massachusetts. It was the result of analysis, extension and application of the ideas from the work of Klopf A. Harry ”Brain function and adaptive systems: a heterostatic theory” [3]. Growth in computational powers and techniques, fast decreasing of computers prices and ﬂexibility of agents make RL a popular and promising area. All RL algorithms are based on a simple consequence: to get the observation of the current state of the environment, to apply some rule to choose the next action to reach the goal, to receive reward or punishment and to improve the rule. Observation is a representation of environment that agent can get and process. State is an observation at some moment of time. Observed environment has to be assumed as a Markov Decision Process (MDP). MDP is a mathematical framework for modeling decision-making problems. To denote MDP at environment Markov Property should be satisﬁed: each state st at any timestep t is conditionally independent of all previous states st−n, ∀n ∈N and actions at−n, while the next state reached from current after some action applied should be deﬁnable. State-action mapping rules in RL agents are expressed in policy function π(st, a). Policy denotes',\n",
       " '1710.04019': 'FAILED',\n",
       " '1407.7390': 'In recent years, interest has grown on aﬀordable devices (e.g. Microsoft Kinect or ASUS Xtion Pro) that capture depth quite reliably. Such devices provide a depth image (D), along with an RGB image (thus RGB-D). A depth image can be further processed to obtain marker-less body pose estimation by means of a skeleton model consisting of a series of joints. Due to their low cost, high sample rate and capability to combine visual and depth information, these devices have become widespread in both research and commercial applications. Furthermore, their use has not been restricted to games, for which they were initially designed, but other applications where natural human-computer interaction is required. These devices are widely used in the ﬁeld of human action recognition (HAR), particularly in indoor scenarios for the recognition of activities of daily living. For research purposes, a variety of datasets for human action (or gesture) recognition  2 Table 1. State-of-the-art datasets for action recognition based on depth or skeletal features, sorted from more quoted to less quoted according to Google Scholar. Name Actions Actors Times Samples Citations Year MSR Action3D [1] 20 10 2 or 3 567 176 2010 MSR DailyActivity3D [2] 16 10 2 320 138 2012 RGBD-HuDaAct [3] 12 30 2 or 4 1189 86 2011 CAD-60 [4] 12 2+2 - 60 80 2012 UTKinect Action [5] 10 10 2 - 73 2012 MSRC-12 KinectGesture [6] 12 30 - 594 39 2012 CAD-120 [7] 10 2+2 - 120 33 2013 MSR ActionPairs [8] 6 10 3 180 29 2013 MSR Gesture3D [9] 12 10 2 or 3 336 25 2012 LIRIS Human Activities [10] 10 21 - - 24 2012 Berkeley MHAD [11] 11 7+5 5 ∼660 18 2013 G3D [12] 20 10 3 - 11 2012 ACT4 Dataset [13] 14 24 >1 6844 9 2012 UPCV Action [14] 10 20 - - 6 2014 WorkoutSu-10 Gesture [15] 10 15 10 1500 6 2013 IAS-Lab Action [16] 15 12 3 540 3 2013 Florence 3D Action [17] 9 10 2 or 3 215 2 2012 have been recorded using RGB-D devices (see Table 1). The MSR Action3D dataset [1] from Microsoft Research stands out as one of the most used in the literature, as many developed methods for action recognition have been validated with this dataset. Hence, it should be easy to determine the best human action recognition method in a straightforward way by comparing their success and processing rates. However, to the best of our knowledge, this is not possible at the moment as we found that almost all the works compare results obtained with diﬀerent validation methods. Therefore, this work aims to ﬁll the existing gap in order to enable a fair comparison of the state of the art. We have reviewed 176 papers that make reference to the MSR Action3D dataset. Out of these 176 papers, 62 papers have been considered as they use the MSR Action3D dataset for the validation of the human',\n",
       " '1710.10898': 'In inverse problems the goal is to determine model parameters from indirect noisy observations. Example of such problems arise in many different ﬁelds in science and engineering, e.g., in X-ray computed tomography (CT) [27], electron tomography [28], and magnetic resonance imaging [8]. Machine learning has recently also been applied in this area, especially in imaging applications. Using supervised machine-learning to solve inverse problems in imaging requires training data where ground truth images are paired with corresponding noisy indirect observations. The learning provides a mapping that associates observations to corresponding images. However, in several applications there are difﬁculties in obtaining the ground truth, e.g., in many cases it may have undergone a distortion. For example, a recent study showed that MRI images may be distorted by up to 4 mm due to, e.g., inhomogeneities in the main magnetic ﬁeld [36]. If these images are used for training, the learned MRI reconstruction will suffer in quality. Similar geometric inaccuracies arise in several other imaging modalities, such as Cone Beam CT and full waveform inversion in seismic imaging. This work seeks to provide a scheme for learning a reconstruction scheme for an ill-posed inverse problem with a Wasserstein loss by leveraging upon recent advances in efﬁcient solutions of optimal transport [10, 22] and learned iterative schemes for inverse problems [3]. The proposed method is demonstrated on a computed tomography example, where we show a signiﬁcant improvement compared to training the same network using mean squared error loss. In particular, using the Wasserstein loss instead of standard mean squared error gives a result that is more robust against potential miss-alignment in training data. arXiv:1710.10898v1  [cs.CV]  30 Oct 2017  2 Background 2.1 Inverse problems In inverse problems the goal is to reconstruct an estimate of the signal ftrue ∈X from noisy indirect measurements (data) g ∈Y assuming g = T (ftrue) + δg. (1) In the above X and Y are referred to as the reconstruction and data space, respectively. Both are typically Hilbert or Banach spaces. Moreover T : X →Y denotes the forward operator, which models how a given signal gives rise to data in absence of noise. Finally, δg ∈Y is the noise component of data. Many inverse problems of interest are ill-posed, meaning that there is no uniques solution to (1) and hence there is no inverse to T . Typically reconstructions of ftrue are sensitive to the data and small errors gets ampliﬁed. One way to mitigate these effects is to use regularization [12]. Variational regularization In variational regularization one formulates the reconstruction problem as an optimization problem. To this end, one introduces a data discrepancy functional f 7→L(T (f), g), where L : Y × Y →R, that quantiﬁes the miss-ﬁt in data space, and a regularization functional S : X →R that encodes a priori information about ftrue by penalizing undesirable solutions. For a given g ∈Y , this gives an optimization problem of the form min f∈X',\n",
       " '1707.06892': 'Nowadays billions of mobile users receive seamless and stable wireless services supported by the communication infrastructures. With the rapid development of mobile communications, dozens of network standards have emerged, including the Third Generation Partnership Project (3GPP) Long Term Evolution (LTE) standards. In addition to advanced multiple-input multipleoutput (MIMO) technologies [1], small cells and heterogeneous networks [2], cloud radio access networks (CRAN) have emerged as a popular technology for future mobile networks [3]. CRAN features centralized resource management, with all the computing, control, and data storage of the network gathered into the cloud. The centralized data centers, cellular core networks and backbone networks are equipped with computing, storage and network management functions. However, recent research [4], [5] has shown that the completely centralized architecture of CRAN makes it hard to cope with the unpredictable mobility of users, the increasing density of base stations (BSs) [6], and the explosive growth of user data demand. The planning and optimization of heterogeneous networks are facing complicated inter-cell interference problems and increased management complexities. More recently, heterogeneous cloud radio access network (HCRAN) has been proposed [7], where remote radio heads (RRHs) working in coordination with high power nodes can effectively mitigate co-channel interference. Although HCRAN may offer better cost efﬁciency than CRAN [7], the complex cost structure behind HCRAN, how its resource optimization should be supported by the baseband unit (BBU) pool, and its trafﬁc burden on the cloud center require more in-depth studies. Since all information is exchanged through the BBU pool, HCRAN may cause additional burden on the fronthaul and backhaul links, especially the wireless ones [8], as compared with CRAN. In the meanwhile, more data is generated from various social media platforms due to their increasing popularity. Hence, it becomes increasingly important to consider social networking and local information in the management and optimization of RANs. This is not easily achieved in CRAN or HCRAN because of their centralized architecture. July 24, 2017 DRAFT  3 In view of the above issues related to CRAN and HCRAN and the requirements of the future communication scenarios, FRAN was introduced by Cisco to exploit local signal processing and computing, cooperative resource management, and distributed storing/caching capabilities at the network edge [9]. In FRAN, a large amount of signal processing and computing is performed in a distributed manner, rather than all by the centralized BBU pool, and local data can be stored in edge devices, such as access points (APs) and user equipment (UE), instead of the cloud data center. A unique feature of FRAN is to maximize the use of edge devices of the network, e.g., to perform collaborated radio signal processing. As a result, the burden on the fronthaul is much relieved than CRAN or HCRAN. Due to these distinctive characteristics of FRAN, network management and optimization mechanisms need to be revisited for FRAN. In [10], cooperative interference mitigation and handover management were studied for heterogeneous cloud small cell networks. An information-centric wireless network virtualization framework was studied in [11]. These requirements translate into a tremendous demand for bandwidth',\n",
       " '1808.07528': 'Depth estimation is one of the most extensively studied tasks by the computer vision community, largely due to its value in facilitating scene understanding and geometric relations between objects [27, 29, 10]. Fusing depth has demonstrated improved performance on a number of computer vision tasks including semantic segmentation, topographical reconstruction, and activity recognition [54, 33, 17]. Previously, the computer vision community relied on multiview methods such as stereo vision and structurefrom-motion for depth estimation [40, 4, 3, 38, 55, 2]. However, situations where multiple measurements from the same scene may not be available or difﬁcult to acquire moFigure 1: Representative images showing estimated depth on NYUv2 and Make 3D datasets via our proposed adversarial depth estimation paradigm. tivate the need for developing monocular depth estimation methods. Though deep networks have shown promise in estimating depth from monocular images, many methods rely on local pixel-wise loss functions that do not capture higherorder statistics of the training data. To make these networks more context-aware, many loss functions calculate image gradients to capture changes in depth and preserve structural details [10, 48, 19]. This problem has also been partially addressed by the many combinations of deep learning and graphical model-based methods [31, 11, 34, 35]. CNN-graphical model setups such as jointly trained CNNCRF methods are more context-aware as compared to regular CNNs. While hybrid CNN-CRF models such as Liu et al. [31] and Mahmood et al. [34, 35] maintain some spaarXiv:1808.07528v3  [cs.CV]  15 Jun 2019  tial consistency between the prediction and the ground truth depth map via the pairwise potential, over-segmenting the image into super-pixels prevents the network from learning higher-order statistics that may describe depth cues in the image. Recently, conditional generative adversarial networks (cGANs) have become an emerging technique in learning mapping distributions of high-dimensional data [21]. Such methods have mainly been used for image-to-image translation tasks such as artistic style transfer, super-resolution [5], and synthetic data reﬁnement [50]. However, they can also be used in inference tasks such as semantic segmentation[32], in which the generator learns a mapping from objects to their semantic labels in an image, and the discriminator provides feedback to the generator about its accuracy. As argued by Luc et al. and Isola et al. [32, 21], this adversarial term can be interpreted as a non-local loss that penalizes the joint conﬁguration of pixel values. We argue further that this non-local loss, when calculated at the patch-level, is beneﬁcial for learning depth cues. From our experiments, the beneﬁts of conditional adversarial learning are two fold: a) networks can learn a loss function for depth estimation, which promotes the recovery of features that would be generally lost due to the limitations of a local pixel-wise loss function, and (b) such a setup is more context-aware, as the',\n",
       " '1511.06645': 'Human body pose estimation methods have become increasingly reliable. Powerful body part detectors [36] in combination with tree-structured body models [37, 7] show impressive results on diverse datasets [21, 3, 33]. These benchmarks promote pose estimation of single pre-localized persons but exclude scenes with multiple people. This problem deﬁnition has been a driver for progress, but also falls short on representing a realistic sample of real-world images. Many photographs contain multiple people of interest (see Fig 1) and it is unclear whether single pose approaches generalize directly. We argue that the multi person case deserves more attention since it is an important real-world task. Key challenges inherent to multi person pose estimation 1Models and code available at http://pose.mpi-inf.mpg.de 1 2 3 4 5 6 1 2 3 4 5 6 1 2 4 6 1 3 5 6 1 2 3 4 5 6 1 3 5 6 1 6 (a) (b) (c) Figure 1. Method overview: (a) initial detections (= part candidates) and pairwise terms (graph) between all detections that (b) are jointly clustered belonging to one person (one colored subgraph = one person) and each part is labeled corresponding to its part class (different colors and symbols correspond to different body parts); (c) shows the predicted pose sticks. are the partial visibility of some people, signiﬁcant overlap of bounding box regions of people, and the a-priori unknown number of people in an image. The problem thus is to infer the number of persons, assign part detections to person instances while respecting geometric and appearance constraints. Most strategies use a two-stage inference process [29, 18, 35] to ﬁrst detect and then independently estimate poses. This is unsuited for cases when people are in close 1 arXiv:1511.06645v2  [cs.CV]  26 Apr 2016  proximity since they permit simultaneous assignment of the same body-part candidates to multiple people hypotheses. As a principled solution for multi person pose estimation a model is proposed that jointly estimates poses of all people present in an image by minimizing a joint objective. The formulation is based on partitioning and labeling an initial pool of body part candidates into subsets that correspond to sets of mutually consistent body-part candidates and abide to mutual consistency and exclusion constraints. The proposed method has a number of appealing properties. (1) The formulation is able to deal with an unknown number of people, and also infers this number by linking part hypotheses. (2) The formulation allows to either deactivate or merge part hypotheses in the initial set of part candidates hence effectively performing non-maximum suppression (NMS). In contrast to NMS performed on individual part candidates, the model incorporates evidence from all other parts making the process more reliable. (3) The problem is cast in the form of an Integer Linear Program (ILP). Although the problem is NP-hard, the ILP formulation facilitates the computation of bounds and feasible solutions',\n",
       " '1604.05668': 'In secure multiparty computation (MPC), mutually distrusting users wish to communicate with each other in such a way that, at the end of the communication, each user can compute a function of the distributed private inputs The work of M. Mishra and B. K. Dey is supported in part by the Bharti Centre for Communication, IIT Bombay, a grant from the Department of Science and Technology, Government of India and by the Information Technology Research Academy (ITRA), Government of India under ITRA-Mobile grant ITRA/15(64)/Mobile/USEAADWN/01. V. M. Prabhakaran’s work was supported in part by a Ramanujan Fellowship from the Department of Science and Technology, Government of India and by the Information Technology Research Academy (ITRA), Government of India under ITRA-Mobile grant ITRA/15(64)/Mobile/USEAADWN/01. The work of S. Diggavi was supported in part by NSF grant 1321120. This work was presented in part at the 2014 and 2015 IEEE International Symposia on Information Theory and at the IEEE Information Theory Workshop, Hobart, 2014 M. Mishra and B. K. Dey are with the Department of Electrical Engineering, Indian Institute of Technology Bombay (IIT Bombay), Mumbai, India(email: mmishra,bikash@ee.iitb.ac.in). V. M. Prabhakaran is with the School of Technology and Computer Science, Tata Institute of Fundamental Research (TIFR), Mumbai, India(email: vinodmp@tifr.res.in).S. Diggavi is with the Department of Electrical Engineering, University of California at Los Angeles (UCLA), Los Angeles, USA(email: suhasdiggavi@ucla.edu). September 8, 2018 DRAFT  2 without learning any more than what the function output and the private input reveal about other users’ inputs and outputs. Applications such as voting, auctions and data-mining, amongst several others [4] illustrate the need for secure MPC in real life. It is well known that information-theoretically (unconditionally) secure computation between two users is not possible in general, when the users have only private randomness and noiseless communication as a resource to enable the computation. A combinatorial characterization of functions that can be securely computed was derived in [6]. However, additional stochastic resources, such as a noisy channel [7] or distributed sources, can be used to enable two users to compute a function unconditionally securely. Oblivious Transfer (OT) is a secure two-user computation which has been shown to be a primitive for all two-user secure computation [8], [9]. That is, if the two users can obtain OT using the resources available to them, then they can securely compute any function of their inputs. In particular, OT can be achieved if the two users have access to a noisy channel. A 1-of-2 string OT is a two-party computation where user Alice’s private inputs are two equal-length strings and user Bob’s private input is a choice bit. Bob obtains exactly one string of his choice from Alice’s strings, without Alice ﬁnding out the identity of the string chosen by Bob. If a discrete memoryless channel (DMC) is',\n",
       " '1606.03504': 'Data in the format of tensors, or multilinear arrays, arise naturally in many modern applications. A kth order hypercubic tensor of dimension d × · · · × d has dk entries so that these datasets typically are of fairly large size even for moderate d and small k. Therefore, it is oftentimes impractical to observe or store the entire tensor, which naturally brings about the question of tensor completion: How to reconstruct a kth order tensor T ∈Rd1×···×dk from observations {T (ω) : ω ∈Ω} where Ωis a uniformly sampled subset from [d1] × · · · × [dk]? Here [d] = {1, . . . , d}. The goal of this paper is to study in its full generality a class of tensor completion methods via nuclear norm minimization focusing on higher order tensors (k ≥3). 1.1 Tensor completion Obviously, for reconstructing T from a subset of its entries to be possible at all, T needs to have some sort of low dimensional structure which is often characterized by certain notion of low-rankness. In particular, let Lj(X) be the linear subspace of Rdj spanned by the mode-j ﬁbers: \\x08 X(a1, . . . , aj−1, ·, aj+1, . . . , ak) ∈Rdj : a1 ∈[d1], . . . , ak ∈[dk] \\t . Denote by rj(X) the dimension of Lj(X). The tuplet {r1(X), . . . , rk(X)} is the so-called Tucker ranks of X. It is not hard to see that there are a total of O(rk−1d) free parameters in specifying a kth order hypercubic tensor of dimension d × · · · × d whose Tucker ranks are upper bounded by r, which suggests the possibility of recovering a large tensor of low rank from a fairly small fraction of the entries. In addition to low-rankness, it is also essential to tensor completion that every entry of T contains similar amount of information about the entire tensor so that missing any of them would not stop us from being able to reconstruct it – a property that can be formally characterized through the coherence of the linear subspace Lj(T ). See, e.g, Cand`es and Recht (2008). More speciﬁcally, the coherence of an r dimensional linear subspace U of Rd 2  is deﬁned as µ(U) = d r max 1≤i≤d ∥P Uei∥2 ℓ2 = max1≤i≤d ∥P Uei∥2 ℓ2 d−1 Pd i=1 ∥P Uei∥2 ℓ2 , where P U is the orthogonal projection onto U and ei’s are the canonical basis for Rd. We call a tensor X µ∗-incoherent if µj(X) := µ(Lj(X)) ≤µ∗. An especially popular class of techniques to tensor completion is based on nuclear norm minimization where we seek among all tensors that agree with T on all observed entries the one with the smallest nuclear norm. 1.2 Nuclear norm minimization Recall that the spectral and nuclear norms of a tensor X ∈Rd1×···×dk are deﬁned as ∥X∥= sup uj∈Rdk:∥uj∥ℓ2≤1 ⟨X, u1 ⊗· · · ⊗uk⟩ and ∥X∥∗= sup Y ∈Rd1×···×dk :∥Y ∥≤1 ⟨X, Y ⟩, respectively, where ⟨·, ·⟩is the usual vectorized inner product, and ∥·∥ℓp',\n",
       " '1704.08063': 'Recent years have witnessed the great success of convolutional neural networks (CNNs) in face recognition (FR). Owing to advanced network architectures [13, 23, 29, 4] and discriminative learning approaches [25, 22, 34], deep CNNs have boosted the FR performance to an unprecedent level. Typically, face recognition can be categorized as face identiﬁcation and face veriﬁcation [8, 11]. The former classiﬁes a face to a speciﬁc identity, while the latter determines whether a pair of faces belongs to the same identity. In terms of testing protocol, face recognition can be evaluated under closed-set or open-set settings, as illustrated in Fig. 1. For closed-set protocol, all testing identities are predeﬁned in training set. It is natural to classify testing face images to the given identities. In this scenario, face veriﬁcation is equivalent to performing identiﬁcation for a pair of faces respectively (see left side of Fig. 1). Therefore, closedset FR can be well addressed as a classiﬁcation problem, 1See the code at https://github.com/wy1iu/sphereface. Testing  Set  Identities DO NOT appear in training set ... Identities appear in training set Face Verification Face Identification Closed-set Face Recognition Open-set Face Recognition Training  Set Equivalent  Task ... ... Classification Problem Metric Learning Problem Learn separable  features Learn large-margin  features ... Training  Set Testing  Gallery ... ...Training Set Feature  Label  Predictor IDi Feature  Extractor ... ... Compare Distance Feature  Feature  Extractor Training Set Training Set ... ... ... ... ... ... Feature  Features  Compare Distance Label  Predictor IDi IDj Compare label Figure 1: Comparison of open-set and closed-set face recognition. where features are expected to be separable. For open-set protocol, the testing identities are usually disjoint from the training set, which makes FR more challenging yet close to practice. Since it is impossible to classify faces to known identities in training set, we need to map faces to a discriminative feature space. In this scenario, face identiﬁcation can be viewed as performing face veriﬁcation between the probe face and every identity in the gallery (see right side of Fig. 1). Open-set FR is essentially a metric learning problem, where the key is to learn discriminative large-margin features. Desired features for open-set FR are expected to satisfy the criterion that the maximal intra-class distance is smaller than the minimal inter-class distance under a certain metric space. This criterion is necessary if we want to achieve perfect accuracy using nearest neighbor. However, learning features with this criterion is generally difﬁcult because of the intrinsically large intra-class variation and high interclass similarity [21] that faces exhibit. Few CNN-based approaches are able to effectively formulate the aforementioned criterion in loss functions. PiarXiv:1704.08063v4  [cs.CV]  29 Jan 2018  -20 -15 -10 -5 0 5 10 15 0 5 10 15 20 25 30 -0.6 -0.4 -0.2 0 0.2 0.4 0.6 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0',\n",
       " '1312.6197': 'Dropout (Hinton et al., 2012) has recently garnered much attention as a novel regularization strategy for neural networks involving the use of structured masking noise during stochastic gradient-based optimization. Dropout training can be viewed as a form of ensemble learning similar to bagging (Breiman, 1994) on an ensemble of size exponential in the number of hidden units and input features, where all members of the ensemble share subsets of their parameters. Combining the predictions of this enormous ensemble would ordinarily be prohibitively expensive, but a scaling of the weights admits an approximate computation of the geometric mean of the ensemble predictions. Dropout has been a crucial ingredient in the winning solution to several high-proﬁle competitions, notably in visual object recognition (Krizhevsky et al., 2012a) as well as the Merck Molecular Activity Challenge and the Adzuna Job Salary Prediction competition. It has also inspired work on activation function design (Goodfellow et al., 2013a) as well as extensions to the basic dropout technique (Wan et al., 2013; Wang and Manning, 2013) and similar fast approximate model averaging methods (Zeiler and Fergus, 2013). Several authors have recently investigated the mechanism by which dropout achieves its regularization effect in linear models (Baldi and Sadowski, 2013; Wang and Manning, 2013; Wager et al., 2013), as well as linear and sigmoidal hidden units (Baldi and Sadowski, 2013). However, many of the recent empirical successes of dropout, and feed forward neural networks more generally, have utilised piecewise linear activation functions (Jarrett et al., 2009; Glorot et al., 2011; Goodfellow et al., 2013a; Zeiler et al., 2013). In this work, we empirically study dropout in rectiﬁed linear networks, employing the recently popular hidden unit activation function f(x) = max(0, x). 1 arXiv:1312.6197v2  [stat.ML]  2 Jan 2014  We begin by expanding upon previous work which investigated the quality of dropout’s approximate ensemble prediction by comparing against Monte Carlo estimates of the correct geometric average (Srivastava, 2013; Goodfellow et al., 2013a). Here, we compare against the true average, in networks of size small enough that the exact computation is tractable. We ﬁnd, by exhaustive enumeration of all sub-networks in these small cases, that the weight scaling approximation is a remarkably and somewhat surprisingly accurate surrogate for the true geometric mean. Next, we consider the importance of the geometric mean itself. Traditionally, bagged ensembles produce an averaged prediction via the arithmetic mean, but the weight scaling trick employed with dropout provides an efﬁcient approximation only for the geometric mean. While, as noted by (Baldi and Sadowski, 2013), the difference between the two can be bounded (Cartwright and Field, 1978), it is not immediately obvious what effect this source of error will have on classiﬁcation performance in practice. We therefore investigate this question empirically and conclude that the geometric mean is indeed a suitable replacement for the arithmetic mean in the context of a dropout-trained ensemble. The questions raised thus far pertain primarily to the approximate model averaging performed at test time, but dropout',\n",
       " '1803.11366': '3D face shapes reconstructed from 2D images have been proven to beneﬁt many tasks, e.g., face alignment or facial landmark localization [18, 43], face animation [9, 13], and face recognition [5, 12]. Many prior work have been devoted to reconstructing 3D face shapes from a single 2D image, including shape from shading (SFS)-based methods [14, 20], 3D morphable model (3DMM) ﬁtting- ∗This work is supported by the National Key Research and Development Program of China (2017YFB0802300) and the National Natural Science Foundation of China (61773270, 61703077). †Corresponding author. Email: qjzhao@scu.edu.cn. Figure 1. Comparison between the learning process of (a) existing methods and (b) our proposed method. GT denotes Ground Truth. (d) and (e) are 3D face shapes and disentangled identity shapes reconstructed by our method for the images in (c) from LFW [15]. based methods [4, 5], and recently proposed regressionbased methods [23, 24]. These methods mostly aim to recover 3D face shapes that are loyal to the input 2D images or retain as much facial detail as possible (see Fig. 1). Few of them explicitly consider the identity-sensitive and identity-irrelevant features in the reconstructed 3D faces. Consequently, very few studies have been reported about recognizing faces using the reconstructed 3D face either by itself or by fusing with legacy 2D face recognition [5,34]. Using real 3D face shapes acquired by 3D face scanners 1 arXiv:1803.11366v1  [cs.CV]  30 Mar 2018  for face recognition, on the other hand, has been extensively studied, and promising recognition accuracy has been achieved [6, 11]. Apple recently claims to use 3D face matching in its iPhone X for cellphone unlock [1]. All of these prove the discriminative power of 3D face shapes. Such a big performance gap between the reconstructed 3D face shapes and the real 3D face shapes, in our opinion, demonstrates that existing 3D face reconstruction methods seriously undervalue the identity features in 3D face shapes. Taking the widely used 3DMM ﬁtting based methods as example, their reconstructed 3D faces are constrained in the limited shape space spanned by the pre-determined bases of 3DMM, and thus perform poorly in capturing the features unique to different individuals [41]. Inspired by the latest development in disentangling feature learning for 2D face recognition [27, 35], we propose to disentangle the identity and non-identity components of 3D face shapes, and more importantly, fulﬁll reconstructing accurate 3D face shapes loyal to input 2D images and learning discriminative shape features effective for face recognition in a joint manner. These two tasks, at the ﬁrst glance, seem to contradict each other. On one hand, face recognition prefers identity-sensitive features, but not every detail on faces; on the other hand, 3D reconstruction attempts to recover as much facial detail as possible, regardless whether the detail beneﬁts or distracts facial identity recognition. In this paper, however, we will show that by exploiting the ‘contradictory’ objectives of recognition and reconstruction, we are able to disentangle',\n",
       " '1805.00979': 'Upon learning patterns from data in real-life applications, labelling examples often consume signiﬁcant time and money, which makes it infeasible to obtain large training sets. For example, sentiment analysis of texts requires extensive manual annotation, which costs expert time. Another example is the optimization of black box functions, for which the evaluation is costly or derivatives are not available. In these cases, active learning can be used to query labels for the most informative instances. modAL is an active learning framework for Python, designed with modularity, ﬂexibility and extensibility in mind. Built on top of scikit-learn (Pedregosa et al. (2011); Buitinck et al. (2013)), it allows the rapid prototyping of active learning workﬂows with a large degree of freedom. It was designed to be easily extensible, allowing researchers to implement and test novel active learning strategies with minimal eﬀort. 2. Design principles and features Our objective with modAL was to create an active learning library which takes advantage of the advanced features of Python and the extensive ecosystem of scikit-learn, making 1. https://github.com/modAL-python/modAL 1  the implementation of complex workﬂows simple and intuitive. Speciﬁcally, modAL was designed with the following goals in mind. 1. Modularity: separating and recombining parts of a workﬂow. In general, an active learning workﬂow consists of a learning algorithm and a query strategy. In modAL, this is represented by the ActiveLearner class, for which these components are passed upon object creation. Learning algorithms can be used with query strategies in any combination, making rapid prototyping possible. 2. Extensibility: simple customization of parts. In a modAL active learning workﬂow, a query strategy is simply a function, given to the object representing the active learning algorithm upon initialization. Implementing custom query strategies can be done without understanding class structures or modAL internals. Thus it requires minimal eﬀort, allowing researchers to easily test novel strategies and compare them with existing ones. 3. Flexibility: compatibility with the scikit-learn ecosystem. scikit-learn is one of the most popular machine learning tools in Python, used by researchers and practicioners as well. modAL is built on top of it, allowing the use any of its classiﬁer and regressor algorithms in active learning pipelines. Objects in modAL also follow the scikit-learn API, making it possible to insert them into already existing workﬂows. modAL supports a wide range of active learning algorithms for both pool-based and stream-based (Atlas et al. (1990)) scenarios. For multiclass problems, uncertainty sampling methods such as least conﬁdent (Lewis and Catlett (1994)), max margin and max entropy sampling; committee-based methods such as query by committee (Seung et al. (1992)) and query by disagreement (Cohn et al. (1994)); ranked batch-mode sampling (Cardoso et al. (2017)); expected error reduction (Roy and McCallum (2001)) is provided. For multilabel classiﬁcation, SVM binary minimum (Brinker (2006)); max loss and mean max loss (Li et al. (2004)); MinConﬁdence, AvgConﬁdence, MinScore, AvgScore (Esuli and Sebastiani (2009)) algorithms are implemented. For density weighting',\n",
       " '1806.09771': 'Collectible Card Games (CCGs) have been popular since the 90s, evidenced by the large player base of these kinds of games. For instance, Magic: the Gathering has more than 20 million players globally [1], while an online free-to-play CCG Hearthstone (Blizzard Inc.) reached a record of 40 million registered accounts in 2016 [2]. A CCG typically has hundreds to thousands of different cards, each of which supports speciﬁc in-game rules and effects. When playing CCGs, before each match, every player is asked to build a deck comprising of a subset of all available cards. While in game, each player takes turns to draw cards from their respective deck and place them on the game board to fare (e.g., attack, counter-attack, cast spell, etc.) against their opponent cards. In general, there is no single deck which can universally win against all other decks because CCGs often design cards with sophisticated synergistic and oppositional relationships. For example, in Hearthstone, there are two distinguished types of decks that counter each other in different phases of a match. An Aggro deck, taking an aggressive approach, is built with cards capable of dealing damage to the opponents as quickly as possible. In contrast, a control deck is the opposite archetype with cards which can survive long enough to triumph in the late game through powerful but expensive cards or complex combos. The goal of deck building is to identify a set of cards which suits the player’s own play style and effectively counters either an individual opponent or a group of opponents with speciﬁc play styles and decks. As deck building is regarded as a crucial part of game play, there exist many online forums and websites for players to discuss, analyze and test deck building strategies (e.g., [3], [4]). A deck recommendation system for the purpose of deck building can beneﬁt players and game developers in several ways. First, it can ease choices made by players in deck building. Players may also learn new strategies of deck building and practice their skills based on recommended decks. Second, such a system can be useful to increase player’s engagement, by controlling match outcomes to keep players interested [5], [6]. Deploying a deck recommendation system in certain modes (e.g., a practice mode) could help re-engage players who are frustrated with the difﬁculty of building effective decks. Last, from a game developer’s perspective, a deck recommendation system is also useful for debugging games. For example, balancing the power of cards is an important topic in CCGs [7] or similar games [8]. The game developer can use a deck recommendation system to check whether certain combinations of cards are powerful or weak. As a deck is a combination of cards, deck building can be formulated as a combinatorial optimization problem (COP), which relates to ﬁnding an optimal solution (the most winningeffective deck) in a ﬁnite search space of all possible decks. Deck building has a large',\n",
       " '1002.1436': 'In a recent series of papers [26], [27], [37], [39], the rank-modulation scheme was suggested as a way of storing information in ﬂash-memory devices. Basically, instead of a conventional multi-level ﬂash cell in which the charge level of a single cell is measured and quantized to a symbol from the input alphabet, in the rank-modulation scheme the permutation induced by the relative charge levels of several cells is the stored information. The scheme, ﬁrst described in [26] in the context of ﬂash memory, works in conjunction with a simple cell-programming operation called “push-to-the-top”, which raises the charge level of a single cell above the rest of the cells. It was suggested in [26] that this scheme eliminates the over-programming problem in ﬂash memories, reduces corruption due to retention, and speeds up cell programming. This is certainly not the ﬁrst time permutations have been used for modulation purposes. Permutations have been used as codewords as early as the works of Slepian [35] (later extended in [2]), in which permutations were used to digitize vectors from a time-discrete memoryless Gaussian source, and Chadwick and Kurz [9], in which permutations were used in the context of signal detection over channels with non-Gaussian noise (especially impulse noise). Further early studies include works such as [2]–[4], [8], [12], [13]. More recently, permutations were used for communicating over powerlines (for example, see [38]), and for modulation schemes for ﬂash memory [26], [27], [37], [39]. An important application for rank-modulation in the context of ﬂash memory was described in [26]. A set of n cells, over which the rank-modulation scheme is applied, is used to simulate a single conventional multi-level ﬂash cell with n! levels corresponding to the alphabet {0, 1, . . ., n! −1}. The simulated cell supports an operation which raises its value by 1 modulo n!. This is the only required operation in many rewriting schemes for ﬂash memories (see [5], [23]–[25], [40]). This operation is realized by a Gray code traversing the n! states where, physically, the transition between two adjacent states in the Gray code is achieved by using a single “pushto-the-top” operation. Most generally, a gray code is a sequence of distinct elements from an ambient space such that adjacent elements in the sequence are “similar”. Ever since their original publication by Gray [21], the use of Gray codes has reached a wide variety of areas, such as storage and retrieval applications [10], processor allocation [11], statistics [14], hashing [18], puzzles [20], ordering documents [28], signal encoding [29], data compression [30], circuit testing [31], and more. For a survey on Gray codes the reader is referred to [33]. A drawback to the rank-modulation scheme is the need for a large number of comparisons when reading the induced permutation from a set of n cell-charge levels. Instead, in a recent work [39] the n cells are partially viewed through a sliding',\n",
       " '1703.00978': 'Over the last decade, machine learning (ML) algorithms have achieved impressive results providing solutions to practical large-scale problems (see, e.g., [4, 26,20,17]). Not surprisingly, ML is being used in cyber-physical systems (CPS) — systems that are integrations of computation with physical processes. For example, semi-autonomous vehicles employ Adaptive Cruise Controllers (ACC) or Lane Keeping Assist Systems (LKAS) that rely heavily on image classiﬁers providing input to the software controlling electric and mechanical subsystems (see, e.g., [5]). The safety-critical nature of such systems involving ML raises the need for formal methods [35]. In particular, how do we systematically ﬁnd bugs in such systems? We formulate this question as the falsiﬁcation problem for CPS models with ML components (CPSML): given a formal speciﬁcation ϕ (say in a formalism such as signal temporal logic [23]) and a CPSML model M, ﬁnd an input for which M does not satisfy ϕ. A falsifying input generates a counterexample trace that reveals a bug. To solve this problem, multiple challenges must be tackled. First, the input space to be searched can be intractable. For instance, a simple model of a semi-autonomous car already involves several control signals (e.g., the angle of the acceleration pedal, steering angle) and other rich sensor input (e.g., images captured by a camera, LiDAR, RADAR). Second, the formal veriﬁcation of ML components is a diﬃcult, and somewhat ill-posed problem due to the complexity of the underlying ML algorithms, large feature spaces, and the lack of consensus on a formal deﬁnition of correctness of an ML component. The last point is an especially tricky challenge for ML-based perception; see [35,34] for a longer discussion on speciﬁcation of ML components. Third, CPSML are often designed using languages such as C, C++, or Simulink for which clear semantics are not given, and involve third-party components that are opaque or poorly-speciﬁed. This obstructs the development of formal methods for the analysis of CPSML models and may force one to treat them as gray-boxes or black-boxes. Hence, we need a technique to systematically analyze ML components within the context of a CPS that can handle all three of these challenges. In this paper, we propose a new framework for the falsiﬁcation of CPSML addressing the issues described above. Our technique is compositional (modular) in that it divides the search space for falsiﬁcation into that of the ML component and of the remainder of the system, while establishing a connection between the two. The obtained projected search spaces are respectively analyzed by a temporal logic falsiﬁer (“CPS Analyzer”) and a machine learning analyzer (“ML analyzer”) that cooperate to search for a behavior of the closedloop system that violates the property ϕ. This cooperation mainly comprises a sequence of input space projections, passing information about interesting regions in the input space of the full CPSML model to identify a sub-space of  Compositional Falsiﬁcation of',\n",
       " '1710.07797': 'In supervised learning, given a sample of n pairs of inputs and outputs, the goal is to estimate a function to be used to predict future outputs based on observing only the corresponding inputs. The quality of an estimate is often measured in terms of the mean-squared prediction error, in which case the regression function is optimal. Since the properties of the function to be estimated are not known a priori, nonparametric techniques, that can adapt their complexity to the problem at hand, are often key to good results. Kernel methods [15, 36] are probably the most common nonparametric approaches to learning. They are based on choosing a reproducing kernel Hilbert space (RKHS) as the hypothesis space in the design of learning algorithms. A classical learning algorithm using kernel methods to perform learning tasks is kernel ridge regression (KRR), which is based on minimizing the sum of a data-ﬁtting term and an explicit penalty term. The penalty term is used for regularization, and controls the complexity of the solution, preventing overﬁtting. The statistical properties of KRR have been studied extensively, see e.g. [5, 39], and are known to be optimal in a minmax sense ∗This work was done when J.L. was working in the LCSL, IIT@MIT. J.L. is now with the LIONS, EPFL. (jhlin5@hotmail.com) 1 arXiv:1710.07797v1  [stat.ML]  21 Oct 2017  [43]. The drawbacks of KRR are mainly computational. Indeed, a standard implementation of KRR requires the computation of a linear system deﬁned by a kernel matrix, which thus requires costs O(n3) in time and O(n2) in memory, where n is the number of points. Such scalings are prohibitive when in large scale scenario, where the sample size n is large. A possible alternative is considering learning algorithms based on iterative procedure [14, 51, 47]. In this kind of learning algorithms, an empirical objective function is optimized in an iterative way with no explicit constraint or penalization, and the regularization against overﬁtting is realized by early-stopping the empirical procedure. Early-stopping has certain computational advantage over KRR, as it does not require the computation of the inverse of a kernel matrix. Indeed, if the algorithm stops after T iterations, the aggregate time complexity is O(Tn2) for gradient descent [47, 30] and conjugate gradient methods [3], while O(Tn) for stochastic gradient methods (SGM) [32, 21]. Although the statistical aspects of early-stopping procedures are well understood, either the computation or the storage of these algorithms can be challenging for large datasets. Indeed, the storage and/or computational cost of these algorithms, are/is at least quadratic in the number of training examples, due to the storage and/or calculation of a fully empirical kernel matrix. To avoid storing and/or computing a large kernel matrix, a natural approach is to replace the standard kernel matrix with a smaller matrix obtained by subsampling [38, 44]. Such an approach, referred to as Nystr¨om',\n",
       " '0712.3277': 'In wireless communications, channel conditions vary randomly over time due to mobility and changing environment, and the degree of channel side information (CSI) assumed to be available at the receiver and transmitter is a key assumption in the study of wireless fading channels. The case in which the channel is assumed to be perfectly known at the receiver and/or transmitter has been extensively studied. In an early work, Ericsson [1] obtained the capacity of ﬂat fading channels with perfect receiver CSI. More recently, Ozarow et al. [2] studied the average and outage capacity values in the cellular mobile radio setting assuming perfect channel knowledge at the receiver. Goldsmith and Varaiya [3] analyzed the capacity of ﬂat fading channels with perfect CSI at the transmitter and/or receiver. The assumption of having perfect channel knowledge is unwarranted when communication is trying to be established in a highly mobile environment. This consideration has led to another line of work where both the receiver and transmitter are assumed to be completely uninformed of the channel conditions. Abou-Faycal et al. [4] studied the capacity of the unknown Rayleigh fading channel and showed that the optimal input amplitude has a discrete structure. This is in stark contrast to the optimality of a continuous Gaussian input in known channels. In [16] and [18], the discreteness of the capacity-achieving amplitude distribution is proven for noncoherent Rician fading channels under input peakedness constraints. When the input is subject to peak power constraints, the discrete nature of the optimal input is shown for a general class of single-input single-output channels in [7]. Marzetta and Hochwald [5] gave a characterization of the optimal input structure for unknown multipleantenna Rayleigh fading channels. This analysis subsequently led to the proposal of unitary space-time modulation techniques [6]. Chan et al [8] considered conditionally Gaussian multiple-input multiple-output (MIMO) channels with bounded inputs and proved the discreteness of the optimal input under certain conditions. Zheng and Tse [10] analyzed the multiple-antenna Rayleigh channels and identiﬁed the high signal-to-noise ratio (SNR) behavior of the channel capacity. Heretofore, the two extreme assumptions of having either perfect CSI or no CSI have been discussed. Practical wireless systems live in between these two extremes. Unless there is very high mobility, wireless systems generally employ estimation techniques to learn the channel conditions, albeit with errors. Hence, it is of utmost interest to analyze fading channels with imperfect CSI. M´edard [13] investigated the effect upon channel capacity of imperfect channel knowledge and obtained upper and lower bounds on the input-output mutual information. Lapidoth and Shamai [12] analyzed the effects of channel estimation errors on the performance if Gaussian codebooks are used and nearest neighbor decoding is employed. The capacity of imperfectly-known fading channels is characterized in the low-SNR regime in [14] and in the high-SNR regime in [9]. The aforementioned studies have not considered explicit training and estimation techniques, and resources allocated to them',\n",
       " '1702.08536': 'There is wide interest in detecting and quantifying bias in human decisions, but well-known problems with traditional statistical tests of discrimination have hampered rigorous analysis. The primary goal of such work is to determine whether decision makers apply diﬀerent standards to groups deﬁned by race, gender, or other protected attributes—what economists call taste-based discrimination (Becker, 1957). For example, in the context of banking, such discrimination might mean that minorities are granted loans only when they are exceptionally creditworthy. The key Proceedings of the 21st International Conference on Artiﬁcial Intelligence and Statistics (AISTATS) 2018, Lanzarote, Spain. PMLR: Volume 84. statistical challenge is that an individual’s qualiﬁcations are typically only partially observed (e.g., researchers may not know an applicant’s full credit history); it is thus unclear whether observed disparities are attributable to discrimination or omitted variables. To address this problem, Simoiu et al. (2017) recently proposed the threshold test, which considers both the decisions made (e.g., whether a loan was granted) and the outcomes of those decisions (e.g., whether a loan was repaid). The test simultaneously estimates decision thresholds and risk proﬁles via a Bayesian latent variable model. This approach mitigates some of the most serious statistical shortcomings of past methods. Fitting the model, however, is computationally challenging, often requiring several hours on moderately sized datasets. As is common in full Bayesian inference, the threshold model is typically ﬁt with Hamiltonian Monte Carlo (HMC) sampling. In this case, HMC involves repeatedly evaluating gradients of conditional beta distributions that are expensive to compute. Here we introduce a family of distributions on the interval [0, 1]—which we call discriminant distributions—that is eﬃcient for performing common statistical operations. Discriminant distributions comprise a natural subset of logit-normal mixture distributions which is suﬃciently expressive to approximate logit-normal and beta distributions for a wide range of parameters. By replacing the beta distributions in the threshold test with discriminant distributions, we speed up inference by two orders of magnitude. To demonstrate our method, we analyze 2.7 million police stops of pedestrians in New York City between 2008 and 2012. We apply the threshold test to assess possible bias in decisions to search individuals for weapons. We also extend the threshold test to detect discrimination in the decision to stop an individual. For both problems (search decisions and stop decisions), our method accelerates inference by more than 75-fold. Such performance gains are consequential in part because each new application requires running the threshold test dozens of times to conduct a battery of standard robustness checks. To carry out the experiments in this paper, we ran the threshold test nearly arXiv:1702.08536v3  [stat.ML]  10 Mar 2018  Fast Threshold Tests for Detecting Discrimination 100 times. That translates into about two months of continuous, serial computation under the standard ﬁtting method; our approach required less than one',\n",
       " '1810.03944': 'I T is critical to evaluate the distances between samples in pattern analysis and machine learning applications. If an appropriate distance metric can be obtained, even the simple k-nearest neighbor (k-NN) classiﬁer, or k-means clustering can perform well [1], [2]. In addition, for largescale and efﬁcient information retrieval, the results are usually obtained directly according to the distances to the query [3], and a good distance metric is also the key of many other important applications, such as face veriﬁcation [4] and person re-identiﬁcation [5]. To learn a reliable distance metric, we usually need large amount of label information, which can be the class labels or target values as used in the typical machine learning approaches (such as classiﬁcation or regression), and it is more common to utilize some pair or triplet-based constraints [6]. Such constraints are weakly-supervised since the exact label for an individual sample is unknown. However, in real-world applications, the label information is often scarce since manually labeling is labor-intensive and it is exhausted or even impossible to collect abundant side information for a new learning problem. Transfer learning [7], which aims to mitigate the label deﬁciency issue in model training, is thus introduced to improve the performance of distance metric learnng (DML) • Y. Luo and Y. Wen are with the School of Computer Science and Engineering, Nanyang Technological University, Singapore. E-mail: yluo180@gmail.com, ygwen@ntu.edu.sg • L. Duan is with the School of Electronics Engineering and Computer Science, Institute of Digital Media, Peking University, China. E-mail: lingyu@pku.edu.cn • D. Tao is with the UBTECH Sydney Artiﬁcial Intelligence Centre and the School of Information Technologies in the Faculty of Engineering and Information Technologies at University of Sydney, 6 Cleveland St, Darlington, NSW 2008, Australia. E-mail: dacheng.tao@sydney.edu.au when the label information is insufﬁcient in a target domain. This leads to the so-called transfer metric learning (TML), which has been found to be very useful in many applications. For example, in face veriﬁcation [8], the main step is to estimate the similarities/distances between face images. The data distributions of the images captured under different scenarios vary due to the varied background, illumination, etc. Therefore, the metric learned in one scenario may be not effective in a new scenario and TML would be helpful. In person re-identiﬁcation [5], [9], the key is to estimate the similarities/distances between images of persons appeared in different cameras. The data distributions of the images captured using different cameras vary due to the varied camera setting and scenario. In addition, the distribution for the same camera may change over time. Hence, calibration is needed to achieve satisfactory performance and TML is able to reduce such effort. A more general example is image retrieval, where the data distributions of images in different datasets vary [10]. It would also be very useful to utilize expensive or semantic features to',\n",
       " '1012.3476': 'Restricted Boltzmann Machines (RBM) (Freund & Haussler, 1994; Welling et al., 2005; Hinton et al., 2006) have become a model of choice for learning unsupervised features for use in deep feedforward architectures (Hinton et al., 2006; Bengio, 2009) as well as for modeling complex, highdimensional distributions (Welling et al., 2005; Taylor & Hinton, 2009; Larochelle et al., 2010). Their success can be explained in part through the bi-partite structure of their graphical model. Units are grouped into a visible layer v and a hidden layer h, prohibiting connections within the same layer. The use of latent variables affords RBMs a rich modeling capacity, while the conditional independence property yields a trivial inference procedure. RBMs are parametrized by an energy function E(v, h) which is converted to probability through the Boltzmann distribution, after marginalizing out the hidden units. The probability of a given conﬁguration p(v) is thus given by p(v) = 1 Z P h exp(−E(v, h)), where Z is the partition function deﬁned as Z = P v,h exp(−E(v, h)). Despite their popularity, direct learning of these models through maximum likelihood remains problematic. The maximum likelihood gradient with respect to the parameters θ of the model is: ∂log p(v) ∂θ = − X h p(h|v)∂E(v, h) ∂θ + X v−,h− p(v−, h−)∂E(v−, h−) ∂θ (1) The ﬁrst term is trivial to calculate and is referred to as the positive phase, as it raises the probability of training data. The second term or negative phase is intractable in most applications of interest, 1 arXiv:1012.3476v1  [stat.ML]  15 Dec 2010  as it involves an expectation over p(v, h). Many learning algorithms have been proposed in the literature to address this issue: • Contrastive Divergence (CD) (Hinton, 1999; Hinton, 2002) replaces the expectation with a ﬁnite set of negative samples, which are obtained by running a short Markov chain initialized at positive training examples. This yields a biased, but low-variance gradient which has been shown to work well as a feature extractor for deep networks such as the Deep Belief Network (Hinton et al., 2006). • Stochastic Maximum Likelihood (SML) or Persistent Contrastive Divergence (PCD) (Younes, 1998; Tieleman, 2008) on the other hand, relies on a persistent Markov chain to sample the negative particles. The chain is run for a small number of steps between consecutive model updates, with the assumption that the Markov chain will stay close to its equilibrium distribution as the parameters evolve. Learning actually encourages this process, in what is called the “fast-weight effect” (Tieleman & Hinton, 2009). • Ratio Matching and Score Matching (Hyv¨arinen, 2005; Hyv¨arinen, 2007) avoid the issue of the partition function altogether by replacing maximum likelihood by another learning principle, based on matching the change in likelihood to that implied by the empirical distribution. (Marlin et al., 2010) recently compared these algorithms on a variety of tasks and found SML to be the most attractive method when',\n",
       " '1602.08877': 'P AR-CONSTRAINED sequences, such as unimodular or low peak-to-average power ratio (PAR), have many applications in both single-input single-output (SISO) and multiinput multi-output (MIMO) communication systems. For example, the M-ary phase-shift keying techniques allow only symbols of constant-modulus, i.e., unimodular, to be transmitted [1]. In MIMO radars and code-division multiple-access (CDMA) applications, the practical implementation demands from hardware, such as radio frequency power ampliﬁers and analog-to-digital converters, require the sequences transmitted to be unimodular or low PAR [2]–[4]. In this paper, we consider the design of optimal unimodular or low PAR sequences for channel estimation. There is an extensive literature on designing single unimodular sequences with good correlation properties such that the autocorrelation of the sequence is zero at each nonzero lag. As such properties are usually difﬁcult to achieve, metrics of “goodness” have been proposed instead where autocorrelation sidelobes are suppressed rather than literally set to zero, and This work was supported by the Hong Kong RGC 16206315 research grant. Zhongju Wang and Daniel P. Palomar are with the Hong Kong University of Science and Technology (HKUST), Hong Kong. E-mail: {zwangaq, palomar}@ust.hk. Prabhu Babu was with the Hong Kong University of Science and Technology (HKUST), Hong Kong. He is now with CARE, IIT Delhi, Delhi, India. Email: prabhubabu@care.iitd.ac.in. optimization problems are thus formulated and solved with numerical algorithms [5], [6]. Speciﬁcally, the work [5] provides several cyclic algorithms (CA) for either minimizing integrated sidelobe level (ISL) or maximizing ISL-related merit factor (MF). In [6], a computationally efﬁcient algorithm called MISL for minimizing ISL is proposed, and it is demonstrated that MISL results in lower autocorrelation sidelobes with less computational complexity. The good correlation property of a single unimodular sequence is also extended to MIMO systems, where multiple sequences are transmitted. The good autocorrelation is deﬁned for each sequence as that for a single sequence. Meanwhile, good cross-correlation demands that any sequence be nearly uncorrelated with time-shifted versions of the other sequences. In [3], algorithms CA-direct (CAD) and CA-new (CAN) are developed to obtain sequence sets of low autoand crosscorrelation sidelobes. Also [7] proposes some efﬁcient algorithms to minimize the same metric in [3]. The aforementioned ISL and ISL-related metrics are both alternative ways to describe the impulse-like correlation characteristics. Sequences with such properties enable matched ﬁlters at the receiver side to easily extract the signals backscattered from the range bin of interest and attenuate signals backscattered from other range bins [3]. Nevertheless, matched ﬁlters take no advantage of any prior information on the channel when the unimodular low-ISL sequences are used for estimation. The unimodular constraint is actually a special case of the low PAR constraint, which imposes how the largest amplitude of the sequence compares with its average power. The low PAR constraint, as',\n",
       " '1001.2738': 'FAILED',\n",
       " '1805.10367': 'Zeroth-order (gradient-free) optimization is increasingly embraced for solving machine learning problems where explicit expressions of the gradients are difﬁcult or infeasible to obtain. Recent examples have shown zeroth-order (ZO) based generation of prediction-evasive, black-box adversarial attacks on deep neural networks (DNNs) as effective as state-of-the-art white-box attacks, despite leveraging only the inputs and outputs of the targeted DNN [1–3]. Additional classes of applications include network control and management with time-varying constraints and limited computation capacity [4, 5], and parameter inference of black-box systems [6, 7]. ZO algorithms achieve gradientfree optimization by approximating the full gradient via gradient estimators based on only the function values [8, 9]. Although many ZO algorithms have recently been developed and analyzed [5, 10–18], they often suffer from the high variances of ZO gradient estimates, and in turn, hampered convergence rates. In addition, these algorithms are mainly designed for convex settings, which limits their applicability in a wide range of (non-convex) machine learning problems. In this paper, we study the problem of design and analysis of variance reduced and faster converging nonconvex ZO optimization methods. To reduce the variance of ZO gradient estimates, one can draw motivations from similar ideas in the ﬁrst-order regime. The stochastic variance reduced gradient (SVRG) is a commonly-used, effective ﬁrst-order approach to reduce the variance [19–23]. Due to the variance reduction, it improves the convergence rate of stochastic gradient descent (SGD) from O(1/ √ T)1 to O(1/T), where T is the total number of iterations. 1In the big O notation, the constant numbers are ignored, and the dominant factors are kept. Preprint. arXiv:1805.10367v2  [cs.LG]  7 Jun 2018  Although SVRG has shown a great promise, applying similar ideas to ZO optimization is not a trivial task. The main challenge arises due to the fact that SVRG relies upon the assumption that a stochastic gradient is an unbiased estimate of the true batch/full gradient, which unfortunately does not hold in the ZO case. Therefore, it is an open question whether the ZO stochastic variance reduced gradient could enable faster convergence of ZO algorithms. In this paper, we attempt to ﬁll the gap between ZO optimization and SVRG. Contributions We propose and evaluate a novel ZO algorithm for nonconvex stochastic optimization, ZO-SVRG, which integrates SVRG with ZO gradient estimators. We show that compared to SVRG, ZO-SVRG achieves a similar convergence rate that decays linearly with O(1/T) but up to an additional error correction term of order 1/b, where b is the mini-batch size. Without a careful treatment, this correction term (e.g., when b is small) could be a critical factor affecting the optimization performance. To mitigate this error term, we propose two accelerated ZO-SVRG variants, utilizing reduced variance gradient estimators. These yield a faster convergence rate towards O(d/T), the best known iteration complexity bound for ZO stochastic optimization. Our work offers a comprehensive study on how ZO gradient estimators affect SVRG on both iteration',\n",
       " '1609.01962': 'There is an increasing need to interpret and act upon rumours spreading quickly through social media during breaking news, where new reports are released piecemeal and often have an unveriﬁed status at the time of posting. Previous research has posited the damage that the diffusion of false rumours can cause in society, and that corrections issued by news organisations or state agencies such as the police may not necessarily achieve the desired effect sufﬁciently quickly [Lewandowsky et al. 2012; Procter et al. 2013a]. Being able to determine the accuracy of reports is therefore crucial in these scenarios. However, the veracity of rumours in circulation is usually hard to establish [Allport and Postman 1947], since as many views and testimonies as possible need to be assembled and examined in order to reach a ﬁnal judgement. Examples of rumours that were later disproven, after being widely circulated, include a 2010 earthquake in Chile, where rumours of a volcano eruption and a tsunami warning in Valparaiso spawned on Twitter [Mendoza et al. 2010]. Another example is the England riots in 2011, where false rumours claimed that rioters were going to attack Birmingham’s Children’s Hospital and that animals had escaped from London Zoo [Procter et al. 2013b]. Previous work by ourselves and others has argued that looking at how users in social media orient to rumours is a crucial ﬁrst step towards making an informed judgement on the veracity of a rumourous report [Zubiaga et al. 2016; Tolmie et al. 2015; Mendoza et al. 2010]. For example, in the case of the riots in England in August 2011, Procter et al. manually analysed the stance expressed by users in social media towards rumours [Procter et al. 2013b]. Each tweet discussing a rumour was manually categorised as supporting, denying or questioning it. It is obvious that manual methods have their disadvantages in that they do not scale well; the ability to perform stance categorisation of tweets in an automated way would be of great use in tracking rumours, ﬂagging those that are largely denied or questioned as being more likely to be false. Determining the stance of social media posts automatically has been attracting increasing interest in the scientiﬁc community in recent years, as this is a useful ﬁrst step towards more in-depth rumour analysis: — It can help detect rumours and ﬂag them as such more quickly [Zhao et al. 2015]. — It is useful for tracking public opinion about rumours and hence for monitoring their wider effect on society. arXiv:1609.01962v1  [cs.CL]  7 Sep 2016  Table I. Tweets pertaining to a rumour about hospital being attacked during 2011 England Riots. text position Birmingham Children’s hospital has been attacked. F***ing morons. #UKRiots support Girlfriend has just called her ward in Birmingham Children’s Hospital & there’s no sign of any trouble #Birminghamriots deny Birmingham children’s hospital guarded by police? Really? Who would target a childrens hospital #disgusting #Birminghamriots question — Aggregate stance information and dynamics over',\n",
       " '1604.04795': 'The advent of natural-language-based queries and entitycentric search has led to the enormous growth and applicability of Knowledge Graphs (KG) to model known relationships between entity-pairs. Large KGs have not only been built in academic projects like DBpedia [Bizer et al., 2009],but are also used by leading organizations like Google, Microsoft, etc., to support user-centric Internet services and missioncritical data analytics. KGs are generally represented using the RDF data model [Klyne and Carroll, 2006], in which the KG corresponds to a ﬁnite set of subject-predicate-object (SPO) triples whose terms can be URIs, blank nodes, or literal values [Klyne and Carroll, 2006]. Since many Web applications rely on RDF-style KGs during their processing, efﬁcient and scalable querying on huge KGs with billions of RDF triples have necessitated intelligent KG representation. In concept, KGs can be managed using a variety of platforms, like RDF engines [Yuan et al., 2013; Gurajada et al., 2014; Neumann and Weikum, 2008], relational stores [Sidirourgos et al., 2008], or graph database systems [Robinson et al., 2015]. In this context, the storage of RDF terms in raw format is both space and process inefﬁcient since these are typically long strings. As such, all existing approaches encode the RDF terms typically by mapping them to ﬁx-length integer IDs, with the original strings retrieved only during execution. Objectives. Modern KGs are typically queried using the W3C SPARQL language [Harris et al., 2013]. Currently, the impact of different ID mappings on advanced SPARQL operations (like query joins, index compression, etc.) is less well studied. Ideally, the encoding of RDF terms into numerical IDs should: i) Consider the skew in the term frequencies in the KG, and assign smaller IDs to frequent terms in order to facilitate efﬁcient down-stream compression (by the storage engine). ii) For more advanced query access patterns, particularly for join operations, data locality should be increased as much as possible by the encoding. That is, terms that are often accessed together should have close ID assignment in order to further reduce memory and index access [Harbi et al., 2015]. iii) It is often crucial to quickly load billions of triples, for example, when a KG is required as background knowledge for new analytic applications, or for append-only bulk update operations. Thus, the encoding process should support parallelism as much as possible for better scale-up. Problem Statement. Current RDF engines generally employ four types of encodings: order or hash-based, syntactic, or based on coordinates. Order-based approaches assign consecutive IDs for new incoming triples in the order of appearance. Hash-based procedures use term hashes as IDs. Syntactic encoding assigns IDs to terms based on their lexicographic order. Coordinate-based techniques stored the terms in special data structures and use memory coordinates as IDs. Interestingly, we observe that none of the existing approaches performs well along all three dimensions of our desiderata. Assigning consecutive identiﬁers leads to good',\n",
       " '1702.02526': 'Autoencoders (AEs) are a class of neural networks that gained increasing interest in recent years [18,23,25]. AEs are used for unsupervised learning of eﬀective hidden representations of input data [3,11]. These representations should capture the information contained in the input data, while providing meaningful features for tasks such as clustering and classiﬁcation [2]. However, what an eﬀective representation consists of is highly dependent on the target task. In standard AEs, representations are derived by training the network to reconstruct inputs through either a bottleneck layer, thereby forcing the network to learn how to compress input information, or through an over-complete representation. In the latter, regularization methods are employed to, e.g., enforce sparse representations, make representations robust to noise, or penalize sensitivity of the representation to small changes in the input [2]. However, regularization provides limited control over the nature of the hidden representation. In this paper, we hypothesize that an eﬀective hidden representation should capture the relations among inputs, which are encoded in form of a kernel matrix. ⋆michael.c.kampﬀmeyer@uit.no ⋆⋆http://site.uit.no/ml/ arXiv:1702.02526v1  [stat.ML]  8 Feb 2017  2 M. Kampﬀmeyer et al. Such a matrix is used as a prior to be reproduced by inner products of the hidden representations learned by the AE. Hence, in addition to minimizing the reconstruction loss, we also minimize the normalized Frobenius distance between the prior kernel matrix and the inner product matrix of the hidden representations. We note that this process resembles the kernel alignment procedure [26]. The proposed model, called deep kernelized autoencoder, is related to recent attempts to bridge the performance gap between kernel methods and neural networks [5,27]. Speciﬁcally, it is connected to works on interpreting neural networks from a kernel perspective [21] and the Information Theoretic-Learning Auto-Encoder [23], which imposes a prior distribution over the hidden representation in a variational autoencoder [18]. In addition to providing control over the hidden representation, our method also has several beneﬁts that compensate for important drawbacks of traditional kernel methods. During training, we learn an explicit approximate mapping function from the input to a kernel space, as well as the associated back-mapping to the input space, through an end-to-end learning procedure. Once the mapping is learned, it can be used to relate operations performed in the approximated kernel space, for example linear methods (as is the case of kernel methods), to the input space. In the case of linear methods, this is equivalent to performing non-linear operations on the non-transformed data. Mini-batch training is used in our proposed method in order to lower the computational complexity inherent to traditional kernel methods and, especially, spectral methods [4,15,24]. Additionally, our method applies to arbitrary kernel functions, even the ones computed through ensemble methods. To stress this fact, we consider in our experiments the probabilis',\n",
       " '1812.00117': 'Secure network coding is a method to securely transmit the message via noiseless network when a part of edges or a part of intermediate nodes are eavesdropped [1], [2], [3], [4], [5], [6]. Since the real channel has noise, we apply the error correction to the real channel. Then, we apply secure network coding to the noiseless channel realized by error correction. That is, in the above scenario, we separately apply the error correction and secure network coding. Therefore, there is a possibility that we have an advantage by jointly applying the error correction and secure network coding. This idea is called physical network coding [7], [8], [9]. That is, to consider this improvement for the security, we discuss the secure version of physical layer network coding, i.e., secure physical layer network coding, which is a method to securely transmit a message by a combination of coding operation on nodes when the network is given as a set of noisy channels. There are two kinds of codes in secure physical layer network coding. Once we have secure network coding, we can attach physical layer network coding. This method can be considered as a simple combination of secure network coding and physical layer network coding. The other type of codes in secure physical layer network coding are codes that cannot be made by such a simple combination. Unfortunately, there are almost no studies for secure physical layer network coding of the latter type. That is, existing studies addressed The material in this paper was presented in part at the 2018 IEEE Information Theory Workshop (ITW), Guangzhou, China, 25-29 November 2018. [25] Masahito Hayashi is with Graduate School of Mathematics, Nagoya University, Nagoya, Japan, Shenzhen Institute for Quantum Science and Engineering, Southern University of Science and Technology, and Centre for Quantum Technologies, National University of Singapore, Singapore. e-mail: masahito@math.nagoya-u.ac.jp Manuscript submitted 1st December 2018; revised xxx, 2018. only secure computation-and-forward, which is a method to securely transmit the modulo sum of two input message when noisy multiple access channel is given [10], [11], [12], [13], [14], [15]. The motivation of these studies is the realization of secure two way-relay channel with untrusted relay. To seek the further possibility of secure physical layer network coding, we need to ﬁnd more examples of concrete coding schemes of secure physical layer network coding. In fact, secure network code mainly focuses on the secrecy for the attack to channels. Some typical secure network codes cannot realize the secrecy when one of intermediate nodes is eavesdropped. In contrast, secure physical layer network coding is advantageous for attacks on intermediate nodes. In this paper, we give two examples of network, in which, secure physical layer network coding realizes a performance that cannot be realized by secure network coding. One is butterﬂy network [16] and the other is a network with three source nodes. The remaining parts of this paper are organized as follows. Section II reviews the',\n",
       " '1711.01062': 'Human detection has been a hot research area due to its wide usage in video surveillance, self-driving vehicles, humanmachine interaction, and robotics. With the development of depth cameras like Kinect and Intel Realsense, various vision-based applications are boosted with the depth information acquired by the devices which are more robust against illumination and texture variations. Among these applications, RGB-D based human detection receives continuous research attention recently. Recent years have seen a considerable amount of work to solve the RGB-D based human detection problem. Spinello and Arras [1] takes inspiration from Histogram of Oriented Gradients (HOG) [2] and proposes Histogram of Oriented Depths (HOD) to detect people in dense depth data. A reversible jump Markov chain Monte Carlo (RJ-MCMC) particle ﬁltering method was proposed for human detection and tracking on both ﬁxed and moving color-depth cameras [3]. Bagautdinov et al. [4] proposed a generative model to compute the probabilities of presence of potentially occluding pedestrians from a single depth map provided by RGB-D sensors. ∗Corresponding author Neural networks have shown their strong capability in a variety of ﬁelds, such as object recognition [5][6][7][8], activity recognition [9][10][11][12], semantic segmentation [13][14], and RGB based human detection [15]. Very recently, Xue et al. [16] also explored to apply neural networks for RGB-D based human detection and tracking. A deep CNN was used in their method to identify generated proposals. However, they did not consider the utilization of multi-scale multi-part contextual color-depth information, which is often important for reliable human detection. Based on an observation, when detecting and identifying a target, humans tend to catch a wide-range glimpse to get overview knowledge ﬁrst, then shrink the area of focus gradually until eyes focus exactly on discriminative parts of the target. Owing to the effective utilization of the contextual information among the multiple glimpses, negative factors like occlusion could be more easily handled by human. Therefore, we propose to explicitly utilize the contextual multi-scale multi-part information for RGB-D based human detection. Long short-term memory(LSTM) is a powerful neural network structure which is able to model the dynamics and contextual dependences in sequential information. Consequently, in this paper, we propose a Multi-Glimpse LSTM (MG-LSTM) to model the contextual multi-scale color depth information. Besides, to effectively fuse the two modalities of RGB and depth, we further propose a novel fusion strategy for LSTM. In our fusion framework, two bypass LSTM chains take the multi-scale color depth information respectively and fuse it at the main LSTM chain to generate the prediction. This structure can fuse the data ﬂow of RGB and depth more effectively whilst allows the two bypass chains to remain relatively independent. To the best of our knowledge, this is the ﬁrst attempt to utilize LSTM network for RGB-D based human detection. The main contributions of',\n",
       " '1412.0980': 'The highest rate at which quantum information can be transmitted asymptotically reliably per channel use is called quantum capacity. The private classical capacity of a quantum channel characterizes the highest possible rate at which classical information can be transmitted asymptotically reliably per channel use such that no information about the message leaks to the environment. Both of these quantities are mathematically characterized by a multi-letter expression, using regularization, that is complicated to evaluate — as a matter of fact, it is not even known to be computable [11, 17]. In general, it is even diﬃcult to derive good upper and lower bounds that can be evaluated eﬃciently for the two capacities. For degradable channels, which are characterized by the feature that the complementary channel can be written as a composition of the main channel with a degrading channel, the channel’s coherent and private classical information are additive and coincide. As a result, the regularized expressions describing the quantum and private classical capacity reduce to the same single-letter formula for degradable channels [14, 35]. This simpliﬁes the task of computing the capacity enormously and it happens that for some degradable channels the two capacities can be computed analytically. Degradable channels form an important class of channels for which, thanks to the induced additivity properties, there is a good understanding of their quantum and private classical capacity. At the same time, the notion of a degradable channel seems to be fragile as a tiny perturbation of a degradable channel may not be degradable anymore. Furthermore, it is unknown whether a channel for which the degradability condition is approximately satisﬁed (up to some ε ≥0 with respect to the diamond norm) is close to a degradable channel or not. Here, we introduce a robust generalization of the concept of a degradable channel. We call a channel ε-degradable if the degradability condition with respect to the diamond norm is satisﬁed up to some ε ≥0. (The precise deﬁnition is given in Deﬁnition 3.1.) We show that these ε-degradable channels approximately inherit all the desirable properties that degradable channels have, such as additivity ∗{suttedav, scholz, renner}@phys.ethz.ch † andreas.winter@uab.cat 1  2 of the channel’s coherent and channel private information. We further show that for an arbitrary channel, the smallest ε ≥0 such that the channel is ε-degradable can be eﬃciently computed via a semideﬁnite program. This oﬀers a universal method to compute eﬃciently upper bounds to the quantum and private classical capacity. This will be demonstrated by concrete examples, including the depolarizing channel. Structure. The remainder of this article is structured as follows. Section 2 introduces a few preliminary results and gives an overview of what is known for degradable channels. Section 3 presents our main contribution which is a deﬁnition of approximate degradable channels that approximately inherits all the desirable properties degradable channels have. We show that for an arbitrary channel',\n",
       " '1707.03069': 'Since the publication of the seminal work of Arrow (1951) and Uzawa (1956), coherent choice functions have been used widely as a model of the rational behaviour of an individual or a group. In particular, Seidenfeld et al. (2010) established an axiomatisation of coherent choice functions, generalising Rubin’s (1987) axioms to allow for incomparability. Under this axiomatisation, they proved a representation theorem for coherent choice functions in terms of probability-utility pairs: a choice function C satisﬁes their coherence axioms if and only if there is some non-empty set S of probability-utility pairs such that f ∈C(A) whenever the option f maximises p-expected u-utility over the set of options A for some (p,u) in S. Allowing for incomparability between options may often be of crucial importance. Faced with a choice between two options, a subject may not have enough information to establish a (strict or weak) preference of one over the other: the two options may be incomparable. This will indeed typically be the case when the available information is too vague or limited. It arises quite intuitively for group decisions, but also for decisions made by a single subject, as was discussed quite thoroughly by Williams (1975), Levi (1980), and Walley (1991), amongst many others. Allowing for incomparability lies at the basis of a generalising approach to probability theory that is often referred to by the term imprecise probabilities. It uniﬁes a diversity of well-known uncertainty models, including typically non-linear (or non-additive) functionals, credal sets, and sets of desirable gambles; see the introductory book by Augustin et al. (2014) for a recent overview. Among these, coherent sets of desirable gambles, as discussed by Quaeghebeur (2014), are usually considered to constitute the most general and powerful type of model. Such sets collect the gambles that a given subject considers strictly preferable to the status quo. Nevertheless, choice functions clearly lead to a still more general model than sets of desirable gambles, because the former’s preferences are not necessarily completely determined by the pair-wise comparisons between options that essentially constitute the Key words and phrases. Choice functions, coherence, lexicographic probabilities, horse lotteries, maximality, preference relations, convexity, sets of desirable gambles. 1  2 ARTHUR VAN CAMP, GERT DE COOMAN, AND ENRIQUE MIRANDA latter. This was of course already implicit in Seidenfeld et al.’s (2010) work, but was investigated in detail in one of our recent papers (Van Camp et al., 2017), where we zoomed in on the connections between choice functions, sets of desirable gambles, and indifference. In order to explore the connection between indifference and the strict preference expressed by choice functions, we extended the above-mentioned axiomatisation by Seidenfeld et al. (2010) to choice functions deﬁned on vector spaces of options, rather than convex sets of horse lotteries, and also let go of two of their axioms: (i) the Archimedean one, because it prevents choice functions from',\n",
       " '1707.01009': 'Neural networks have shown great performance on the Machine Translation (MT) task. The encoder-decoder framework [1] has been since widely adopted. An attention mechanism has been introduced by Bahdanau et al. [2] to learn to focus on different parts of the input sentence while decoding. Other modalities, like images, can make use of such attention mechanisms. A previous work [3] has shown they are able to learn to attend to the salient parts of an image when generating a text captions. Integrating multimodal information efﬁciently still remains a challenge. It requires combining diverse modality vector representations. A few attempts [4, 5, 6, 7, 8] have been made during the WMT 2016 Multimodal Machine Translation evaluation campaign. These initial efforts have not convincingly demonstrated that visual context can improve translation quality. Meanwhile, few improvements have been made, [9] proposed a doubly-attentive decoder that outperformed all previous baselines with less data and without re-scoring, [10] tried multiple attention models and image attention optimizations such as the gating [3] and pre-attention [11] mechanism. Recently, [12] introduced a model where visually grounded representations are learned. In this paper, our aim is to propose a ﬁrst empirical investigation on improving MNMT by using improved visual and word representations. More speciﬁcally, we believe that visual and word representations obtained through models pre-trained on large data sets should bring further improvement. Most importantly, we want to leverage models that provide a closer link between image understanding and language understanding. For extracting image modality vector representations, we will make use of a model trained on a dense captioning task, namely DenseCap [13]. Compared to models trained on object recognition tasks (such as ImageNet [14], as used in previous MNMT proposal), the hope is that the representation contains richer information, also encoding object attributes and important relationship for linguistic description of the images. For extracting the vector representations of the word modality, we will make use of word vectors obtained from large scale text corpora, but we will also use visual representations of the referents of those words, using a recent paradigm of ”imagined” visual representations of those words. The hope is that these visually grounded word representation will facilitate the integration of both modalities during the decoding process, hence improving translation results. Our paper is structured as follows. In section 2, we brieﬂy describe our NMT model as well as the conditional GRU activation used in the decoder. We also explain how multi-modalities can be implemented within this framework. In the following section 3 and 4, we detail the process of our visual embeddings and features creation. Finally, we report and analyze our results in section 6. 2. Model 2.1. Text-based NMT We describe the attention-based NMT model introduced by [2] in this section. Given a source sentence X = (x1, x2, . . . , xM), the neural network directly models the conditional probability p(Y |X) of its translation Y = (y1, y2, . . . , yN). The network consists',\n",
       " '1703.07051': 'With the rapid development of wireless communication system, there has been a new surge of interest in energy efﬁcient systems, due to the contradiction between the ever-increasing energy demand and the societal and economical concerns. As one of key technologies of 5G mobile communication systems, massive MIMO has been put forward to signiﬁcantly improve the system capacity with extra degrees of freedom which facilitate transmit diversity and spatial multiplexing gains [1]. Recently, there has been an increasing research interest in energy efﬁciency (EE) for massive MIMO systems. As discussed in [2], it is of primary importance to set up an accurate power consumption model for reliable guidelines of EE optimization. By using a reﬁned power consumption model, closed-form EE-optimal value of transmit power was derived in [2] by means of some properties of Lambert W function. However, the optimization problem there without any constraints on quality of service (QoS) failed to model the real scenario in communication systems. In the uplink of massive MIMO systems, the maximum transmit power and the minimum data rate for each user terminal (UT) should be included into basic QoS requirements. In [3], the problem of maximizing the EE as a function of the numbers of UTs and antennas in BS was analyzed, for a given spectral efﬁciency and ﬁxed transceiver power consumption parameters. Similarly, the impact of system parameters (the average channel gain to the UTs and the power consumption parameters) on the optimal EE was studied in [4] for maximizing the EE with a ﬁxed sum spectral efﬁciency. Besides the theoretical analysis on the relationships between system parameters and the optimal EE, it is of great importance to develop optimization methods for maximizing EE under the multi-cell scenario. More recently, the Markov decision process (MDP) method has been utilized to deal with the resource allocation problems for communication systems. In [5], by using the semi-MDP method, a resource allocation scheme was proposed to achieve the optimal power efﬁciency for QoS-guaranteed services in OFDMA multi-cell cooperation networks. However, the technicalities and complexities associated with semi-MDP seldom lead to practical algorithms [6]. On the other hand, in order to meet the QoS requirements, only a few works on the constrained Markov decision process (CMDP) method for resource allocation in MIMO systems [6] and OFDM systems [7] have been reported. The problem of power and rate allocation in MIMO systems was modeled as a CMDP in [6] with the goal of minimizing the transmit power subject to delay constraints, while the problem of power and subcarrier allocation for downlink OFDMA systems was formulated as a CMDP in [7] with the goal of maximizing the EE under average delay constraints. By introducing a middle state called “post-decision state”, an online solution was proposed in [7]. Motivated by the aforementioned results, we propose a novel ofﬂine power allocation scheme to achieve the global optimum EE under QoS constraints in the uplink of multi-cell massive MIMO',\n",
       " '1805.08443': 'Camera re-localization from a single input image is an important topic for many computer vision applications such as SLAM [1], augmented reality and navigation [2]. Due to rapid camera motion or occlusions, tracking can be lost, making re-localization methods an essential component of such applications. Early methods focus on keyframe [3] or descriptor matching by using SIFT or ORB [4] features to obtain point correspondences from which the camera pose could be inferred. However, those methods usually do not perform well under occlusion or in poorly textured environments. On the other side, machine learning methods have recently shown great capabilities in estimating camera poses from a single image. In particular, regression forests have been employed for a robust pixel-to-scene coordinate prediction. Correspondence samples are then used to obtain multiple pose hypotheses, and a robust pose estimate is found using RANSAC [5], [6], [7], [8]. Recently, deep learning methods have emerged, mainly focusing on RGB images as input and directly regressing the camera pose, thus offering fast camera pose estimates [9], [10]. Most of these methods, however, cannot achieve an accuracy similar to the scene coordinate regression approaches. This leads to the assumption that the intermediate step of regressing scene coordinates plays a crucial role in estimating the camera pose for deep learning algorithms and the generalization of those methods. Moreover, RANSAC [11] usually plays a vital role in achieving good accuracy in any of the methods focusing on camera relocalization via scene coordinate regression. 1 Department of Informatics, Technichal University Munich, Germany 2 Siemens AG, Munich, Germany 3 Whiting School of Engineering, Johns Hopkins University, USA In this paper, we introduce a method, which as a ﬁrst step, densely regresses pixel-wise scene coordinates given an input RGB image using deep learning. In addition, we propose a new form of regularization, that smoothes the regressed coordinates and which can be applied to further improve the regressed coordinates. Thus, a detailed analysis of scene coordinate regression and the inﬂuence of different loss functions on the quality of the regressed scene coordinates is conducted. Our main contribution is seen in the second step, where the conﬁdences of the obtained image to scene coordinate correspondences are regressed, based on which erroneous predictions can immediately be discarded, which in turn results in a more robust initial pose hypothesis. In addition, the resulting conﬁdence predictions can be used to optimize the estimated camera poses in a reﬁnement step similar to previous works [12]. In contrast to these methods, our approach offers a more general solution by not restricting itself in terms of the optimization function and thresholding, which are typically used to deﬁne the inliers and outliers in RANSAC optimizations. II. RELATED WORK There exists a vast amount of research focusing on the topic of camera pose estimation. The most related to our work can be divided into two categories: correspondence learning and direct regression. The ﬁrst focuses on descriptor matching to obtain point correspondences from which the camera pose',\n",
       " '1810.12558': 'Model-free deep RL algorithms have been employed in solving a variety of complex tasks [8, 18, 20, 21, 30, 33, 35, 37]. Model-free RL consists of onand oﬀ-policy methods. Oﬀ-policy methods allow a target policy to be learned at the same time following and acquiring data from another policy (i.e., behavior policy). It means that an agent learns about a policy distinct from the one it is carrying out while there is a single policy (i.e., target policy) in on-policy methods. It means that the agent learns only about the policy it is carrying out. In short, if two policies are same (i.e., π = b), then setting is called on-policy. Otherwise, the setting is called oﬀ-policy (i.e., π ̸= b) [5, 7, 8, 12, 13, 27]. From the Figure 1(a) we can see that oﬀ-policy learning contains mainly two policies, behavioral policy (b) (also referred to as the sampling distribution) and target policy (π) (also referred to as the target distribution). The Figure 1(a) also shows that there is often a discrepancy between these two policies (π and b). This discrepancy makes oﬀ-policy unstable; a bigger diﬀerence between these policies, instability is also high and a smaller diﬀerence between these policies, the instability is also low in oﬀ-policy learning whereas on-policy has a single policy (i.e., target policy) as shown in Figure 1(b). The instability is not an issue for on-policy learning due to the sole policy. Therefore, compared to oﬀ-policy, on-policy is more stable. Apart from above, there are other advantages and disadvantages of oﬀand on-policy learning. For example, on-policy methods oﬀer unbiased but often suﬀer from high variance and sample ineﬃciency. Oﬀ-policy methods are more sample eﬃcient and safe but unstable. Neither onnor oﬀ-policies are perfect. Therefore, several methods have been proposed to get rid of the deﬁciency of each policy. For example, how on-policy can achieve a similar sample eﬃciency as oﬀ-policy [8, 14, 20, 29, 30] and how oﬀ-policy can achieve a similar stability as on-policy [5, 7, 10, 19, 42]. The aim of this study is to make oﬀ-policy as stable as on-policy using the actor-critic algorithm in the deep neural network. Thus, this research primarily focuses on oﬀ-policy rather than on-policy. A well-established technique is to use importance sampling methods for stabilizing oﬀ-policy generated by the mismatch between the behavior policy and target policy [8, 11, 28]. Importance sampling is a well-known method to evaluate oﬀ-policy, permitting oﬀ-policy data to be used as if it was on-policy [12]. IS can be used to study one distribution while a sample is made from another distribution [24]. The degree of deviation of the target policy from the behavior policy at each time',\n",
       " '1701.05544': 'Study of random matrices has been a very active area of research for the last few decades and has found enormous applications in various areas of modern mathematics, physics, engineering, biological modeling, and other ﬁelds [1]. In this article, we focus on square symmetric matrices with +−1 entries, referred to as square symmetric sign matrices. For such matrices, Wigner [2] demonstrated that if the elements of the upper triangle of an N × N square symmetric matrix are independent Rademacher (+−1 with equal probabilities) random variables, then as N grows, a properly scaled empirical spectral measure converges to the semicircular law (Wigner originally showed convergence in expectation, which was later improved to convergence in probability [3] and to almost sure weak convergence [4, 5]). This work was supported by the Fulbright Foundation and Army Research Ofﬁce grant No. W911NF-15-1-0479. In many engineering applications, one needs to simulate random matrices. The most natural way to generate an instance of a random N × N sign matrix is to toss a fair coin N(N+1) 2 times, ﬁll the upper triangular part of a matrix with the outcomes and reﬂect the upper triangular part into the lower. Unfortunately, for large N such approach would require a powerful source of randomness due to the independence condition [6]. In addition, when the data is generated by a truly random source, atypical non-random looking outcomes have nonzero probability of showing up. Yet another issue is that any experiment involving tossing a coin would be impossible to reproduce. All these reasons stimulated researchers and engineers from different areas to seek for approaches of generating randomlooking data usually referred to as pseudo-random sources or sequences of binary digits [7, 8]. A wide spectrum of pseudo-random number generating algorithms have found applications in a large variety of ﬁelds including radar, navigation systems, digital signal processing, CDMA, error correction, cryptographic systems, Monte Carlo simulations, scrambling, coding theory, etc. [7]. The term pseudo-random is used to emphasize that the binary data at hand is indeed generated by an entirely deterministic causal process with low algorithmic complexity, but its statistical properties resemble some of the properties of data generated by tossing a fair coin. Remarkably, most efforts were focused on one dimensional pseudo-random sequences [7, 8] due to their natural applications and to the relative simplicity of their analytical treatment. One of the most popular methods of generating pseudo-random sequences is due to Golomb [8] and is based on linear-feedback shift registers capable of generating pseudo-random sequences of very low algorithmic complexity. The study of arXiv:1701.05544v5  [cs.IT]  26 Feb 2018  2 pseudo-random arrays and matrices was launched around the same time [9–12]. Among the known two dimensional pseudo-random constructions the most popular are the so-called perfect maps [9, 13, 14], and two dimensional cyclic codes [11, 12]. However, none of these works considered spectral properties as the',\n",
       " '1607.06792': 'For discrete-alphabet signals, the Shannon entropy function H(X) and the entropy rate ¯H(X) = limn→∞H(Xn|Xn−1) measure the complexity of a random variable X and a stationary stochastic process X = {Xi}, respectively. Both of these measures are closely connected to the minimum number of bits per symbol required for representing stochastic sources [2] and can also be thought of as measures of signal structure. However, when we shift from discrete alphabet to continuous alphabet, both the entropy and the entropy rate become inﬁnite. Instead, for analog signals, the notion of information dimension (ID) introduced by R´enyi [3] provides a framework that can be used to quantify signal structure. To illustrate what is meant for an analog process to be structured, consider a stationary memoryless (i.e., independent and identically distributed or i.i.d.) process X = {Xi}∞ i=0 such that Xi ∼(1 −p)δ0 + pfc, where fc denotes the probability density function (pdf) of an absolutely continuous distribution and δ0 denotes the Dirac measure with an atom at 0. In other words, for each i, with probability p ∈[0, 1], Xi is exactly equal to zero; otherwise, it is drawn from fc. By the strong law of large numbers, for large values of blocklength n, with probability approaching one, a block Xn generated by this source contains around n(1 −p) entries equal to zero, and the rest of the entries are real numbers in the domain of fc. To describe Xn with a certain precision, for zero entries, it sufﬁces to describe their locations. The This work is part of a paper under review by the IEEE Transactions on Information Theory, available at [1]. This research was supported by the National Science Foundation under Grant CCF-1420575. number of bits required for this description does not depend on the reconstruction quality. However, for the remaining approximately np elements of Xn, it is known from ratedistortion theory that the required number of bits grows with the desired reconstruction quality. This intuitively suggests that p, which controls the number of non-zero elements in Xn, is a fundamental quantity related to the complexity and structure of Xn. This intuition is accurately captured by the ID of this source which can be shown to be equal to p [3]. In fact, δ0 can be changed to any discrete probability distribution with ﬁnite entropy and the result will not change since the R´enyi ID of a discrete source is 0. A further signiﬁcance of the ID as a measure of structure is its relationship to the problem of compressed sensing. Consider the problem of recovering a signal Xn o from underdetermined measurements Y m = AXn o , where m < n. It is known that if the input signal Xn o is sparse, or in general “structured”, it can be accurately recovered from the measurements, even if m is far fewer than n [4]–[9]. For stationary memoryless processes, under some mild conditions on the',\n",
       " '1210.3312': 'Automatic Text Summarization (ATS) is the process to automatically generate a compressed version of a source document [15]. Query-oriented summaries focus on a user’s request, and extract the information related to the speciﬁed topic given explicitly in the form of a query [2]. Generic mono-document summarization tries to cover as much as possible the information content. Multi-document summarization is a oriented task to create a summary from a heterogeneous set of documents on a focused topic. Over the past years, extensive experiments on query-oriented multi-document summarization have been carried out. Extractive Summarization produces summaries choosing a subset of representative sentences from original documents. Sentences are ordered and then assembled according to their relevance to generate the ﬁnal summary [10]. This article introduces a new method of summarization based in sentences extraction on Vector Space Model (VSM). We score each sentence by calculating their inner product with a pseudo-sentence vector and a pseudo-word vector. Results show that Artex not only preserves the content of the summaries generated using this new representation, but often, surprisingly the performance can be improved. Artex could be an interesting and simple algorithm using the extractive summarization paradigm. Our tests on trilingual corpora (English, Spanish and French) evaluated by the Fresa algorithm (without human references) conﬁrm the good performance of Artex. In this paper, related work is given in Section 2. Section 3 presents the new algorithm of Automatic Text Summarization. Experiments are presented in Section 4, followed by Results in Section 5 and Conclusions in Section 6. 1 arXiv:1210.3312v1  [cs.IR]  11 Oct 2012  2 Related works Research in Automatic Text Summarization was introduced by H.P. Luhn in 1958 [9]. In the strategy proposed by Luhn, the sentences are scored for their component word values as determined by tf*idf-like weights. Scored sentences are then ranked and selected from the top until some summary length threshold is reached. Finally, the summary is generated by assembling the selected sentences in the original source order. Although fairly simple, this extractive methodology is still used in current approaches. Later on, [3] extended this work by adding simple heuristic features such as the position of sentences in the text or some key phrases indicate the importance of the sentences. As the range of possible features for source characterization widened, choosing appropriate features, feature weights and feature combinations have become a central issue. A natural way to tackle this problem is to consider sentence extraction as a classiﬁcation task. To this end, several machine learning approaches that uses document-summary pairs have been proposed [6, 12], An hybrid method mixing statistical and linguistics algorithms is presented in [1]. [10] and [15] propose a good state-of-art of Automatic Text Summarization tasks and algorithms. 2.1 Document Pre-processing The ﬁrst step to represent documents in a suitable space is the pre-processing. As we use extractive summarization, documents have to be chunked into',\n",
       " '1706.03148': 'Learning distributed sentence representations is an important and hard topic in both the deep learning and natural language processing communities, since it requires machines to encode a sentence with potential unlimited language content into a ﬁxed-dimension vector ﬁlled with continuous values. We are interested in learning to build a distributed sentence encoder in an unsupervised fashion by exploring the structure and relationship in a large unlabelled corpus. Since humans understand sentences by composing from the meanings of the words, we deﬁne that learning a sentence encoder should be composed of two essential components, which are learning distributed word representations, and learning how to compose a sentence representation from the representations of words in the given sentence. With the development of deep learning techniques, recurrent neural networks (RNNs) [1, 2, 3] have shown encouraging results on natural language processing (NLP) tasks, and become the dominant methods in processing sequential data. [4] proposed LSTM-based sequence to sequence learning (seq2seq) model for machine translation. Later [5] applied the seq2seq model for unsupervised representation learning on language, and then ﬁnetuned the model for supervised tasks. The seq2seq model can be jointly trained to learn the word representation and the composition function on word representations, also it shows encouraging idea that knowledge learned from unsupervised training could be transferred to help other related supervised tasks. [6] proposed the skip-thought model, which is an encoder-decoder model for unsupervised distributed sentence representation learning. The paper exploits the semantic similarity within a tuple of adjacent sentences as a supervision, and successfully built a generic, distributed sentence encoder. Rather than applying the conventional autoencoder model, the skip-thought model tries to reconstruct the surrounding 2 sentences instead of itself. The learned sentence representation encoder outperforms arXiv:1706.03148v1  [cs.CL]  9 Jun 2017  previous unsupervised pretrained models on the evaluation tasks with no ﬁnetuning, and the results are comparable to the models which were trained directly on the datasets in a supervised fashion. In this paper, We aim to trim and improve the original skip-thought model by three techniques. First, given the neighborhood hypothesis ﬁrst proposed in [7], we directly abandon one of the decoders in the skip-thought model, and leave only one encoder and one decoder for learning from inferring the next sentence given the current one. Second, we replace the plain connection used between the encoder and decoder with the Average+Max Connection, which is a non-linear non-parametric feature engineering method proposed by [8] for Stanford Natural Language Inference (SNLI) [9] challenge, and enhances the model to capture more complex interactions among the hidden states. Third, a good initialization for word embeddings boosts the transferability of the model trained in unsupervised fashion, which may raise the importance of the word embeddings in unsupervised learning algorithms. In addition, we show that increasing the dimension of the encoder improves the performance of our proposed model, but still keeps the number of parameters much smaller than the original skip-thought model. Detailed',\n",
       " '1503.01910': 'Predicting the preferences of users in order to present them with more relevant engagements is a fundamental component of any recommendation system [27, 25]. Over the years, a wide variety of approaches have been proposed for this problem (see [1] for a survey). These include content based approaches that rely on generating user and item proﬁles based on available data [22, 18], collaborative ﬁltering approaches [24, 13] that recommend items based on similarity measures between users and/or items, and a combination of both [4, 8]. In this paper, motivated by several settings of interest in which explicit feedback about the relevance of the recommendations can be received from the user on small timescales, we pursue a less studied approach (see [28]) of modeling the recommendation process as a sequential optimization problem. Below are a few examples of such settings. • Online retail: A user enters an online shopping portal to purchase an accessory, e.g. a watch. She is sequentially presented with various design choices and based on her feedback to these designs, the system adaptively presents recommendations that are more likely to be liked by her. • Online media-on-demand services: A user using an online music-on-demand service would like to ﬁnd a new genre of music to listen to. Short sound-clips are played for her sequen1 arXiv:1503.01910v1  [cs.LG]  6 Mar 2015  tially, and based on the feedback that she provides for these clips, the recommendation system seeks to adaptively ﬁnd genres that are better suited to her tastes. • Advertising in online video: As video ads are inherently more disruptive of a user’s attention, and thus potentially more valuable than sponsored search ads, there is a strong motivation for designing ad allocation mechanisms that take into account the relevance of these ads to the users. Services like YouTube and Hulu collect explicit feedback about the relevance of an ad after it is shown, and this feedback can be used to adaptively learn the preferences of the users and show more relevant ads. We consider a model that is derived from cluster models for collaborative ﬁltering (see [6]) in which the history of user behaviors is compressed into a predictive model, where users are classiﬁed into ‘types’ that capture the preference proﬁle of the user. A typical recommendation generation algorithm dynamically observes user behavior and uses maximum-likelihood estimates based on this predictive model to choose products that are more likely to be relevant. Our approach replaces this maximum-likelihood estimation with a sophisticated optimization problem, in which the two conﬂicting goals of presenting the most relevant products based on current predictions of user preferences, and learning the underlying type of the user so that more relevant engagements can be shown later, are concurrently optimized in a precise and systematic way. Our model assumes that a user that enters the system is sampled from a probability distribution over a set of types that is a priori known to',\n",
       " '1708.00667': 'The objective of inquiry dialogs is to cooperatively answer questions (or problems) shared by participants [1]. In inquiry dialogs, participants (including the dialog system) do not have complete domain knowledge, so they share their own knowledge with their partners. This setting is different from slotﬁlling dialog settings (e.g., [2, 3, 4]), where the systems are required to have complete domain knowledge. Thus, the realization of practical IDSs extends the capabilities of current dialog systems. In addition, IDSs can actively expand their own knowledge bases through dialogs, which helps to reduce the costs of manual knowledge base expansion. Although there has been previous research on IDS, the focus has not been on learning its policies. Amgoud, Parsons and McBurney have discussed the fundamental principles of inquiry dialog [5, 6, 7, 8], and Black and Hunter proposed policies for inquiry dialogs [9, 10]. In addition, Fan and Toni proposed policies for inquiry and information-seeking dialogs [11, 12]. These studies dealt with rule-based policies that only work efﬁciently in limited situations; learning efﬁcient policies in various conditions remains still an open problem. In this work, we apply DRL to learn the policies for IDS. In addition, in order to make learning these policies more effective, we propose a logical formula embedding framework. In Section 2, we introduce our inquiry dialog domain and IDS framework. We show how dialog states and dialog acts are represented by logical formulae in the framework. In Section 3, we explain how to apply DRL to inquiry dialogs. Speciﬁcally, we use “Deep Q-Learning with experience replay” (DQL) [13, 14] for DRL and introduce a logical formula embedding framework to it. In Section 4, we evaluate the effectiveness of the DRL and the logical formula embedding framework for producing good policies. We conclude the paper in Section 5 with a brief summary. Our research contribution is two-fold: ﬁrst, to our knowledge, this is the ﬁrst study that applies reinforcement learning to learning inquiry dialog policies, and second, we introduce logical formula embedding frameworks for DRL in order to make learning inquiry dialog policies more effective. 2. Inquiry Dialog 2.1. Inquiry Dialog and its Domain In inquiry dialogs, an IDS and its user collaborate in order to answer their shared questions. They start the dialog with shared questions (queries), and then, in order to come up with an answer, they share what they believe in (beliefs) by reasonable assertion (arguments) and then make new arguments reﬂecting those shared beliefs. Sharing their beliefs is continued until they ﬁnd an answer (or ﬁnd that there is no possible answer). The shared beliefs are stored in the commitment store, and participant’s beliefs are stored in the belief base. As an example of inquiry dialog domains, we discuss a system and its user working on Compliance Violation Detection. In this setting, the system and the user play detectives. They are given different information sources',\n",
       " '1804.00521': 'Image segmentation aims to locate and extract objects of interest from an image, which is one of the fundamental problems in medical research. Take the brain extraction problem as an example. To study the brain, magnetic resonance imaging (MRI) is the most popular modality choice. However, before the quantitative analysis of brain MRIs, e.g., measuring normal brain development and degeneration, uncovering brain disorders such as Alzheimer’s disease, or diagnosing brain tumors or lesions, skull stripping is typically a preliminary but essential step, and many approaches have been proposed to tackle this problem. In literature, the approaches developed for brain MRI extraction can be divided into two categories: traditional methods (manual, intensity or shape model based, hybrid, and PCA-based methods [3,11]) and deep learning methods [7,10]. Deep neural networks have demonstrated the improved quality of the predicted brain mask, compared to traditional methods. However, these deep networks focus on learning image features mainly for brain tissue from a training dataset, which is typically a collection of normal (or apparently normal) brain MRIs, because these images are more commonly available than brain scans with pathologies. Thus, their model performance is sensitive to unseen pathological tissues. arXiv:1804.00521v2  [cs.CV]  17 Jun 2018  In this paper, we propose a novel deep neural network architecture for skull stripping from brain MRIs, which improves the performance of existing methods on brain extraction and more importantly is invariant to brain pathologies by only training on publicly available regular brain scans. In our new design, a network learns features for both brain tissue and non-brain structures, that is, we consider the complementary information of an object that is outside of the region of interest in an image. For instance, the structures outside of the brain, e.g., the skull, are highly similar and consistent among the normal and pathological brain images. Leveraging such complementary information about the brain can help increase the robustness of a brain extraction method and enable it to handle images with unseen structures in the brain. We explore multiple complementary segmentation networks (CompNets). In general, these networks have two pathways in common: one to learn what is the brain tissue and to generate a brain mask; the other to learn what is outside of the brain and to help the other branch generate a better brain mask. There are three variants, i.e., the probability, plain, and optimal CompNets. In particular, the probability CompNet needs an extra step to generate the ground truth for the complementary part such as the skull, while the plain and optimal CompNets do not need this additional input. The optimal CompNet is built upon the plain one and introduces dense blocks (a series of convolutional layers fully connected to each other [4]) and multiple intermediate outputs [1], as shown in Fig. 1. This optimal CompNet has an end-to-end design, fewer number of parameters to estimate, and the best performance amon',\n",
       " '1502.05556': 'The problem of recovering a ranking over n items from noisy outcomes of pairwise comparisons has attracted, in the last century, much research interest, driven by applications in sports [Elo, 1978], social sciences [Thurstone, 1927, Salganik and Levy, 2015] and—more recently—recommender systems [Houlsby et al., 2012]. Whereas pairwise comparison models and related inference algorithms have been extensively studied, the issue of which pairwise comparisons to sample, also known as active learning, has received signiﬁcantly less attention. To understand the potential beneﬁts of adaptively selecting samples, consider the case where comparison outcomes are noiseless, i.e., consistent with a linear order on a set of n items. If pairs of items are selected at random, it is necessary to collect Ω(n2) comparisons to recover the ranking [Alon et al., 1994]. In contrast, by using an eﬃcient sorting algorithm, O(n log n) adaptively chosen comparisons are suﬃcient. In this work, we demonstrate that sorting algorithms can also be helpful in the noisy setting, where some comparison outcomes are inconsistent with the ranking: despite errors, sorting algorithms tend to select informative samples. We focus on the Bradley–Terry (BT) model, a widely-used probabilistic model of comparison outcomes. In this model, each item is ∗School of Computer and Communication Sciences, EPFL, Switzerland. 1 arXiv:1502.05556v2  [stat.ML]  15 Jun 2017  associated with a parameter on the real line, and the probability of observing an incorrect outcome decreases as the distance between the items’ parameters increases. First, we study the output of a single execution of Quicksort when comparison outcomes are generated from a BT model, under the assumption that the distance between adjacent parameters is (stochastically) uniform across the ranking. We measure the quality of a ranking estimate by its displacement with respect to the ground truth, i.e., the sum of rank diﬀerences. We show that Quicksort’s output is a good approximation to the ground-truth ranking: no method comparing every pair of items at most once can do better (up to constant factors). Furthermore, we show that by aggregating O(log5 n) independent runs of Quicksort, it is possible to recover the exact rank for all but a vanishing fraction of the items. These theoretical results suggest that adaptive sampling is able to bring a substantial acceleration to the learning process. Second, we propose a practical active-learning (AL) strategy that consists of repeatedly sorting the items. We evaluate our sorting-based method on three datasets and compare it to existing AL methods. We observe that all the strategies that we consider lead to better ranking estimates noticeably faster than random sampling. However, most strategies are challenging to operate and computationally expensive, thus hindering wider adoption [Schein and Ungar, 2007]. In this regard, sorting-based AL stands out, as a) it is computationally-speaking as inexpensive as random sampling, b) it is trivial to implement, and c) it requires no tuning of hyperparameters. 1.1 Preliminaries and Notation We consider n items that',\n",
       " '1611.09464': 'We physically interact with people around us while mentally engaging with them via joint attention. For example, you as an audience in a concert are locally affected by the people around you and are globally connected to the people on the other side of the stage by sharing joint attention. While the physical connection delineates the proximal space around us, the mental connection encodes the group’s intent in a way that facilitates communications, role playing, and group task accomplishment. These connections provide social cues to further reason about the spatial and temporal extent of the social behaviors, which is a key design factor for an artiﬁcial intelligence of social robots. However, such social cues are rather ambiguous, subtle, and situation dependent, which is challenging to be comFigure 1. We predict a group trajectory of basketball players from ﬁrst person videos. The red is the ground truth and blue is the predicted trajectories with gaze direction. putationally learned by third person computer vision systems [4, 25, 26, 32] due to their limited expressibility: it is necessary to tap into what we actually see. In this paper, we propose to use ﬁrst person cameras collectively to decode the social cues and to further predict their future social behaviors. What visual information makes us to stay connected to people, physically and mentally? We conjecture that two unique signals recorded in ﬁrst person videos can describe the connections. (1) Individually, a ﬁrst person video encodes the egocentric visual semantics that provides a social and spatial context to take the next action. (2) Collectively, ﬁrst person videos follow joint attention spatially arranged by social formation [24, 38], e.g., audiences dynamically change their social formation to secure visibility, which links the individuals to a group. As a proof-ofconcept, we integrate these two learning signals to predict the movement (location and gaze directions) of basketball players, one of most complex forms of social interactions, from their ﬁrst person videos (Figure 1). Our method takes an input, the ﬁrst person videos of basketball players and outputs a set of plausible future trajectories. We learn an egocentric visual representation to recognize similar social and spatial conﬁgurations, e.g., which makes us to move, using a Siamese neural network. This representation is used to retrieve a set of future trajectories per player. We ﬁnd a plausible group trajectory set from the retrieved trajectories of all players by maximizing a measure of social compatibility—the gaze alignment towards joint attention predicted by their social formation— via a generalized Dijkstra algorithm. The dynamics of joint attention is learned by a long-term recurrent convolutional 1 arXiv:1611.09464v1  [cs.CV]  29 Nov 2016  network (LRCN) based on social formation features that encode locations and velocities of the players. Note that we predict not only the future locations but also their gaze directions and joint attention. Our key innovation',\n",
       " '1309.5823': 'H OW to measure the distance (or similarity/dissimilarity) between two data points is a fundamental issue in unsupervised and supervised pattern recognition. The desired distance metrics can vary a lot in different applications due to their underlying data structures and distributions, as well as the speciﬁcity of the learning tasks. Learning a distance metric from the given training examples has been an active topic in the past decade [1], [2], and it plays a crucial role in improving the performance of many clustering (e.g., kmeans) and classiﬁcation (e.g., k-nearest neighbors) methods. Distance metric learning has been successfully adopted in many real world applications, e.g., face identiﬁcation [3], face veriﬁcation [4], image retrieval [5], [6], and activity recognition [7]. Generally speaking, the goal of distance metric learning is to learn a distance metric from a given collection of similar/dissimilar samples by punishing the large distances F. Wang and W. Zuo are with the School of Computer Science and Technology, Harbin Institute of Technology, Harbin 150001, China (e-mail: tshfqw@163.com; cswmzuo@gmail.com). L. Zhang and D. Zhang are with the Biometrics Research Centre, Department of Computing, Hong Kong Polytechnic University, Hong Hom, Kowloon, Hong Kong (e-mail: cslzhang@comp.polyu.edu.hk; csdzhang@comp.polyu.edu.hk). D. Meng is with the Institute for Information and System Sciences, Faculty of Mathematics and Statistics, Xi’an Jiaotong University, Xi’an 710049, China (e-mail: dymeng@mail.xjtu.edu.cn). between similar pairs and the small distances between dissimilar pairs. So far, numerous methods have been proposed to learn distance metrics, similarity metrics, and even nonlinear distance metrics. Among them, learning the Mahalanobis distance metrics for k-nearest neighbor classiﬁcation has been receiving considerable research interests [3], [8]-[15]. The problem of similarity learning has been studied as learning correlation metrics and cosine similarity metrics [16]-[20]. Several methods have been suggested for nonlinear distance metric learning [21], [22]. Extensions of metric learning have also been investigated for semi-supervised learning [5], [23], [24], multiple instance learning [25], and multi-task learning [26], [27], etc. Despite that many metric learning approaches have been proposed, there are still some issues to be further studied. First, since metric learning learns a distance metric from the given training dataset, it is interesting to investigate whether we can recast metric learning as a standard supervised learning problem. Second, most existing metric learning methods are motivated from speciﬁc convex programming or probabilistic models, and it is interesting to investigate whether we can unify them into a uniﬁed framework. Third, it is highly demanded that the uniﬁed framework can provide a good platform for developing new metric learning algorithms, which can be easily solved by standard and efﬁcient learning tools. With the above considerations, in this paper we present a kernel classiﬁcation framework for metric learning, which can unify most state-of-the-art metric learning methods, such as large margin nearest neighbor (LMNN) [8], [28], [29], information theoretic metric learning (ITML) [10], and lo',\n",
       " '1807.09289': 'Many successful applications of neural networks (Krizhevsky et al., 2012; Sutskever et al., 2014; van den Oord et al., 2016) are in restricted settings where predictions are only made for inputs similar to the training distribution. In real-world scenarios, neural networks can face truly novel data points during inference, and in these ∗Correspondence to mail@danijar.com. settings it can be valuable to have good estimates of the model’s uncertainty. For example, in healthcare, reliable uncertainty estimates can prevent overconﬁdent decisions for rare or novel patient conditions (Schulam and Saria, 2015). Another application are autonomous agents that should actively explore their environment, requiring uncertainty estimates to decide what data points will be most informative. Epistemic uncertainty describes the amount of missing knowledge about the data generating function. Uncertainty can in principle be completely reduced by observing more data points at the right locations and training on them. In contrast, the data generating function may also have inherent randomness, which we call aleatoric noise. This noise can be captured by models outputting a distribution rather than a point prediction. Obtaining more data points allows the noise estimate to move closer to the true value, which is usually different from zero. For active learning, it is crucial to separate the two types of randomness: we want to acquire labels in regions of high uncertainty but low noise (Lindley et al., 1956). Bayesian analysis provides a principled approach to modeling uncertainty in neural networks (Denker et al., 1987; MacKay, 1992b). Namely, one places a prior over the network’s weights and biases. This induces a distribution over the functions that the network represents, capturing uncertainty about which function best ﬁts the data. Specifying this prior remains an open challenge. Common practice is to use an independent normal prior in weight space, which is neither informative about the induced function class nor the data (e.g., it is sensitive to parameterization). This can cause the induced function posterior to generalize in unforeseen ways on out-of-distribution (OOD) inputs, which are inputs outside of the distribution that generated the training data. Motivated by these challenges, we introduce noise contrastive priors (NCPs), which encourage uncertainty outside of the training distribution through a loss in data space. NCPs are compatible with any model that represents functional uncertainty as a random variable, are easy to scale, and yield reliable uncertainty estimates that show signiﬁcantly improved active learning performance. arXiv:1807.09289v3  [stat.ML]  1 Jul 2019  1 0 1 2 dist 1.0 0.5 0.0 0.5 1.0 0.5 1.0 1.5 noise (a) Deterministic 1 0 1 2 dist 0.25 0.50 0.75 uncert 1.0 0.5 0.0 0.5 1.0 0.4 0.8 1.2 noise 1.0 0.5 0.0 0.5 1.0 0.08 0.16 0.24 infogain (b) BBB 1 0 1 2 dist 0.25 0.50',\n",
       " '1811.07945': 'The noiseless forward model of a computational imaging system is g = Hf, (1) where f is the unknown object, H is the forward operator and g is the raw intensity image captured by the camera. The standard method of solving this inverse problem for linear ill-posed forward operators H is ˆf =argmin f n ||Hf −g||2 + Φ(f) o , (2) where Φ(f) expresses prior knowledge about the class of objects of interest, and is known as the regularizer. Compressive imaging techniques[4, 5, 6, 9], in particular, have been very effective at improving the condition of the inverse problem by enforcing sparsity constraints, as long as the basis where the objects are sparse is known. Alternatively, in dictionary-based methods [11, 2, 34] the basis set is learnt from examples. If more general priors are applicable to the problem, then machine learning techniques, especially Deep Neural Networks [23] (DNNs) become attractive. ∗These authors contributed equally Several forms of machine learning architectures have been used for solving problems of the form (2). One approach inspired by the Learning Iterative Shrinkage and Thresholding Algorithm (LISTA) [18], is a cascade of DNNs with the conjugate forward operator Ht acting as residual [28]. Two simpler alternatives are the end-to-end approach, where the input to the DNN is directly the raw intensity image g and the output is the estimate ˆf[38, 31]; and the preprocessor approach, where g is fed into an approximant H∗before going into the DNN [31, 17]. The quality of the inverse estimate ˆf depends on our knowledge of the prior Φ if (2) is used; and on the content of the training example database if a machine learning approach is used. One feature of the examples that we have found to strongly inﬂuence training is the examples’ spatial frequency content relative to the spatial frequency behavior of the forward operator H. Let us consider the case when H suppresses high frequencies, which is often encountered in practice due to undersampling or the ﬁnite aperture of optical systems; and that we train using a database such as ImageNet, which is well-known to have an inverse-square law (spatial) power spectral density (PSD) [40]. In that case, does the DNN learn the inverse square law? Li et al have found [25] that this is not necessarily the case. Because high frequencies are sparser in the database, and the training process is highly nonlinear, low frequencies may end up dominating the prior by more than their fair share; lowpass ﬁltering of the inverse ˆf and loss of ﬁne detail ensues. The same work [25] proposed a spectral pre-modulation approach to compensate for the scarcity of high spatial frequencies in the database and showed that indeed ﬁne details are recovered; however, at the same time, high-frequency artifacts appeared in the reconstructions, evidently because the spectral pre-modulation also taught the DNN',\n",
       " '1901.08770': 'Graphical models are a way of eﬃciently representing the conditional independence relationships satisﬁed by a collection of random variables. They form the starting point for many eﬃcient estimation and inference algorithms. Thus, learning the graphical model of a collection of random variables is a fundamental, and very well-studied problem. For jointly Gaussian random variables, the graphical model is given by the non-zeros in the inverse of the covariance matrix, also known as the precision matrix. We ask a natural variant of this fundamental problem: suppose we observe the random variables with independent additive noise. Thus, in the inﬁnite sample limit, rather than knowing the covariance matrix, Σ, we have access only to M = Σ + D, the sum of the covariance matrix and a diagonal matrix. In general, (Σ + D)−1 does not share the sparsity structure of Σ−1. In the language of probability, if two random variables X and Y are independent conditioned on Z, then we do not expect that (X + W1) and (Y + W2) are independent when conditioned on (Z + W3), even when W1, W2 and W3 are independent. We ask: when is it possible to recover the conditional independence structure (graphical model) of the underlying variables, i.e., when can we recover the sparsity pattern of Σ−1? Despite the voluminous literature on Gaussian graphical models, to the best of our knowledge, there has been no answer to this question. Contributions of this paper. We show the following: • A negative result of unidentiﬁability (Theorem 1): Even for a simple Markov chain on three nodes, the problem is unidentiﬁable even when an arbitrarily small amount of independent noise is added. That is, there are covariance matrices that diﬀer only on their diagonal entries, and yet whose inverses have diﬀerent sparsity patterns. • A positive result of limited unidentiﬁability (Theorem 2): While unidentiﬁable, even for large independent noise, the ambiguity is highly limited. Speciﬁcally, we show that for tree-structured graphical models, distinguishing leaves from their immediate neighbors is impossible, but the remaining structure of the graph is identiﬁable (see Figure 1 for an illustration). • Identiﬁability with Side Information: – (Theorem 3) We characterize an upper bound on the noise which, if given as side information, makes the problem identiﬁable. 1 arXiv:1901.08770v1  [stat.ML]  25 Jan 2019  – (Theorem 4) If there is side information that in the precision matrix, for a leaf node, the diagonal entry is greater than the absolute value of the other non-zero entry, the problem is identiﬁable. – (Theorems 5, 6) Given a lower bound on the minimum eigenvalue of the true covariance matrix as side information, we characterize the upper bound on the noise for which the problem is identiﬁable. We also characterize a lower bound on the noise which makes the problem unidentiﬁable. • We provide, an O(n3) algorithm that identiﬁes the equivalence class of the underlying tree (Section 5). Related Work Estimating Gaussian graphical models has been a very widely explored topic. Various algorithms based on the ℓ1 penalized',\n",
       " '1705.06196': 'Gastrointestinal diseases are the primary diagnosis for about 28 million patient visits per year in the United States[1]. In many cases, endoscopy is an eﬀective diagnostic and therapeutic tool, and as a result about 7 million upper and 11.5 million lower endoscopies are carried out each year in the U.S. [2]. Wireless capsule endoscopy (WCE), introduced in 2000 by Given Imaging Ltd., has revolutionized patient care by enabling inspection of regions of the GI tract that are inaccessible with traditional endoscopes, and also by reducing the pain associated with traditional endoscopy [3]. Going beyond passive inspection, researchers are striving to create capsules that perform active locomotion and intervention [4]. With the integration of further functionalities, e.g. remote control, biopsy, and embedded therapeutic modules, WCE can become a key technology for GI diagnosis and treatment in near future. Several research groups have recently proposed active, remotely controllable robotic capsule endoscope prototypes equipped with additional operational functionalities, such as highly localized drug delivery, biopsy, and other medical functions [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]. To facilitate eﬀective navigation and intervention, the robot must be accurately localized and must also accurately perceive the surrouding tissues. Three-dimensional intraoperative SLAM algorithms will therefore be an indispensable component of future active capsule systems. Several localization methods have been proposed for robotic capsule endoscopes such as ﬂuoroscopy [17], ultrasonic imaging [18], positron emission tomography (PET) [17, 18], magnetic resonance imaging (MRI) [17], radio transmitter based techniques, and magnetic ﬁeld-based techniques [18, 19, 20, 21]. It has been proposed that combinations of sensors, such as RF range estimation and visual odometry, may improve the estimation accuracy [22, 23]. Morover, solutions that incorporate vision are attractive because a camera is already present on capsule endoscopes, and vision algorithms have been widely applied for robotic localization and map reconstruction. 2  Feature-based SLAM methods have been applied on endoscopic type of image sequences in the past e.g [24, 25, 26, 27]. As improvements to accomodate the ﬂexibility of the GI tract, [28] suggested a motion compensation model to deal with peristaltic motions, whereas [29] proposed a learning algorithm to deal with them. [30] adapted parallel tracking and mapping techniques to a stereo-endoscope to obtain reconstructed 3D maps that were denser when compared to monoscopic camera methods. [31] has applied ORB features to track the camera and proposed a method to densify the reconstructed 3D map, but pose estimation and map reconstruction are still not accurate enough. All of these methods can fail to produce accurate results in cases of low-texture areas, motion blur, specular highlights, and sensor noise – all of which are typically present during endoscopy. In this paper, we propose that a non-rigid and dense RGB Depth fusion method, which combines magnetic localization and visual pose estimation using particle ﬁltering and recurrent neural network-based motion model estimation, can provide real-time',\n",
       " '1705.05394': \"Reinforcement learning has shown to be a powerful technique leading to impressive performance across a number of domains [31]. For example, reinforcement learning methods have been used to train a computer to outperform human performance in 49 Atari games [14], [18]. Recently, a learningbased method was used to train a computer (AlphaGo) to beat a champion Go player [27]. Similar methods have also been used to train robots to perform a number of difﬁcult tasks in simulation [10], [26] and in the real world [8], [22]. However, when applied to robotics tasks in the real world, learning-based methods that adapt their parameters online have the potential to be dangerous. For example, a selfdriving car or quadrotor that performs online learning might suddenly adapt its parameters in such a way that causes it to crash into a pedestrian or another obstacle. Although there are many ways in which a robot can be dangerous, for this work, we focus on the dangers caused by a robot manipulator applying high torques. Such a robot might break the object that it is interacting with, break a nearby object, or damage itself. One approach that is often used in practice is to place the robot in an isolated environment while training, where it cannot break anything of importance. In such an environment, the robot can perform learning with minimal risk. However, if the isolated training environment is different from the test environment, then this difference can lead to unexpected and possibly dangerous behavior. For example, suppose we want a robot to operate around or collaboratively with people; 1 Department of Electrical Engineering and Computer Science, University of California, Berkeley, Berkeley, CA 94720 2International Computer Science Institute (ICSI), University of California, Berkeley, Berkeley, CA 94704 3 OpenAI, San Francisco, CA 94110 Simula'on  Reality  Safe Policy  Transfer  Fig. 1. After training a robot to perform a task in simulation, we adapt the learned policies to the real world. However, as the robot is adapting, we enforce damage constraints via safety-based torque limits to prevent the robot from applying high torques (and risk breaking something) when the performance is poor. the isolated training environment would likely not contain any people, and thus the training environment would not be representative of the test environment in which the robot must operate. Another solution is to train the robot in simulation. Efforts can be made to make the simulation mimic the test environment as much as possible; however, despite one’s best efforts, there will likely be differences between simulation and reality, leading to policies that do not work correctly when brought into the real world. If the robot must re-learn how to behave in the real world, there is a risk of the robot operating dangerously while it is adapting its behavior. We propose that, when a robot is placed in a new environment, it should initially operate at low torques. Only once the robot has demonstrated sufﬁcient\",\n",
       " '1701.05973': 'G ENERAL distributed computing frameworks, such as MapReduce [2] and Spark [3], along with the availability of large-scale commodity servers, such as Amazon EC2, have A. Reisizadeh and R. Pedarsani are with the Department of Electrical and Computer Engineering, University of California, Santa Barbara, Santa Barbara, CA 93106 USA (e-mail: reisizadeh@ucsb.edu; ramtin@ece.ucsb.edu). S. Prakash and A. S. Avestimehr are with the the Department of Electrical and Computer Engineering, University of Southern California, Los Angeles, CA 90089 USA (e-mail: sauravpr@usc.edu; avestimehr@ee.usc.edu). A part of this work was presented in IEEE International Symposium on Information Theory, 2017 [1]. made it possible to carry out large-scale data analytics at the production level. These “virtualized data centers” enjoy an abundance of storage space and computing power, and are cheaper to rent by the hour than maintaining dedicated data centers round the year. However, these systems suffer from various forms of “system noise” which reduce their efﬁciency: system failures, limited communication bandwidth, straggler nodes, etc. The current state-of-the-art approaches to mitigate the impact of system noise in cloud computing environments involve creation of some form of “computation redundancy”. For example, replicating the straggling task on another available node is a common approach to deal with stragglers [4], while partial data replication is also used to reduce the communication load in distributed computing [5]. However, there have been recent results demonstrating that coding can play a transformational role for creating and exploiting computation redundancy to effectively alleviate the impact of system noise. In particular, there have been two coding concepts proposed to deal with the communication and straggler bottlenecks in distributed computing. The ﬁrst coding concept introduced in [6]–[8] enables an inverse-linear tradeoff between computation load and communication load in distributed computing. This result implies that increasing the computation load by a factor of r (i.e. evaluating each computation at r carefully chosen nodes) can create novel coding opportunities that reduce the required communication load for computing by the same factor r. Hence, these codes can be utilized to pool the underutilized computing resources at network edge to slash the communication load of Fog computing [9]. Other related works tackling the communication bottleneck in distributed computation include [10]–[14]. In the second coding concept introduced in [10], an inverselinear tradeoff between computation load and computation latency (i.e. the overall job response time) is established for distributed matrix multiplication in homogeneous computing environments. More speciﬁcally, this approach utilizes coding to effectively inject redundant computations to alleviate the effects of stragglers and speed up the computations. Hence, by utilizing more computation resources, this can signiﬁcantly speed up distributed computing applications. A number of related works have been proposed recently to mitigate stragglers in distributed computation. In [15], the authors propose the use of redundant short dot products to speed up distributed computation of linear transforms. The work in [16] proposes coding schemes for mitigating stragglers in distributed batch',\n",
       " '1803.08624': 'FAILED',\n",
       " '1208.6231': 'Recent technological advances, such as the Internet, multi-media devices or social networks provide abundance of relational data. For instance, in retail recommender systems, in addition to retail data showing who has bought which items, we may also have access to customers’ social networks, i.e., who is friends with whom. In such complex problems, jointly analyzing data from multiple sources has great potential to increase our ability for capturing the underlying structure in data. Data fusion, therefore, is a viable candidate for addressing the challenging link prediction problem. Applications in many areas including recommender systems and social network analysis deal with link prediction, i.e., the problem of inferring whether there is a relation between the entities of interest. For instance, if a customer buys an item, the customer and the item can be considered to be linked. The task of recommending other items the customer may be interested in can be cast as a missing link prediction problem. However, the results are likely to be poor if the prediction is done in isolation on a single view of data. Such arXiv:1208.6231v1  [cs.LG]  30 Aug 2012  II Fig. 1: A third-order tensor coupled with two matrices in two diﬀerent modes. datasets, whilst large in dimension, are already very sparse [1] and potentially represent only a very incomplete picture of the reality [2]. Therefore, relational data from other sources is often incorporated into link prediction models [3]. Matrix factorisations have proved to be very useful in recommender systems [4]. An eﬀective way of including side information via additional relational data in a link prediction model is to represent diﬀerent relations as a collection of matrices. Subsequently, this collection of matrices are jointly analyzed using collective matrix factorisation [5,6]. In many applications, however, matrices are not suﬃcient for a faithful representation of multiple attributes, and higherorder tensor and matrix factorisation methods are needed. An inﬂuential study in this direction is by Banerjee et al. [7], where a general clustering method for joint analysis of heterogeneous data has been studied. The goal here is clustering entities based on multiple relations, where each relation is represented as a matrix (e.g., movies by review words matrix showing movie reviews) or a higher-order tensor (e.g., movies by viewers by actors tensor showing viewers’ ratings). In this paper, we address link prediction problem using coupled analysis of datasets in the form of matrices and higher-order tensors. As an example application, we study a real-world GPS (Global Positioning System) dataset [8] for location-activity recommendation such that given an incomplete dataset showing which users perform which activities at various locations, we would like to ﬁll in the missing links between (user, activity, location) triplets (X1). We also make use of additional sources of information showing the locations visited by users based on GPS trajectories (X2) and the features of locations in terms of number of diﬀerent points of interest at each location (X3',\n",
       " '1805.11183': 'Variational inference (VI) is an optimization based method that is widely used for approximate Bayesian inference. It introduces variational distribution Q over the latent variables to approximate the posterior (Jordan et al., 1999), and its stochastic version is scalable to big data (Hoffman et al., 2013). VI updates the parameters of Q to move it closer to the posterior in each iteration, where the closeness is in general measured by the Kullback–Leibler (KL) divergence from the posterior to Q, minimizing which is shown to be the same as maximizing the evidence lower bound (ELBO) (Jordan et al., 1999). To make it simple to climb the ELBO to a local optimum, one often takes the 1Department of Statistics and Data Sciences, 2Department of IROM, McCombs School of Business, The University of Texas at Austin, Austin TX 78712, USA. Correspondence to: Mingzhang Yin <mzyin@utexas.edu>, Mingyuan Zhou <mingyuan.zhou@mccombs.utexas.edu>. Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018 by the author(s). mean-ﬁeld assumption that Q is factorized over the latent variables. The optimization problem is further simpliﬁed if each latent variable’s distribution is in the same exponential family as its prior, which allows exploiting conditional conjugacy to derive closed-form coordinate-ascent update equations (Bishop & Tipping, 2000; Blei et al., 2017). Despite its popularity, VI has a well-known issue in underestimating the variance of the posterior, which is often attributed to the mismatch between the representation power of the variational family that Q is restricted to and the complexity of the posterior, and the use of KL divergence, which is asymmetric, to measure how different Q is from the posterior. This issue is often further ampliﬁed in mean-ﬁeld VI (MFVI), due to the factorized assumption on Q that ignores the dependencies between different factorization components (Wainwright et al., 2008; Blei et al., 2017). While there exists a variety of methods that add some structure back to Q to partially restore the dependencies (Saul & Jordan, 1996; Jaakkola & Jordan, 1998; Hoffman & Blei, 2015; Giordano et al., 2015; Tran et al., 2015; 2016; Han et al., 2016; Ranganath et al., 2016; Maaløe et al., 2016; Gregor et al., 2015), it is still necessary for Q to have an analytic probability density function (PDF). To further expand the variational family that Q belongs to, there has been signiﬁcant recent interest in deﬁning Q with an implicit model, which makes the PDF of Q become intractable (Husz´ar, 2017; Mohamed & Lakshminarayanan, 2016; Tran et al., 2017; Li & Turner, 2017; Mescheder et al., 2017; Shi et al., 2017). While using an implicit model could make Q more ﬂexible, it makes it no longer possible to directly computing the log density ratio, as required for evaluating the ELBO. Thus, one often resorts to density ratio estimation, which, however, not only adds an additional level of complexity into each iteration of the optimization, but',\n",
       " 'cs/0204026': 'FAILED',\n",
       " '1708.02901': \"Visual invariance is a core issue in learning visual representations. Traditional features like SIFT [39] and HOG [6] are histograms of edges that are to an extent invariant to illumination, orientations, scales, and translations. Modern deep representations are capable of learning high-level invariance from large-scale data [47] , e.g., viewpoint, pose, deformation, and semantics. These can also be transferred Intra-instance Invariance Inter-instance Invariance Intra-instance Invariance Transitive Invariance More Examples: Object A Object B Tracked  Object A' Tracked  Object B' A B A' B' Figure 1: We propose to obtain rich invariance by applying simple transitive relations. In this example, two different cars A and B are linked by the features that are good for inter-instance invariance (e.g., using [9]); and each car is linked to another view (A′ and B′) by visual tracking [61]. Then we can obtain new invariance from object pairs ⟨A, B′⟩, ⟨A′, B⟩, and ⟨A′, B′⟩via transitivity. We show more examples in the bottom. to complicated visual recognition tasks [17, 38]. In the scheme of supervised learning, human annotations that map a variety of examples into a single label provide supervision for learning invariant representations. For example, two horses with different illumination, poses, and breeds are invariantly annotated as a category of “horse”. Such human knowledge on invariance is expected to be learned by capable deep neural networks [33, 28] through 1 arXiv:1708.02901v3  [cs.CV]  15 Aug 2017  carefully annotated data. However, large-scale, high-quality annotations come at a cost of expensive human effort. Unsupervised or “self-supervised” learning (e.g., [61, 9, 45, 63, 64, 35, 44, 62, 40, 66]) recently has attracted increasing interests because the “labels” are free to obtain. Unlike supervised learning that learns invariance from the semantic labels, the self-supervised learning scheme mines it from the nature of the data. We observe that most selfsupervised approaches learn representations that are invariant to: (i) inter-instance variations, which reﬂects the commonality among different instances. For example, relative positions of patches [9] (see also Figure 3) or channels of colors [63, 64] can be predicted through the commonality shared by many object instances; (ii) intra-instance variations. Intra-instance invariance is learned from the pose, viewpoint, and illumination changes by tracking a single moving instance in videos [61, 44]. However, either source of invariance can be as rich as that provided by human annotations on large-scale datasets like ImageNet. Even after signiﬁcant advances in the ﬁeld of selfsupervised learning, there is still a long way to go compared to supervised learning. What should be the next steps? It seems that an obvious way is to obtain multiple sources of invariance by combining multiple self-supervised tasks, e.g., via multiple losses. Unfortunately, this na¨ıve solution turns out to give little improvement (as we will show by experiments). We argue that the trick lies not in the tasks\",\n",
       " '1711.04141': 'Massive MIMO is a very promising candidate to increase the sum-rate (bits/s/Hz) performance of future wireless networks by an order of magnitude compared to currently deployed cellular wireless systems [1]. Early works on massive MIMO proposed the use of maximum ratio transmission (MRT) in the downlink (DL) and maximum ratio combining (MRC) in the uplink (UL), since these schemes have very low precoder/detector complexity and can be easily distributed across different digital processing units [2]. It was quickly shown through theoretical analysis [3], [4] and experiments [5], that the regime of number of BS antennas per user at which MRT/MRC do not suffer from a large performance gap with respect to their more complex counterparts, namely, regularized zero-forcing (RZF) precoding for the DL and linear Minimum Mean-Square Error (MMSE) detection for the UL, is unpractically large. As a matter of fact, in order to exploit the full potential of massive MIMO in practice, RZF precoding and MMSE detection must be implemented. These require the computation of matrix inverses of K × K matrices, where K denotes the number of single-antenna users to be served simultaneously by spatial multiplexing, in the same timefrequency slot. Such matrix inverses must be calculated for each transmission resource block (RB) where the channel matrix is constant over time and frequency. Furthermore, even though the physical channel coherence time interval ∆tc and coherence frequency ∆Wc yield a fairly number of signal dimensions ≈⌈∆tc×∆Wc⌉ over which the channel matrix remains constant [6], in a practical situation where the set of K active users is scheduled according to some dynamic scheduling algorithm operating with fast slot granularity, the set of users changes (due to scheduling) from slot to slot. Therefore, a new precoding matrix must be calculated for each scheduling slot, at a rate that may be signiﬁcantly faster than the physical channel coherence. For concreteness, consider a massive MIMO BS serving a cell with a total of 100 connected users. Suppose that the BS has M = 128 antennas and serves up to K = 20 users simultaneously, by allocating the whole bandwidth in time division, and scheduling over groups of 20 users. Typical values for the channel coherence time and bandwidth are ∆tc = 10 ms and ∆Wc = 100 kHz [6], yielding a coherence block of ≈1000 signal dimensions. However, in LTE [7] the scheduler may operate with the granularity of a single RB, spanning 12 subcarriers in frequency and 14 OFDM symbols in time, for a total of 168 signal dimensions. With LTE numerology, subcarriers are spaced by 15 kHz and OFDM symbols have duration 66.7 µs, such that the RB has duration of about 1 ms. It would be of course completely impractical to pre-calculate the precoding matrix for all possible \\x00100 20 \\x01 scheduled users combinations. Therefore, the precoding matrix must be recomputed at each RB period for current the set of scheduled users, despite the fact that their physical channel matrix may change signiﬁcantly more',\n",
       " '1504.06165': 'Predicting user preferences, for items such as for commercial products, movies, and businesses, is an important and well-studied problem in recommendation systems. Collaborative ﬁltering using matrix factorization [10], in particular, has found widespread adoption as the tool of choice for this problem. By relying on cooccurrences in the ratings, however, these methods do not perform well on users or items that do not have ample observed ratings, i.e. users and items that are rare or new to the system. Fortunately, since users and items are part of a larger database, extra relational information about such users and items can often be utilized for predicting preferences. It is, for example, often not difﬁcult to obtain information such as product categories, album genres, review text, and attributes/features of the items, however this external evidence is rarely complete or noise-free. A number of existing approaches have thus been proposed to use these sources of information for improving user preferences. Koren [8], for example, combines the factorization model with an encoding of the external information as fully-observed features. Several studies have also investigated algorithms for incorporating speciﬁc sources of information, for example modeling user reviews [13, 12, 4], integrating context information [6, 5], exploiting item taxonomy [7, 24] and learning changes in user preferences and expertise over time [9, 14] to improve rating prediction. However, these approaches face a number of disadvantages when applied to heterogeneous, incomplete, multi-relational schema common in practice. First, these approaches are designed for certain types of relations and are restricted to relations of that type. Thus, it is not clear how additional sources of information can be incorporated, for example, how partially observed product categories can be used to improve rating prediction in McAuley et al. [13]. Further, by training the model to predict entries of only one or two relations, these approaches ignore the dependencies between other relations and entities in the database, such as simultaneously predicting the cuisine of a restaurant, and the users that will like it, from the user reviews of the restaurant. There’s a need for a generic machine learning approach that is able to leverage the dependencies between users, items, and additional data for estimating user preferences more accurately. In this paper, we present a collective factorization model for incorporating heterogeneous relational data for user preference prediction in a domain-independent manner. Collective factorization assigns a latent low-dimensional vector (an embedding or factor) for every entity in the database that is used to predict all of the observed relations between pairs of entities. The collective model thus extends the intuition behind matrix factorization based recommendation systems that include embeddings for every user and business/product, and is a generalization of [13] that assign factors to every user, business/product, and review words. Since the latent embeddings in collective factorization are used to model all of the observed entries in the database, it is capable',\n",
       " '1708.01641': 'Consider the video depicted in Figure 1, in which a little girl jumps around, falls down, and then gets back up to start jumping again. Suppose we want to refer to a particular temporal segment, or moment, from the video, such as ∗Work done at Adobe Research during LAH’s summer internship when the girl resiliently begins jumping again after she has fallen. Simply referring to the moment via an action, object, or attribute keyword may not uniquely identify it. For example, important objects in the scene, such as the girl, are present in each frame. Likewise, recognizing all the frames in which the girl is jumping will not localize the moment of interest as the girl jumps both before and after she has fallen. Rather than being deﬁned by a single object or activity, the moment may be deﬁned by when and how speciﬁc actions take place in relation to other actions. An intuitive way to refer to the moment is via a natural language phrase, such as “the little girl jumps back up after falling”. Motivated by this example, we consider localizing moments in video with natural language. Speciﬁcally, given a video and text description, we identify start and end points in the video which correspond to the given text description. This is a challenging task requiring both language and video understanding, with important applications in video retrieval, such as ﬁnding particular moments from a long personal holiday video, or desired B-roll stock video footage from a large video library (e.g., Adobe Stock1, Getty2, Shutterstock3). Existing methods for natural language based video retrieval [24, 51, 46] retrieve an entire video given a text string but do not identify when a moment occurs within a video. To localize moments within a video we propose to learn a joint video-language model in which referring expressions and video features from corresponding moments are close 1https://stock.adobe.com 2http://www.gettyimages.com 3https://www.shutterstock.com 1 arXiv:1708.01641v1  [cs.CV]  4 Aug 2017  in a shared embedding space. However, in contrast to whole video retrieval, we argue that in addition to video features from a speciﬁc moment, global video context and knowing when a moment occurs within a longer video are important cues for moment retrieval. For example, consider the text query “The man on the stage comes closest to the audience”. The term “closest” is relative and requires temporal context to properly comprehend. Additionally, the temporal position of a moment in a longer video can help localize the moment. For the text query “The biker starts the race”, we expect moments earlier in the video in which the biker is racing to be closer to the text query than moments at the end of the video. We thus propose the Moment Context Network (MCN) which includes a global video feature to provide temporal context and a temporal endpoint feature to indicate when a moment occurs',\n",
       " '1211.3169': 'This review deals with the analysis of inﬂuences that one system, be it physical, economical, biological or social, for example, can exert over another. In several scientiﬁc ﬁelds, the ﬁnding of the inﬂuence network between different systems is crucial. As examples, we can think of gene inﬂuence networks [75], [76], relations between economical variables [29], [80], communication between neurons or the ﬂow of information between different brain regions [84], or the human inﬂuence on the Earth climate [41], [88], and many others. The context studied in this report is illustrated in ﬁgure 1. For a given system, we have at disposal a number of different measurements. In neuroscience, these can be local ﬁeld potentials recorded in the brain of an animal; In November 27, 2024 DRAFT  2 Local Field Potentials  in the awake cat Solar indices Velocity at different scales  in a turbulent ﬂuid energy ? Fig. 1. Illustration of the problem of information ﬂow in networks of stochastic processes. Each node of the network is associated to a signal. Edges between nodes stand for dependence (shared information) between the signals. The dependence can be directed or not. This framework can be applied to different situations as solar physics, neuroscience or the study of turbulence in ﬂuids, as illustrated by the three examples depicted here. solar physics, these can be solar indices measured by sensors onboard some satellite; In the study of turbulent ﬂuids, these can be the velocity measured at different scales in the ﬂuid (or can be as in the ﬁgure, the wavelet analysis of the velocity at different scales). For these different examples, the aim is to ﬁnd dependencies between the different measurements, and if possible, to give a direction to the dependence. In neuroscience, this will allow to understand how information ﬂows between different areas of the brain; In solar physics, this will allow to understand the links between indices and their inﬂuence on the total solar irradiance received on Earth; In the study of turbulence, this can conﬁrm the directional cascade of energy from large down to small scales. In a graphical modeling approach, each signal is associated to a particular node of a graph, and dependence are represented by edges, directed if a directional dependence exists. The questions addressed in this paper concern the assessment of directional dependence between signals, and thus concern the inference problem of estimating the edge set in the graph of signals considered. Climatology and neuroscience were already given as examples by Norbert Wiener in 1956 [95], a paper which inspired econometrist Clive Granger to develop what is now termed Granger causality [32]. Wiener proposed in this paper that a signal x causes another time series y, if the past of x has a strictly positive inﬂuence on the quality of prediction of y. Let us quote Wiener [95]: “As an application of this, let us consider the case where f1(α) represents the temperature at 9 A.M. November 27, 2024 DRAFT  3 in Boston and f2(α) represents the',\n",
       " '1710.04142': 'In past few years, several data-sets have been released which include text, images and videos (Ferraro et al., 2015). There are several other datasets which generate automatic descriptions using images (Bernardi et al., 2016). Although there has been no past dataset that can be used to study gender bias. Gender bias detection from text has been an emerging area of interest among researchers. The next step to gender bias detection is Gender Bias removal which has been gaining a lot of attention. Bias Detection and removal has also been investigated in social sciences and natural language processing. The work has been mainly based on some real world observations and theories. Nonetheless, there is only a little scientiﬁc work in detecting gender bias in text. There are no publicly available data-sets for this task. While there are recent works where gender bias has been studied in different walks of life (Soklaridis et al., 2017),(?), (Carnes et al., 2015), (Terrell et al., 2017), (Saji, 2016), the analysis majorly involves information retrieval tasks involving a wide variety of prior work in this area. (Fast et al., 2016) have worked on gender stereotypes in English ﬁction particularly on the Online Fiction Writing Community. The work deals primarily with the analysis of how males and females behave and are described in this online ﬁction. Furthermore, this work also presents that males are over-represented and ﬁnds that traditional gender stereotypes are common throughout every genre in the online ﬁction data used for analysis. Apart from this, there have been various works where Hollywood movies have been analyzed for having such gender bias present in them (Anderson and Daniels, 2017). Similar analysis has been done on children books and music lyrics which found that men are portrayed as strong and violent, and on the other hand, women are associated with home and are considered to be gentle and less active compared to men. These studies have been very useful to know the trend but the derivation of these analyses has been done on very small data sets. In some works, gender drives the decision for being hired in corporate organizations (Dobbin and Jung, 2012). Not just hiring, it has been shown that human resource professionals’ decisions on whether an employee should get a raise have also been driven by gender stereotypes by putting down female claims of raise requests. While, when it comes to consideration of opinion, views of females are weighted less as compared to those of men (Otterbacher, 2015). On social media and dating sites, women are judged by their appearance while men are judged mostly by how they behave (Rose et al., 2012). When considering occupation, females are often designated lower level roles as compared to their male counterparts in image search results of occupations (Kay et al., 2015). In our work we work with Bollywood movies to create a dataset which can be leveraged for removing such biases. The Bollywood Movie Corpus consists of data of 4000',\n",
       " '1007.3622': 'Besides their classical and traditional applications in signal processing and communications (Bahl et al., 1974; Brushe et al., 1998; Hayes et al., 1982; Viterbi, 1967) (cf. also further references in (Capp´e et al., 2005)) and speech recognition (Huang et al., 1990; Jelinek, 1976, 2001; McDermott and Hazen, 2004; Ney et al., 1994; Padmanabhan and Picheny, 2002; Rabiner and Juang, 1993; Rabiner et al., 1986; Shu et al., 2003; Steinbiss et al., 1995; Str¨om 1 arXiv:1007.3622v4  [stat.ML]  16 Apr 2013  Lember and Koloydenko et al., 1999), hidden Markov models have recently become indispensable in computational biology and bioinformatics (Brejov´a et al., 2008; Burge and Karlin, 1997; Durbin et al., 1998; Eddy, 2004; Krogh, 1998; Majoros and Ohler, 2007) as well as in natural language modeling (Manning and Sch¨utze, 1999; Vogel et al., 1996) and information security (Mason et al., 2006). At the same time, their spatial extensions, known as hidden Markov random ﬁeld models (HMRFM), have been immensely inﬂuential in spatial statistics (Besag and Green, 1993; Green and Richardson, 2002; K¨unsch et al., 1995; Mcgrory et al., 2009), and particularly in image analysis, restoration, and segmentation (Besag, 1986; Geman and Geman, 1984; Li et al., 2000; Marroquin et al., 2003; Winkler, 2003). Indeed, hidden Markov models have been called ‘one of the most successful statistical modeling ideas that have [emerged] in the last forty years’ (Capp´e et al., 2005). HM(RF)Ms owe much of their success on the one hand to the penetration of the Markov property from the hidden layer to the posterior distribution, and on the other, to the richness of the observed system (K¨unsch et al., 1995). In other words, in addition to the prior, the posterior distribution of the hidden layer also possesses a Markov property (albeit generally inhomogeneous even with homogeneous priors), whereas the marginal law of the observed layer can still include global, i.e. non-Markovian, dependence. The Markov property of the posterior distribution and the conditional independence of the observed variables given the hidden ones, have naturally led to a number of computationally feasible methods for inference about the hidden realizations as well as model parameters. HMMs are naturally a special case of graphical models (Lauritzen, 1996), (Bishop, 2006, ch. 8). HMMs, or one dimensional HMRFMs, have been particularly popular not least due to the fact that the linear order of the indexing set (usually associated with time) makes exploration of hidden realizations relatively straightforward from the computational viewpoint. In contrast, higher dimensional HMRFMs generally require approximate, possibly stochastic, techniques in order to compute optimal conﬁgurations of the hidden ﬁeld (Cocozza-Thivent and Bekkhoucha, 1993; Joshi et al., 2006; Mcgrory et al., 2009; Winkler, 2003). In particular, a maximum a posteriori (MAP) estimator of the hidden layer of an HMM is eﬃciently and exactly computed by a dynamic programming algorithm bearing the name of Viterbi, whereas a general higher dimensional HMRFM would commonly employ a simulated annealing type method',\n",
       " '1810.04632': 'A multi-output Gaussian process (MOGP) is a Gaussian process (GP) with a covariance function that accounts for dependencies between multiple and related outputs [Bonilla et al., 2008]. Having models that exploit such dependencies is particularly important when some of the outputs are expensive to measure and the other more inexpensive outputs can be used as surrogates of the expensive output to improve its prediction. A typical example comes from geostatistics, where the accuracy of predicting the concentration of toxic heavy metals like lead or copper, which can be expensive to measure, can be improved by including measurements of pH as secondary variables, something that is signiﬁcantly less expensive to measure [Goovaerts, 1997]. One of the challenges in multi-output GPs is deﬁning a cross-covariance function between outputs that leads to a valid covariance function for the joint GP. There is extensive literature looking at ways to build such types of cross-covariance functions [Álvarez et al., 2012]. One such approach is ∗Corresponding author: mauricio.alvarez@sheffield.ac.uk. MAA and WW have been ﬁnanced by the Engineering and Physical Research Council (EPSRC) Research Project EP/N014162/1. MAA has also been ﬁnanced by the EPSRC Research Project EP/R034303/1. CG would like to thank Convocatoria 567 from Administrative Department of Science, Technology and Innovation of Colombia (COLCIENCIAS) for the ﬁnancial support. 1 arXiv:1810.04632v2  [stat.ML]  27 Feb 2019  known as process convolution, for which each output is the convolution integral between a smoothing kernel and a latent random process. The approach was introduced by Barry and Ver Hoef [1996] to build covariance functions for single-output GPs, and later for multi-outputs in Ver Hoef and Barry [1998] and Higdon [2002]. The convolution integral linearly transforms the underlying latent process, which is usually assumed to be a Gaussian process. The output process is then a GP with a covariance equal to the convolution operators acting to modify the covariance function of the latent GP. The main contribution in this paper is the introduction of a non-linear version of the process convolution construction suitable both for single-output and multi-output GPs. The non-linear model is constructed using a Volterra series where the input function is a latent random process. The Volterra series has been widely studied in the literature of non-linear dynamical systems [Haber and Keviczky, 1999]. They generalise the Taylor expansion for the case of non-instantaneous input functions. We treat the latent process as a Gaussian process and, using formulae for the product moments of Gaussian variables, we provide closed-form expressions for the mean function and covariance function of the output process. We approximate the output as a Gaussian process using these mean and covariance functions. Most attempts to generate non-linear models that involve Gaussian processes come from an alternative representation of the convolution integral based on state space approaches [Hartikainen and Särkkä, 2011, Särkkä et al., 2013]. Exceptions include the works by Lawrence et al. [2007] and Titsias et al. [2009] where the non-linearity is a static transformation of the underlying latent GP',\n",
       " '1805.06641': 'The problem of egomotion or self-motion estimation from a moving monocular observer, after many years of research, is still considered a diﬃcult problem. Recently it has attracted renewed attention in the Computer Vision community due to emerging applications in robotics, autonomous navigation and augmented reality. Physically, the motion of the camera can be interpreted as the linear combination of a 3D translation followed by a 3D rotation. The instantaneous motion captured contains information about the camera’s 3D motion and the 3D scene geometry. Egomotion estimation amounts to computing ﬁve parameters: three for the 3D rotation and two for the axis of the 3D translation, because without additional information, there is an ambiguity between translational velocity and depth. Based on the 3D motion, the 3D relative structure can be estimated. The classic approach to estimating structure and motion employs three steps: ﬁrst, the full dense optical ﬂow between sucessive frames is estimated; second, the 3D translation and 3D rotation are recovered using the optical ﬂow, possibly making assumptions about the camera motion and the scene; third, the 3D geometry up to the scaling factor is estimated [1, 2, 3, 4]. Instead of dense ﬂow, a sparse set of feature correspondences is often used, as is common in standard visual odometry and SLAM methods [5, 6, 7]. However, recent SLAM formulations [8] do not estimate 3D motion through constraints independent of depth, but estimate 3D motion and depth combined by minimizing photometric/geometric distance that explain image patch matches. The focus of this paper is on the evaluation of depth independent constraints. The main constraint to estimate 3D motion from video independent of structure, is the epipolar contraint. However, it requires as input optical ﬂow or correspondences. One problem is that optical ﬂow cannot be estimated accurately. $ c⃝2018. This manuscript version is made available under the CC-BY-NC-ND 4.0 license http://creativecommons.org/licenses/by-nc-nd/4.0/ ∗Corresponding author Email address: fbarranco@ugr.es (Francisco Barranco) Preprint submitted to Journal of LATEX Templates May 18, 2018 arXiv:1805.06641v1  [cs.CV]  17 May 2018  Most top optical ﬂow techniques are based on the work of Horn & Schunk [9]. The key assumption is that the change of the intensity over a small time interval remains constant. Since this only provides one equation and ﬂow ﬁelds are two-dimensional, additional constraints on the ﬂow ﬁeld are enforced assuming a smooth variation of the ﬁeld spatially in local neighborhoods [10, 11, 12]. These assumptions cause the optical ﬂow to be imprecise at object contours, where there are occlusions or when the motion is large. Motion ﬁelds do not vary smoothly close to object boundaries, occlusions cause mismatches, and large motions violate the assumption of local intensity constancy. Another motion constraint, independent of structure, is the depth positivity constraint [13, 14], also referred to as cheirality constraint [15]. The scene has to be in front of the camera, and thus the depth has to be positive. This constraint',\n",
       " '1812.01662': 'Basic relations such as equality are fundamental to relational data structures. One goal of applying neural networks to relational data is that the networks learn to infer these relational structure from data. Although equality is typically not learned from data, equality or approximate equality may be embedded as part of other tasks. The modelling of equality is clearly in the hypothesis space of feed-forward neural networks (FFNNs) [1], but [2, 3] already highlighted that learning of identity relationships with neural networks may not generalise to unseen data. Therefore, we see learning to recognise equality as relevant from a theoretical and practical perspective. In this study we test whether feed-forward networks learn equality as well as a numeric comparison, thresholded digit sum, and digit reversal of pairs of binary vectors and then generalise this to new data in different settings regarding the task, the amount of data provided, and the depth of the network. We ﬁnd that the recognition of binary relations is not generalised reliably by feed-forward networks. To address this problem, we introduce an inductive bias with additional predeﬁned network structures, that we call differential rectiﬁer (DR) units. We ﬁnd in our experiments that DR units induce reliable perfect generalisation for equality and all other tasks except in digit reversal. We see two questions that these results raise: First, which other relations neural networks do not learn and what that means for more complex tasks. Second, what kinds of inductive biases to design and how to implement them. The remainder of this paper is organised as follows: Section 2 reviews related literature, Section 3 introduces the task of learning vector equality and our DR units for inductive bias. Section 4 presents the experimental results and in Section 5 follow the conclusions of this paper. 32nd Conference on Neural Information Processing Systems (NIPS 2018), Montréal, Canada. arXiv:1812.01662v1  [cs.LG]  4 Dec 2018  2 Related work In relational learning, equality is often not learned from the data, with the exception of the work by [4] who learn to detect equality attributed of objects from images. Learning equality could be interesting in the context of constraint learning [5] to learn when equality constraints should be regarded as satisﬁed. Another relevant area is rule learning and application, where soft uniﬁcation like in [6] could be replaced with a learnt model. Since neural networks are currently by far the most popular machine learning method, it seems of interest whether they can learn equality. There have been a number of theoretical contributions showing that feed-forward networks are universal approximators, most generally to our knowledge by [1]. Presumably because of these results there was relatively little interest in the question which functions neural networks can not learn. One of the few studies in this direction was undertaken in [2] in 1999, where a recurrent neural network failed to distinguish abstract patterns, based on equality relations between sequence elements, although seven-month-old infants showed the ability to distinguish them after',\n",
       " '1812.02099': 'The Sauer-Shelah-Perles Lemma [38,40,43] is arguably the most basic fact in VC theory; it asserts that any class C ⊆{0, 1}n satisﬁes |C| ≤ \\x00 n ≤d \\x01 , where d = VC-dim(C). A beautiful generalization of Sauer-Shelah-Perles’s inequality asserts that |C| ≤|X(C)|, where X(C) is the family of subsets that are shattered by C.1 The latter inequality is a part of the Sandwich Lemma [3, 8, 13, 33], which also provides a lower bound for |C| (and thus “sandwiches” |C|) in terms of the number of its strongly shattered subsets (see Section 2). A class C is called maximum/ample if the Sauer-Shelah-Perles/Sandwich upper bounds are tight (respectively). Every maximum class is ample, but not vice versa. Maximum classes were studied mostly in discrete geometry and machine learning, e.g. [15, 16,18,23,45]. The history of ample classes is more interesting as they were discovered independently by several works in disparate contexts [3,5,8,13,24,29,46]. Consequently, they received diﬀerent names such as lopsided classes [24], extremal classes [8,29], and ample classes [5,13]. Lawrence [24] was the ﬁrst to deﬁne them for the investigation of the possible sign patterns realized by points of a convex set of Rd. Interestingly, Lawrence’s deﬁnition of these classes does not use the notion of shattering nor the Sandwich Lemma. In this context, these classes were discovered by Bollob´as and Radcliﬀe [8] and Bandelt et al. [5], and the equivalence between the two deﬁnitions appears in [5]. Ample classes admit a multitude of combinatorial and geometric characterizations [5,6,8,24] and comprise many natural examples arising from discrete geometry, combinatorics, graph theory, and geometry of groups [5,24]. 1.1. Main Results. 1.1.1. Corner Peelings. A corner in an ample class C is any concept c ∈C that belongs to a unique maximal cube of C (equivalently, c is a corner if C \\\\{c} is also ample, see Lemma 4.1). A sequence of corner removals leading to a single concept is called a corner peeling; corner peeling Key words and phrases. VC-dimension, Sample Compression, Sauer-Shelah-Perles Lemma, Sandwich Lemma, Maximum Class, Ample Class, Extremal Class, Corner Peeling, Unique Sink Orientation. ∗An extended abstract [11] of this paper has appeared in the proceedings of ICALP 2019. 1Note that this inequality indeed implies the Sauer-Shelah-Perles Lemma, since X(C) ⊆ \\x00[n] ≤d \\x01 . 1 arXiv:1812.02099v2  [cs.DM]  5 Jan 2022  2 J. CHALOPIN, V. CHEPOI, S. MORAN, AND M. K. WARMUTH is a strong version of collapsibility. Wiedemann [46] and independently Chepoi (unpublished, 1996) asked whether every ample class has a corner. The machine learning community studied this question independently in the context of sample compression schemes for maximum classes: Rubinstein and Rubinstein [35] showed that corner peelings lead to optimal unlabeled sample compression schemes (USCS). In Theorem 4.5 we refute this conjecture. The crux',\n",
       " '1707.05697': 'Channel encoding and decoding are important components in modern communication systems. Inspired by Shannon’s original work [1], tremendous progresses have been made both in coding theory and its applications. For example, low-density parity-check (LDPC) codes [2] are able to yield a performance close to the Shannon capacity for AWGN channels with a properly optimized encoding structure and the This work has been supported by the National Natural Science Foundation of China under Grant 61631017. The authors are with the Laboratory of Future Networks, School of Information Science and Technology, University of Science and Technology of China.  2 well developed belief-propagation (BP) decoding algorithm [3]. As another example, short to mediumblock length linear codes such as Bose-Chaudhuri-Hocquenghem (BCH) code [4] and Polar code [5] are of great interest to the recent development in 5G [6], for delay-sensitive and mission-critical applications. However, in practical communication systems, channels sometimes exhibit correlations in the noise samples due to ﬁltering, oversampling [7], channel fading and multi-user interference [8]. A welldesigned channel code may not have satisfactory performance if the receiver is not designed to handle noise correlations. The difﬁculty in addressing this issue mainly comes from the high-complexity model introduced by the colored noise. In theory, the decoder can ﬁrst estimate the noise distribution, and then optimize the BP decoder using the estimated joint distribution. This approach, nevertheless, is modelbased and may suffer from not obtaining a well-behaved joint distribution for noise samples. Furthermore, optimizing the BP decoder with a joint noise distribution may be highly complex when the correlation is strong. Hence, a low-complexity, highly-adaptive and robust decoder structure that can fully exploit the characteristics of noise correlations and have good decoding performance is desired. Recent advances in deep learning provide a new direction to tackle this problem. Instead of ﬁnding an algorithm based on a pre-deﬁned model, deep learning technologies allow the system to learn an efﬁcient algorithm directly from training data. Deep learning has been applied in computer vision [9], natural language processing [10], autonomous vehicles [11] and many other areas, and the results have been quite remarkable. Inspired by these advances, researchers have recently tried to solve communication problems (including channel decoding) using deep learning technologies [12]–[22], and a summary of these works is provided in Section II. However, none of these works address the problem of efﬁcient decoding of linear codes under correlated channel noise. In this paper, we design a novel receiver architecture to tackle the decoding problem when correlation exists in channel noise. This architecture concatenates a trained convolutional neural network (CNN) with a standard BP decoder, and the received symbols are iteratively processed between BP and CNN – hence the name iterative BP-CNN. At the receiver side, the received symbols are ﬁrst processed by the BP decoder to obtain an initial decoding. Then, subtracting the estimated transmit symbols from the received symbols, we obtain an estimation of channel noise',\n",
       " '1204.2435': 'Recently, the design and analysis of coding schemes representing generalizations of Gallager’s low-density parity-check (LDPC) codes [1] has gained increasing attention. This interest is motivated above all by the search for coding schemes which offer a better compromise between waterfall and error ﬂoor performance than is currently offered by state-of-the-art LDPC codes. In the Tanner graph of an LDPC code, any degree-q variable node (VN) may be interpreted as a length-q repetition code, i.e., as a (q, 1) linear block code. Similarly, any degree-s check node (CN) may be interpreted as a length-s single paritycheck (SPC) code, i.e., as a (s, s −1) linear block code. The ﬁrst proposal of a class of linear block codes generalizing LDPC codes may be found in [2], where it was suggested to replace each CN of a regular LDPC code with a generic This work was supported in part by the EC under Seventh FP grant agreement n. 288502 CONCERTO, and in part by Science Foundation Ireland (grants 07/SK/I1252b and 11/RFP.1/ECE/3206). The material in this paper was presented in part at the IEEE Global Communications Conference (GLOBECOM ’09), Honolulu, Hawaii, Nov./Dec. 2009, in part at the IEEE International Conference on Communications (ICC ’10), Cape Town, South Africa, May 2010, and in part at the 2nd International Symposium on Applied Sciences in Biomedical and Communication Technologies (ISABEL ’09), Bratislava, Slovakia, Nov. 2009. M. F. Flanagan is with the School of Electrical, Electronic and Communications Engineering, University College Dublin, Belﬁeld, Dublin 4, Ireland (e-mail:mark.ﬂanagan@ieee.org). E. Paolini and M. Chiani are with the Department of Electronic, Electrical and Information Engineering, University of Bologna, via Venezia 52, 47521 Cesena (FC), Italy (e-mail:e.paolini@unibo.it, marco.chiani@unibo.it). M. P. C. Fossorier is with ETIS ENSEA, UCP, CNRS UMR-8051, 6 avenue du Ponceau, 95014 Cergy Pontoise, France (e-mail: mfossorier@ieee.org). linear block code, to enhance the overall minimum distance. The corresponding coding scheme is known as a regular generalized LDPC (GLDPC) code, or Tanner code, and a CN that is not a SPC code as a generalized CN. More recently, irregular GLDPC codes were considered (see for instance [3]). For such codes, the VNs exhibit different degrees and the CN set is composed of a mixture of different linear block codes. A further generalization step is represented by doublygeneralized LDPC (D-GLDPC) codes [4]. In a D-GLDPC code, not only the CNs but also the VNs may be represented by generic linear block codes. The VNs which are not repetition codes are called generalized VNs. The main motivation for introducing generalized VNs is to overcome some problems connected with the use of generalized CNs, such as an overall code rate loss which makes GLDPC codes interesting mainly for low code rate applications, and a loss in terms of decoding threshold (for a',\n",
       " '1702.06354': 'Outlier detection (a.k.a Anomaly detection), the problem of ﬁnding anomalies in data, is attracting a lot of attention in the machine learning and data mining communities [1]. It is needed in various real-world applications including spacecraft anomaly detection, computer fault detection, and intrusion detection in network systems [2, 3, 4]. Recently, the problem of outlier detection from high-dimensional data such as multi-sensor data has been attracting increasing attention. Moreover, the demand for interpretable models of data is increasing, and it would be highly useful if models used to detect outliers would be interpretable as well; interpretability could be achieved by models that select descriptive features. However, to the best of our knowledge, there is no existing framework to select features of outliers. Unsupervised outlier detection is a common approach to detect anomalies. For example, one-class support vector machines (OSVM) [5], kernel density estimation (KDE) [6], and local outlier factors (LOF) [7] are widely used unsupervised outlier detection algorithms. The key idea of these approaches is to regard samples which are located in low-density region as outliers. Unsupervised algorithms perform well if the low-density assumption holds. If the low-density assumption does not hold, new approaches are needed, and in any case models need to be made interpretable which is not straightforward in kernel methods in particular. If the low-density assumption does not hold, or does not result in high enough detection accuracy, inlier-based outlier detection is useful [8, 9, 10, 11]. The inlier-based methods model known normal samples (inliers), and detect deviations in test samples. Since additional knowledge is available instead of just the test samples, in the form of some training samples being known to be normal, inlier-based methods tend to have higher detection accuracies than unsupervised algorithms. A widely used inlier-based method is based on the density-ratio between inlier and test densities, and uses the density-ratio as a measure of plausibility of data being outliers. 1 arXiv:1702.06354v1  [stat.ML]  21 Feb 2017  To estimate the density-ratio, a number of direct density-ratio estimation algorithms have been proposed, based on logistic regression [12], a Kullback-Leibler importance estimation procedure (KLIEP) [13], and (relative) unconstrained least-squares importance ﬁtting (uLSIF/RuLSIF) [14, 15]. The key idea of the direct estimation methods is to directly estimate the density ratio function without estimating probability densities. The inlierbased outlier detection algorithms empirically outperform unsupervised counterparts. However, since the direct methods employ kernel models, it is hard to interpret the detected outliers. In this paper, we propose an inlier-based outlier detection method, which incorporates feature selection into the outlier detection algorithm. More speciﬁcally, we model each sample xi ∈Rd by introducing a locally linear density-ratio model exp(w⊤ i xi), where wi ∈Rd is the model parameter vector for the sample xi. Since the model is locally linear, we can apply well-functioning feature selection methods to make the local models interpretable in',\n",
       " '1807.03257': 'Due to the continuous semiconductor scaling from 10nm technology node (N10) to 7nm node (N7) [1], [2], the prediction of printed pattern sizes is becoming increasingly difﬁcult and complicated due to the complexity of manufacturing process and variations. However, complex designs demand accurate simulations to guarantee functionality and yield. Resist modeling, as a key component in lithography simulation, is critical to bridge the aerial image simulation to manufactured wafer data. Rigorous simulations that perform physics-level modeling suffer from large computational overhead, which are not suitable when used extensively. Thus compact resist models are widely used in practice. Figure 1(a) shows the process of lithography simulations where the aerial image is computed from the input mask patterns and the optical model, and the output pattern is computed from the aerial image and the resist model. As the aerial image contains the light intensity map, the resist model needs to determine the slicing thresholds for the output patterns as shown in Figure 1(b). With the thresholds, the critical dimensions (CDs) of printed patterns can be computed, which need to match CDs measured from manufactured patterns. In practice, various factors may impact a resist model such as the physical properties of photoresist, design rules of patterns, process variations. Critical dimension usually refers to the smallest dimension on a lithography level that must be accurately controlled when fabricating a device. Here critical dimensions refer to the sizes of printed patterns. Accurate lithography simulation like rigorous physics-based simulation is notorious for its long computational time, while simulation with compact models suffers from accuracy issues [3], [4]. On the Y. Lin, M. Li and D. Z. Pan are with The Department of Electrical and Computer Engineering, The University of Texas at Austin, TX, USA. Y. Watanabe, T. Kimura, T. Matsunawa, and S. Nojima are with Toshiba Memory Corporation, Yokohama, Japan. Mask pattern Aerial image Resist pattern Optical model Resist model (a) Slicing threshold Simulated CD (b) Fig. 1: (a) Process of lithography simulation with optical and resist models. (b) Thresholds for aerial image determine simulated CD, which should match manufactured CD. other hand, machine learning techniques are able to construct accurate models and then make efﬁcient predictions. These approaches ﬁrst take training data to calibrate a model and then use this model to make predictions on testing data for validation. The effectiveness of learning-based solutions has been studied in various lithography related areas including aerial image simulation [5], hotspot detection [6]–[11], optical proximity correction (OPC) [12]–[15], subresolution assist features (SRAF) [16], [17], resist modeling [3], [4], etc. In resist modeling, a convolutional neural network (CNN) that predicts slicing thresholds in aerial images is proposed [4]. The neural network consists of three convolution layers and two fully connected layers. Since the slicing threshold is a continuous value, learning a resist model is a regression task rather than a classiﬁcation task. Around 70% improvement in accuracy is reported compared with calibrated compact models from Mentor',\n",
       " '1702.07108': 'Millimeter wave (mmWave) communication has been recognized as a promising technology in 5G cellular network for its large transmission bandwidth [1], [2]. To compensate the severe pathloss of mmWave link, large-scale antenna array is needed to provide high precoding gains [3]. However, the prohibitive cost and power consumption of radio frequency (RF) chains at mmWave bands makes the fully digital precoding infeasible. To tackle this RF hardware constraint, a hybrid precoding transceiver architecture has been recently proposed, where the large-scale antenna array is driven by a small number of RF chains [4]. The two stage hybrid precoder is implemented by a high-dimensional RF beamformer using cost-efﬁcient analog phase shifters, cascaded with a reduceddimensional digital precoder [5]. Considering single user MIMO systems, the hybrid precoder is designed to approach the performance of fully digital precoder by solving a matrix factorization problem [6]. When it comes to multiuser MIMO systems, [7] maximized the sum M. Dai and B. Clerckx are with the Department of Electrical and Electronic Engineering, Imperial College London, SW7 2AZ, UK (e-mail: {m.dai13, b.clerckx}@imperial.ac.uk). This work has been partially supported by the EPSRC of UK, under grant EP/N015312/1. rate by iteratively optimizing the analog and digital precoder until convergence. The work [8] analyzed the rate performance in the large array regime for a given hybrid precoder design. Furthermore, [9] considered a partially-connected phase shifter networks. All these works determined the hybrid precoder assuming perfect full dimensional channel state information at the transmitter (CSIT). In practical mmWave systems, only an imperfect CSIT is attainable through channel estimation [10], [11] and quantization. With limited feedback, [12] proposed a low complexity hybrid precoding approach. In the ﬁrst stage, the RF beamformer is designed to maximize the desired signal power of each user by beam search and feedback. In the second stage, the digital precoder depends on the random vector quantization (RVQ) and feedback of the effective channel (the channel concatenated with the RF beamformer). This hybrid precoding method relies on two-stage feedback and thus requires a complicated signalling and feedback procedure. So far, there has been no investigation on how to simplify the signalling and feedback procedure while maintaining the rate performance. In presence of statistical CSIT, we propose a hybrid precoding design based on one-stage feedback. Speciﬁcally, we make use of all feedback overhead for the ﬁrst stage to enable precise design of beamforming directions and take advantage of the second-order channel statistics to mitigate multiuser interference. Hereinafter, this is referred to as One-Stage Feedback plus Statistical CSIT (‘OSF + Stat’)-based hybrid precoding scheme. To make a fair comparison, we consider an enhanced design of [12] by employing a second-order channel statistics-based quantization codebook in the secondstage feedback. Hereinafter, this is referred to as the TwoStage Feedback plus Adaptive Codebook (‘TSF + Adp CB’)- based hybrid precoding scheme. With a ﬁxed total feedback constraint, we',\n",
       " '1712.00202': 'Over the past decades, inverse problems have been widely studied in image and signal processing and computer vision, e.g., denoising [15], deconvolution [2], superresolution [48] and compressive sensing [18]. An inverse problem is resulted from the forward model which maps unknown signals, i.e., the ground-truth, to acquired/observed information about them, which we call data or measure- ∗The authors contributed equally to this work. ments. This forward problem, generally relies on a developed physical theory which reveals the link between the ground-truth and the measurements. Solving inverse problems involves learning the inverse mapping from the measurements to the ground-truth. Speciﬁcally, it recovers a signal from one or a small number of degraded or noisy measurements, which is usually ill-posed [42]. Mathematically, the goal is to reconstruct a high dimensional groundtruth x ∈Rn from a low dimensional measurement denoted as y ∈Rm, which is reduced from x by a a forward model A such that y = Ax. This forward model A is constructed to tie the observed data y to a set of learned model parameters x. For example, in compressive sensing, y is a compressive measurement with random sampled regions and A is the measurement matrix, e.g., a random Gaussian matrix; in super-resolution, y is a low-resolution image and the operation A downsamples high resolution images. The main difﬁculty of these underdetermined systems comes from the operator A which has a non-trivial null space leading to an inﬁnite number of feasible solutions. Though most of the inverse problems are formulated directly to the setting of an optimization problem associated with the forward model [41], a number of learning-based algorithms have been proposed to solve inverse problems by learning a mapping from the measurement domain of y to the signal space of x, with the help of large datasets and neural nets [32, 14]. 1 More recently, deep learning techniques have arisen as a promising framework and gained great popularity for providing state-of-the-art performance on applications include pattern analysis (unsupervised), classiﬁcation (supervised), computer vision, image processing, etc [13]. Exploiting deep neural networks to solve inverse problems has been explored recently [14, 40, 1, 24]. In these works, inverse problems are viewed as a pattern mapping problem and most existing learning-based methods propose to learn an 1These algorithms refer to directly learning optimum mappings from the observed data to their high-resolution correspondents and are different from learning from training datasets some speciﬁc priors to be incorporated in the regularized iterative algorithms[15, 47]. 4321 arXiv:1712.00202v1  [cs.CV]  1 Dec 2017  end-to-end mapping from y to x [37, 40]. By leveraging the powerful approximation ability of deep neural networks, these deep learning based data-driven methods have achieved state-of-the-art performance in many challenging inverse problems like super-resolution [5, 14, 40], image reconstruction [35',\n",
       " '1508.04306': 'In real world perception, we are often confronted with the problem of selectively attending to objects whose features are intermingled with one another in the incoming sensory signal. In computer vision, the problem of scene analysis is to partition an image or video into regions attributed to the visible objects present in the scene. In audio there is a corresponding problem known as auditory scene analysis [1,2], which seeks to identify the components of audio signals corresponding to individual sound sources in a mixture signal. Both of these problems can be approached as segmentation problems, where we formulate a set of “elements” in the signal via an indexed set of features, each of 1 arXiv:1508.04306v1  [cs.NE]  18 Aug 2015  which carries (typically multi-dimensional) information about part of the signal. For images, these elements are typically deﬁned spatially in terms of pixels, whereas for audio signals they may be deﬁned in terms of time-frequency coordinates. The segmentation problem is then solved by segmenting elements into groups or partitions, for example by assigning a group label to each element. Note that although clustering methods can be applied to segmentation problems, the segmentation problem is technically different in that clustering is classically formulated as a domain-independent problem based on simple objective functions deﬁned on pairwise point relations, whereas partitioning may depend on complex processing of the whole input, and the task objective may be arbitrarily deﬁned via training examples with given segment labels. Segmentation problems can be broadly categorized into class-based segmentation problems where the goal is to learn from training class labels to label known object classes, versus more general partition-based segmentation problems where the task is to learn from labels of partitions, without requiring object class labels, to segment the input. Solving the partition-based problem has the advantage that unknown objects could then be segmented. In this paper, we propose a new partitionbased approach which learns embeddings for each input elements, such that the correct labeling can be determined by simple clustering methods. We focus on the single-channel audio domain, although our methods are applicable to other domains such as images and multi-channel audio. The motivation for segmenting in this domain, as we shall describe later, is that using the segmentation as a mask, we can extract parts of the target signals that are not corrupted by other signals. Since class-based approaches are relatively straightforward, and have been tremendously successful at their task, we ﬁrst brieﬂy mention this general approach. In class based vision models, such as [3–5], a hierarchical classiﬁcation scheme is trained to estimate the class label of each pixel or superpixel region. In the audio domain, single-channel speech separation methods, for example, segment the time-frequency elements of the spectrogram into regions dominated by a target speaker, either based on classiﬁers [6–8], or generative models [9–11]. In recent years, the success of deep neural networks',\n",
       " '1611.05384': 'Chinese word segmentation and part-of-speech (POS) tagging are two core and fundamental tasks in Chinese natural language processing (NLP). The state-of-theart approaches are based on joint segmentation and tagging (S&T) model, which can be regarded as character based sequence labeling task. The joint model can alleviate the error propagation problem of pipeline models. Previously, the traditional hand-crafted feature based models have achieved great success on joint S&T task (Jiang et al., 2008; Kruengkrai et al., 2009; Qian et al., 2010; Zhang and Clark, 2008, 2010). Despite of their success, their performances are easily affected by following two limitations. The ﬁrst is model complexity. Since the decoding space of joint S&T task is relatively large, the traditional models often rely on millions of discrete features. Therefore, the efﬁciency of joint S&T models is rather low. Moreover, these models suffer from data sparsity. Recently, some neural models (Huang et al., 2015; Chen et al., 2015a; Ma and Hovy, 2016) are proposed to reduce the efforts of feature engineering and the model complexity. However, these neural models ∗Corresponding author. 来 推 、 动 发 展 S_PU S_MSP B_VV E_VV B_NN E_NN 结 合 B_VV E_VV 革 改 B_VV E_VV 精 简 B_JJ E_JJ 机 构 B_NN E_NN incorporate reform simplify institution to speed up development B_NN E_NN B_VV E_VV Figure 1: An example. CRF makes mistakes on words “reform” and “simplify”. The red tags with strikethrough lines indicate the wrong predictions. just concatenate the embeddings of the context characters, and feed them into neural network. Since the concatenation operation is relatively simple, it is difﬁcult to model the complicated features as the traditional discrete feature based models. Although the complicated interactions of inputs can be modeled by the deep neural network, the previous neural models show that the deep model cannot outperform the one with a single non-linear model. The second is long term dependency. Unlike pure POS tagging task which can utilize contextual features on word level, joint S&T task usually extracts the contextual features on character level. Thus, the joint model need longer dependency on character level. As the example shown in Figure 1, conditional random ﬁeld (CRF) model makes mistakes on words “reform” and “simplify” since it is hard for CRF to disambiguate the POS tags without using long distance information. However, restricted by model complexity and data sparsity, a larger window size (greater than 5) will instead hurt the performance. Therefore, how to exploit the long distance information without increasing the model complexity is crucial to joint S&T task. In order to address these two problems, we propose a feature-enriched neural model for joint S&T task, which consists of several key components: (1) a convolutional layer to simulate compositional features as complex hand-crafting features; (2) a pooling layer to select the most va',\n",
       " '1803.00773': 'We consider the observation model in a Hilbert space H (with associated norm ∥· ∥H): y = Mx0 (1) where M is an under-determined linear operator, y is a m-dimensional vector and x0 is the unknown. We suppose that x0 belongs to a low-dimensional model Σ (a union of subspaces). We consider the following minimization program. x∗∈arg min Mx=y R(x) (2) where R is a regularization function. A huge body of work gives practical regularizers ensuring that x∗= x0 for several low-dimensional models (in particular sparse and low rank models, see [7] for a most complete review of these results). The operator M is generally required to satisfy some property (e.g., the restricted isometry property) to guarantee recovery. In this work, we aim at ﬁnding the “best” regularizer for exact recovery of x0 ∈Σ. Ideally we would like to set R = ιΣ (the characteristic function of Σ) but it is not practical in many cases (sparse and low rank recovery) as it is generally not convex, and even NP-hard to compute as a combinatorial problem. Consequently, we restrict the search for the best regularizer to a class of interesting regularizers C. In our examples, the set C is a subset of the set of convex functions. Other interesting classes might be considered, such as partly smooth functions [12].  1.1. Best regularizer with respect to a low dimensional model Deﬁning what is the “best” regularizer in C for recovery is not immediate. Ideally, to ﬁt to the inverse problem, we must deﬁne a compliance measure that depends on both the kind of unknown and measurement operator we consider. If we have some knowledge that M ∈M where M is a set of linear operators, we want to deﬁne a compliance measure AΣ,M(R) that tells us if a regularizer is good in these situations, and maximize it. Such maximization might yield a function R∗that depends on M (e.g., in [10], when looking for tight continuous relaxation of the ℓ0 penalty a dependency on M appears). We aim for a more universal notion of optimal regularizer that does not depend on M. Hence, we look for a compliance measure AΣ(R) and its maximization R∗∈arg max R∈C AΣ(R). (3) In the sparse recovery example studied in this article, the existence of a maximum of AΣ(R) is veriﬁed. However, we could ask ourselves what conditions on AΣ(R) and C are necessary and suﬃcient for the existence of a maximum, which is out of the scope of this article. 1.2. Compliance measures When studying recovery with a regularization function R, two types of guarantees are generally used: uniform and non-uniform. To describe these recovery guarantees, we use the following deﬁnition of descent vectors. Deﬁnition 1.1 (Descent vectors). For any x ∈H, the collection of descent vectors of R at x is TR(x) := {z ∈H : R(x + z) ≤R(x)} . (4) We write TR(Σ',\n",
       " '1707.04610': 'Deep learning has started to gain popularity in powering up modern mobile applications. Training deep neural networks requires access to large amounts of data and computing powers. As a result, these neural networks are often trained by leveraging cheaper, yet more powerful cloud GPU clusters. Once trained, the inference phase can be completed in a reasonable amount of time, e.g., less than one second, using a single machine. Pre-trained models can be hosted for private use or offered as public cloud deep learning services [1], [2]. To utilize cloud-based pre-trained models, mobile app developers use exposed cloud APIs to ofﬂoad deep learning inference tasks, such as object recognition shown in Figure 1, to the hosting server. Mobile apps that execute inference tasks this way is referred to as cloud-based deep inference. Despite their increasing popularity, the use case scenarios of cloud-based deep inference can be limited due to data privacy concern, unreliable network condition, and impact on battery life. Alternatively, we can perform inference tasks locally using mobile CPU and GPU [3]. We refer to this mobile deep learning approach as on-device deep inference. On-device deep inference can be a very attractive alternative to the cloud-based approach, e.g., by providing mobile applications the ability to function even without network access. Image Data Input Layer Hidden Layer(s) Output Layer Inference Labels “Greenhouse, nursery, glasshouse’’ Deep Neural Network Fig. 1: Object recognition with deep neural networks. An image passes through a deep neural network that consists of layers of neurons. The output layer produces the inference labels that best describe the image. Given the above two design choices for implementing deep inference, it is beneﬁcial for developers to understand the performance differences. However, it is not straightforward to reason about mobile apps performance when using on-device deep inference. The difﬁculties can be attributed to the following reasons. First, deep neural networks (DNN) can differ vastly in terms of network architecture, number of parameters, and model sizes (see Figure 4). Second, the inference tasks can be of different complexities depending on the input data, e.g., large images vs. small images, and the DNN model in use. Third, mobile devices often have heterogenous resource capacities and can exhibit different runtime behaviors, such as garbage collection activities, given different deep learning models and inference tasks combinations. To address the challenges of understanding deep learning inference, in this paper we develop a mobile application benchmark that allows end users to supply conﬁgurations including inference mode, model, and input data. We conduct a detailed measurement study using our mobile application with cloud-based and on-device deep inference, three convolutional neural networks, and a dataset of ﬁfteen images. Our evaluation shows that cloud-based approach can save up to two orders of magnitude in terms of both end-to-end response time and mobile energy consumption. Further, we analyze the performance differences between on-device and cloudbased approaches with an in',\n",
       " '1708.02637': 'Machine learning, and in particular, deep learning, is a ﬁeld of growing importance. With the deployment of large GPU clusters in datacenters and cloud computing services, it is now possible to apply these methods not only in theory, but integrate them successfully into production systems. Engineers working on production systems have only recently gained the ability to apply advanced machine learning, driven in large part by the availability of machine learning frameworks that ∗Corresponding authors: {clemensm,wicke}@google.com Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and the full citation on the ﬁrst page. Copyrights for third-party components of this work must be honored. For all other uses, contact the owner/author(s). KDD’17, August 13–17, 2017, Halifax, NS, Canada. © 2017 Copyright held by the owner/author(s). 978-1-4503-4887-4/17/08. DOI: htp://dx.doi.org/10.1145/3097983.3098171 implement the lower level numerical computations in eﬃcient ways and allow engineers to focus on application-speciﬁc logic (see e.g., [2–5, 7, 8, 11, 14, 17–20]). However, the huge amounts of data involved in training, especially for deep learning models, as well as the complications of running high intensity computations eﬃciently on heterogeneous and distributed systems, has prevented the most advanced methods from being widely adopted in production. As the ﬁeld of deep learning is still young and developing fast, any framework hoping to remain relevant must be expressive enough to not only represent today’s model architectures, but also next year’s. If the framework is to be used for experimentation with model architectures (most serious product work requires at least some experimentation), it is also crucial to oﬀer the ﬂexibility to change details of models without having to change components that are deeply embedded, and which have a highly optimized, low level implementation. Tere is a natural tension between such ﬂexibility on the one hand, and simplicity and robustness on the other hand. We use simplicity in a broad sense: From a practitioner’s point of view, implementing models should not require fundamentally new skills, assuming that the model architecture is known. Experimenting with model features should be transparent, and should not require deep insights into the inner workings of the framework used to implement the model. We talk of robustness both as a quality of the sofware development process, as well as a quality of the resulting sofware. We call a framework robust if it is easy to write correct and high-quality sofware using it, but hard to write broken or poorly performing sofware. A framework which nudges the developer to use best practices, and which makes it hard to “shoot yourself in the foot” is robust. Because of the need to keep up with and enable research, many deep',\n",
       " '1401.6432': 'Metric based decoders are usually used to decode codes in digital communication. Typically, the metric tries to capture the most likely codeword that was transmitted. When the channel over which the codeword was transmitted is known at the receiver, the Maximum Likelihood (ML) decoder is used for optimal performance (in terms of block error rate). When the channel is not known at the receiver, other solutions are required. Usually another assumption is made, for example, the channel Wθ(y|x) belongs to some family of channels indexed by θ ∈Θ. The family of channels can have some measure deﬁned over it (Bayesian approach), e.g., fading channel, or the channel is one of several possible channels (deterministic approach), e.g., discrete memoryless channels (DMCs). The performance in the ﬁrst case can be measured over the channel realization, and in the latter per speciﬁc channel. A universal decoding is optimal with respect to a given family of channels if the performance when using the universal decoder is not worse (in the error exponent sense) than when the optimal decoder is used; speciﬁcally, the error exponent is not smaller than that of the optimal decoder. In [3], Goppa offered the maximum mutual information (MMI) decoder, which decides in favor of the codeword having the maximum empirical mutual information with the channel output sequence. Other universal decoders have been suggested over the years for ISI channels [4], [5], [6],Interference channels [7], ﬁnite state channels [8], [9], Individual channels [10], and [11]. In [12], Feder and Lapidoth provide a fairly general construction of a universal decoder for a given class of channels. Their construction has two key points. The ﬁrst is the use of uniform random coding distribution (prior), which means that all codewords have the same probability; this allows the use of the merged decoder. The second is the deﬁnition of a separable family, which means that there is a countable set of channels that can be used as representative, in the sense that if the performance of the universal decoder is good over these channels, then it would be good over the whole family of channels. In [1] Merhav proposed another framework of universal decoding, namely, universality relative to a given set of decoding metric over arbitrary channels, where optimality means that the performance of the universal decoder is not worse (in the error exponent sense) than the performance when any other metric from the family is used. The decoder proposed by Merhav in [1] uses an equivalent of “types” that is a set of input and output sequences of the channel for which the metrics of the family provides the same value. The universal decoder that is based on ties in the metric, thus, does not seem to be the most general. In this paper we generalize the construction in [1], which in some sense also generalizes Feder and Lapidoth‘s universal decoder, [12]. The quantity pe,m',\n",
       " '1812.06515': 'Network data science has traditionally focused on studies capturing two-way interactions or connections between pairs of vertices or agents in networks. In this context, the problems of interest have been to identify heterogeneous and power law vertex degree distributions (e.g., determine if the networks are scale-free) as well as dense subgraphs and cliques, and eﬃciently detect and isolate community structures (Newman 2003; Barab´asi and Albert 1999; Watts and Strogatz 1998). It has by now become apparent that many aspects of relational organization, functionality and the evolving structure of a complex network can only be understood through higher-order 1Emails: Paul - paul.963@osu.edu, Milenkovic - milenkov@illinois.edu, Chen - yuguo@illinois.edu 1 arXiv:1812.06515v1  [stat.ML]  16 Dec 2018  subgraph (motif) interactions involving more than two vertices (Milo et al. 2002; Shen-Orr et al. 2002; Mangan and Alon 2003; Honey et al. 2007; Alon 2007; Porter et al. 2009; Benson et al. 2016; Yavero˘glu et al. 2014). Certain subgraphs in networks function as fundamental units of control and regulation of network communities and dynamics: for example, network motifs are crucial regulators in brain networks (Sporns and K¨otter 2004; Park and Friston 2013; Battiston et al. 2017), transcriptional regulatory networks (Mangan and Alon 2003), food webs (Paulau et al. 2015; Li and Milenkovic 2017), social networks (Girvan and Newman 2002; Snijders 2001) and air traﬃc networks (Rosvall et al. 2014; Benson et al. 2016). Traditionally, statistical and algorithmic work on network motifs has been concerned with discovering and counting the frequency of over-expressed subgraphs (which are usually determined in comparison with some statistical null model) in various real world networks (Alon 2007; Klusowski and Wu 2018). Indeed, frequency distributions or spectra of motifs have been shown to provide useful information about the regulatory and dynamic organization of networks obtained from disparate sources. Network motifs have also recently been used to perform learning tasks such as community detection (Benson et al. 2016; Li and Milenkovic 2017; Tsourakakis et al. 2017). A parallel line of work has focused on identifying communities in hypergraphs and was reported in Zhou et al. (2006); Angelini et al. (2015); Kim et al. (2017); Ghoshdastidar et al. (2017); Chien et al. (2018). Unfortunately, existing random graph models with community structures based on Erd¨osR´enyi random graphs (Erd¨os and R´enyi 1960), such as the Stochastic Block Models (Holland et al. 1983; Snijders and Nowicki 1997; Bickel and Chen 2009; Choi et al. 2012; Rohe et al. 2012; Celisse et al. 2012; Rohe et al. 2011; Qin and Rohe 2013; Jin 2015; Lei et al. 2015; Decelle et al. 2011; Hajek et al. 2016; Abbe and Sandon 2015; Gao et al. 2017), their degreecorrected versions (Karrer and Newman 2011; Zhao et al. 2012), and other extensions fail to produce graphs with strong local clustering, i.e., with over-abundant triangles and other relevant higher-order structures. To investigate community structures in terms',\n",
       " '1403.1023': 'We consider the problem of detecting a single anomalous process among M processes. Borrowing terminologies from target search, we refer to these processes as cells and the anomalous process as the target which can locate in any of the M cells. The decision maker is allowed to search for the target The authors are with the Department of Electrical and Computer Engineering, University of California, Davis. Email: {yscohen, qzhao}@ucdavis.edu This work was supported by Army Research Lab under Grant W911NF1120086 and by National Science Foundation under Grants CCF-1320065 and CNS-1321115. Part of this work was presented at the Information Theory and Applications (ITA) Workshop, San Diego, California, USA, Feb. 2014.  2 over K cells at a time (1 ≤K ≤M). The observations from searching a cell are i.i.d. realizations drawn from two different distributions f and g, depending on whether the target is absent or present. The objective is a sequential search strategy that dynamically determines which cells to search at each time and when to terminate the search so that the expected detection time is minimized under a constraint on the probability of declaring a wrong location of the target. The problem under study applies to intrusion detection in cyber-systems when an intrusion to a subnet has been detected and the objective is to locate the abnormal component in the subnet (since the probability of each component being compromised is small, with high probability, there is only one abnormal component). It also ﬁnds applications in target search, fraud detection, and spectrum scanning in cognitive radio networks. A. A Case of Active Hypothesis Testing The above problem is a special case of the sequential experiment design problem ﬁrst studied by Chernoff in 1959 [1]. Compared with the classic sequential hypothesis testing pioneered by Wald [2] where the observation model under each hypothesis is predetermined, the sequential design of experiments has a control aspect that allows the decision maker to choose the experiment to be conducted at each time. Different experiments generate observations from different distributions under each hypothesis. Intuitively, as more observations are gathered, the decision maker becomes more certain about the true hypothesis, which in turn leads to better choices of experiments. Chernoff focused on the case of binary hypotheses and showed that a randomized strategy, referred to as the Chernoff test, is asymptotically optimal as the maximum error probability diminishes. Speciﬁcally, the Chernoff test chooses the current experiment based on a distribution that depends on past actions and observations. Variations and extensions of the problem and the Chernoff test were studied in [3]–[8], where the problem was referred to as controlled sensing for hypothesis testing in [4]–[6] and active hypothesis testing in [7], [8] (see a more detailed discussion in Section I-C). It is not difﬁcult to see that the quickest anomaly detection problem considered in this paper is a special case of the active hypothesis testing problem considered in [1], [3]–[5], [7], [8]. In particular, under',\n",
       " '1807.02371': 'Recent advances prove the feasibility of end-to-end robot control by replacing the classic chain of perception, planning and control with a neural network that directly maps sensor input to control output [11]. For cars, direct perception [5] and end-to-end control [13] were showcased in the TORCS car racing game using Reinforcement Learning (RL). As RL relies on try and error strategies an end-to-end driving prototype still seems too dangerous for real-life learning and there is still a lot of progress to be done as the ﬁrst studies use simulators with simpliﬁed graphics and physics, and the obtained driving results lack realism. We propose a method (ﬁg. 1) beneﬁting from recent asynchronous learning [13] and building on our preliminary work [17] to train an end-to-end agent in World Rally Championship 6 (WRC6), a realistic car racing game with stochastic behavior (animations, light). In addition to remain close to real driving conditions we rely only on image and speed to predict the full longitudinal and lateral control of the car. Together with our learning strategy, the method converges faster than previous ones and exhibits some generalization capacity despite the signiﬁcantly more complex environment that exhibits 29.6km of training tracks with various visual appearances (snow, mountain, coast) and physics (road adherence). Although it is fully trained in a simulation environment the algorithm was tested successfully on real driving videos, and handled scenarios unseen in the training (e.g. oncoming cars). Section II describes the few related works in end-to-end driving. Section III details our methodology and learning strategies. Exhaustive evaluation is discussed in IV and generalization on real videos is shown in V. 1Inria, RITS Team, 2 rue Simone Iff, 75012 Paris surname.last-name@inria.fr 2Valeo Driving Assistance Research, Bobigny first.lastname@valeo.com State encoder Policy Network Rallye Game Front cam (84x84x3) Environment state Reward Image Control command Metadata API (32) Brake Gas Handbrake Steering 30fps (a) Overall pipeline (red = for training only) Snow (SE) 11.61km Mountain (CN) 13.34km Coast (UK) 4.59km Crashes frequencies (b) Training performance (3 tracks, 29.6km) Fig. 1: (a) Overview of our end-to-end driving in the WRC6 rally environment. The state encoder learns the optimal control commands (steering, brake, gas, hand brake), using only 84x84 front view images and speed. The stochastic game environment is complex with realistic physics and graphics. (b) Performance on 29.6km of training tracks exhibiting a wide variety of appearance, physics, and road layout. The agent learned to drive at 73km/h and to take sharp turns and hairpin bends with few crashes (drawn in yellow). II. RELATED WORK Despite early interest for end-to-end driving [18], [3] the trend for self-driving cars is still to use perception-planningcontrol paradigm [21], [22], [16]. The slow development of end-to-end driving can be explained both due to the computational and algorithmic limitations that evolved recently with deep',\n",
       " '1812.03230': 'The abundance and diversity of training data are important for building successful machine learning (ML) models. But, high-quality training data are scarce. Collaborative learning, in which multiple parties contribute their private data to jointly train an ML model, aims to address the shortage of high-quality training resources. However, in many missioncritical and privacy-sensitive domains, such as health care, ﬁnance, and education, training data are tightly controlled by their owners. Sharing raw data is not permitted by law or regulations. To meet the security and privacy requirements, multiple distributed collaborative learning paradigms [1], [2] have been proposed to ensure that sensitive training data never leave the participants’ compute infrastructures. Shokri and Shmatikov [1] proposed a distributed collaborative training system that exploited the parallelism property of stochastic gradient descent (SGD). Training participants can locally and independently build a model with their private datasets, then selectively share subsets of the model’s parameters. In Federated Learning [2], a central server can coordinate an iterative model averaging process. At each training round, a subset of randomly selected training participants compute the 1CALTRAIN stands for Conﬁdential and Accountable Training System differences to the global model with their local private training set and communicate the updates to the central server. The beneﬁts of client-controlled autonomous data protection come at a price. These approaches are vulnerable to data poisoning attacks, which can be instantiated by malicious or compromised training participants. The reason for this inherent vulnerability stems from how security is enforced in most distributed learning mechanisms. There, training data are kept invisible to all participants, except for the data owner. Consequently, malicious data contributors can exploit this nontransparency to feed poisoned/mislabeled training data and implant backdoors into the corresponding models [3]–[8]. Thus, they can inﬂuence and drift the ﬁnal models’ predictions for their own beneﬁts. All of the above highlight an important paradox: data conﬁdentiality is in conﬂict with model accountability in distributed collaborative learning. Especially with amortized and stochastic model updates, links between training data, training participants, and models have been completely dismantled. Once model users encounter erroneous predictions at runtime, they can no longer backtrack the responsible “bad” training data and their provenance. Separately, there is an emerging trend towards leveraging Trusted Execution Environments (TEEs), or isolated enclaves, to secure machine learning training pipelines. For example, Ohrimenko et al. [9] proposed using Intel Software Guard Extensions (SGX) to enable multi-party training for different machine learning methods. More recently, Chiron [10] and Myelin [11] integrated SGX to support private deep learning training services. In general, current TEE-based training approaches encounter two performance limiters: (1) TEEs lack hardware acceleration, and (2) TEEs are memory constrained. As a consequence, it is challenging to execute deep and complex learning models entirely within an isolated execution environment. To address the aforementioned problems, we design and implement CALTRAIN, a TEE-based centralized collaborative learning system, to simultaneously achieve both data conﬁdentiality and model accountability. CALTRAIN uses Intel',\n",
       " '0806.2682': 'Superimposed codes (SCs) and designs were introduced by Kautz and Singleton [1], for the purpose of studying database retrieval and group testing problems. In their original formulation, superimposed designs were deﬁned as arrays of binary codewords with the property that bitwise OR functions of all sufﬁciently small collections of codewords are distinguishable. Superimposed designs can therefore be viewed as binary “parity-check” matrices for which syndromes represent bitwise OR, rather than XOR, functions of selected sets of columns. The notion of binary superimposed codes was further generalized by prescribing a distance constraint on the OR evaluations of subsets of columns, and by extending the ﬁelds in which the codeword symbols lie [2]. In the latter case, Ericson and Györﬁintroduced Euclidean superimposed codes (ESCs), for which the symbol ﬁeld is R, for which the OR function is replaced by real addition, and for which all sums of less than K codewords are required to have pairwise Euclidean distance at least d. The best known upper bound on the size of Euclidean superimposed codes was derived by Füredi and Ruszinko [3], who used a combination of sphere packing arguments and probabilistic concentration formulas to prove their result. On the other hand, compressed sensing (CS) is a new sampling method usually applied to K-sparse signals, i.e. signals embedded in an N-dimensional space that can be represented by only K ≪N signiﬁcant coefﬁcients [4]– [6]. Alternatively, when the signal is projected onto a properly chosen basis of the transform space, its accurate representation relies only on a small number of coefﬁcients. Encoding of a K-sparse discrete-time signal x of dimension N is accomplished by computing a measurement vector y that consists of m ≪N linear projections, i.e. y = Φx. Here, Φ represents an m×N matrix, usually over the ﬁeld of real numbers. Consequently, the measured vector represents a linear combination of columns of the matrix Φ, with weights prescribed by the nonzero entries of the vector x. Although the reconstruction of the signal x ∈RN from the (possibly noisy) projections is an ill-posed problem, the prior knowledge of signal sparsity allows for accurate recovery of x. ∗This work is supported by the NSF Grant CCF 0644427, the NSF Career Award, and the DARPA Young Faculty Award of the second author. Parts of the results were presented at the CCIS’2008 ant ITW’2008 conferences.  2 The connection between error-correcting coding theory and compressed sensing was investigated by Candès and Tao in [7], and remarked upon in [8]. In the former work, the authors studied random codes over the real numbers, the noisy observations of which can be decoded using linear programming techniques. As with the case of compressed sensing, the performance guarantees of this coding scheme are probabilistic, and the K-sparse signal is assumed to lie in RN. We propose to study a new class of codes, termed weighted superimposed codes (WSCs), which provide a link between SCs and CS matrices. As with the',\n",
       " '0904.1812': 'Space-time (ST) coding is a bandwidth-efﬁcient transmission technique that can improve the reliability of data transmission in MIMO wireless systems [1], [2]. Orthogonal space-time block coding (OSTBC) is one of the most attractive ST coding approaches because the special structure of orthogonality guarantees a full diversity and a simple (linear) maximum-likelihood (ML) decoding. The ﬁrst OSTBC design was proposed by Alamouti in [1] for two transmit antennas and was then extended by Tarokh et. al. in [2] for any number of transmit antennas. A class of OSTBC from complex design with the code rate of 1/2 was also given by Tarokh et. al. in [2]. Later, systematic constructions of complex OSTBC of rates (k + 1)/(2k) for M = 2k −1 or M = 2k transmit antennas for any positive integer k were proposed in [3]–[5]. However, the OSTBC has a low code rate not more than 3/4 for more than two transmit antennas [6]. To enhance the transmission rate of the STBC, various STBC design approaches were proposed such as quasi-OSTBC [7]–[9], [11]–[13], [15]–[18] and algebraic number theory based STBC [19]–[27]. The quasi-OSTBC increases the code rate by relaxing the orthogonality condition on the code matrix, which was originally proposed in [7], [8], and [9], independently. Due to the group orthogonality, the ML decoding is performed pair-wise or group-wise with an increased complexity compared to the single-symbol decoding. In [14]–[16], quasi-OSTBC was studied in the sense of minimum decoding complexity, i.e., a real pair-wise symbols decoding. In [16]– [18], the pair-wise decoding was generalized to a general group-wise decoding. The decoding for these codes is the ML decoding and their rates are basically limited by that of OSTBC. The algebraic number theory based STBC are designed mainly based on the ML decoding that may have high complexity and even though some near-ML decoder, such as sphere decoder [28] can be used, the expected decoding complexity is still dominated by polynomial terms of a number of symbols which are jointly detected [29]. To reduce the large decoding complexity of the high rate STBC aforementioned, several fastdecodable STBC were recently proposed [30] [31]. The STBC proposed in [30] achieves a high rate and a reduced decoding complexity at the cost of loss of full diversity. The fast-decodable STBC in [31] can obtain full rate, full diversity and the reduced ML decoding complexity, but the code design is limited to 2 × 2 and 4 × 2 MIMO transmissions only. Another new  2 perspective of reducing the decoding complexity was recently considered in [33] and [34] to resort to conventional linear receivers such as zero-forcing (ZF) receiver or minimum mean square error (MMSE) receiver instead of the ML receiver to collect the full diversity. The outage and diversity of linear receivers in ﬂat-fading MIMO channels were studied in [32], but no explicit code design was given to achieve the',\n",
       " '1806.05241': 'FAILED',\n",
       " '1710.10689': 'Graphs are powerful structures that can be used to model almost any kind of data. Social networks, textual documents, the World Wide Web, chemical compounds, and protein-protein interaction networks, are all examples of data that are commonly represented as graphs. As such, graph classiﬁcation is a very important task, with numerous signiﬁcant real-world applications. However, due to the absence of a uniﬁed, standard vector representation of graphs, graph classiﬁcation cannot be tackled with classical machine learning algorithms. Kernel methods oﬀer a solution to those cases where instances cannot be readily vectorized. The trick is to deﬁne a suitable object-object similarity function (known as a kernel function). Then, the matrix of pairwise similarities can be passed to a kernel-based supervised algorithm such as the Support Vector Machine to perform classiﬁcation. With properly crafted kernels, this two-step approach was shown to give state-of-the-art results on many datasets [12], and has become standard and widely used. One major limitation of the graph kernel + SVM approach, though, is that representation and learning are two independent steps. In other words, the features are precomputed in separation from the training phase, and are not optimized for the downstream task. 3https://github.com/giannisnik/cnn-graph-classification arXiv:1710.10689v2  [cs.LG]  7 Sep 2018  2 G. Nikolentzos et al. Conversely, Convolutional Neural Networks (CNNs) learn their own features from the raw data during training, to maximize performance on the task at hand. CNNs thus provide a very attractive alternative to the aforementioned two-step approach. However, CNNs are designed to work on regular grids, and thus cannot process graphs. We propose to address this challenge by extracting patches from each input graph via community detection, and by embedding these patches with graph kernels. The patch vectors are then convolved with the ﬁlters of a 1D CNN and pooling is applied. Finally, to perform graph classiﬁcation, a fully-connected layer with a softmax completes the architecture. We compare our proposed method with state-of-the-art graph kernels and a recently introduced neural architecture on 10 bioinformatics and social network datasets. Results show that our Kernel CNN model is very competitive, and oﬀers in many cases signiﬁcant accuracy gains. 2 Related Work Graph kernels. A graph kernel is a kernel function deﬁned on pairs of graphs. Graph kernels can be viewed as graph similarity functions, and currently serve as the dominant tool for graph classiﬁcation. Most graph kernels compute the similarity between two networks by comparing their substructures, which can be speciﬁc subgraphs [13], random walks [16], cycles [6], or paths [2], among others. The Weisfeiler-Lehman framework operates on top of existing kernels and improves their performance by using a relabeling procedure based on the WeisfeilerLehman test of isomorphism [12]. Recently, two other frameworks were presented for deriving variants of popular graph kernels [19,18]. Inspired by recent advances in NLP, they oﬀer a way to take into account substructure similarity. Some graph kernels',\n",
       " '1705.10470': 'Machine teaching is the problem of constructing an optimal (usually minimal) dataset according to a target concept such that a student model can learn the target concept based on this dataset. Recently, there is a surge of interests in machine teaching which has found diverse applications in model compression (Bucila et al., 2006; Han et al., 2015; Ba & Caruana, 2014; Romero et al., 2014), transfer learning (Pan & Yang, 2010) and cyber-security problems (Alfeld et al., 2016; 2017; Mei & Zhu, 2015). Furthermore, machine teaching is also closely related to other subjects of interests, such as curriculum learning (Bengio et al., 2009) and knowledge distilation (Hinton et al., 2015). 1Georgia Institute of Technology 2Indiana University. Correspondence to: Weiyang Liu <wyliu@gatech.edu>, Le Song <lsong@cc.gatech.edu>. Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017 by the author(s). Sample query Sample labeled by oracle Oracle Dataset Provide training set Teacher Provide information Construct minimal training set Interact only once Learner Teacher Iterative Learner Provide information Provide samples for this iteration Interact iteratively  Iterative Machine Teaching Active Learning Passive Learning Machine Teaching Figure 1. Comparison between iterative machine teaching and the other learning paradigms. In the traditional machine learning paradigm, a teacher will typically construct a batch set of examples, and provide them to a learning algorithm in one shot; then the learning algorithm will work on this batch dataset trying to learn the target concept. Thus, many research work under this topic try to construct the smallest such dataset, or characterize the size of of such dataset, called the teaching dimension of the student model (Zhu, 2013; 2015). There are also many seminal theory work on analyzing the teaching dimension of different models (Shinohara & Miyano, 1991; Goldman & Kearns, 1995; Doliwa et al., 2014; Liu et al., 2016). However, in many real world applications, the student model is typically updated via an iterative algorithm, and we get the opportunity to observe the performance of the student model as we feed examples to it. For instance, • In model compression where we want to transfer a target “teacher model” to a destination “student model”, we can constantly observe student model’s prediction on current training points. Intuitively, such observations will allow us to get a better estimate where the student model is and pick examples more intelligently to better guide the student model to convergence. • In cyber-security setting where an attack wants to mislead a recommendation system that learns online, the attacker can constantly generate fake clicks and observe the system’s response. Intuitively, such feedback will allow the attacker to ﬁgure out the state of the learning system, and design better strategy to mislead the system. From the aspects of both faster model compression and betarXiv:1705.10470v3  [stat.ML]  17 Nov 2017  Iterative Machine Teaching ter avoiding hacker attack, we seek to understand some fundamental questions',\n",
       " '1512.08103': 'Acquisition of depth information of 3D scenes is essential for many applications in computer vision and graphics. Applications range from 3D modeling to 3DTV and augmented reality. A number of applications require accurate and high-resolution depth maps, for instance, object reconstruction, robot navigation and automotive driver assistance. Recently, modern depth cameras such as Kinect and Timeof-Flight (ToF) (e.g, SwissRanger SR4000) shown impressive results and become increasingly affordable. They can obtain dense depth measurements at a high frame rate. Figure 1. 8× upsampling results. (a) The noisy low resolution depth map patch and the corresponding color image. (b) The ground truth. (c) The upsampling result of the state-of-the-art method of [31]. The upsampling result of our method (d) without adaptive bandwidth selection and (e) with adaptive bandwidth selection. (f) The corresponding bandwidth map of our adaptive bandwidth selection. However, their depth maps usually suffer from missing values, noise and being of low resolution. To facilitate the use of depth data, tremendous efforts have been spent on the restoration of depth maps obtained by modern depth cameras. The depth map can be restored by different example-based methods such as [22, 17, 10, 7], which enhance the quality with a single depth map. This category of methods tend to fail to cope with large upsampling factors and most state-of-the-art methods mainly focus on up to 4× upsampling. Another direction is to restore the depth map from multiple low-quality depth maps such as [26, 8, 25, 11]. This category of methods are more practical for static scenes than for dynamic environments. There are also strong research interests in developing image guided restoration schemes such as [5, 14, 24, 31, 32, 18], which restore the depth map with the guidance of the registered (aligned) color image. These methods are often based on the assumption that there exists a joint occurrence between depth discontinuities and color image edges. They can produce promising restoration quality with larger upsampling factors and are also not subject to static scenes 1 arXiv:1512.08103v1  [cs.CV]  26 Dec 2015  when compared with the ﬁrst two categories of methods. However, their depth maps often suffer from texture copy artifacts and blurring depth discontinuities when the depth discontinuities are inconsistent with the color edges. In this paper, we propose a novel technique for robust image guide depth map restoration. The main contributions of our paper are as follows. 1. To handle heavy noises in depth maps, we develop a robust data term that measures ‘pixel to patch’ difference which is penalized by a robust error norm function within a Gaussian window. The proposed data term is inspired by the work in image denoising [23] and image editing [1]. We show that it is more robust in presence of heavy noises. To our knowledge, we are the ﬁrst to introduce this robust data term in guided depth',\n",
       " 'cs/9906002': 'FAILED',\n",
       " '1803.08071': 'In traditional Computer Vision, many tasks can be solved by ﬁnding the singularor eigen-vector corresponding to the smallest, often zero, singularor eigen-value of the matrix encoding a linear system. Examples include estimating essential matrices or homographies from matched keypoints and computing pose from 3D to 2D correspondences. In the era of Deep Learning, there is growing interest in embedding these methods within a deep architecture to allow end-to-end training. For example, it has recently been shown that such an approach can be used to train networks to detect and match keypoints in image pairs while accounting for the global arXiv:1803.08071v2  [cs.CV]  26 Mar 2018  2 (a) (b) Fig. 1: Eigenvector switching. (a) 3D points lying on a plane in black and distant outlier in red. (b) When the weights assigned to all the points are one, the eigenvector corresponding to the smallest eigenvalue is esub, the vector shown in blue in (a), and on the right in the top portion of (b), where we sort the eigenvectors by decreasing eigenvalue. As the optimization progresses and the weight assigned to the outlier decreases, the eigenvector corresponding to the smallest eigenvalue switches to enoise, the vector shown in green in (a), which introduces a sharp change in the gradient values. consistency of the correspondences [1]. More generally, this approach would allow us to explicitly encode notions of geometry within deep networks, thus sparing the network the need to re-learn what has been known for decades and making it possible to learn from smaller amounts of training data. One way to implement this approach is to design a network whose output deﬁnes a matrix and train it so that the smallest singluaror eigen-vector of the matrices it produces are as close as possible to ground-truth ones. This is the strategy used in [1] to simultaneously establish correspondences and compute the corresponding Essential Matrix: The network’s outputs are weights discriminating inlier correspondences from outliers and are used to assemble an auxiliary matrix whose smallest eigenvector is the sought-for Essential Matrix. The main obstacle to implementing this approach is that it requires being able to diﬀerentiate the singular value decomposition (SVD) or the eigendecomposition (ED) in a stable manner to train the network, a non-trivial problem that has already received considerable attention [2,3,4]. As a result, these decompositions are already part of standard Deep Learning frameworks, such as TensorFlow [5] or PyTorch [6]. However, they ignore two key practical issues. First, when optimizing with respect to the matrix itself or with respect to parameters deﬁning it, the vector corresponding to the smallest singular value or eigenvalue may switch abruptly as the relative magnitudes of these values change, which is essentially non-diﬀerentiable. This is illustrated in the example of Fig. 1, discussed in detail in Section 2. Second, computing the gradient requires dividing by the diﬀerence between two singular values or eigenvalues, which could',\n",
       " '1901.03674': 'Imitation learning is a paradigm that learns from expert demonstration to perform a task. The most straightforward approach of imitation learning is behavioral cloning (Pomerleau, 1991), which learns from expert trajectories to predict the expert action at any state. Despite its simplicity, behavioral cloning ignores the accumulation of prediction error over time. Consequently, although the learned policy closely resembles the expert policy at a given point in time, their trajectories may diverge in the long term. To remedy the issue of error accumulation, inverse reinforcement learning (Russell, 1998; Ng and Russell, 2000; Abbeel and Ng, 2004; Ratliﬀet al., 2006; Ziebart et al., 2008; Ho and Ermon, 2016) jointly learns a reward function and the corresponding optimal policy, such that the expected cumulative ∗Northwestern University †University of Minnesota Twin Cities ‡Georgia Institute of Technology 1  reward of the learned policy closely resembles that of the expert policy. In particular, as a unifying framework of inverse reinforcement learning, generative adversarial imitation learning (GAIL) (Ho and Ermon, 2016) casts most existing approaches as iterative methods that alternate between (i) minimizing the discrepancy in expected cumulative reward between the expert policy and the policy of interest and (ii) maximizing such a discrepancy over the reward function of interest. Such a minimax optimization formulation of inverse reinforcement learning mirrors the training of generative adversarial networks (GAN), which alternates between updating the generator and discriminator, respectively. Despite its prevalence, inverse reinforcement learning, especially GAIL, is notoriously unstable in practice. More speciﬁcally, most inverse reinforcement learning approaches involve (partially) solving a reinforcement learning problem in an inner loop, which is often unstable, especially when the intermediate reward function obtained from the outer loop is ill-behaved. This is particularly the case for GAIL, which, for the sake of computational eﬃciency, alternates between policy optimization and reward function optimization without fully solving each of them. Moreover, such instability is exacerbated when the policy and reward function are both parameterized by deep neural networks. In this regard, the training of GAIL is generally more unstable than that of GAN, since policy optimization in deep reinforcement learning is often more challenging than training a standalone deep neural network. In this paper, we take a ﬁrst step towards theoretically understanding and algorithmically taming the instability in imitation learning. In particular, under a minimax optimization framework, we for the ﬁrst time establish the global convergence of GAIL under a fundamental setting known as linear quadratic regulators (LQR). Such a setting of LQR is studied in a line of recent works (Bradtke, 1993; Fazel et al., 2018; Tu and Recht, 2017, 2018; Dean et al., 2018a,b; Simchowitz et al., 2018; Dean et al., 2017; Hardt et al., 2018) as a lens for theoretically understanding more general settings in reinforcement learning. See Recht (2018) for a thorough review. In imitation learning, particularly GAIL, the setting of LQR captures four critical challenges of more general settings: (i) the minimax optimization formulation, (ii) the lack of convex-concave geometry, (iii) the alternating update',\n",
       " '1705.06400': 'An intriguing way to instruct a robot is to ﬁrst demonstrate the task at hand. In such a setup, a human teacher performs the necessary steps while the robot observes the human’s motion. This way of robot programming is commonly referred to as programming by demonstration [38, 12, 6] and has been extensively studied. However, observing only the motion of a human teacher is often not suﬃcient as the demonstrator will often include additional or corrective instructions to the student using natural language. In other words, the teacherstudent interaction is inherently multi-modal. Natural language presents itself as an intuitive way of communicating with the robot since it can be used to describe even rather complex motions and their parameterizations. For example, the description “A person waves with the left hand ﬁve times.” encodes the motion (waving), the body part that should perform it (left hand) and the number of repetitions (ﬁve times). Enabling a robot to combine such rich descriptions in natural language with human wholebody motion therefore facilitate a much richer human-robot communication. In recent years, deep learning [39, 21] has proven to be very successful in computer vision [36, 27], natural language processing [57, 20, 72] and speech recognition [23]. More recently, researchers have also reported promising results when applying deep learning techniques to problems in robotics [41, 25, 40]. In this paper, we use deep learning techniques to link human whole-body ∗Corresponding author Email addresses: matthias.plappert@partner.kit.edu (Matthias Plappert), mandery@kit.edu (Christian Mandery), asfour@kit.edu (Tamim Asfour) 2  motion and natural language. More speciﬁcally, we make use of sequence-tosequence learning [57] to learn a bidirectional mapping between human wholebody motion and natural language. Human whole-body motion is represented in joint space under the Mater Motor Map (MMM) [68] framework and descriptions thereof are in the form of complete English sentences. Figure 1 illustrates the desired mapping. On one hand, this mapping allows us to generate rich descriptions of observed human motion, which can, for example, be used in a motion database. On the other hand, our model is capable of generating a wide range of diﬀerent motions only from a description thereof in natural language. Even more so, the proposed system is capable of successfully synthesizing certain variations of motion, e.g. waving with the left or the right hand as well as walking quickly or slowly simply by specifying this parametrization in the natural language description. The remainder of this paper is organized as follows. In Section 2 we review work that is related to our approach of combining human motion and natural language. Section 3 describes in detail how we represent both modalities, human motion and natural language, for use in the proposed bidirectional mapping. The model that is used to learn this mapping is presented in Section 4. In Section 5 we show that the proposed approach is capable of learning the desired bidirectional mapping. We also',\n",
       " '0711.4175': '1.1 Main results Informally, one of the key problems in proving lower bounds on circuits is to identify and prove that certain Circuit topologies (e.g. small circuits) provide information bottlenecks for information ﬂows. We introduce the notion of (private/public) graph entropy and show that this notion in a very precise way captures such information bottlenecks in the context of communication networks. More speciﬁcally we show that a given communication network N with k source and k corresponding target nodes provide an information bottleneck (i.e. is unsolvable) if and only if the entropy (or public entropy) of GN is strictly less than k. In the seminal works [28, 29] and [8] it was shown that Shannon’s information inequalities (commonly known as Shannon’s laws of information theory) are in general insuﬃcient to identify speciﬁc information bottlenecks in communication ﬂow problems. Relying on this result we will show that a similar type of result is valid in the context of graphs entropy. By combining Theorem 1, Theorem 9 as well as Theorem 10, and modifying the acyclic multiple unicast version of the Vamos graph introduced in [8] (by passing to the corresponding line graph and by identifying each source node with each corresponding target node) we show that the resulting graph has an entropy that cannot be calculated using Shannon’s Classical information inequalities and that better bounds can be achieved by use of Zhang and Young’s non-shannon-information inequalities. 1 In the paper we introduce a number of new (directed) graph parameters2. These include the (private/public) entropy, the Shannon (private/public) entropy, the Zhang-Young (public/ private) entropy as well as the DoghteryFreiling-Zeger (private/public) entropy. The Concepts are in general diﬀerent from (but linked to) graph parameters that have already been extensively studied in the literature. In general we drop the preﬁx ”private” (when no confusion is possible) and refer to the (private) graph parameters as Entropy, S-entropy, ZY-entropy and DFZ-entropy. 1later and joint with Sun Yun, we found - partly by extensive computer searches - somewhat smaller and simpler examples 2throughout the paper graphs are always assumed to be directed 2  1.2 Experimental results for small graphs Using computer calculations we tested millions of (small) graphs and found that quite diﬀerent notions (diﬀerent variants of guessing numbers and Graph Entropy) led to identical numbers on the vast majority of graphs3. Key concepts (most of which we will introduce in this paper), like the Graph Entropy, the guessing number, the S-entropy and the ZY-entropy - gave identical results for the vast majority of graphs we tested. One interesting aspect is that although the diﬀerent calculations usually lead to the same numbers for the graphs we tested by computer (using weeks of computer time), there appears to be a very sparse set of (small) graphs where the calculations leads to slightly diﬀerent results. It should, however, be noticed that small graphs are atypical and it would be',\n",
       " '1802.00917': 'The paradigm shift from traditional macro cellular network to small cell networks is unrelenting, whereas more and more user equipments (UEs), including smartphones, tablets, and smartwatches, will be connected to the small access points (SAPs) [1]. Since the wireless spectrum is usually limited, there is inevitable contention among UEs for communication resource. At this stage, operators need to choose an appropriate trafﬁc scheduling protocol to allocate resource among different UEs so as to meet the delay requirement [1]. Among the large number of proposed scheduling schemes [2], random scheduling (RS) and round robin (RR) are the most popular practical choices due to their low-implementation cost [3]. Even though, a full understanding on the respective delay performance of RS and RR is still essential to help devise insights and perform suitable design. While the delay performance of both schemes has been well understood in wired data networks [3], it remains in darkness from the perspective of wireless small cell networks because: i) the irregular deployment of SAPs leads to asymmetric UE performance, e.g., some UEs may succeed in capturing a large portion of resources than others because of their relative position in the network, and thus enjoy preferential treatment; ii) the shared nature of Manuscript received Feb. 03, 2018, revised Mar. 31, and May 28, 2018, and accepted May 29, 2018. The associate editor coordinating the review of this letter and approving it for publication was Dr. Chun Tung Chou. This work was supported in part by the MOE ARF Tier 2 under Grant MOE2015-T2-2-104 and in part by the SUTD-ZJU Research Collaboration under Grant SUTD-ZJU/RES/01/2016. H. H. Yang and T. Q. S. Quek are with the Singapore University of Technology and Design (e-mail: howard yang@sutd.edu.sg, tonyquek@sutd.edu.sg). Y. Wang is with Nanjing University of Post and Telecommunications (e-mail: wangy1585@163.com). wireless channel results in the queuing evolution of any typical cell strongly interacted with its neighbors, which piles on analytical complications. Most of the previous works only focus on one aspect of the issue [3]–[6], i.e., they model only the temporal arrival of packets [3] or the spatial lotations [4]–[6], and thus fail to track the other. Recently, several attempts have been made to analyze delay in large-scale networks by modeling the spatial-temporal randomness [7]–[10]. However, the results in [7] only give upper and lower bounds, that can be loose in light trafﬁc condition, for the delay distribution, hence may fail to explicitly capture the interplay between spatial topology and temporal queuing evolution. While [8] attains a precise expression for the distribution of mean delay, the result holds for single UE per cell scenario, which do not allow one to investigate the effect of different scheduling policies. The model in [9], [10] consider uplink random access for multi-UE per cell and accounts for the intra-cell and inter-cell interference due to the',\n",
       " '1808.09907': 'With the vast amount of data and powerful hardware resources, deep learning algorithms have obtained high performance across many applications, such as computer vision [1], natural language processing [2]. DNN is one of the most popular showcases of deep learning algorithms. It contains multiple no-linear hidden layers, which can learn very complicated relationships in the data. However, by building such a complex model, it is more prone to perfectly ﬁt the training data while with less generalization for the real test data. This is called overﬁtting which is a major problem for Neural Networks. Many regularization methods have proposed to reduce overﬁtting including soft weight-sharing [3], early stopping technique, L1 and L2 regularization. The standard Dropout [4, 5] is a widely used regularization technique that speciﬁc to DNN. During every iteration of training stage, this technique randomly shutdowns parts of neurons (hidden and visible) in a neural network with probability p using samples from a Bernoulli distribution. So each iteration has a different “thinned” network. The resulting network is interpreted as a combination of these multiple “thinned” networks, which usually leads to a better generalization for unseen test data. Dropout can be regarded as an ensemble method. As mentioned by [4], the combination of multiple models is most helpful when the architectures of individual models are different from each other. Inspired by the Tabu Strategy successfully used in local search algorithms, in this work, we design a Tabu strategy to guide the Dropout to generate more different neural network architectures within a certain number of iterations. We call this new technique Tabu Dropout. From the second forward propagation of the training stage, a (0,1)-matrix is used to mark the dropped status of units in last forward propagation, which is called the Tabu list. More speciﬁcally, if 0 that unit is dropped, while if 1 the unit is kept. Then the units will not be allowed to drop if they have been marked as 0 in the Tabu list. The Tabu ∗Corresponding author: zongjie.ma@grifﬁthuni.edu.au (Preprint and Work in progress.) arXiv:1808.09907v1  [cs.LG]  29 Aug 2018  A PREPRINT - AUGUST 30, 2018 List is updated after each forward propagation and only stores the status of units from the last forward propagation. The reason for using this short-memory is to make a balance between the time-complexity and the diversiﬁcation of neural networks. Tabu Dropout is computationally cheap and only has one parameter, the dropout rate p, as the standard dropout. We carry out experiments to compare Tabu Dropout with the standard Dropout and AlphaDropout [6] on the MNIST and Fashion-MNIST datasets. The experimental results show that Tabu Dropout outperforms the other two dropout techniques on these datasets. Especially, Tabu Dropout can achieve better performance in the early iterations, which will be useful for large and hard datasets. 2 Preliminaries 2.1 Deﬁnitions and Notations Given a deep neural network M with L',\n",
       " '1804.11239': 'Deep learning has increasingly drawn attentions in many research fields, such as speech recognition [13], computer vision [12, 18], selfdriving cars [14, 36], and unmanned aircraft systems [29]. Largescale deep neural networks (DNNs) typically consist of multiple layers, and at least millions of weight parameters for the entire model [18]. One major advantage of the larger-scale DNNs is that they extract more complex high-level features from the inputs (e.g., images/videos, speeches), and as a result, achieving a significant improvement in model accuracy [36]. On the other hand, as the size of DNNs grows continuously, there exist tremendous demands in increasing computational capability and memory requirement. Therefore, improving the performance and energy efficiency while maintaining the accuracy of DNNs becomes extremely critical. Two trends have characterized the research advance in order to achieve higher performance and energy efficiency. The first trend is hardware acceleration. FPGA-based accelerators have the advantage of friendly programmability and high-degree parallelism. Stochastic Computing (SC), in which all the inputs and weight values are represented as streams of random bits, has been investigated and successfully applied to hardware acceleration of DNNs [22–26, 28, 33, 34, 41]. Data-path optimization technique [8] have also been studied to map a limited number of Processing elements (PEs) on FPGA and reuse the mapped PEs by iterating data through them. On the other hand, ASIC-based implementations have been explored to further accelerate DNNs. A substantial number of high-tech companies have declared their ASIC chip designs in DNNs such as Google [15] and IBM TrueNorth [6]. In the field of academia, Eyeriss [2], EIE [10], and DaDianNao [1] mainly focus on the convolutional layers, the fully-connected layers, and the memory design/organization at the architectural level, respectively. The second trend is model compression motivated by energy efficiency limitation of large DNN models. Weight pruning [11] and lower rank approximation [37] have aimed to the reduce the number of operations involved in DNNs. They achieve a parameter reduction to some extent with inconsequential accuracy degradation. However, they have brought the new challenges into DNNs such as irregular network structure caused by sparsity regularization [40], and increased training complexity caused by the additional pruning process [11] or low rank approximation step [37]. In this work, to address the limitations of existing works in model size compression and acceleration and to achieve ultra-high energy efficiency and performance for FPGA and ASIC-based hardware implementations, we propose the structured weight matrices (SWM)-based compression technique on both FPGA and ASIC implementations. The SWM-based framework adopts the general block-circulant matrices to achieve a fine-grained tradeoff between accuracy and compression ratio. For FPGA implementations on DCNNs, we achieve at least 152X and 72X improvement in performance and energy efficiency, respectively using SWM-based arXiv:1804.11239v1  [cs.DC]  28 Mar 2018  framework, compared with the baseline of IBM TrueNorth processor under same accuracy',\n",
       " '1807.07803': 'Fully convolutional neural networks (F-CNNs) are being increasingly adopted for pixel/voxel-wise semantic segmentation of images in an end-to-end fashion. F-CNNs are typically constructed with a dumb-bell like architecture comprising of the encoder and decoder blocks in sequence [1]. One of the main architectural advances has been the introduction of connectivity amongst and within these blocks, which has in turn improved parameter optimization and gradient ﬂow. Computational graph elements associated with such a connectivity can be broadly categorized into long-range and short-range connections. Long-range connections were ﬁrst introduced by Ronnerberger et al. [2] as skip connections between the encoder and decoder blocks and were demonstrated to improve information recovery and gradient ﬂow. Short-range connections between convolutional layers were introduced in the seminal work on residual networks by He et al. [3]. This idea was taken further within the work of densely-connected neural networks [4], wherein multiple convolutional layers were stacked in sequence along with connections that iteratively concatenate the feature maps arXiv:1807.07803v1  [cs.CV]  20 Jul 2018  2 with outputs of the previous layers. Introducing these short-range dense connections alleviate vanishing gradients, encourage feature reusability and strengthen information propagation across the network [4]. 0.9 0.8 0.6 0.5 maxout concat 0.9 0.2 0.4 0.9 0.8 0.5 0.8 0.5 0.9 0.9 0.2 0.4 0.9 0.8 0.5 0.2 0.4 Fig. 1: Maxout activation: The maxout operation computes the maximum at each spatial location across feature maps. This is a more selective fusion operation than concatenation and results in a lower dimensional feature space. One commonality between design of the computational graph within the aforementioned architectures is the use of concatenation layers to aggregate information through these connections. Such a design increases the size of the output feature map along the feature channels, which in turn results in the need to learn ﬁlters with a higher number of parameters. Goodfellow et al. introduced the idea of competitive learning through maxout activations [5], which was adapted by Liao and Carneiro [6] for competitive pooling of multi-scale ﬁlter outputs. Both [6] and [5] proved that the use of a maxout competitive unit boosts performance by creating a large number of dedicated sub-networks within a network that learns to target speciﬁc sub-tasks within the training task and reduces the number of parameters required. In this paper, we explore how such competitive units fare within a FCNN architecture targeted at biomedical image segmentation. We propose the Competitive Dense Fully Convolutional Network (CDFNet) by using competitive layers instead of concatenation by suitably adopting the DenseNet architecture proposed by Roy et al. in [7]. Particularly, we demonstrate that competitive units promote the formation of dedicated local sub-networks in each of the densely connected blocks',\n",
       " '1005.2770': 'Parallel channels are used to serve as a model for a time-varying communication channel. In this model, each one of the parallel channels corresponds to a possible state of the time-varying channel, and the communication takes place over one of these parallel channels according to the instantaneous state of the time-varying channel. The model of arbitrarily-permuted parallel channels was introduced in [1] where each message is encoded into a number (say S) of code-sequences with a common block length, each one of the S code-sequences is transmitted over a different parallel channel where the assignment of codewords to channels is known to the receiver, and it is modeled by an arbitrary permutation π of the set {1, . . . , S} where code-sequence no. s ∈{1, . . . , S} is transmitted over the parallel channel no. r = π(s). Finally, the receiver estimates the transmitted message based on the knowledge of this permutation and the received outputs from the S parallel channels. This model of parallel channels can be viewed as a special case of the classical compound channel setting [2]. Channel coding over arbitrarily-permuted parallel channels was studied in [1] and more recently in [3], where it was assumed that all these parallel channels have an identical input alphabet. In the case where all the parallel channels have the same capacity-achieving input distribution, it was proved in [1, Theorem 1] that the capacity of the system is equal to the sum of the capacities of the parallel channels. Furthermore, [1] also addresses the case where the parallel channels have different capacity-achieving input distributions, and it determines the capacity of the system also in this case (see [1, Theorem 2]). This research was supported by the Israel Science Foundation (grant no. 1070/07), and by the European Commission in the framework of the FP7 Network of Excellence in Wireless Communications (NEWCOM++).  2 SUBMITTED TO THE IEEE TRANSACTIONS ON INFORMATION THEORY IN AUGUST 2, 2010. LAST UPDATED: AUGUST 15, 2012. Arbitrarily-permuted parallel channels may be of interest when analyzing, e.g., networking applications, OFDM and BICM systems. For example, the channel frequency bands or the bits may not be allocated at the transmitter level, and though this allocation is ﬁxed, it takes the form of a random permutation that is selected once per transmission. In the setting of transmission of data through packets, these packets can be viewed as being transmitted over a set of parallel channels where each packet goes through one of the available parallel channels depending on the higher level of the communication protocol. The transmission in this case is done in an interleaved manner where consecutive bits are separated to different packets, the number of which is the cardinality S of the set of parallel channels. This, again, provides the model of arbitrarily-permuted parallel channels, though we do not deal in this work with data ﬂow issues (assuming that the system is at equilibrium as far as the data/ packet',\n",
       " '1308.3558': 'The alternating direction method of multipliers (ADMM) [1], [2], [3] considers problems of the form min x,y Φ(x, y) ≡φ(x) + ψ(y) : Ax + By = c, (1) where φ, ψ are convex functions, and A, B (resp. c) are constant matrices (resp. vector) of appropriate sizes. Because of the ﬂexibility in splitting the objective into φ(x) and ψ(y), it has been a popular optimization tool in many machine learning, computer vision and data mining applications. For example, on large-scale distributed convex optimization, each φ or ψ can correspond to an optimization subproblem on the local data, and the constraint Ax + By = c is used to ensure all the local variables reach a global consensus; for regularized risk minimization which will be the focus of this paper, φ can be used for the empirical loss, ψ for the regularizer, and the constraint for encoding the sparsity pattern of the model parameter. In comparison with other state-of-theart optimization methods such as proximal gradient methods [4], [5], the use of ADMM has been shown to have faster convergence in several difﬁcult structured sparse regularization problems [6]. Existing works on ADMM often assume that Φ(x, y) is deterministic. In the context of regularized risk minimization, this corresponds to batch learning and each iteration needs to visit all the samples. With the proliferation of data-intensive applications, it can quickly become computationally expensive. For example, in using ADMM on the overlapping grouplasso, the matrix computations become costly when both the Leon Wenliang Zhong and James T. Kwok are with the Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong. number of features and data set size are large [7]. To alleviate this problem, the use of stochastic and online techniques have recently drawn a lot of interest. Wang and Banerjee [8] ﬁrst proposed the online ADMM, which learns from only one sample (or a small mini-batch) at a time. However, in general, each round involves nonlinear optimization and is not computationally appealing. Very recently, three stochastic variants of ADMM are independently proposed [9], [6]. Two are based on the stochastic gradient descent (SGD) [10], while one is based on regularized dual averaging (RDA) [5]. In both cases, the difﬁcult nonlinear optimization problem inherent in the online ADMM is circumvented by linearization, which then allows the resultant iterations in these stochastic variants to be efﬁciently performed. However, despite their low per-iteration complexities, these stochastic ADMM algorithms converge at a suboptimal rate compared to their batch counterpart. Speciﬁcally, the algorithms in [9], [6] all achieve a rate of O(1/ √ T), where T is the number of iterations, for general convex problems and O(log T/T) for strongly convex problems; whereas batch ADMM achieves convergence rates of O(1/T) and O(µT ) (where 0 < µ < 1), respectively [11], [12]. This gap in the convergence rates between stochastic and batch ADMM algorithms is indeed not surprising',\n",
       " '1511.08887': 'Various wireless relaying techniques have been extensively studied for decades due to their capability to extend the coverage and enhance the capacity of wireless networks [1]–[4]. In This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible. T. Ding and S.C. Liew are with the Department of Information Engineering, the Chinese University of Hong Kong. X. Yuan is with the School of Information Science and Technology, ShanghaiTech University, Shanghai. arXiv:1511.08887v2  [cs.IT]  25 Feb 2017  2 particular, two-way relaying based on physical-layer network coding (PNC) has attracted much research interest in the past decade [4]–[8]. In the two-way relay channel, two users exchange information via a single relay node. Compared with conventional one-way relaying, PNC potentially doubles the spectral efﬁciency by allowing a relay node to decode and forward message combinations rather than individual messages. Later, the idea of PNC was extended to support efﬁcient communications over multiway relay channels (mRC) [9], where multiple users exchange data with the help of a single relay. Efﬁcient PNC design has been studied for various data exchange models, including pairwise data exchange [10], [11], full data exchange [10], [12], and clustered pairwise/full data exchange [10], [13]–[15]. Multiple-input multiple-output (MIMO) techniques have also been incorporated into PNC-aided relay networks to achieve spatial multiplexing [16]. The capacity of the MIMO mRC generally remains a challenging open problem [17], [18]. Existing work [19]–[26] was mostly focused on analyzing the degrees of freedom (DoF) that characterizes the capacity slope at high signal-to-noise ratio (SNR). Various signaling techniques have been developed to intelligently manipulate signals and interference based on the ideas of PNC and interference alignment [27]. Particularly, the authors in [22]–[24] studied the DoF of the MIMO Y channel, where three users exchange data in a pairwise manner with the help of a single relay. To derive the DoF of this model, a key difﬁculty is how to jointly optimize the linear processors, including the precoders at the user transmitters, the precoder at the relay, and the post-processers at user receivers. This problem was elegantly solved in [23] by optimal design of the signal space seen at the relay, where the user precoders and post-processors are constructed by pairwise signal alignment and uplink-downlink symmetry, and the relay precoder by appropriate orthogonal projections. Similar ideas have also been used to derive the DoF of other multiway relay models [13], [17]. In the work on MIMO mRC mentioned above, a major limitation is that a single relay node is employed to serve multiple user nodes simultaneously. This implies that the relay node is usually the performance bottleneck of the overall network [13], [15]. As such, some recent work began to explore the potential of deploying more relay nodes for enhancing the network capacity. For instan',\n",
       " '1503.05667': 'Semantic similarity measure serves as the foundation of knowledge discovery and management processes such as ontology matching, ontology alignment & mapping, ontology merging, etc [Shvaiko and Euzenat, 2013]. Ontological concept similarity can be based on diﬀerent approaches: (i) string matching of concept labels (i.e. lexical similarity) [Stoilos et al., 2005], (ii) external lexical resource/ontology based matching (i.e. lexico-semantic similarity) [Rada et al., 1989a], (iii) graph-based matching using lexicons such as WordNet [Stuckenschmidt, 2007] (i.e. structural similarity), (iv) property analysis (as in FCA-based similarity [Cimiano et al., 2005]) or instance analysis (as in Jaccard similarity [Jaccard, 1998]) based matching over a large sample of concept instance occurrences (i.e. instance-driven similarity), (v) matching based on statistical analysis of attribute-value or distribution analysis within ﬁxed context-windows of concepts over large corpora (i.e. statistical similarity) [Li and Clifton, 1994], and (vi) model-theoretic matching of formal concept descriptions (i.e. formal semantic similarity) [Alsubait et al., 2014]. It can be argued that, in comparison to other approaches, formal semantic similarity measure modeling has not received equal research attention. Nevertheless, existing literature is signiﬁcant, and can be broadly classiﬁed into two approaches: (i) Propositional Logics based [Nienhuys-Cheng, 1998; Ramon and Bruynooghe, 1998], and (ii) Description Logics (DL) based [Alsubait et al., 2014; Lehmann and Turhan, 2012; Stuckenschmidt, 2007; Fanizzi and dAmato, 2006; Borgida et al., 2005]. The former requires: (a) representation of ontologies (mostly in RDFS/OWL format) in First Order Predicate Logic, (b) a set of axioms (or domain knowledge, mostly as upper ontologies/thesaurus), and (c) a SAT solver that checks satisﬁability (and hence, satisﬁability) of disjointness of concept pairs. The latter approach, on the other hand, does not necessarily require any formal language transformation or satisﬁability checker. In this paper we propose an algebraic similarity measure, called BitSim (σBS), that can compute semantic similarity of pair of concepts deﬁned in ALCH+1. The motivation behind σBS is to formulate a formal semantic similarity measure that provides: (i) a platform for fast, scalable, and accurate semantic similarity computation of DL concepts, and (ii) a sound and complete correspondence with conventional semantic interpretation of DL. σBS is algebraic, in the sense that it maps a given pair of concept codes (called bit-code), instead of concept DL deﬁnitions/axioms, to a positive real space. For this we deﬁne a novel algebraic interpretation function, called IB, that maps an ALCH+ deﬁnition to a unique string, called bit-code, (ωB) belonging to the language LB deﬁned over a novel algebraic alphabet P B. We prove that IB has complete correspondence with IALCH+. We also show that σBS is highly adaptive to any kind of similarity measure that relies on set operation. As an example, we have shown how σBS can be plugged into Jaccard similarity index. The contribution of the paper is as follows: • IB : A',\n",
       " '1511.04777': 'Recently, there is a surge of research studying nonconvex formulations and provable algorithms for a number of central problems in signal processing and machine learning, including, e.g., low-rank matrix completion/recovery [4]– [25], phase retreival [26]–[36], tensor recovery [37]–[41], mixed regression [42], [43], structured element pursuit [41], [44], blind deconvolution [45]–[49], noisy phase synchronization and community detection [50]–[52], deep learning [53], [54], numerical linear algebra and optimization [55], [56]. The research efforts are fruitful in producing more practical and scalable algorithms and even signiﬁcantly better performance guarantees than known convex methods. In a companion paper [3], we set out to understand the surprising effectiveness of nonconvex heuristics on the dictionary learning (DL) problem. In particular, we have focused on the complete dictionary recovery (DR) setting: given Y = A0X0, with A0 ∈Rn×n complete (i.e., square and invertible), and X0 ∈Rn×p obeying an i.i.d. Bernoulli-Gaussian (BG) model with rate θ (i.e., [X0]ij = ΩijZij with Ωij ∼Ber(θ) and Zij ∼N(0, 1)), recover A0 and X0. In this setting, row(Y ) = row(X0), where row(·) denotes the row space. To ﬁrst recover rows of X0, we have tried to ﬁnd the sparsest vectors in row(Y ), and proposed solving the nonconvex formulation minimize f(q; bY ) .= 1 p p X k=1 hµ(q∗byk) subject to q ∈Sn−1, (I.1) where bY is a proxy of Y (i.e., after appropriate processing), byk is the k-th column of bY , and hµ(z) .= µ log cosh(z/µ) is a (convex) smooth approximation to the absolute-value function. The spherical constraint renders the problem nonconvex. JS, QQ, and JW are all with Electrical Engineering, Columbia University, New York, NY 10027, USA. Email: {js4038, qq2105, jw2966}@columbia.edu. An extended abstract of the current work has been published in [1]. Proofs of some secondary results are contained in the combined technical report [2]. Manuscript received xxx; revised xxx. arXiv:1511.04777v3  [cs.IT]  1 Sep 2016  IEEE TRANSACTION ON INFORMATION THEORY, VOL. XX, NO. XX, XXXX 2016 2 Despite the apparent nonconvexity, our prior analysis in [3] has showed that all local minimizers of (I.1) are qualitatively equally good, because each of them produces a close approximation to certain row of X0 (Corollary II.4 in [3]). So the central issue is how to escape from saddle points. Fortunately, our previous results (Theorem II.3 in [3]) imply that all saddle points under consideration are ridable, i.e., the associated Hessians have both strictly positive and strictly negative values (see the recapitulation in Section II-B). Particularly, eigenvectors of the negative eigenvalues are direction of negative curvature, which intuitively serve as directions of local descent. Second-order methods can naturally exploit the curvature information to escape from ridable saddle points. To gain some intuition, consider an unconstrained optimization problem minimizex∈Rn φ(x). The second-order Taylor expansion of φ at a saddle point x0 is bφ(δ; x0) = φ(x0) + 1',\n",
       " '1707.01450': 'A negotiation is deﬁned as a bargaining process between two or more parties (each with its own aims, needs, and viewpoints) seeking to discover a common ground and reach an agreement to settle a matter of mutual concern or resolve a conﬂict. From a dialogue point of view, one distinguishes negotiation dialogue from standard dialogue by the mutual sharing of information1, by its required user adaptation2, and by the non-stationarity induced by its non fully cooperative structure: the user and system objectives correlate but also differ to some extent, and they are consequently adversely co-adapting. Research on negotiation dialogue experiences a growth of interest. At ﬁrst, Reinforcement Learning (Sutton and Barto, 1998), the most popular framework for dialogue management in dialogue systems (Levin and Pieraccini, 1997; Laroche et al., 2009; Lemon and Pietquin, 2012), was applied to negotiation with mitigated results (English and Heeman, 2005; Georgila and Traum, 2011; Lewis et al., 2017), because the non-stationary policy of the opposing player prevents those algorithms from converging consistently. Then, Multi-Agent Reinforcement Learning (Bowling and Veloso, 2002) was applied but also with convergence 1whereas standard dialogue mainly relies on discovering the user information or intent, 2whereas standard dialogue, such as form ﬁlling applications, is rather indifferent to the user’s characteristics, difﬁculties (Georgila et al., 2014). Finally, recently, Stochastic Games (Shapley, 1953) were applied successfully (Barlier et al., 2015), with convergence guarantees, but only for zero-sum games, which is inconsistent with dialogue since most tasks are cooperative. Here, we extend (Laroche and Genevay, 2017)’s abstraction of the negotiation dialogue literature applications: (di Eugenio et al., 2000; English and Heeman, 2005) consider sets of furniture, (Afantenos et al., 2012; Efstathiou and Lemon, 2014; Georgila et al., 2014; Litman et al., 2016; Lewis et al., 2017) resource trading, and (Putois et al., 2010; Laroche et al., 2011; El Asri et al., 2014; Genevay and Laroche, 2016; Laroche and F´eraud, 2017) appointment scheduling. Indeed, these negotiation dialogue problems are cast into a generic agreement problem over a shared set of options. The goal for the players is to reach an agreement and select an option. This negotiation dialogue game can be parametrised to make it zero-sum, purely cooperative, or general sum. However, (Laroche and Genevay, 2017) only consider elementary options: they are described through a single entity. We formalise in this paper the game for options that are compounded in the sense that they are characterised by several features. For instance, Tuesday morning is deﬁned by two features: the day and the moment of the day. Considering compounded options naturally leads to richer expressions, and therefore to a larger set of actions: I’m available whenever on Tuesday, or I’d prefer in the afternoon. Since the options are uttered in a compounded way, as opposed to their elementary deﬁnition in (Laroche and Genevay, 2017), the state representation also becomes more complex. This extension',\n",
       " '1901.10674': 'Distributed computation clusters are routinely used in domains such as machine learning and scientiﬁc computing. In these applications, datasets are often so large that they cannot be housed in the disk of a single server. Furthermore, processing the data on a single server is either infeasible or unacceptably slow. Thus, the data and the processing is distributed and processed across a large number of nodes. While large clusters have numerous advantages, they also present newer operational challenges. These clusters (which can be heterogeneous in nature) suffer from the problem of “stragglers” which are deﬁned as slow nodes (node failures are an extreme form of a straggler). It is evident that the overall speed of a computation on these clusters is typically dominated by stragglers in the absence of a sophisticated assignment of tasks to the worker nodes. In recent years, approaches based on coding theory (referred to as “coded computation”) have been effectively used for straggler mitigation [1]–[9]. Coded computation offers signiﬁcant beneﬁts for speciﬁc classes of problems, e.g., matrix computations. We illustrate this by means of a matrix-vector multiplication example in Fig. 1, where a matrix A is blockrow decomposed as AT = [AT 0 AT 1 AT 2 ]T . Each worker node is given the responsibility of computing two submatrix-vector products so that the computational load on each worker is 2/3-rd of the original. It can be observed that even if one worker fails, there is enough information for a master node This work was supported in part by the National Science Foundation (NSF) under grant CCF-1718470. to compute the ﬁnal result. However, this requires the master node to solve simple systems of equations. This approach can be generalized (and also adapted for matrix multiplication) by using Reed-Solomon (RS) code like approaches [1]–[5]. These methods allow the master node to recover Ax if any τ of the worker nodes complete their computation; τ is called the recovery threshold. A signiﬁcant amount of prior work treats stragglers as node failures (see [6], [8], [9] for exceptions), or, equivalently from the point of view of coding theory, as erasures. This matches the conventional erasure coding problem very well and allows the adaptation of well-known approaches, e.g, RS codes to the problem of distributed matrix computations. However, there are certain features of the distributed matrixvector multiplication problem that distinguish it from classical erasure correction that we now discuss. • Leveraging partial computation performed by stragglers. Each worker node operates in a sequential fashion on its assigned rows, e.g., in Fig. 1, worker W0, ﬁrst computes ˆA00x and only then ˆA01x. If node 0 is a straggler (but not a failure), ignoring the partial computation it performs will be wasteful. • Numerically stable decoding. The RS-based approach requires the master node to solve a real Vandermonde system of linear equations or equivalently perform polynomial interpolation. It is well recognized that real Vandermonde matrices have a rather',\n",
       " '1409.2905': 'Adaboost [10] is a very popular classiﬁcation learning algorithm. It is a simple and effective algorithm. While generally successful, the sensitivity of Adaboost to random label noise is well documented [6, 9, 2]. The random label noise setup is one where we take a dataset for which our learning algorithm generates an accurate classiﬁer and we ﬂip each label in the training set with some small ﬁxed probability. Note that the classiﬁer that was a good classiﬁer in the noiseless setup is still a good classiﬁer. The problem is that in the noisy setup the noisy examples mislead the learning algorithm and cause it to diverge signiﬁcantly from the good classiﬁer. LogitBoost [7] is believed to be less sensitive to random noise than Adaboost, but it still falls pray to high levels of random labels noise. In fact, Servedio and Long [8] proved that, in general, any boosting algorithm that uses a convex potential function can be misled by random label noise. Freund [4] suggested a boosting algorithm, called Brownboost, that uses a non-convex potential function and claims to overcome random label 1 arXiv:1409.2905v1  [cs.LG]  9 Sep 2014  noise. The main contribution of this paper is experimental evidence that support this claim. The other contribution is a heuristic for automatically tuning the parameters that Brownboost needs as input. 2 Boosting, margins and convexity All non-recursive boosting algorithms generate a classiﬁcation rule which is a thresholded linear combination of so-called “base” classiﬁcation rules. More precisely, let (x, y), with y ∈{−1, +1} denote a labeled example. Let hi : X →{−1, +1} denote the base rules. then the output of the boosting algorithm is a rule of the form F(x) = sign  X i αihi(x) ! As it turns out, the sum which is the operand of the sign function is important for understanding the operation of boosting algorithms as well as the generalization error of the generated classiﬁer. It is convenient to replace the sum with a dot product: X i αihi(x) = ⃗α · ⃗h(x) with ⃗α and ⃗h deﬁned in the natural way. To characterize the relationship of the value of the sum and the label y, Schapire et. al. [11] deﬁnes the “margin” of an example as: m(x, y) = y⃗α · ⃗h(x) Thus m(x, y) > 0 if and only if the classiﬁcation rule is correct on the example (x, y). The natural goal is therefore to ﬁnd base rules {hi} and weights {αi} such that the number of training examples with negative margin i.e. the number of misclassiﬁed examples is minimized. From a computational point of view, the easy case occurs when the training data is separable. In other words, when when there exists a setting of α such that m(x, y) > 0 for all of the training examples. In that case ﬁnding an appropriate setting for α is easy and can be done using the perceptron algorithm. On the',\n",
       " '1811.04026': 'Recent advances in machine learning and data analytics have yielded transformative results across diverse scientiﬁc disciplines, including image Preprint submitted to Journal of Computational Physics November 12, 2018 arXiv:1811.04026v1  [stat.ML]  9 Nov 2018  recognition [1], natural language processing [2], cognitive science [3], and genomics [4]. In all aforementioned areas, the volume of data has increased substantially compared to even a decade ago, but analyzing big data is expensive and time-consuming. Data-driven methods, which have been enabled by the availability of sensors, data storage, and computational resources, are taking center stage across many disciplines of science. We now have highly scalable solutions for problems in object detection and recognition, machine translation, text-to-speech conversion, recommender systems, and information retrieval [2]. All of these solutions attain state-of-the-art performance when trained with large amounts of data. However, more often than not, in laboratory experiments and large-scale simulations aiming to elucidate and predict complex phenomena, a large number of quality and error-free data is prohibitively costly to obtain. Under this setting, purely data-driven approaches for machine learning present diﬃculties when the data is scarce relative to the complexity of the system. The vast majority of state-of-the art machine learning techniques (e.g., deep neural nets, convolutional networks, recurrent networks, etc. [5]) are lacking robustness and fail to provide any guarantees of convergence or quantify the error/uncertainty associated with their predictions. Hence, the ability to learn in a robust and sample-eﬃcient manner is a necessity in these datalimited domains. Even less well understood is how one can constrain such algorithms to leverage domain-speciﬁc knowledge and return predictions that satisfy certain physical principles (e.g., conservation of mass, momentum, etc.). These shortcomings often generate skepticism and disbelief among applied mathematicians and engineers regarding the solid grounding of purely data-driven machine learning approaches. In recent work, Raissi et. al. [6, 7, 8, 9, 10] set foot exactly at this relatively unexplored interface between applied mathematics and contemporary machine learning by revisiting the idea of penalizing the loss function of deep neural networks using diﬀerential equation constraints, as ﬁrst put forth by Psichogios and Ungar [11] and Lagaris et. al. [12]. This line of work has empirically demonstrated how such physics-informed constraints regularize learning in small data regimes, can lead to the discovery of governing equations and reduced-order models, as well as enable the prediction of complex dynamics from incomplete models and incomplete data. Despite a series of impressive results in canonical problems, Raissi et. al. [6, 7] have also pointed out cases in which the training phase of these algorithms faces severe diﬃculties for reasons that are cur2  rently poorly understood. In lack of supporting theory on convergence and a-posteriori error estimation, this naturally poses the need for for scalable algorithms for uncertainty quantiﬁcation. A literature review of the current state-of-the-art in uncertainty',\n",
       " '1410.6558': 'The idea that signals reside in a union of low dimensional subspaces has been used extensively in the recent decade in many ﬁelds and applications [1]. One of the main problems that has beneﬁted remarkably from this theory is the one of compressed sensing. In this problem we want to recover an unknown signal x ∈Rd from a small number of noisy linear measurements: y = Mx + e, (1) where M ∈Rm×d is the measurements matrix, e ∈Rm is an additive noise and y ∈Rm is the noisy measurement. If the signal x can be any signal then we are in a hopeless situation in the task of recovering it from y. However, if we restrict it to a low-dimensional manifold that does not intersect with the null space of M at any point except the origin then we are more likely to be able to recover x from y by looking for the signal at this manifold, which is closest to y after multiplying it by M. An example for such a low dimensional manifold is the one of k-sparse signals under a given dictionary D ∈Rd×n. In this case our signal x satisﬁes x = Dα, ∥α∥0 ≤k, (2) where ∥α∥0 is the ℓ0-pseudo norm that counts the number of non-zero entries in a vector. In this case we may recover x from y by minimizing the following problem, ˆαS −ℓ0 = argmin ˜α ∥˜α∥0 s.t ∥y −MD˜α∥2 ≤λe. (3) Email address: raja.giryes@duke.edu. (Raja Giryes) Preprint submitted to Draft October 9, 2021  where λe is an upper bound for ∥e∥2 if the noise is bounded and adversarial, or a scalar dependent on the noise distribution [2]. As this problem is NP-hard [3] many approximation methods have been proposed for it [4, 5], such as orthogonal matching pursuit (OMP) [6] and the ℓ1-relaxation strategy that replaces the ℓ0-pseudo norm with the ℓ1-norm in (3) [7]. One of the main theoretical questions being asked with regard to these algorithms is what are the requirements on M, D, m and k such that the representation, α, of x may be stably recovered from y using these techniques, i.e., their recovery ˆα will satisfy ∥ˆα −α∥2 ≤C ∥e∥2 , (4) where C is a certain constant (diﬀerent for each algorithm). Two main tools have been used to answer this question. The ﬁrst is the coherence of MD [8], which is the maximal (normalized) inner product between the columns of MD. It has been shown that if the matrix MD is incoherent (has a small coherence) then it is possible to get a stable recovery using OMP and the ℓ1-relaxation. The problem with the coherence based recovery conditions is that they limit the number of measurements m to be of the order of k2, while m = 2k is enough to guarantee uniqueness for (1) in the noiseless case and m = O(k log',\n",
       " '1802.04592': 'Bike sharing, especially dockless bike sharing, is booming all over the world. For example, Mobike, a Chinese bikesharing giant, has deployed over 7 million bikes in China and abroad. Being an environment-friendly approach, bike sharing provides people with a convenient way for commuting by sharing public bikes among users, and solves the “last mile” problem (Shaheen, Guzman, and Zhang 2010). Different from traditional docked bike sharing systems (BSS), e.g., Hubway, where bikes can only be rented and returned ∗The work of Longbo Huang and Ling Pan was supported in part by the National Natural Science Foundation of China Grants 61672316, 61303195, the Tsinghua Initiative Research Grant, and the China Youth 1000-Talent Grant. Pingzhong Tang and Qingpeng Cai were supported in part by the National Natural Science Foundation of China Grant 61561146398, a China Youth 1000-talent program and an Alibaba Innovative Research program. Copyright c⃝2019, Association for the Advancement of Artiﬁcial Intelligence (www.aaai.org). All rights reserved. at ﬁxed docking stations, users can access and park sharing bikes at any valid places. This relieves users’ concerns about ﬁnding empty docks when they want to use bikes, or getting into fully occupied stations when they want to return them. However, due to similar travel patterns of most users, the rental mode of BSS leads to bike imbalance, especially during rush hours. For example, people mostly ride from home to work during morning peak hours. This results in very few bikes in residential areas, which in turn suppresses potential future demand, while subway stations and commercial areas are paralyzed due to the overwhelming number of shared bikes. This problem is further exaggerated for dockless BSS, due to unrestrained users’ parking locations. This imbalance can cause severe problems not only to users and service providers, but also to cities. Therefore, it is crucial for bike sharing providers to rebalance bikes efﬁciently, so as to serve users well and to avoid congesting city sidewalks and causing a bike mess. Bike rebalancing faces several challenges. First, it is a resource-constrained problem, as service providers often pose limited budgets for rebalancing the system. Naively spending the budget to increase the supply of bikes will not resolve the problem and is also not cost-efﬁcient. Moreover, the number of bikes allowed is often capped due to regulation. Second, the problem is computationally intractable due to the large number of bikes and users. Third, the user demand is usually highly dynamic and changes both temporally and spatially. Fourth, if users are also involved in rebalancing bikes, the rebalancing strategy needs to efﬁciently utilize the budget and incentivize users to help, without knowing users’ private costs. There have been a considerable set of recent results on bike rebalancing, which mainly focuses on two approaches, i.e., the vehicle-based approach (O’Mahony and Shmoys 2015; Liu et al. 2016; Ghosh, Trick, and Varakantham 2016; Li, Zheng, and',\n",
       " '1007.3808': 'Low-density parity-check (LDPC) codes attract a lot of interest due to their excellent performance. For various communication channels, it was shown either analytically or empirically that LDPC-like codes attain capacity, when decoded by iterative message-passing algorithms (for example, see [5], [6], [7]). In attempt to construct a framework for analysis of LDPClike codes, it was observed by Wiberg that the message-passing algorithms operate locally on the Tanner graph of the code [9]. Therefore, the performance of the decoder is similar, whether it is applied to the Tanner graph itself, or to its so-called graph cover. This observation led to a deﬁnition of computational tree pseudocodewords. Later, a closely related concept of graph-cover pseudocodewords was extensively studied by Koetter and Vontobel [8]. These pseudocodewords were also found to be a reason for failure events of linear-programming decoder applied to binary linear codes [1], [2]. The graph-cover pseudocodewords, when viewed as points in the Euclidean space, lie inside a fundamental cone [4], [8]. The cone boundaries depend on the parity-check matrix of the code rather than on the code itself. For binary codes, the fundamental cone was thoroughly studied in [4]. However, as the size of the underlying ﬁeld grows, the number of inequalities describing the boundaries of the fundamental cone also grows. In this work, we aim to extend the results in [4] towards codes deﬁned over F3 by providing a detailed characterization of the corresponding fundamental cone. II. DEFINITIONS AND SETTINGS Let C be a linear code of length n over a ﬁnite ﬁeld F △= Fq with q elements, and denote by F∗a set of nonzero elements of F. The code C can be deﬁned as C = {c ∈Fn : cHT = 0} (1) where H is an m × n matrix with entries from F (called the parity-check matrix of C), and 0 is all-zeros vector. Denote the set of column indices and the set of row indices of H by I = {1, 2, · · · , n} and J = {1, 2, · · · , m}, respectively. We use notation Hj for the j-th row of H, where j ∈J . Denote by supp(c) the support of a vector c. For each j ∈J , let Ij = supp(Hj). Denote by ||x|| a norm of a real vector x. The Tanner graph of a linear code C over F is an equivalent characterization of the code’s parity-check matrix H. The Tanner graph G = (V, E) has a vertex set V = U ∪V , where U = {ui}i∈I and V = {vj}j∈J . There is an edge between ui ∈U and vj ∈V if and only if Hj,i ̸= 0. This edge is labeled with the value Hj,i. We denote by N(v) the set of neighbors of a vertex v ∈V. To illustrate this concept, consider the following example from [3]. Example 2.1: Let C be a [4, 2] linear code over F = F3 with parity-check',\n",
       " '1707.00189': 'A lack of manual training data is a perennial problem in information retrieval [18]. To enable training supervised rankers for new domains, we propose a weak supervision approach based on pairs of text to train neural ranking models and a ﬁltering technique to adapt the dataset to a given domain. Our approach eliminates the need for a query log or large amounts of manually-labeled in-domain relevance judgments to train neural rankers, and exhibits stronger and more varied positive relevance signals than prior weak supervision work (which relies on BM25 for these signals). Others have experimented with weak supervision for neural ranking (see Section 2.2). Our weak supervision approach diﬀers from these approaches in a crucial way: we train neural rankers ∗Work conducted while the author was at the Max Planck Institute for Informatics. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and the full citation on the ﬁrst page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission and/or a fee. Request permissions from permissions@acm.org. SIGIR ’19, July 21–25, 2019, Paris, France © 2019 Association for Computing Machinery. ACM ISBN 978-1-4503-6172-9/19/07...$15.00 https://doi.org/10.1145/3331184.3331316 using datasets of text pairs that exhibit relevance, rather than using a heuristic to ﬁnd pseudo-relevant documents for queries. For instance, the text pair from a newswire dataset consisting of an article’s headline and its content exhibits an inherent sense of relevance because a headline often provides a concise representation of an article’s content. To overcome possible domain diﬀerences between the training data and the target domain, we propose an approach to ﬁlter the training data using a small set of queries (templates) from the target domain. We evaluate two ﬁlters: an unsupervised heuristic and using the neural ranker itself as a discriminator. We evaluate our approaches by training several leading neural ranking architectures on two sources of weak supervision text pairs. We show that our methods can signiﬁcantly outperform various neural rankers when trained using a query log source (as proposed by [5]), the ranker when trained on a limited amount of manually-labeled in-domain data (as one would encounter in a new domain), and well-tuned conventional baselines. In summary, we (1) address existing shortcomings of weak supervision to train neural rankers by using training sources from text pairs, (2) address limitations related to domain diﬀerences when training rankers on these sources using novel ﬁltering techniques, and (3) demonstrate the eﬀectiveness of our methods for ad-hoc',\n",
       " '1804.01640': 'Efﬁcient inference on probabilistic graphical models (PGMs) is a core topic in artiﬁcial intelligence (AI) and standard inference techniques are based on tree decomposition [21, 13, 23, 28] . The runtime of such algorithms is exponential in the treewidth (tw) of the underlying graph, which in the worst case, is unavoidable. Over the years, efforts in the logic, database and AI communities to reﬁne tw into a ﬁnergrained measure of complexity have culminated in generalized hypertree decompositions (GHDs) [18, 15]. Recently, FAQ/AJAR [4, 22] theoretically reconnected such GHD-based algorithms with probabilistic inference and achieved tighter bounds based on a ﬁner-grained notion of width called fractional hypertree width (fhtw). However, (1) the practical signiﬁcance of such GHD based PGM inference has met with some skepticism: Dechter et al. [14], via experimental evaluation, conclude that classical treewidth-based algorithms run faster on PGM benchmarks than those optimizing GHD-based measures. Their experiments suggest that the advantages of the latter manifest only in instances with substantial factor sparsity (i.e. large number of factor entries have zero probabilities) and high factor arity. (2) Translating the superior asymptotic bounds of GHDs into practice is a non-trivial challenge. In theory, these algorithms assume that one can exhaustively search over all potential GHDs, which is often untenable due to the combinatorial explosion of possible GHDs with thousands of variables and factors. Indeed, the theoretical runtimes of these algorithms completely ignore the dependence on the number of variables and factors; in practice, their asymptotic advantages may be negated by large constants. 1 arXiv:1804.01640v1  [cs.AI]  5 Apr 2018  ρ low ρ high RD small RD medium RD large 1-105x fast 1-1010x slow 1010-1020x slow 102-103x fast 1-5x fast 1-20x (mean: 5x) slow 1-20x (mean: 10x) slow Band 1 (JoinInfer) Band 2 (JoinInfer) Band 3 (JoinInfer) Band 4 (JoinInfer) Band 5 (libDAI) Band 6 (libDAI) Figure 1: Datasets are divided into six bands depending on the sizes of RD and ρ. The red shade in each box denotes the speedup of GHD based system over a treewidth based system and the blue shades shows the speedup of JoinInfer with respect to libDAI. The “winner\" is stated explicitly for each band. In the current work, we revisit the conclusions in (1) and overcome the challenges of (2) using a proofof-concept inference engine — JoinInfer — that leverages recently introduced worst case optimal joins [31] in conjunction with improved data structures. In particular, we make the following contributions: GHDs revisited. • Experimental evaluation in [14] used a ratio of theoretical bounds based on the GHD measure of hypertree width (htw) and the treewidth measure (we call the analogous version of this ratio RD: where we replace htw with fhtw). However, we suggest that the predictions made by RD are, in practice, contingent upon the total number of entries processed across all bags of the GHD (we call this ρ). Engines such as libDAI that',\n",
       " '1711.10789': 'Reinforcement learning (RL) is the dominant class of algorithms to learn sequential decision-making from data. In RL we start with zero prior knowledge and need to actively collect our own data. Therefore, we should not settle on a policy too early, instead of trying out actions we have not properly explored yet. However, we neither want to continue exploring sub-optimal actions, when we already know what is best. This challenge is known as the exploration/exploitation trade-off. Most state-of-the-art reinforcement learning implementations use undirected forms of exploration, such as ϵ-greedy or Boltzmann exploration. These methods act on point estimates of the mean actionvalue, usually applying some random perturbation to avoid only selecting the currently optimal action. However, these undirected methods are known to be highly inefﬁcient (Osband et al., 2014). By only tracking point estimates of the mean state-action value, these algorithms lack the information to, for example, discriminate between an action that has never been tried before (and requires exploration) and an action that has been tried extensively and deemed sub-optimal (and can be avoided). A natural solution to this problem originates from tracking uncertainties/distributions. The intuition is that with limited data and large uncertainty there is reason to explore, while narrow distributions naturally transfer to exploitation (see Appendix C for a detailed illustration). For this work we identify two types of uncertainties/distributions that are interesting for exploration: • Parametric uncertainty: This is the classical statistical uncertainty which is a function of the number of available data points. The cardinal example is the posterior distribution of the mean (action-value). • Return uncertainty: This is the distribution over returns from a state-action pair given the policy. For this work we focus on deterministic domains, which makes the return distribution entirely induced by the (exploratory) stochastic policy. 31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA. arXiv:1711.10789v1  [cs.LG]  29 Nov 2017  We argue that - for deterministic environments - we can explore by acting probabilistically optimal with respect to both distributions (see Section 3). We identify neural network methods to estimate each of them separately, and subsequently show that both can be combined in one network, which we call the Double Uncertain Value Network (DUVN). To the best of our knowledge, we are the ﬁrst to 1) distinguish between uncertainty due to limited data (parametric) and uncertainty over the return distribution, 2) propagate both through the Bellman equation, 3) track both with neural networks (i.e., high-capacity function approximators), and 4) use both to improve exploration.1 The remainder of this paper is organized as follows. In Section 2 we provide a general introduction to Bayesian deep learning and distributional reinforcement learning. In Section 3, we discuss parametric and return uncertainty, and identify their potential for exploration. Section 4 discusses their implementations for policy evaluation with neural networks, and also discusses how to derive a policy from the learned distributions based on Thompson',\n",
       " '1010.5416': 'Sensor nodes deployed for monitoring a random ﬁeld are characterized by limited battery power, computational resources and storage space. Often, once deployed the battery of these nodes are not changed. Hence when the battery of a node is exhausted, the node dies. When sufﬁcient number of nodes die, the network may not be able to perform its designated task. Thus the life time of a network is an important characteristic of a sensor network ([1]) and it depends on the life time of a node. Recently, energy harvesting techniques ([2], [3]) are gaining popularity for increasing the network life time. Energy harvester harnesses energy from environment or other energy sources (e.g., body heat) and converts them to electrical energy. Common energy harvesting devices are solar cells, wind turbines and piezo-electric cells, which extract energy from the environment. Among these, harvesting solar energy through photo-voltaic effect seems to have emerged as a technology of choice for many sensor nodes ([3], [4]). Unlike for a battery operated sensor node, now there is potentially an inﬁnite amount of energy available to the node. However, the source of energy and the energy harvesting device may be such that the energy cannot be generated at all times (e.g., a solar cell). Furthermore the rate of generation of energy can be limited. Thus the new design criteria may be to match This work is partially supported by a grant from ANRC to Prof. Sharma. This work was done when Prof. Viswanath was visiting Indian Institute of Science. The visit of Prof. Viswanath is supported by DRDO-IISc Programme on Advanced Mathematical Engineering. the energy generation proﬁle of the harvesting source with the energy consumption proﬁle of the sensor node. If the energy can be stored in the sensor node then this matching can be considerably simpliﬁed. But the energy storage device may have limited capacity. The energy consumption policy should be designed in such a way that the node can perform satisfactorily for a long time. In [2] such an energy/power management scheme is called energy neutral operation. We study the Shannon capacity of such an energy harvesting sensor node transmitting over a fading Additive White Gaussian Noise (AWGN) Channel. We provide the capacity under various energy buffer constraints and perfect/no channel state information at the transmitter (CSIT). We show that the capacity achieving policies are related to the throughput optimal policies ([5]). We also provide an achievable rate for this system with inefﬁciencies in the energy storage. Finally we provide the capacity when energy is used not only in transmission but also for sensing, processing etc. In the following we survey the relevant literature. Energy harvesting in sensor networks are studied in [6] and [7]. Conditions for energy neutral operation for various models of energy generation and consumption are provided in [2]. A practical solar energy harvesting sensor node prototype is described in [8]. In [9] the authors study optimal sleep-wake cycles for event detection',\n",
       " '1805.05487': 'CNNs introduced by Lecun [19] have gained enormous attention in the past decade especially after the demonstration of the signiﬁcant success on Imagenet data by Krizhevsky et al. [18] and others. The key property of equivariance to translation of patterns in the image is utilized in the CNN to share learned weights across a layer in the network. Thus, one might consider exploiting equivariance to transformation groups as a key design principle in designing neural network architectures suitable for these groups. For data sets that are samples of functions deﬁned on Riemannian manifolds, it would then be natural to seek a symmetry group property that the manifold admits and deﬁne the correlation operation (on the manifold) that would be equivariant to this symmetry group. For instance, on the n-sphere, the natural group action is the rotation group. Rotations in n-dimensions are elements of the well known group called the special orthogonal group, SO(n), which is a Lie group [14]. Thus, to develop correlation of functions on the sphere, one seeks equivariance with respect to rotations. This way, one has the ﬂexibility to seek ﬁlters/masks that are orientation sensitive. Steerable ﬁlters have been recognized as being of great importance in Computer Vision literature several decades ago in the context of hand crafted features [13, 9, 22]. Steerability here refers to synthesis of all deformations (scale, rotation and translation) of the ﬁlter using a small number of basis functions. Recently, steerable CNNs have been reported in literature [10, 7, 6] that are applicable to data which are samples of functions on a 2-sphere and hence are equivariant with respect to rotations in 3D. In [11], authors describe what they call polar transformer networks, which are equivariant to rotations and scaling transformations deﬁned on the domain of the data. By combining them with what is known in literature as a spatial transformer [16], they achieve the required equivariance to translations as well. For literature on deep networks where data reside on 2-manifolds, we refer the interested reader to a recent excellent survey paper [2] and references therein. In this paper, we present a generalization to the well known and widely used result that linear shift-equivariant systems are characterized fully by convolution and vice-versa in linear system theory for vector-spaces. In the context of deep networks, the actual operation is not a convolution but a correlation [7]. We will therefore use the term correlation instead of convolution from here on for the rest of the paper. The generalization here states that linear group equivariant systems on these manifolds are characterized by correlation and vice-versa. As a corrolary, we prove that correlation of functions has the property of equivariance to group actions admitted by Riemannian homogeneous manifolds. A homogeneous Riemannian manifold for a group G is a nonempty topological space M on which G acts transitively [15]. The elements of G are called symmetries of M. Intuitively, a',\n",
       " '1811.04784': 'Reasoning about abstract concepts has been a long standing challenge in machine learning. Recent work by Barret et al. [1] introduces a concrete problem setting for testing generalization in the form of a relational reasoning problem derived from Raven Progressive Matrices that are often used in human IQ-tests. The problem exists of a grid of 3-by-3 related images where the bottom right one is missing and a set of 8 possible answers, of which exactly one is correct. Two examples are shown in Figure 1. In this work we use the same dataset, which can be downloaded from https://github.com/deepmind/abstract-reasoning-matrices. Figure 1: Two example PGM problems: a grid of 3-by-3 related images where the bottom right one is missing and a set of 8 possible answers. The correct choice panels are A and C respectively. To create a Procedurally Generated Matrices (PGM) dataset, a set of properties is ﬁrst randomly sampled from the following primitive sets: • Relation types: (R, with elements r): progression, XOR, OR, AND, consistent union • Attribute types: (A, with elements a): size, type, colour, position, number • Object types: (O, with elements o): shape, line The structure S of a PGM then, is a set of triples, S = {[r, o, a] : r ∈R, o ∈O, a ∈A}. These triples determine the challenge posed by one particular matrix problem. In the used dataset, up to 4 triples can be present in a single problem: 1 ≤|S| ≤4. 32nd Conference on Neural Information Processing Systems (NIPS 2018), Workshop on Relational Representation Learning, Montréal, Canada. arXiv:1811.04784v1  [cs.LG]  12 Nov 2018  Figure 2: WReN model from [1]: A CNN processes each context panel and an individual answer choice panel independently to produce 9 vector embeddings. This set of embeddings is then passed to an RN network [2], whose output is a single sigmoid unit encoding the “score” for the associated answer choice panel. 8 such passes are made through this network (here we only depict 2 for clarity), one for each answer choice, and the scores are put through a softmax function to determine the model’s predicted answer. To solve a PGM problem, Barrett et al. propose a Wild Relation Network (WReN) architecture [2] as shown in Figure 2. In this architecture, all given images (the 8 context panels and the 8 choice panels, all represented as 80x80 grayscale images) are ﬁrst processed by a small convolutional neural network (CNN), resulting in 16 feature embeddings (one per panel). The 8 context embeddings are then sequentially combined with each option embedding, yielding a total of 8 stacks of 9 embeddings. These are ﬁnally processed by the WReN network, yielding a single scalar value for each choice panel, indicating its ‘matching-score’ with the given problem. The entire pipeline is then trained to produce the label of the correct missing panel as an output answer by optimizing a cross entropy loss using stochastic gradient descent. To include spatial information',\n",
       " '1802.07412': 'In many applications such as drone-based video surveillance and self driving cars, one has to process images and videos containing undesirable artifacts such as rain, snow, and fog. Furthermore, the performance of many computer vision systems often degrades when they are presented with images containing some of these artifacts. Hence, it is important to develop algorithms that can automatically remove these artifacts. In this paper, we address the problem of rain streak removal from a single image. Various methods have been proposed in the literature to address this problem [17, 6, 35, 19, 2, 14, 9, 1, 36, 33, 5]. One of the main limitations of the existing single image de-raining methods is that they are designed to deal with certain types of rainy images and they do not effec- (a) (b) (c) (d) (e) (f) Figure 1: Image de-raining results. (a) Input rainy image. (b) Result from Fu et al. [6]. (c) DID-MDN. (d) Input rainy image. (e) Result from Li et al. [33]. (f) DID-MDN. Note that [6] tends to over de-rain the image while [33] tends to under de-rain the image. tively consider various shapes, scales and density of rain drops into their algorithms. State-of-the-art de-raining algorithms such as [33, 6] often tend to over de-rain or under de-rain the image if the rain condition present in the test image is not properly considered during training. For example, when a rainy image shown in Fig. 1(a) is de-rained using the method of Fu et al. [6], it tends to remove some important parts in the de-rained image such as the right arm of the person, as shown in Fig. 1(b). Similarly, when [33] is used to de-rain the image shown in Fig. 1(d), it tends to under de-rain the image and leaves some rain streaks in the output de-rained image. Hence, more adaptive and efﬁcient methods, that can deal with different rain density levels present in the image, are needed. One possible solution to this problem is to build a very large training dataset with sufﬁcient rain conditions containing various rain-density levels with different orientations and scales. This has been achieved by Fu et al. [6] and Yang et al.[33], where they synthesize a novel large-scale dataset consisting of rainy images with various conditions 1 arXiv:1802.07412v1  [cs.CV]  21 Feb 2018  and they train a single network based on this dataset for image de-raining. However, one drawback of this approach is that a single network may not be capable enough to learn all types of variations present in the training samples. It can be observed from Fig. 1 that both methods tend to either over de-rain or under de-rain results. Alternative solution to this problem is to learn a density-speciﬁc model for deraining. However, this solution lacks ﬂexibility',\n",
       " '1901.10170': 'Advances in computer vision algorithms can often be applied to a wide variety of ﬁelds, including biomedical imaging. The current widespread use of convolutional neural networks for detection and segmentation tasks has signiﬁcant applications in the medical ﬁeld, where tasks often laboriously done by researchers can be replaced by automated systems. Recently, deep convolutional neural networks have seen increased use in biomedical and medical ﬁelds in tasks such as organ segmentation from CT scans [1]. Automatic nuclei instance segmentation from microscopy images is an important task due to the subjectivity of manual segmentations and the increased throughput that data automation enables. Accurate segmentation requires expert level knowledge and images may contain up to tens of thousands of nuclei that need to be labeled by hand. This seems an ideal application of computer vision, as algorithms can be trained to match experts in accuracy while being able to process thousands of images quickly. Traditionally, nuclei segmentation has been done with classical computer vision methods such as watershed and active contours. However, neural networks with sufﬁcient amount of training data outperform these systems by a signiﬁcant margin [2] and with the increasingly large amount of free and open source software libraries, they have become viable for everyday use in laboratories. For example, a popular open source package CellProﬁler now supports adding neural networks to its processing pipeline [3]. Object detection and segmentation networks suitable for this task like U-Net [4] and Mask-RCNN [5] are available as open source libraries, often packaged with pretrained models. Still, tuning these networks to get acceptable results in different domains requires expert knowledge. While CNNs are an obvious solution to this problem, numerous competing frameworks exist and choosing the best one for different tasks is difﬁcult. This study compares two popular object detection and segmentation frameworks, UNet and Mask-RCNN, to ﬁnd where they excel and fail. In addition, an ensemble model combining these two networks’ predictions was trained and was found to exceed the performance of both of these models by a signiﬁcant margin, in some cases more than 5 percent. Kaggle’s 2018 Data Science Bowl [6] presented the nuclei segmentation task in a competition format. The model frameworks used here are inspired by some of the best performing U-Net and Mask-RCNN models from the competition. 2 Method 2.1 U-Net U-Net [4] is a U-shaped convolutional network that uses skipconnections to preserve features at different resolutions. The basic model uses a simple downsampling path, which can be replaced with a deeper network such as ResNet [7]. This allows the model to learn more complex features as the network depth can be greatly increased with residual blocks. Another beneﬁt is that pretrained ResNet networks can be used to initialize the network; for example, pretrained models for ImageNet [8] and COCO [9] datasets exist. This is especially important when only a relatively small amount of',\n",
       " '1612.00583': 'Active search describes the problem where an agent is given a target to search for in an unknown environment and actively makes data-collection decisions so as to locate the target as quickly as possible. Examples of this setting include using aerial robots to detect gas leaks, radiation sources, and human survivors of disasters. The statistical principles for efﬁcient designs of measurements date back to Gergonne (1815), but the growing trend to apply automated search systems in a variety of environments and with a variety of constraints has drawn much research attention recently, due to the need to address the disparate aspects of new applications. One possibility in such active search scenarios we aim to explore, inspired by the robotic aerial search setting but with statistical insights that we hope to generalize, is the opportunity to take aggregate measurements that summarize Copyright c⃝2017, Association for the Advancement of Artiﬁcial Intelligence (www.aaai.org). All rights reserved. large contiguous regions of space. For example, an aerial robot carrying a radiation sensor will sense a region of space whose area depends on its altitude. How can such a robot dynamically trade off the ability to make noisier observations of larger regions of space against making higher-ﬁdelity measurements of smaller regions? To simplify the discussion, we will limit such region sensing observations to reveal the average value of an underlying function on a rectangular region of space, corrupted by independent observation noise. Noisy binary search is a simple realization of active search using such an observation scheme. This mechanism turns out to be sufﬁciently informative in the cases that we analyze to offer insights into a variety of search problems. The ability to make aggregate region measurements in noisy environments has rarely been considered in previous work. Bayesian optimization, which has been used for localization of sparse signals (Carpin et al. 2015; Ma et al. 2015; Hernández-Lobato, Hoffman, and Ghahramani 2014; Jones, Schonlau, and Welch 1998), usually considers only point measurements of an objective function. Notice that point observations can be considered in our framework if the allowed region sensing actions are constrained to be arbitrarily small. On the other extreme, compressive sensing (Donoho 2006; Candès and Wakin 2008; Wainwright 2009), considers scenarios where every measurement can reveal information about the entire environment through linear projection with arbitrary coefﬁcients. This is not always a realistic assumption, as for example for an aerial robot, which can only sense its immediate vicinity. Between the two extremes, Jedynak, Frazier, and Sznitman (2012); Rajan et al. (2015); Haupt et al. (2009); Carpentier and Munos (2012); Abbasi-Yadkori (2012); Yue and Guestrin (2011) considered policies for search where observations can be made on any arbitrary subset of the search space, including discontiguous subsets, which is also often incompatible with the constraints in physical search systems. Another assumption we make, common for example in compressive sensing, is sparsity. We assume that there are only a small number',\n",
       " '1806.04728': 'Due to the great success of deep neural networks (DNNs) in the tasks of image classiﬁcation and detection [7, 11, 12, 14, 32, 44], they are now widely accepted as the ‘feature extractors of choice’ for almost all computer vision applications, mainly for their ability to learn good features from ∗The authors have contributed equally to this work the data. It is well-known that training a regular DNN model from scratch requires a signiﬁcant amount of training data [26]. Yet, in many practical applications, one may be given only a few training samples per class to learn a classiﬁer. This is known as the few-shot learning problem. Figure 1. One-shot detection example. Surrounding images: examples of new categories unseen in training. Center image: detection result for the one-shot detector on an image containing instances of partridge, which is one of the new categories. Recent studies have achieved signiﬁcant advances in using DNNs for few-shot learning. This has been demonstrated for domain-speciﬁc tasks, such as face recognition [28] and for the classiﬁcation of general categories [6, 10, 33, 38, 40, 43]. However, very few works have investigated the problem of few-shot object detection, where the task of recognizing instances of a category, represented 1 arXiv:1806.04728v3  [cs.CV]  18 Nov 2018  + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + Dog class representatives (a) (b) Novel class representatives Backbone, embedding space and representatives are learned jointly Few-Shot novel class examples (Other) novel class representatives Truck class representatives Training batches Test Image Bike class representatives Fine-tune Background Train Time Test Time Figure 2. Overview of our approach. (a) Train time: backbone, embedding space and mixture models for the classes are learned jointly, class representatives are mixture mode centers in the embedding space; (b) Test time: new (unseen during training) classes are introduced to the detector in the learned embedding space using just one or a few examples. Fine tuning the representatives and the embedding (on the episode train data) can be used to further improve performance (Section 5). For brevity, only two novel classes are illustrated in the test. The class posteriors are computed by measuring the distances of the input features to the representatives of each of the classes. by a few examples, is complicated by the presence of the image background and the need to accurately localize the objects. Recently, several interesting papers demonstrated preliminary results for the zero-shot object detection case [1, 23] and for the few-shot transfer learning [5] scenario. In this work, we propose a novel approach for Distance Metric Learning (DML) and demonstrate its effectiveness on both few-shot object detection and object classiﬁcation. We represent each class by a mixture model with multiple modes, and consider the centers of these modes as the representative vectors for the class. Unlike previous methods, we simultaneously learn the embedding space, backbone network parameters, and the representative vectors of the training categories, in a single end-to',\n",
       " '1712.03660': 'FAILED',\n",
       " '1805.03829': 'FAILED',\n",
       " '1811.08039': 'Deep neural networks (DNNs) have become the preferred model for supervised learning tasks after their success in various ﬁelds of research. However, due to their highly non-convex nature, DNNs pose a diﬃcult * Equal Contribution problem during training time; the optimization landscape consists of many saddle points and local minima which make the trained model generalize poorly (Chaudhari et al., 2016; Dauphin et al., 2014). This has motivated regularization schemes such as weight decay (Krogh and Hertz, 1992), batch normalization (Ioﬀe and Szegedy, 2015), and dropout (Srivastava et al., 2014) so that the solutions generalize better to the test data. In spite of this, backprop used along with stochastic gradient descent (SGD) or similar variants like Adam (Kingma and Ba, 2015) suﬀer from a variety of problems. One of the most notable problems is the vanishing gradient problem which slows down gradient-based methods during training time. Several approaches have been proposed to deal with the problem; for example, the introduction of rectiﬁed linear units (ReLU). However, the problem persists. For a discussion on the limitations of backprop and SGD, we direct the reader to Section 2.1 of Taylor et al. (2016). One approach to deal with this problem is to introduce auxiliary variables that increase the dimension of the problem. In doing so, the training problem decomposes into multiple, local sub-problems which can be solved eﬃciently without using SGD or Adam; in particular, the methods of choice have been block coordinate descent (BCD) (Askari et al., 2018; Lau et al., 2018; Zhang and Brand, 2017; Carreira-Perpinan and Wang, 2014) and the alternating direction method of multipliers (ADMM) (Taylor et al., 2016; Zhang et al., 2016). By lifting the dimension of the problem, these models avoid many of the problems DNNs face during training time. In addition, lifting oﬀers the possibility of penalizing directly the added variables, which opens up interesting avenues into the interpretability and robustness of the network. While these methods, which we refer to as “lifted” models for the remainder of the paper, oﬀer an alterarXiv:1811.08039v3  [cs.LG]  14 Nov 2019  Fenchel Lifted Networks native to the original problem with some added beneﬁts, they have their limitations. Most notably, traditional DNNs are still able to outperform these methods in spite of the diﬃcult optimization landscape. As well, most of the methods are unable to operate in an online manner or adapt to continually changing data sets which is prevalent in most reinforcement learning settings (Sutton and Barto, 1998). Finally, by introducing auxiliary variables, the dimensionality of the problem greatly increases, making these methods very diﬃcult to train with limited computational resources. 1.1 Paper contribution To address the problems listed above, we propose Fenchel lifted networks, a biconvex formulation for deep learning based on Fenchel’s duality theorem that can be optimized using BCD. We show that our method is a rigorous lower bound for the learning',\n",
       " '1707.05373': 'Deep learning has redeﬁned the landscape of machine intelligence [22] by enabling several breakthroughs in notoriously difﬁcult problems such as image classiﬁcation [20, 16], speech recognition [2], human pose estimation [35] and machine translation [4]. As the most successful models are permeating nearly all the segments of the technology industry from self-driving cars to automated dialog agents, it becomes critical to revisit the evaluation protocol of deep learning models and design new ways to assess their reliability beyond the traditional metrics. Evaluating the robustness of neural networks to adversarial examples is one step in that direction [32]. Adversarial examples are synthetic patterns carefully crafted by adding a peculiar noise to legitimate examples. They are indistinguishable from the legitimate examples by a human, yet they have demonstrated a strong ability to cause catastrophic failure of state of the art classiﬁcation systems [12, 25, 21]. The existence of adversarial examples highlights a potential threat for machine learning systems at large [28] that can limit their adoption in security sensitive applications. It has triggered an active line of research concerned with understanding the phenomenon [10, 11], and making neural networks more robust [29, 7] . Adversarial examples are crucial for reliably evaluating and improving the robustness of the models [12]. Ideally, they must be generated to alter the task loss unique to the application considered directly. For instance, an adversarial example crafted to attack a speech recognition system should be designed to maximize the word error rate of the targetted system. The existing methods for generating adversarial examples exploit the gradient of a given differentiable loss function to guide the search in the neighborhood of legitimates examples [12, 25]. Unfortunately, the task loss of several structured prediction problems of interest is a combinatorial non-decomposable quantity that is not amenable to gradient-based methods for generating adversarial example. For example, the metric for evaluating human pose estimation is the percentage of correct keypoints (normalized by the head). Automatic *equal contribution arXiv:1707.05373v1  [stat.ML]  17 Jul 2017  adversarial attack original semantic segmentation framework compromised semantic segmentation framework Figure 1: We cause the network to generate a minion as segmentation for the adversarially perturbed version of the original image. Note that the original and the perturbed image are indistinguishable. speech recognition systems are assessed using their word (or phoneme) error rate. Similarly, the quality of a semantic segmentation is measured by the intersection over union (IOU) between the ground truth and the prediction. All these evalutation measures are non-differentiable. The solutions for this obstacle in supervised learning are of two kinds. The ﬁrst route is to use a consistent differentiable surrogate loss function in place of the task loss [5]. That is a surrogate which is guaranteed to converge to the task loss asymptotically. The second option is to directly optimize the task loss by using approaches such as Direct Loss Minimization [14]. Both of these strategies have severe limitations. (1) The use of differentiable surrogates is satisfactory',\n",
       " '1809.02147': 'Sanskrit used to be the ‘lingua franca’ for the scientiﬁc and philosophical discourse in ancient India with literature that spans more than 3 millennia. Sanskrit primarily had an oral tradition, and the script used for writing Sanskrit varied widely across the time spans and regions. With the advent of printing press, Devanagari emerged as the prominent script for representing Sanskrit. With standardisation of Romanisation using IAST in 1894 (Monier-Williams, 1899), printing in Sanskrit was extended to roman scripts as well. There 1The data and the codes for our system are available here - https://github.com/majumderb/ sanskrit-ocr has been a surge in digitising printed Sanskrit manuscripts written in Roman such as the ones currently digitised by the ‘Krishna Path’ project2. In this work, we propose a model for postOCR text correction for Sanskrit written in Roman. Post-OCR text correction, which can be seen as a special case of spelling correction (Schnober et al., 2016), is the task of correcting errors that tend to appear in the output of the OCR in the process of converting an image to text. The errors incurred from OCR can be quite high due to numerous factors including typefaces, paper quality, scan quality, etc. The text can often be eroded, can contain noises and the paper can be bleached or tainted as well (Schnober et al., 2016). Figure 1 shows the sample images we have collected for the task. Hence it is beneﬁcial to perform a post-processing on the OCR output to obtain an improved text. Figure 1: Sample images from our test set with different stylistic parameters In the case of Indic OCRs, there have been considerable efforts in collection and annotation of data pertaining to Indic Scripts (Kumar and Jawahar, 2007; Bhaskarabhatla et al., 2004; Govindaraju and Setlur, 2009; Krishnan et al., 2014). Earlier attempts on Indian scripts were primarily based on handcrafted templates (Govindan and Shivaprasad, 1990; Chaudhuri and Pal, 1997) or features (Arora et al., 2010; Pal et al., 2009) which extensively used the script and language-speciﬁc 2http://www.krishnapath.org/library/ arXiv:1809.02147v1  [cs.CL]  6 Sep 2018  information (Krishnan et al., 2014). Sequential labelling approaches were later proposed that take the word level inputs and make character level predictions (Shaw et al., 2008; Hellwig, 2015). The word based sequence labelling approaches were further extended to use neural architectures, especially using RNNs and its variants such as LSTMs and GRUs (Sankaran and Jawahar, 2012; Krishnan et al., 2014; Saluja et al.; Adiga et al., 2018; Mathew et al., 2016). But, OCR is putative in exhibiting few long-range dependencies (Schnober et al., 2016). Singh and Jawahar (2015) ﬁnd that extending the neural models to process the text at the sentence level (or a textline) leads to improvement in the performance of the OCR systems. This was further corroborated by Saluja et',\n",
       " '1509.00244': 'F ACE recognition has been one of the most extensively studied topics in computer vision. The importance of face recognition is closely related to its great potential in multimedia applications, e.g., photo album management in social networks, human machine interaction, and digital entertainment. With years of effort, signiﬁcant progress has been achieved for face recognition. However, it remains a challenging task for multimedia applications, as observed in recent works [1], [2]. In this paper, we handle the face recognition problem for matching internet face images appeared in social networks, which is one of the most common applications in multimedia circumstances. Recognizing the face images appeared in social networks is difﬁcult, due to the reasons mainly from the following two perspectives. First, the face images uploaded to social networks are captured in real-world conditions; therefore faces in these images usually exhibit rich variations in pose, illumination, expression, and occlusion, as illustrated in Fig. 1. Second, face recognition in social networks is a large-scale recognition problem due to the numerous face images of potentially large amount of users. The prediction accuracy of face recognition C. Ding and D. Tao are with the Centre for Quantum Computation and Intelligent Systems, and the Faculty of Engineering and Information Technology, University of Technology, Sydney, 81 Broadway, Ultimo, NSW 2007, Australia (email: changxing.ding@student.uts.edu.au, dacheng.tao@uts.edu.au). Fig. 1. Face images in multimedia applications usually exhibit rich variations in pose, illumination, expression, and occlusion. algorithms usually degrades dramatically with the increase of face identities. Accurate face recognition depends on high quality face representations. Good face representation should be discriminative to the change of face identify while remains robust to intra-personal variations. Conventional face representations are built on local descriptors, e.g., Local Binary Patterns (LBP) [3], Local Phase Quantization (LPQ) [4], [5], DualCross Patterns (DCP) [6], and Binarised Statistical Image Features (BSIF) [7]. However, the representation composed by local descriptors is too shallow to differentiate the complex nonlinear facial appearance variations. To handle this problem, recent works turn to Convolutional Neural Networks (CNNs) [8], [9] to automatically learn effective features that are robust to the nonlinear appearance variation of face images. However, the existing works of CNN on face recognition extract features from limited modalities, the complementary information contained in more modalities is not well studied. Inspired by the complementary information contained in multi-modalities and the recent progress of deep learning on various ﬁelds of computer vision, we present a novel face representation framework that adopts an ensemble of CNNs to leverage the multimodal information. The performance of the proposed multimodal system is optimized from two perspectives. First, the architecture for single CNN is elaborately designed and optimized with extensive experimentations. Second, a set of CNNs is designed to extract complementary information from multiple modalities, i.e., the holistic face image, the rendered frontal face image by 3D model, and uniformly sampled face patches. Besides',\n",
       " '1406.0053': 'The computationally most demanding step of the Guruswami–Sudan algorithm [4] is ﬁnding a bivariate interpolation polynomial. Many algorithms have been proposed, both more classical with a quadratic dependence on the code length n, e.g. [6,7], as well as approaches utilising fast multiplication methods with a resulting quasi-linear dependence on n [2,3]. In this work we show how the K¨otter–Nielsen–Høholdt algorithm1 of [7] admits a Divide & Conquer variant to utilise fast multiplication. Our algorithm’s complexity is O(ℓ2s3n) + O ∼(ℓωsn), where ℓ, s are the list size and multiplicity parameters. O ∼means big-O but with log(nsℓ) terms omitted, and ω is the exponent of matrix multiplication, i.e. ω ≤3. This is not the fastest possible way to compute an interpolation polynomial, since [3] achieves O ∼(ℓωsn), but it matches e.g. the speed of [2]. Ours is also a comparatively simple algorithm: for instance, it is trivial to apply the algorithm to K¨otter–Vardy decoding [5] with varying multiplicities, while this is possible but quite complicated for the lattice-basis reduction approaches of [1–3,6]; see [1] for a description of how to accomplish this. The algorithm has been implemented in Sage v. 5.13 and the source code is available at http://jsrn.dk/code-for-articles. 2 Preliminaries and the Problem First some notation: we will write 0 for the all-0 matrix, sub-scripted with dimensions. Likewise I is the identity matrix. For any matrix V , then V [i, j] 1This algorithm is sometimes mistakenly attributed to K¨otter only. However, it appeared ﬁrst in [7], stating that it was obtained as a generalisation of an algorithm in K¨otter’s thesis.  2 3 THE K ¨OTTER–NIELSEN–HøHOLDT ALGORITHM denotes the (i, j)’th entry. If V is over F[x] we will write deg V to denote the greatest degree among the entries of V . For any Q ∈F[x, y] and w ∈Z+, denote by degw Q the (1, w)-weighted degree of Q: degw xiyj = i + wj and degw is then extended to polynomials by the maximal of the monomials’ degw. degw induces a module monomial ordering ≤w, where ties are broken using the power of x. Let F[x, y]ℓ= {Q ∈F[x, y] | ydeg Q ≤ℓ}; this is an F[x]-module, and we will be working with sub-modules of it. Given a set of polynomials B ⊂F[x, y]ℓ then we denote by span(B) the F[x]-module spanned by B. We will be working with Gr¨obner bases of such modules, always on the module monomial ordering ≤w. From now on, this term order is implicit when we say “Gr¨obner bases”. Deﬁnition 1. For any Q ∈F[x, y] and point (x0, y0) ∈F2, then the (dx, dy) Hasse derivative at (x0, y0) for dx, dy ∈N0 is the coeﬃcient to xdxydy in Q(x + x0, y + y0). We denote',\n",
       " '1707.08063': 'T HE depth ordinal information of two objects (points) in an image is an important visual cue for many computer vision tasks such as objects classiﬁcation [4], [5] and semantic segmentation [6], [7], [8]. The objective is to know which one is closer or further (or at the same depth) to the camera, given a pair of pixels. To estimate relative depth order, traditional methods mainly depends on objects’ boundary and junction characteristics such as T-junction, convexity/concavity and inclusion [9], [10], [11]. The accuracy of these methods is limited. Recently, Convolutional Neural Networks (CNNs) have achieved remarkable success on many vision tasks such as object recognition [12], [13], [14] and semantic segmentation [15], [16]. Motivated by the powerful visual representation and generalization capability, recent works [1], [2] of depth estimation have also used CNNs to estimate the ordinal information between the point pairs, and demonstrated superior performance. In [1], [2], both methods attempt to explore multiple features, which include the appearance of the points, the local contextual information, the global scene context and so on. The idea is to use the visual cues as much as possible to improve the models’ performance. Moreover, they both apply the multi-stream network structure. Zhou et al. [2] R. Deng and S. Liu are with Central South University, China. T. Zhao is with Tsinghua University, China. C. Shen is with the University of Adelaide, Australia. This work was done when R. Deng was visiting the University of Adelaide. Fig. 1: The overall pipeline of estimating the depth order of a pair of points. Given a pair of points, we extract its local contextual information and feed it to the proposed model to perform the prediction. The output of the model is the probability of a three-way classiﬁcation, which are three ordinal relationships “at the same depth”, “further” and “closer”. concatenates all the convolutional features. In contrast, Zoran et al.’s [1] network applies hierarchical concatenation of the convolutional features—the global feature ﬁrst concatenates with the RoI mask and is fed into a fully connected layer, then concatenates with the other convolutional features and the masks. Thus, the studies of the recent works have mainly focused on combining various contextual information to train a network, yet without demonstrating if each feature is useful. In this work, we attempt to achieve two objectives: 1) empirically examine the contribution of each context cue; 2) and present a practical model to estimate the ordinal depth information. As we show in the next sections, such an exploration has resulted in several interesting ﬁndings. The global feature vs. the multi-scale local features. Following the insights presented in [1], [2], it makes sense to take advantage of more types of the contextual information for improving the accuracy of the model. However, neither of the them offers an analysis of the contributions of each cue. It is crucial to ﬁnd if each cue plays an important role in the model. For an ineffective',\n",
       " '0903.2226': 'The interference channel (IC) models the situation where M unrelated transmitters communicate their separate messages to M independent receivers, each of which is assigned to a single transmitter. Apart from a few special cases [1], [2], [3], the capacity region of the IC remains unknown. Recently, Etkin et al. [4], [5] showed that in the interference-limited regime, the capacity region of the IC is achievable to within one bit; later Telatar and Tse [6] generalized this result to a wider class of ICs. Shang et al. derived the noisy-interference sum-rate capacity for Gaussian ICs in [7], while Raja et al. [8] characterized the capacity region of the two-user ﬁnite-state compound Gaussian IC to within one bit. Annapureddy and Veeravalli [9] showed that the sum capacity of the two-user Gaussian IC under weak interference is achieved by treating interference as noise. In [10], Akuiyibo and L´evˆeque derived an outer bound on the diversity-multiplexing tradeoff (DMT) region of fading ICs based on the results of Etkin et al. [5]. In this paper, we investigate the achievability of this outer bound and we analyze the DMT realized by a stripping decoder and a ﬁxed-power-split Han and Kobayashi (HK)-type superposition coding scheme. For the sake of simplicity, throughout the paper, we restrict our attention to the two-user case. Furthermore, we assume that the receivers have perfect channel state information (CSI) whereas the transmitters only know the channel statistics. We would like to point out that the schemes used in [5] make explicit use of transmit CSI and so does the scheme in [10], which immediately implies that the results reported in [10] serve as an outer bound on the DMT achievable in the absence of transmit CSI, the case considered here. The contributions in this paper can be summarized as follows: • For very strong interference in the sense of [5], we show that a stripping decoder which decodes interference while treating the intended signal as noise, subtracts the result out, and then decodes the intended signal is DMT-optimal. We furthermore ﬁnd that the optimal-DMT can be achieved if each of the two users employs a code that is DMT-optimal on a single-input single-output (SISO) channel. • For general interference levels, we compute the DMT of a two-message, ﬁxed-power-split HK-type superposition coding scheme and provide design criteria for the corresponding superposition codes. We ﬁnd that this scheme is DMT-optimal for certain multiplexing rates. Notation: The superscripts T and H stand for transpose and conjugate transpose, respectively. xi represents the ith element of the column vector x, and λmin(X) denotes the smallest eigenvalue of the matrix X. IN is the N ×N identity matrix, and 0 denotes the all zeros matrix of appropriate size. All logarithms are to the base 2 and (a)+ = max(a, 0). X ∼CN(0, σ2) stands for a circularly symmetric complex Gaussian random variable (RV) with variance',\n",
       " '1806.08514': 'Advanced techniques about 3D video [1], 360 panorama video [2], light ﬁeld [3], etc., have received more and more attentions and have widely researched due to their practically applied values. However, the information carrier of these techniques mainly refers to image, thus Internet congestion may occur, because of explosive growth image data among social media and other new media. With this trend of rapidly increasing, the main source of Internet congestion will be caused by image/video transmission [4], so different kinds of Corresponding author: Huihui Bai. This work was supported in part by National Natural Science Foundation of China (No. 61672087, 61672373), Key Innovation Team of Shanxi 1331 Project KITSX1331 and the Fundamental Research Funds for the Central Universities (No. 2017YJS053). L. Zhao, H. Bai, Y. Zhao are with the Beijing Key Laboratory of Advanced Information Science and Network Technology, Institute Information Science, Beijing Jiaotong University, Beijing, 100044, P. R. China, e-mail: 15112084, hhbai, yzhao@bjtu.edu.cn. A. Wang is with Institute of Digital Media & Communication, Taiyuan University of Science and Technology, Taiyuan, 030024, P. R. China, e-mail: wah ty@163.com images, especially natural image, should be extremely compressed to alleviate this problem. Image compression aims at reducing the amounts of data to beneﬁt image storage and transmission. Still image compression has been developed from early image compression standards such as JPEG and JPEG2000 to Google’s WebP and BPG, etc. In the earlier times, a lot of works [5–17] mainly put their emphasis on post-processing to reduce coding artifacts so as to improve coding efﬁciency, whose priority exists in that it doesn’t need change any part of existing coding standard. Lately, several works [18–25] employ convolutional neural network (CNN) to remove image blurring and quantization artifacts caused by image compression. Among these works, a very special work [25] is an effective compression framework based on two collaborative convolutional neural networks, where one network is used to compactly represent image and the other one works as post-processing to reduce coding distortion. This method has good performances at the case of very low bit-rate coding, but it doesn’t explore how to improve coding efﬁciency at high bit-rate. Thus, this method’s practical application is very limited, because image coding at low bit-rate is required, only when the band-width is very narrow. Meanwhile, this method directly trains collaborative convolutional neural networks without considering quantization’s effects on neural network ahead of standard codec during back-propagation, so it’s a sub-optimal solution for image compression. Recently, image compression with deep neural networks (DNN) has achieved many great breakthroughs, such as [26–33], among which some methods have exceeded JPEG2000 and even can compete with BPG. These methods target at resolving the challenging problem: quantization function within objective compression loss is non-differentiable. The pioneering work [26] leverages recurrent neural networks to compress image in full-resolution, where the binarization layer with stochastic binarization is used to',\n",
       " '1804.08144': 'The union bound, alternatively known as Boole’s inequality, represents one of the simplest yet nontrivial methods for bounding the probability that either one event or another occurs, in terms of the probabilities of the individual events (see, e.g., [1]). By induction, the bound applies to the union of multiple events, and it often provides a good enough bound in a variety of applications whenever the probabilities of the individual events are small relative to the number of events. Concretely, given a ﬁnite set {Ai}L i=1 of events, the union bound is the following inequality: Pr ( L [ i=1 Ai ) ≤ L X i=1 Pr{Ai}. (1.1) By applying DeMorgan’s law and basic rules of probability theory, we can rewrite the union bound such that it applies to the probability that an intersection of events does not occur 1 −Pr ( L \\\\ i=1 Ai ) ≤ L X i=1 Pr{Ac i}, (1.2) ∗Department of Mathematics, Islamic Azad University, Varamin-Pishva Branch, 33817-7489, Iran †School of Science and Technology, University of Camerino, Via M. delle Carceri 9, I-62032 Camerino, Italy & INFN–Sezione Perugia, Via A. Pascoli, I-06123 Perugia, Italy ‡Hearne Institute for Theoretical Physics, Department of Physics and Astronomy, Center for Computation and Technology, Louisiana State University, Baton Rouge, Louisiana 70803, USA 1  and this is the form in which it is typically employed in applications. Recently, the union bound has been listed as the second step to try when attempting to “upper-bound the probability of something bad,” with the ﬁrst step being to determine if the trivial bound of one is reasonable in a given application [2]. Generalizing the union bound to a quantum-mechanical setup is non-trivial. A natural setting in which we would consider this generalization is when the goal is to bound the probability that two or more successive measurement outcomes do not occur. Concretely, suppose that the state of a quantum system is given by a density operator ρ. Suppose that there are L projective quantum measurements {Pi, I −Pi} for i ∈{1, . . . , L}, where Pi is a projector, thus satisfying Pi = P † i and Pi = P 2 i by deﬁnition. Suppose that the ﬁrst measurement is performed, followed by the second measurement, and so on. If the projectors P1, . . . , PL commute, then the probability that the outcomes P1, . . . , PL do not occur is calculated by applying the Born rule and can be bounded as 1 −Tr{PLPL−1 · · · P1ρP1 · · · PL−1} ≤ L X i=1 Tr{(I −Pi)ρ}, (1.3) with the bound following essentially from an application of the union bound. However, if the projectors P1, . . . , PL do not commute, then classical reasoning does not apply and alternative methods are required. Recently, Gao proved a quantum union bound [3] that has been useful in a variety of applications, including quantum communication theory [3, 4, 5, 6, 7], quantum algorithms [8, 9, 10], quantum complexity',\n",
       " '1806.00194': 'M ANY data in face analysis domain naturally exhibit imbalance in their class distribution. For instance, the numbers of positive and negative face pairs in face veriﬁcation [1], [2] are highly skewed since it is easier to obtain face images with different identities (negative) than faces with matched identity (positive) during data collection. For face attribute prediction [3], it is comparatively easy to ﬁnd persons with “normal-sized nose” attribute from web images than that of “big-nose”. Such face recognition and attribute prediction problems provide perfect testbeds for studying generic imbalanced learning algorithms, either under closedor open-set protocol [4]. Indeed, without handling the imbalance issue conventional methods tend to be biased toward the majority class with poor accuracy for the minority class [5], [6]. Deep representation learning has recently achieved great success due to its high learning capacity, but still cannot escape from the negative impact of imbalanced data. To counter such negative effect, one often chooses from a few available options, which have been extensively studied in the past [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16]. The ﬁrst option is re-sampling, which aims to balance the class priors by under-sampling the majority class or over-sampling the minority class (or both). For instance, Oquab et al. [17] resampled the number of foreground and background image patches for learning a convolutional neural network (CNN) for object classiﬁcation. The second • C. Huang was with the Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, 15213. E-mail: chenh2@andrew.cmu.edu • C. C. Loy is with the School of Computer Science and Engineering, National Technological University, Singapore. E-mail: ccloy@ntu.edu.sg • Y. Li and X. Tang are with the Department of Information Engineering, The Chinese University of Hong Kong. E-mail: {ly015,xtang}@ie.cuhk.edu.hk option is cost-sensitive learning, which assigns higher misclassiﬁcation costs to the minority class than to the majority. Caesar et al. [18] proposed to calibrate an ensemble of SVMs with inverse class frequencies as costs to combat class imbalance in semantic segmentation. Similarly in deep CNNs, the loss function is rescaled with the inverse [19], relative [20] and median [21] class frequencies, respectively for semantic segmentation, face attribute prediction and multitask scene understanding. For image edge detection [22], the softmax loss of CNN is regularized with equal weights for the positive and negative edge classes. An alternative [23] goes beyond conventional cost-sensitive strategies by reweighting the contributions of spatial image pixels based on their actual observed losses for semantic segmentation. Can these methods help the deep face recognition and attribute prediction tasks where data imbalance is barely handled? Are these methods the most effective way to deal with data imbalance in the context of deep representation learning? The aforementioned options are well studied for the ‘shallow’ model [24] but their implications have not yet been systematically studied for deep representation learning. Importantly, such schemes are well-known for some inherent limitations. For instance, over-sampling can',\n",
       " '1811.05381': 'FAILED',\n",
       " '1412.6618': 'In the domain of image recognition, the convolutional layer of a CNN today is almost exclusively associated with a spatial convolution in the image domain. In this work we will take a more signal theoretic viewpoint of the convolutional operation and present an algorithm that allows to process also sparse input data. This work is inspired by the use of special data structures (Adams et al., 2010) for bilateral ﬁlters (Aurich & Weule, 1995; Smith & Brady, 1997; Tomasi & Roberto, 1998) and generalizes it for the use of convolutional architectures. Although the approach presented here is more general, the following two scenarios are instructive. Consider that at training time we have access to full resolution images to train a classiﬁer. At test time only a random number of pixels from the test image is available. In other words, we sample the signal differently during training and test time. For a traditional CNN this would require a preprocessing step, for example to map from subsets of pixels to a dense grid that is the image. In our view there is no change, it is not required that we have a dense grid and access to all pixels of the image. That is the integration domain does not change. This is one example of sparsity, here we deal with a set of pixels, whose values are RGB and features are position. Similarly, color information can be used to deﬁne the ﬁltering operation as well. One can devise a convolution with a domain respecting color and location information (or color alone). One view from the image processing community is that of an edge-aware ﬁlter, the ﬁlter will be adaptive to the color and/or gradient of the image. RGB values do not lie on a regular dense grid, therefore a direct expansion of the spatial convolution is not applicable. This approach falls into line with the view on encoding invariants (Mallat, 2012). It is possible to encode our knowledge invariants that we have about the data with the new way of looking at the data. Encoded in a spatial convolution is the prior knowledge about translation invariance. How to encode roation invariance, how similarity in color space? In the view we take here these are simply convolutions over different domains. A grid based convolution cannot easily be used to work with the sparse data (an interpolation might be needed) but the permutohedral lattice provides the right space and allows efﬁcient implementations. Therefore the runtime is comparable to the ones of spatial convolutions, depending on the size of the invariants to include and can simply be used as a replacement of the traditional layers. 2 PERMUTOHEDRAL LATTICE CONVOLUTION We propose a convolution operation of a d-dimensional input space that entirely works on a lattice. Input data is a tuple (fi, vi) of feature locations fi ∈Rd and corresponding signal values vi ∈ 1  Accepted as a workshop contribution at ICLR 2015 Splat Convolve Slice Figure 1: The permutohedral convolution consists of three steps: ﬁrst',\n",
       " '0908.0358': 'Wireless networks deal with two fundamental limits that make the communication problem challenging and interesting. On the one hand, simultaneous communications from uncoordinated users create undesired interference. On the other hand, ﬂuctuations of the channel condition due to multi-path and mobility cause signals to fade randomly. In today’s cellular and ad-hoc networks orthogonalization techniques, such as F/T/C/SDMA, are employed to avoid interference. However, although leading to simple network architectures, interference avoidance techniques are suboptimal in terms of achievable rates. Moreover, the relative strength of the intended data signal and the interference signals changes over time due to fading. This makes ﬁxed channel access strategies suboptimal. Thus, understanding how to deal simultaneously with interference and with fading holds the key to the deployment of future broadband wireless networks. The simplest model for analyzing these problems jointly is the two-source BlockFading Gaussian InterFerence Channel (BF-GIFC).  2 It is well know that the Han-Kobayashi (HK) [1] scheme with superposition coding, rate splitting, and joint decoding, gives the largest known achievable rate region for GIFC without fading. Several outer bounds are known in the literature for GIFC without fading [2]–[7]. In particular, Etkin et al. [4] showed that a simple rate splitting strategy in the HK scheme is within one bit/sec/Hz of the capacity region of Gaussian unfaded GIFCs for any possible channel parameters. In [4], all interfering signals above the noise ﬂoor are decoded, that is, the private messages –which are treated as noise– are assigned a transmit power such that they are going to be received at, or below, the level of the noise. In doing so, roughly speaking, the effective noise power at the receiver is at most doubled, thus giving a rate penalty of at most 1 bit/sec/Hz. Recently, GIFCs with fading were considered in [?], [9]–[15]. For ergodic channels, such as fast fading channels, the (Shannon) capacity is the performance measure of the ultimate system performance. In [16], it was showed that the sum-rate ergodic capacity of a K-source fading GIFC scales linearly with the number of sources. In [9], the sum-rate capacity of a two-source strong ergodic fading GIFCs was shown to be equal to that of the corresponding compound MAC. In [10], optimal power allocation policies for outer and inner bounds for ergodic fading GIFCs with perfect transmitter CSI were derived. For slow fading channels, the proper measurement of performance is the outage capacity. In particular, the Diversity Multiplex Tradeoff (DMT) [17], quantiﬁes the tradeoff between rate and outage probability as the Signal to Noise Ratio (SNR) grows to inﬁnity. In [11] the DMT of symmetric two-source BFGIFCs was studied based on the “within one bit” outer bound of [4]. The authors of [11] claimed that the derived DMT is actually achievable because the “one bit penalty” for using a simple HK strategy vanishes at high SNR. However, the achievability of the “within one bit” outer',\n",
       " '1101.3354': 'The past decade has seen the rise of the Bag of Features approach in computer vision. Bag of Features (BoF) methods have been applied to image classiﬁcation, object detection, image retrieval, and even visual localization for robots. BoF approaches are characterized by the use of an orderless collection of image features. Lacking any structure or spatial information, it is perhaps surprising that this choice of image representation would be powerful enough to match or exceed state-of-the-art performance in many of the applications to which it has been applied. Due to its simplicity and performance, the Bag of Features approach has become well-established in the ﬁeld. This paper seeks to characterize the Bag of Features paradigm, providing a survey of relevant literature and a discussion of open research issues and challenges. We focus on the application of BoF to weakly supervised image classiﬁcation and unsupervised image retrieval tasks. This survey is of interest to the computer vision community for three reasons. First, Bag of Features methods work. As discussed below, BoF-based systems have demonstrated comparable or better results than other approaches for image classiﬁcation and image retrieval, while being computationally cheaper and conceptually simpler. Second, the BoF approach has appeared under different names in several seemingly unrelated branches of the literature. Besides the computer vision literature, where the term “Bag of Features” Date: July 2010. Key words and phrases. Bag of Features, Classiﬁcation, Retrieval, Visual Localization, Quantization, Feature Descriptors. 1 arXiv:1101.3354v1  [cs.CV]  17 Jan 2011  2 STEPHEN O’HARA AND BRUCE A. DRAPER was coined, closely related approaches appear in the literature on biological modeling, texture analysis, and robot localization. As a result, there is more work on BoF than many researchers may be aware of. Finally, the Bag of Features approach is a multi-step process, with each step presenting many options. Many plausible combinations have never been tried. We hope to contribute to future advances in the ﬁeld through this survey by mapping out the space of BoF algorithms, recording what is known about the steps and how they interact, and identifying remaining research opportunities. Although there is no contemporary survey on Bag of Features methods, related surveys include Frintrop’s survey of computational visual saliency (Frintrop et al, 2010) and Datta’s overview of Content-Based Image Retrieval (CBIR) techniques (Datta et al, 2008). Frintrop reviews techniques that share similarities to the feature extraction stage of BoF methods, as discussed in Section 3 of this report. Datta’s CBIR survey discusses BoFbased image retrieval to some extent, but we present a broader survey of BoF techniques with more details on state-of-the-art methods and speciﬁc mechanisms that have been employed to improve query results and speed. This paper is organized as follows. Section 2 provides an overview of the Bag of Features image representation. Section 3 provides details on the feature detection and extraction techniques commonly employed in BoF',\n",
       " '1812.10784': 'Over the last decade, we have seen an increase in the number of laparoscopic surgeries [1]. During the surgery, such as in cavitary treatment, laser ablation causes smoke [2] which signiﬁcantly degrades the perceptual quality of the images which inevitably inﬂuences the surgeon’s visibility, further it also inﬂuences the performance of computer vision based navigation systems [3]. Moreover, surgical smoke is composed of chemical, physical or ⋆Congcong Wang and Vivek Sharma contributed equally to this work and listed in alphabetical order. biological particles, which may be harmful for surgeons and patients [4–6]. Therefore, it is of vital importance to remove the smoke by computer vision algorithms [7] and by smoke evacuation techniques [8,9]. In order to employ a desmoking technique, as a prior knowledge it is essential to know if the image contains smoke or not. In this work, we propose a method to enhance the images for better classiﬁcation of smoke and non-smoke images. Our goal is to enhance the images, such that the extracted features from the enhanced images are informative for discrimination that can lead to improved smoke/non-smoke image classiﬁcation. Note that our goal is not to enhance the images for visual pleasantness of observers’ perception, but rather enhance the images features for improved classiﬁcation. Our work is inspired from [10,11]. Sharma et al. in [10] enhance the visible (RGB) images using near-infrared (NIR) counterparts and show improvement in the image feature quality for biometric veriﬁcation tasks, further in [11], Sharma et al. emulates several image enhancement methods in convolutional neural networks for an accurate image classiﬁcation. We have a similar goal, though our work differs substantially in technical approach and the application scope. Speciﬁcally, we utilize weighted least squares optimization framework (WLS) [12] to decompose an image to ﬁne and coarse enhanced images, and then combine them in a more meaningful way such that the combined image have better image features for our classiﬁcation task. Our proposed approach is evaluated on Cholec80 dataset for smoke/non-smoke image classiﬁcation. We experimentally show that our proposed method consistently improve the classiﬁcation performance over the baseline RGB images, popular state-of-theart enhancement methods, and the saturation histogram based classiﬁcation methodologies Saturation Analysis (SAN) and Saturation Peak Analysis (SPA). The remainder of this paper is structured as follows. First, we review the related work on image enhancement and smoke detection methods. Next, we describe our proposed method, and discuss the experimental results. Finally, the conclusions are drawn. RELATED WORK Image Enhancement. Image enhancement or ﬁltering techniques enhance the contrast, boost the image details, and produce more vivid colors, and at the same time removes the effects of blur, noise, and compression artifacts. Examples of arXiv:1812.10784v1  [cs.CV]  27 Dec 2018  such ﬁltering methods include weighted least squares (WLS) [12], bilateral ﬁltering [13], image sharpening, guided ﬁltering [14], BFWLS AVG [10] and more',\n",
       " '1409.6911': 'Object detection is a fundamental and crucial problem in computer vision. One of the most heavily studied paradigms and the most prominent example for object detection is deformable part-based models (DPM) algorithm [9]. It combines a set of discriminatively trained parts in a star model which is called pictorial structure [13, 10, 11]. The part ﬁlters in DPM are based on hand-crafted Histogram of Gradients descriptors [3]. However, the progress has been slow during 2010-2012 in the canonical visual recognition task PASCAL VOC object detection [6] with hand-crafted visual features. In the last years, more and more works focus on Deep Convolutional Neural Networks (CNNs) and achieve great success. CNNs were ﬁrstly introduced in 1980 by Kunihiko Fukushima [14], and Yann LeCun et al. improved it Metal&material\\x01 Eye\\x01 Facula\\x01 Texture\\x01 ✔\\x01 ✗\\x01 ✗\\x01 ✔\\x01 Figure 1. Illustration showing the main motivation of this paper. For a parameter-trained network, correspondence between pool5 features and concepts of each channel would also be ﬁxed, such as shape, texture and material properties. It is clear that some concepts are helpful and some are unfriendly for classiﬁcation. in 1998 [25]. This model was initially applied to handwritten digit recognition [24] and OCR [25]. Recently CNNs have been well applied into lots of visual recognition systems in a variety of domains. With the introduction of large labeled image databases [4] and the massive parallel computations of GPU implementations, the large scale CNNs have become the most accurate method for generic object classiﬁcation [23] , detection [15, 29, 31] and segmentation tasks [17, 16]. In 2012, Krizhevsky et al. [23] designed a large CNN with 60 million parameters and 650,000 neurons and obtained substantial improvement of image classiﬁcation accuracy on the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) [22, 4]. In 2013, a joint deep learning architecture was proposed for pedestrian detection, which combines a CNN architecture with the DPM algorithm [27]. Four components are contained in this framework: feature extraction, part deformation handling, occlusion handling, and classiﬁcation. In 2014, Girshick et al. [15] proposed a scalable detection algorithm called R-CNN and showed that R-CNN can obtain dramatically higher object detection performance on PASCAL VOC as compared to algorithms based on HOG-like features. R-CNN is a region-based al1 arXiv:1409.6911v3  [cs.CV]  18 Nov 2014  gorithm that bridges the gap between image classiﬁcation and object detection by operating within the “detection with regions” paradigm [32] instead of the sliding-window strategy. For further improving detection performance, several methods were studied before. One kind approach is to manipulate the training images by different operations, such as rotation, scaling, shearing and stretching, and then merge these transformed images into training set for training a more powerful detector which will improve the viewinvariant representations [20]. Another kind of approach is to perform local transformations in feature learning algorithms like Restricted Boltzmann Machine (RBM) and autoencoders, which combines various kinds of transformed',\n",
       " '1706.08476': 'Task-oriented spoken dialog systems have transformed human-computer interaction by enabling people interact with computers via spoken language (Raux et al., 2005; Young, 2006; Bohus and Rudnicky, 2003). The task-oriented SDS is usually domain-speciﬁc. The system creators ﬁrst map the user utterances into semantic frames that contain domain-speciﬁc slots and intents using spoken language understanding (SLU) (De Mori et al., 2008). Then a set of domain-speciﬁc dialog state variables is tracked to retain the context information over turns (Williams et al., 2013). Lastly, the dialog policy decides the next move from a list of dialog acts that covers the expected communicative functions from the system. Although the above approach has been successfully applied to many practical systems, it has limited ability to generalize to out-of-domain (OOD) requests and to scale up to new domains. For example, even within in a simple domain, real users often make requests that are not included in the semantic speciﬁcations. Due to this, proper error handling strategies that guide users back to the in-domain conversation are crucial to dialog success (Bohus and Rudnicky, 2005). Past error handling strategies were limited to a set of predeﬁned dialog acts, e.g. request repeat, clariﬁcation etc., which constrained the system’s capability in keeping users engaged. Moreover, there has been an increased interest in extending task-oriented systems to multiple topics (Lee et al., 2009; Gaˇsi´c et al., 2015b) and multiple skills, e.g. grouping heterogeneous types of dialogs into a single system (Zhao et al., 2016). Both cases require the system to be ﬂexible enough to extend to new slots and actions. Our goal is to move towards a domain-general task-oriented SDS framework that is ﬂexible enough to expand to new domains and skills by removing domain-speciﬁc assumptions on the dialog state and dialog acts (Bordes and Weston, 2016). To achieve this goal, the neural encoderdecoder model(Cho et al., 2014; Sutskever et al., 2014) is a suitable choice, since it has achieved promising results in modeling open-domain conversations (Vinyals and Le, 2015; Sordoni et al., 2015). It encodes the dialog history using deep neural networks and then generates the next system utterance word-by-word via recurrent neural networks (RNNs). Therefore, unlike the traditional SDS pipeline, the encoder-decoder model is theoretically only limited by its input/output vocabulary. arXiv:1706.08476v1  [cs.CL]  26 Jun 2017  A na`‘ive implementation of an encoderdecoder-based task-oriented system would use RNNs to encode the raw dialog history and generate the next system utterance using a separate RNN decoder. However, while this implementation might achieve good performance in an ofﬂine evaluation of a closed dataset, it would certainly fail when used by humans. There are several reasons for this: 1) real users can mention new entities that do not appear',\n",
       " '1604.04333': 'The last decade of progress on various visual recognition tasks has for the most part been based on the use of SIFT [1] and HOG [2]. The recent success of CNNs is attributed to their ability to learn rich mid-level image representations as opposed to hand-designed low-level features used in other image classiﬁcation methods. [3] has demonstrated that deep CNN features are substantially different from and complementary to those traditional features used in object detection. Searching the parameter space of deep architectures is a difﬁcult task because the training criterion is non-convex and involves many local minima. Nevertheless, deep architecture is capable of automatically learning and fusing rich hierarchical features in an integrated framework. Many techniques, such as Relu [4], Dropout [5], Dropconnect [6], pre-training [7] and data augmentation [8], have been proposed to enhance the performance of deep architectures. Though learning CNN will get into local minima or in a plateau (where due to low curvature the gradients become extremely small), deep convolutional neural networks recently achieved remarkable (a) (b) (c) Fig. 1. Some PASCAL VOC 2007 images. Irrelated regions increase the complexity of CNN learning, which is especially evident in Fig. 1(b) and (c). Figure (a) (b) are labeled as dog and potted plant respectively. Figure (c) has two labels: boat and person. success in many visual recognition tasks, such as image classiﬁcation and object detection, ﬁne-grained recognition, and visual instance retrieval [9]. For the image classiﬁcation task, most of the current deep CNN-based approaches take the whole size-normalized image for input. However, it is very likely that the region of interest in the image may just take a small portion of the image of interest, especially for the object classiﬁcation task of PASCAL VOC dataset. Figure 1 shows some images from the PASCAL VOC 2007 classiﬁcation dataset [10]. Figure 1(a) is a perfect example for whole image input data, which is centered and occupies a large portion of the image. However, Figure 1(b), which is labeled ”potted plant”, would make the learning more complicated for CNN’s use of the whole image as input. The most challenge is that Figure 1(c) has multiple labels. Currently supervised learning CNN takes (data, label) pairs as input; Hence, multiple labeled images would tend to confuse the CNN model. In order to reduce the effect of irrelated regions, we propose a novel framework called latent CNN, which would select the most discriminating region as input for deep CNNs. In this view, latent CNN could also be seen as region-level CNN instead of traditional image-level CNN, which takes the whole size-normalized image as input. One straightforward way to reduce the effect of local minima is to make full use of multiple CNNs with different random initialization [4]. Given multiple CNNs, people simply use majority voting or average the conﬁdence scores from different CNNs. The second contribution in our paper is that we propose a new combination',\n",
       " '1709.05256': 'Face detection plays an important role in the modern face-relevant applications. Despite the great progress made in recent years, the technical challenging of face detection still exists out of the complex variations of real-world face images. As shown in Figure 1, the visual faces vary a lot as the result of the affecting factors including occlusion on the facial part, different scales, illumination conditions, various poses of person, rich expressions, etc. Recently, remarkable advances of objection detection have been driven by the success of region-based methods [1, 2, 3, 4]. Among recent novel algorithms, Fast/Faster R-CNN [3, 4] are representative R-CNN based methods that perform region-wise detections on the regions of interest (RoIs). However, directly applying the strategy of region-speciﬁc operation to fully convolutional networks, such as Residual Nets (ResNets) [5], results in inferior detection performance owing to the overwhelming classiﬁcation accuracy. In contrast, R-FCN [6] is proposed to address the problem in the fully convolutional manner. The ConvNet of R-FCN is built with the computations shared on the entire image, which leads to the improvement of training and testing efﬁciency. Comparing with R-CNN based methods, R-FCN proposes much fewer region-wise layers to balance the learning of classiﬁcation and detection for naturally combining fully convolutional network with region-based module. As a speciﬁc area of generic object detection, face detection has achieved superior performance thanks to the appearance of region-based methods. Previous works primarily focus on the R-CNN based methods and achieve promising results. In this report, we develop a face detector on the top of R-FCN with elaborate design of the details, which achieves more decent performance than the R-CNN face detectors [7, 8]. According to the size of the general face, we carefully design size of anchors and RoIs. Since the contribution of facial parts may be different for detection, we introduce a position-sensitive average pooling to generate embedding features for enhancing discrimination , and eliminate the effect of non-uniformed contribution in each facial part. Furthermore, we also apply the multi-scale training and testing strategy in this work. The on-line hard example mining ∗Corresponding author 1 arXiv:1709.05256v2  [cs.CV]  18 Sep 2017  Figure 1: An example image which has extreme variability in the face regions. Green frames stand for the detection results of the proposed face detector. (OHEM) technique [9] is integrated into our network as well for boosting the learning on hard examples. Our key contributions are summarized below: (1) We develop a face detection framework that takes the special properties of face into account by integrating several innovative and effective techniques. The proposed approach is based on R-FCN and is well suited for face detection, thus we call it Face R-FCN. (2) We introduce a novel position-sensitive average pooling to re-weight embedding responses on score maps and eliminate the effect of non-uniformed contribution in each',\n",
       " '1703.04730': 'A key question often asked of machine learning systems is “Why did the system make this prediction?” We want models that are not just high-performing but also explainable. By understanding why a model does what it does, we can hope to improve the model (Amershi et al., 2015), discover new science (Shrikumar et al., 2017), and provide end-users with explanations of actions that impact them (Goodman & Flaxman, 2016). However, the best-performing models in many domains — e.g., deep neural networks for image and speech recognition (Krizhevsky et al., 2012) — are complicated, blackbox models whose predictions seem hard to explain. Work on interpreting these black-box models has focused on understanding how a ﬁxed model leads to particular predictions, e.g., by locally ﬁtting a simpler model around the test 1Stanford University, Stanford, CA. Correspondence to: Pang Wei Koh <pangwei@cs.stanford.edu>, Percy Liang <pliang@cs.stanford.edu>. Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017 by the author(s). point (Ribeiro et al., 2016) or by perturbing the test point to see how the prediction changes (Simonyan et al., 2013; Li et al., 2016b; Datta et al., 2016; Adler et al., 2016). These works explain the predictions in terms of the model, but how can we explain where the model came from? In this paper, we tackle this question by tracing a model’s predictions through its learning algorithm and back to the training data, where the model parameters ultimately derive from. To formalize the impact of a training point on a prediction, we ask the counterfactual: what would happen if we did not have this training point, or if the values of this training point were changed slightly? Answering this question by perturbing the data and retraining the model can be prohibitively expensive. To overcome this problem, we use inﬂuence functions, a classic technique from robust statistics (Hampel, 1974) that tells us how the model parameters change as we upweight a training point by an inﬁnitesimal amount. This allows us to “differentiate through the training” to estimate in closed-form the effect of a variety of training perturbations. Despite their rich history in statistics, inﬂuence functions have not seen widespread use in machine learning; to the best of our knowledge, the work closest to ours is Wojnowicz et al. (2016), which introduced a method for approximating a quantity related to inﬂuence in generalized linear models. One obstacle to adoption is that inﬂuence functions require expensive second derivative calculations and assume model differentiability and convexity, which limits their applicability in modern contexts where models are often non-differentiable, non-convex, and highdimensional. We address these challenges by showing that we can efﬁciently approximate inﬂuence functions using second-order optimization techniques (Pearlmutter, 1994; Martens, 2010; Agarwal et al., 2016), and that they remain accurate even as the underlying assumptions of differentiability and convexity degrade',\n",
       " '1310.1177': 'In many real world data mining problems, the same instance may appear in different datasets with different representations. Different datasets may emphasize different aspects of instances. An example is grouping the users in an user-oriented recommendation system. For this task, related datasets can be (1) user proﬁle database (as shown in Fig. 1a), (2) users’ log data (as shown in Fig. 1b), and (3) users’ credit score (as shown in Fig. 1c). Learning with such type of data is commonly referred to as multiview learning [1], [2]. Although there are some previous works on multiple datasets, all of them assume the completeness of the different datasets. As far as we know, even the most recently work requires at least one dataset is complete [3]. However, in the real world applications, there are many situations in which complete datasets are not available. For instance, in Fig. 1a, User3 does not complete her proﬁle. However, she has browsing log recorded by the browser. In Fig. 1b, checks and crosses indicates whether user visited the website recently. From the ﬁgure, we can see that User2 and User4 do not have browsing behavior history. This may because that they are new users to the system or they refuse to share the historical behaviors with the system. In Fig. 1c, only User1 and User2 have credit scores in the system. In the situation as shown in Fig. 1, all the previous method will not be applicable. It is very important to ﬁnd an approach that can work for incomplete datasets. In order to deal with the incompleteness of the datasets, it is a natural way to complete the original datasets ﬁrst. However, it is very hard and time-consuming to directly predict the missing features in each dataset especially if there are large number of missing features. Instead, we propose an approach called Collective Kernel Learning (CoKL). This approach iteratively completes the kernel matrix of each dataset using the kernel of other datasets. Basically, CoKL is based on aligning the similarities between examples across all datasets. The completed kernel matrices can be used in any kernel based clustering algorithms. In this paper, we also propose a clustering algorithm based on CoKL and Kernel Canonical Correlation Analysis (KCCA). The proposed clustering algorithm ﬁrst uses CoKL to complete the kernel matrices. Based on the completed kernel matrices, KCCA could ﬁnd the projections that maximize the correlations between the datasets. Then we can perform any standard clustering algorithms on the projected space. As compared with previous papers, this paper has several advantages: 1) The proposed clustering algorithm can be used in situations even when all the datasets are incomplete, in which the other methods are not applicable. 2) Collective kernel learning does not require predicting the missing features in the incomplete datasets using complex method. Predicting the missing features may be very time-consuming when there are large number of missing features. Instead, we construct the full kernel matrices corresponding to the',\n",
       " '1810.01733': 'Recognizing products displayed on store shelves based on computer vision is gathering ever-increasing attention thanks to the potential for improving the customer’s shopping experience (e.g., via augmented reality apps, checkoutfree stores, support to the visually impaired ...) and realizing automatic store management (e.g., automated inventory, on-line shelf monitoring...). The seminal work on product recognition dates back to [12], where Merler et al. highlight the peculiar issues to be addressed in order to achieve a viable approach. First of all, the number of different items to be recognized is (a) - Query (b) - References Figure 1: Given a query image featuring multiple products (a), our system ﬁrst detects the regions associated with the individual items and then recognizes the product enclosed in each region based on a database featuring only one reference image per product (two examples are shown in (b)). All the products are correctly recognized in (a) with bounding boxes colored according to the recognized classes. huge, in the order of several thousands for small to medium shops, well beyond the usual target for current state-of-theart image classiﬁers. Moreover, product recognition can be better described as a hard instance recognition problem, rather than a classiﬁcation one, as it deals with lots of objects looking remarkably similar but for small details (e.g., different ﬂavors of the same brand of cereals). Then, any practical methodology should rely only on the information available within existing commercial product databases, i.e. at most just one high-quality image for each side of the package, either acquired in studio settings or rendered (see Figure 1-(b)). Query images for product recognition are, instead, taken in the store with cheap equipment (e.g., a smart-phone) and featuring many different items displayed on a shelf (see Figure 1-(a)). Unfortunately, this scenario is arXiv:1810.01733v3  [cs.CV]  27 Jan 2019  far from optimal for state-of-the-art multi-class object detectors based on deep learning [15, 9, 16], which require a large corpus of annotated images as similar as possible to the deployment scenario in order to provide good performance. Even acquiring and manually annotating with product labels a huge dataset of in-store images is not a viable solution due to the products on sale in stores, as well as their appearance, changing frequently over time, which would mandate continuous gathering of annotated in-store images and retraining of the system. Conversely, a practical approach should be trained once and then be able to handle seamlessly new stores, new products and/or new packages of existing products (e.g., seasonal packages). To tackle the above issues, we address product recognition by a pipeline consisting of three stages. Given a shelf image, we perform ﬁrst a class-agnostic object detection to extract region proposals enclosing the individual product items. This stage relies on a deep learning object detector trained to localize product items within images taken',\n",
       " '1812.02171': 'Extractive summarisation is the task of selecting a few representative documents from a larger collection. In this paper, we consider comparative summarisation: given groups of document collections, the aim is to select documents that represent each group, but also highlight diﬀerences between groups. This is in contrast to traditional document summaries which aim to represent each group by independently optimising for coverage and diversity, without considering other groups. As a concrete example, given thousands of news articles per month on a certain topic, groups can be formed by publication time, by source, or by political leaning. Comparative summarisation systems can then help answer user questions such as: what is new on the topic of climate change this week, what is diﬀerent between the coverage in NYTimes and BBC, or ∗Now at Google Research. time Feb 2018 Mar 2018 News Media AAAI Times ML Daily News World News CS Press   Local News Figure 1: An illustrative example of comparative summarisation. Squares are news articles, rows denote diﬀerent news outlets, and the x-axis denotes time. The shaded articles are chosen to represent AI-related news during Feb and March 2018, respectively. They aim to summarise topics in each month, and also highlight diﬀerences between the two months. what are the key articles covering the carbon tax and the Paris agreement? In this work, we focus on highlighting changes within a long running news topic over time; see Figure 1 for an illustration. Existing methods for extractive summarisation use a variety of formulations such as structured prediction (Li et al. 2009), optimisation of submodular functions (Lin and Bilmes 2011), dataset interpretability (Kim, Khanna, and Koyejo 2016), and dataset selection via submodular optimisation (Mirzasoleiman, Badanidiyuru, and Karbasi 2016; Wei, Iyer, and Bilmes 2015; Mitrovic et al. 2018). Moreover, recent formulations of comparative summarisation use discriminative sentence selection (Wang et al. 2012; Li, Li, and Li 2012), or highlight diﬀerences in common concepts across documents (Huang, Wan, and Xiao 2011). But the connections and distinctions of these approaches has yet to be clearly articulated. To evaluate summaries, traditional approaches employ automatic metrics such as ROUGE (Lin 2004) on manually constructed summaries (Lin and Hovy 2003; Nenkova, Passonneau, and McKeown 2007). This is diﬃcult to employ for new tasks and new datasets, and does not scale. Our approach to comparative summarisation is based on a novel formulation of the problem in terms of two competing classiﬁcation tasks. Speciﬁcally, we formulate the problem as ﬁnding summaries for each group such that a powerful classiﬁer can distinguish them from documents belonging to arXiv:1812.02171v2  [cs.IR]  2 Jan 2020  other groups, but cannot distinguish them from documents belonging to the same group. We show how this framework encompasses an existing nearest neighbour objective for summarisation, and propose two new objectives based on the maximum mean discrepancy (Gretton et al. 2012) – mmd-diﬀ which emphasises classiﬁcation accuracy and mmd-div which emphasises summary diversity – as well as new gradientbased optimisation strategies for these objectives',\n",
       " '1401.0978': 'The measure of integrated information, φ, is an attempt to a quantify a neural network’s magnitude of conscious experience. It has a long history [1,4,5], and at least three diﬀerent measures have been called φ. Conceptually, the φ measure aims to quantify a system’s “functional irreducibility to disjoint parts”. Although innovative, the φ measure from [1] has some peculiarities. Using Partial Information Decomposition (PID), we derive a principled info-theoretic measure of irreducibility to disjoint parts [6]; our PID-derived measure, ψ, has numerous desirable properties over the φ from [1]. We aim for ψ to be a principled, well-behaved φ-like measure that resides purely within Shannon information theory. We compare ψ to the older φ measure from [1] because it is the most recent purely information-theoretic φ. We recognize that the most recent version of φ [5] knowingly and purposely sits outside standard information theory.1,2 2 Preliminaries We use the following notation throughout. n: the number of indivisible elements in network X. n ≥2. P: a partition of the n indivisible nodes clustered into m parts. Each part has at least one node and each partition has at least two parts, so 2 ≤m ≤n. XP i : a random variable representing a part i at time=0. 1 ≤i ≤m. Y P i : a random variable representing part i after t updates. 1 ≤i ≤m. X: a random variable representing the entire network at time=0. X ≡XP 1 · · · XP m. 1The most recent version of φ [5] utilizes the Earth Mover’s Distance among states and thus varies with the chosen labels of the states. Although less of an issue for binary systems, a canonical property of information theories spanning from Shannon to Kolmogorov (algorithmic information theory) is invariance under relabeling of states. 2If one wished to use ψ within the larger “big phi” conceptual framework per [5] you would replace all instances of the measure “small phi” with ψ. 1 arXiv:1401.0978v3  [cs.IT]  9 Oct 2014  Y : a random variable representing the entire network after t applications of the neural network’s update rule. Y ≡Y P 1 · · · Y P m . y: a single state of the random variable Y . X: The set of the n indivisible elements at time=0. For readers accustom to the notation in [1] the translation is: X ≡X0, Y ≡X1, XP i ≡M i 0, and Y P i ≡M i 1. For pedagogical purposes we conﬁne this paper to deterministic neural networks. Therefore all remaining entropy at time t conveys information about the past, i.e., I(X :Y ) = H(Y ) and I \\x00X :Y P i \\x01 = H \\x00Y P i \\x01 where I(•:•) is the mutual information and H(•) is the Shannon entropy [7]. Our model generalizes to probabilistic units with any ﬁnite number of discrete— but not continuous—states [8]. All calculations are in bits. 2.1 Model Assumptions (A) The φ measure',\n",
       " '1511.07356': 'Recent progress in computer vision has been driven by the use of large convolutional neural networks. Such networks beneﬁt from alternating convolution and pooling layers [16, 23, 22, 29, 24, 27, 42] where the pooling layers serve to summarize small regions of the layer below. The operations of convolution, followed by max-pooling, then decimation cause features in subsequent layers of the network to be increasingly translation invariant, more robust, and to more coarsely summarize progressively larger regions of the input image. As a result, features in the fourth or ﬁfth convolutional layer serve as more robust detectors of more global, but spatially imprecise high level patterns like text or human faces [37]. In practice these properties are critical for many visual tasks, and they have been particularly successful at enabling whole image classiﬁcation [16, 29, 24]. However, for other types of vision tasks these architectural elements are not as well suited. For example on tasks requiring pixel-precise localization or labeling, features arising from max-pooling and decimation operations can only provide approximate localization, as in the process of creating them, the network has already thrown out precise spatial information by design. If we wish to generate features that preserve accurate localization, we may do so using shallow networks without max-pooling, but shallow networks without pooling cannot learn robust, invariant features. What we would like is to have our cake and eat it too: to combine the best of both worlds, merging ﬁnelylocalized information from shallow, non-pooled networks with robust, coarsely-localized features computed by deep, pooled networks. Several recently proposed approaches [17, 13, 31] address this by adding or concatenating the features obtained across multiple levels. We use this approach in our baseline model termed SumNet for our task of interest: facial keypoint localization. To the best of our knowledge this is the ﬁrst time this general approach has been applied to the problem of facial keypoint localization and even our baseline is capable of yielding state of the art results. A possible weakness of these approaches however is that all detection paths, from coarsely to ﬁnely localized features, only become aggregated at the very end of the feature processing pipeline. As a thought experiment to illustrate this approach’s weakness, imagine that we have a photo of a boat ﬂoating in the ocean and would like to train a convnet to predict with single pixel accuracy a keypoint corresponding to the tip of the boat’s bow. Coarsely localized features1 could highlight the rough region of the bow of the boat, and ﬁnely localized features could be tuned to 1From now on we use the shorthand ﬁne/coarse features to mean ﬁnely/coarsely localized features. 1 arXiv:1511.07356v2  [cs.CV]  17 Apr 2016  Figure 1. (Left) Architecture of summation based coarse-ﬁne network (SumNet). C is a convolutional layer. P,C represents a pooling la',\n",
       " '1802.02488': 'W ITH the fast development of Internet and multimedia technologies, heterogeneous multimedia data including image, video, text and audio, has been growing very fast and enriching people’s life. To make better use of such rich multimedia data, it is an important application to retrieve multimedia contents that users have interests in. Thus multimedia retrieval has attracted much attention over the past decades. This work was supported by National Natural Science Foundation of China under Grants 61771025 and 61532005. The authors are with the Institute of Computer Science and Technology, Peking University, Beijing 100871, China. Corresponding author: Yuxin Peng (e-mail: pengyuxin@pku.edu.cn). Text Although dogs are the most  closely related canids to gray  wolves  (the  sequence  divergence  between  gray  wolves and dogs is only  1.8%, as opposed to over 4%  between gray wolves... Early technological progress  owed much to the firm of  Broadwood. John Broadwood  joined with another Scot,  Robert  Stodart,  and  a  Dutchman, Americus Backers  ... The oldest remains of a tigerlike  cat,  called  Panthera  palaeosinensis,  have  been  found in China and Java. This  species lived about 2 million  years ago.... Image The  word  Panthera  is  probably of Oriental origin  and  retraceable  to  the  Ancient Greek word panther,  the Latin word panthera, the  Old French word pantere,  most likely meaning ... Hashing  Functions Bucket Hashing Tables Indexed cross-modal data 0001... ... 0110... ... Bucket Indexed cross-modaldata ... ... 0011... ... This  reclassification  has  implications  for  conservation. If there are two  separate species, each will be  less abundant (particularly  the rarer) and could be more  endangered than . This  reclassification  has  implications  for  conservation. If there are two  separate species, each will be  less abundant (particularly  the rarer) and could be more  endangered than . Although dogs are the most  closely related canids to gray  wolves  (the  sequence  divergence  between  gray  wolves and dogs is only  1.8%, as opposed to over 4%  between gray wolves... Fig. 1. An example of cross-modal hashing with image and text, which projects data of different modalities into a common hamming space and performs fast retrieval. However, with the explosive increase of multimedia data on the Internet, efﬁcient retrieval from large scale databases has become an urgent need and a big challenge. To tackle this problem, many hashing methods [1]–[8] have been proposed to perform efﬁcient yet effective retrieval. Generally speaking, hashing methods aim to transfer high dimensional feature into short binary codes so that similar data can have similar binary codes. Hashing methods have two major advantages when applied in multimedia retrieval: (1) Binary codes enable fast Hamming distance computation based on bit operations which can be efﬁciently implemented. (2) Binary codes take much less storage compared with original high dimensional feature. A large amount of hashing methods are designed for single modality retrieval [1]–[8], that is to say, data can only be retrieved by an query of the same modality, such as image retrieval [3] and video retrieval [9]. However, in real world applications, multimedia data is usually presented with',\n",
       " '1708.07455': 'Emergencies are a major cause of both human and economic loss. They vary in scale and magnitude, from small trafﬁc accidents involving few people, to full-scale natural disasters which can devastate countries and harm thousands of people. Emergency management has become very important to reduce the impact of emergencies. As a consequence, using modern technology to implement innovative solutions to prevent, mitigate, and study emergencies is an active ﬁeld of research. The presence of digital cameras has grown explosively over the last two decades. Camera systems perform real-time recording of visual information in hotspots where an accident or emergency is likely to occur. Examples of such systems are cameras on the road, national parks, inside banks, shops, airports, metros, streets and swimming pools. In Figure 1 we give some examples of frames from videos that could potentially be recorded by some of these monitoring systems. It is estimated that as of 2014 there were over 245 arXiv:1708.07455v2  [cs.CV]  9 Mar 2018  2 Laura Lopez-Fuentes et al. Fig. 1: Example frames from videos that could potentially be recorded to detect different emergencies: a factory being monitored to for rapid ﬁre detection [156], a street monitored to detect ﬂoods [16], a surveillance camera on a pool to detect drowning persons, [26] and a vehicle with on board camera for driver assistance [69]. million active, operational and professionally installed video cameras around the world [76]. Mounting these video cameras has become very cheap but there are insufﬁcient human resources to observe their output. Therefore, most of the data is being processed after an emergency has already occurred, thus losing the beneﬁt of having a real-time monitoring tool in the ﬁrst place. The problem of real-time processing of the visual output from monitoring systems in potential emergency scenarios has become a hot topic in the ﬁeld of computer vision. As we will show in this review, computer vision techniques have been used to assist in various stages of emergency management: from prevention, detection, assistance of the response, to the understanding of emergencies. A myriad of algorithms has been proposed to prevent events that could evolve into disaster and emergency situations. Others have focused on fast response after an emergency has already occurred. Yet other algorithms focus on assisting during the response to an emergency situation. Finally, several methods focus on improving our understanding of emergencies with the aim of predicting the likelihood of an emergency or dangerous situation occurring. This review provides a broad overview of the progress of computer vision covering all sorts of emergencies. The review is organized in four main axes along which researchers working on the topic of computer vision for emergency situations have organized their investigations. The ﬁrst axis relates to the type of emergency being addressed, and the most important division along this axis is the distinction between natural and man-made emergencies. The second',\n",
       " '1806.03547': 'Phase retrieval refers to the problem of recovering an unknown N-dimensional signal vector x ∈HN, with H being the set of either real (R) or complex (C) numbers, from the following nonlinear measurement process: y = f(Ax + ez) + ey. (1) Here, the measurement vector y ∈RM contains M realvalued observations, for example measured through the nonlinear function f(z) = |z|2 that operates element-wise on vectors, A ∈HM×N is a given measurement matrix, and the vectors ez ∈HM and ey ∈RN model signal and measurement noises, respectively. In contrast to the majority of 1School of Electrical and Computer Engineering, Cornell University, Ithaca, NY 2Department of EE, Princeton University 3University of Maryland. Correspondence to: Ramina Ghods <rg548@cornell.edu>, Christoph Studer <studer@cornell.edu>. Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018 by the author(s). existing results on phase retrieval that assume randomness in the measurement matrix A, we focus on the practical scenario in which the measurement matrix A is deterministic, but the signal vector x to be recovered as well as the two noise sources ez and ey are random. 1.1. Phase Retrieval Phase retrieval has been studied extensively over the last decades (Gerchberg & Saxton, 1972; Fienup, 1982) and ﬁnds use in a range of applications, including imaging (Fogel et al., 2016; Yeh et al., 2015; Holloway et al., 2016), microscopy (Kou et al., 2010; Faulkner & Rodenburg, 2004), and X-ray crystallography (Harrison, 1993; Miao et al., 2008; Pfeiffer et al., 2006). Phase retrieval problems were solved traditionally using alternating projection methods, such as the Gerchberg-Saxton (Gerchberg & Saxton, 1972) and Fienup (Fienup, 1982) algorithms. More recent results have shown that semideﬁnite programming enables the design of algorithms with performance guarantees (Cand`es et al., 2013; Cand`es & Li, 2014; Cand`es et al., 2015a; Waldspurger et al., 2015). These methods lift the problem to a higher dimension, resulting in excessive complexity and memory requirements. To perform phase retrieval for highdimensional problems with performance guarantees, a range of convex (Bahmani & Romberg, 2017; Goldstein & Studer, 2017; Hand & Voroninski, 2016; Dhifallah et al., 2017; Dhifallah & Lu, 2017; Yuan & Wang, 2017; Salehi et al., 2018) and nonconvex methods (Netrapalli et al., 2013; Schniter & Rangan, 2015; Cand`es et al., 2015b; Chen & Cand`es, 2015; Zhang & Liang, 2016; Wang et al., 2017a; Zhang et al., 2016; Wei, 2015; Sun et al., 2016; Zeng & So, 2017; Lu & Li, 2017; Ma et al., 2018) have been proposed recently. 1.2. Spectral Initializers All of the above non-lifting-based phase retrieval methods rely on accurate initial estimates of the signal vector to be recovered. Such estimates are typically obtained by means of so-called spectral initializers put forward in (Netrapalli et al., 2013). Spectral initializers ﬁrst compute a Hermitian matrix of the following form: Dβ = β M X m=1 T (ym)amaH m, (2) arXiv:1806.03547v1  [cs',\n",
       " '1811.01057': 'Many state-of-the-art classiﬁers have been shown to fail catastrophically in the presence of small imperceptible but adversarial perturbations. Since the discovery of such adversarial examples [25], numerous defenses have been proposed in attempt to build classiﬁers that are robust to adversarial examples. However, defenses are routinely broken by new attackers who adapt to the proposed defense, leading to an arms race. For example, distillation was proposed [22] but shown to be ineffective [5]. A proposed defense based on transformations of test inputs [20] was broken in only ﬁve days [2]. Recently, seven defenses published at ICLR 2018 fell to the attacks of Athalye et al. [3]. A recent body of work aims to break this arms race by training classiﬁers that are certiﬁably robust to all attacks within a ﬁxed attack model [13, 23, 29, 8]. These approaches construct a convex relaxation for computing an upper bound on the worst-case loss over all valid attacks—this upper bound serves as a certiﬁcate of robustness. In this work, we propose a new convex relaxation based on semideﬁnite programming (SDP) that is signiﬁcantly tighter than previous relaxations based on linear programming (LP) [29, 8, 9] and handles arbitrary number of layers (unlike the formulation in [23], which was restricted to two). We summarize the properties of our relaxation as follows: 1. Our new SDP relaxation reasons jointly about intermediate activations and captures interactions that the LP relaxation cannot. Theoretically, we prove that there is a square root dimension gap between the LP relaxation and our proposed SDP relaxation for neural networks with random weights. 2. Empirically, the tightness of our proposed relaxation allows us to obtain tight certiﬁcates for foreign networks—networks that were not speciﬁcally trained towards the certiﬁcation procedure. For instance, adversarial training against the Projected Gradient Descent (PGD) attack [21] has led to networks that are “empirically” robust against known attacks, but which have only been certiﬁed against small perturbations (e.g. ϵ=0.05 in the ℓ∞-norm for the MNIST dataset [9]). We use our SDP 32nd Conference on Neural Information Processing Systems (NIPS 2018), Montréal, Canada. arXiv:1811.01057v1  [cs.LG]  2 Nov 2018  to provide the ﬁrst non-trivial certiﬁcate of robustness for a moderate-size adversarially-trained model on MNIST at ϵ=0.1. 3. Furthermore, training a network to minimize the optimum of particular relaxation produces networks for which the respective relaxation provides good robustness certiﬁcates [23]. Notably and surprisingly, on such networks, our relaxation provides tighter certiﬁcates than even the relaxation that was optimized for during training. Related work. Certiﬁcation methods which evaluate the performance of a given network against all possible attacks roughly fall into two categories. The ﬁrst category leverages convex optimization and our work adds to this family. Convex relaxations are useful for various reasons. Wong and Kolter [29], Raghunathan et al. [23] exploited the theory of duality to train certiﬁably robust networks on MNIST. In recent work, Dvijotham et al',\n",
       " '1901.05574': 'Sequence classiﬁcation is a fundamental problem in Big Data analysis. Recent advances in Recurrent Neural Networks (RNNs) have achieved convincing results for such classiﬁcation tasks. During the training process, RNN models capture the discriminating patterns that distinguishing them from different categories. It is thus increasingly used in many real-world domains such as funnel optimization for digital marketing, click-stream analysis for online purchase prediction, and patient treatment data analysis for medical recovery predictions. Despite the popularity of RNN techniques, it can be challenging to understand what and how features are interpreted in learning with a high-performing model. As shown in Figure 1, one can encode multidimensional features as one-hot vectors, with categorical or numerical values vary at each element along the temporal (horizontal) axis and the data instance (vertical) axis. It is important to understand which features contribute more and how they contribute to the learning of RNN models in different scenarios. In practice, analysts have difﬁculties in feature selection. Knowing which features contribute to high-performance helps analysts to select meaningful attributes during training. Also, the reasoning of important features can provide guidelines to business goals. For example, in sales performance management, analysts want to understand what kind of behavior, such as visiting or emailing, can help improve sales performance [1]. In this work, we focus on the visual reasoning of feature attribution for RNN models, motivated by the practical need in customer churn prediction and prevention. Analysts try to understand what customer service behaviors and their associated factors may lead to a high risk of churning for maintaining good customer relationship and increase customer loyalty. LSTM . . .  LSTM LSTM h1 h2 h3 x0 ai,0 ai,0 ai,0 softmax x1 x2 D-dimensional Vector   xt Temporal Sequence . . . . . . Training Data . . .  . . .  Class . . Fig. 1. Training data instances: sequences of one-hot vectors and associated classes. Each dimension in the one-hot vectors represents a feature type. Distilled from our interactions with the analysts, here are three challenges when building a visual analytics solution. Pattern Discovery from Multivariate Temporal Sequences. The training data is both complex in the feature dimensionality and in their temporal variance. Comparing the importance of different attributes helps in determining what aspects to address for achieving a certain analytics goal, and clarifying their value level contributions explains how. Analysts try to discover the effect of each attribute as well as the combined attributes. The value levels of these attributes change over time. Because RNNs are known to be able to learn the temporal patterns, the discovery of the contribution of temporal sequences becomes essential. Mixture of Attribute Types. Real-world dataset often contains three attribute types: numerical, categorical and ordinal. From the visual encoding perspective, it is challenging to unify the design for comparing across multiple types. Multidimensional sequence. Sequence data are often associated with metadata describing the result or consequence of the change in attributes over time. Merely visualizing the sequences themselves is insufﬁcient in revealing',\n",
       " '1609.02646': 'Role discovery is a developing area that allows the simpliﬁcation of graphs in a user-interpretable way. Consider a graph of n nodes speciﬁed in an adjacency 1 arXiv:1609.02646v1  [cs.AI]  9 Sep 2016  matrix A. Earlier eﬀorts convert this matrix into a new n × f matrix V so that each node in the graph has a list of f features [22]. Role discovery is then the computation of converting V so that each node/user is mapped to a combination of roles (denoted by the n × r matrix G) and each role is deﬁned with respect to the f features (denoted by the r × f matrix F). This is accomplished by performing a non-negative matrix factor decomposition as shown below: argmin G,F ||V −GF||2 subject to: G ≥0, F ≥0 (1) The n × r matrix G when read row-wise indicates which of the r roles each node plays and to what degree. The r × f matrix F when read row-wise deﬁnes each of the r roles with respect to the f features. The entries in G and F are non-negative real numbers signifying that each node can play each role to varying degrees and that diﬀerent features deﬁne a role in varying degrees. This simpliﬁcation of graphs into roles is not only intuitive for a domain expert, but it has been shown to be useful in a number of interesting settings including prediction, transfer learning, and sense making [21]. Limitations in Existing Work. However, all work developed so far has two limitations. Firstly, role discovery has been typically completely unsupervised in that the domain expert cannot easily inject their expertise and expectations into the simpliﬁcation and secondly role discovery is typically performed on a single relational graph. We now discuss each limitation in turn. Consider a domain expert that is looking for the simplest explanation of a graph during their exploratory phase of analysis. Existing work cannot specify how to emphasize this simplicity apart from requiring a small number of roles to be used. Other forms of parsimonious guidance such as requiring a node only be assigned to a few roles or making each role deﬁned by only a small set of features is desirable but currently not possible. Similarly, if a decomposition yields a set of roles that are not actionable, not interesting or already known, the domain expert cannot enforce an alternative set of roles. These two recent trends in data mining – exploring the addition of positive and negative guidance – have been shown to have wide-scale application in the data mining literature [5][36]; but to our knowledge have not been applied to role discovery. Hence this work marks the ﬁrst paper exploring guided role discovery. To our knowledge previous work in role discovery only focuses on simple graphs with a single relational type. Conversely, many datasets are either directly multi-relational or can be modeled as a multi-relational graph. Consider an email graph',\n",
       " '1710.03839': 'Instead of the colors “blue” and “green”, imagine a language with the concepts of “grue”, which describes something that is green during the daytime and blue at night, and “bleen”, which is blue by day and green by night [1]. The Grue language looks unnecessarily complex to us, as we would have to describe a blue-eyed person as bleen-eyed by day and grue-eyed at night. However, one can imagine that the Grue-speaking people are familiar with two types of jellyﬁsh: a poisonous, grue-colored species and a non-poisonous, bleencolored species. They would ﬁnd our language inconvenient because of cumbersome warnings to avoid “green during the day and blue at night”-jellyﬁsh. Which set of concepts is simpler ultimately depends on the types of observations one is trying to characterize and this can be formalized with the concept of informational synergy. Synergy is colloquially deﬁned as a situation where the “whole is more than the sum of its parts.” To predict the current visual appearance of a green object from a description in the Grue language requires knowing whether the object is grue or bleen and whether it is currently night or day. Knowing either fact alone imparts no information. This mirrors the canonical example of synergy, the XOR gate on binary random variables with X = Z1 ⊕Z2, where either input, Zj, alone is uninformative about X while both together perfectly determine X. The focus of this work is to explore whether synergy can be useful in the context of unsupervised learning. Just as different languages can exhibit more or less synergy while being equally expressive, latent variable models can exhibit more or 1 University of Southern California, Information Sciences Institute gregv@isi.edu, brekelma@usc.edu, galstyan@isi.edu 2 Yerevan State University, hrayr@yerevann.com less synergy while being equally predictive. We thus introduce the principle of minimum synergy (MinSyn) for representation learning. We expect minimally synergistic representations to be more interpretable since each learned latent variable is encouraged to be individually informative about predicted observations. Disentangling factors of variation is often cited as a goal for unsupervised learning [2], but pinning down this hazy concept has proven difﬁcult. Statistical independence of latent factors is often used as a proxy for disentangling [3], [4], but we demonstrate how independence-based approaches can fail to recover true structure while an approach based on synergy minimization succeeds. After reviewing various attempts to deﬁne a well-behaved information-theoretic measure of synergy [5], [6], [7], [8], we identify a candidate measure which is well suited to our unsupervised representation learning problem and derive concrete formulations for the Gaussian and binary cases. We introduce an intuitive benchmark task where we train a model on images of handwritten words and check whether factors are learned that correspond to individual characters. MinSyn learning correctly disentangles the characters while other methods fail. We conclude with a discussion of open questions for using synergy to improve representation learning. II. QUANTIFYING SYNERGY While there is no consensus on the correct way to measure',\n",
       " '1808.01124': 'Content-based image retrieval (CBIR) has been always drawing attention from researchers working on image analysis and pattern recognition within computer vision ﬁeld. Texture, i.e. a powerful image feature involving repeated patterns which can be recognized by human vision, plays a signiﬁcant role in most of CBIR systems. Constructing eﬃcient texture descriptors to characterize the image becomes one of the key components which have been focused in most research works related to texture image retrieval [1,2,3]. From the literature, a great number of multiscale texture analysis methods using probabilistic approach have been developed to tackle retrieval task. In [4], the authors proposed to model the spatial dependence of pyramidal discrete wavelet transform (DWT) coeﬃcients using the generalized Gaussian distributions (GGD) and the dissimilarity measure between images was derived based on the Kullback-Leibler divergences (KLD) between GGD models. Sharing the similar principle, multiscale coeﬃcients yielded by the discrete cosine transform (DCT), the dual-tree complex wavelet transform (DT-CWT), the Gabor Wavelet arXiv:1808.01124v1  [cs.CV]  3 Aug 2018  (GW), etc. were modeled by diﬀerent statistical models such as GGD, the multivariate Gaussian mixture models (MGMM), Gaussian copula (GC), Student-t copula (StC), or other distributions like Gamma, Rayleigh, Weibull, Laplace, etc. to perform texture-based image retrieval [5,6,7,8,9,10,11]. However, one of the main drawbacks of these techniques is the their expensive computational time which has been observed an discussed in several papers [8,9,10]. Other systems which have provided eﬀective CBIR performance include the local pattern-based framework and the block truncation coding (BTC)-based approach. The local binary patterns (LBP) were ﬁrst embedded in a multiresolution and rotation invariant scheme for texture classiﬁcation in [12]. Inspired from this work, many studies have been developed for texture retrieval such as the local maximum edge binary patterns (LMEBP) [13], local ternary patterns (LTP) [14], local tetra patterns (LTrP) [15], local tri-directional patterns (LTriDP) [16], local neighborhood diﬀerence pattern (LNDP) [17], etc. These descriptors, in particular LTrP and LTRiDP, can provide good retrieval rate. However, due to the fact that they work on grayscale images, their performance on natural textures is limited without using color information. To overcome this issue, recent schemes have proposed to incorporate these local patterns with color features. Some techniques can be mentioned here are the joint histogram of color and local extrema patterns (LEP+colorhist) [18], the local oppugnant color texture pattern (LOCTP) [19], the local extrema co-occurrence pattern (LECoP) [20], LBPC for color images [21]. Beside that, many studies have also developed diﬀerent BTC-based frameworks, e.g. the ordered-dither BTC (ODBTC) [22,23], the error diﬀusion BTC (EDBTC) [24] and the dot-diﬀused BTC (DDBTC) [25], which have provided competitive retrieval performance. Within these approaches, an image is divided into multiple non-overlapping blocks and each one is compressed into the so-called color quantizer and bitmap image. Then, a feature descriptor',\n",
       " '1809.10097': 'R GB-D sensors have become very popular for 3Dreconstruction, in view of their low cost and ease of use. They deliver a colored point cloud in a single shot, but the resulting shape often misses thin geometric structures. This is due to noise, quantisation and, more importantly, the coarse resolution of the depth map. In comparison, the quality and resolution of the companion RGB image are substantially better. For instance, the Asus Xtion Pro Live device delivers 1280 × 1024 RGB images, but only up to 640 × 480 depth maps. The depth map thus needs to be upsampled to the same resolution of the RGB image, and the latter could be analysed photometrically to reveal ﬁne-scale details. However, super-resolution of a solitary depth map without additional contraints is an ill-posed problem, and retrieving geometry from either a single color image (shapefrom-shading) or from a sequence of color images acquired under unknown, varying lighting (uncalibrated photometric stereo) is another ill-posed problem. The present study explores the resolution of both these ill-posedness issues by jointly performing depth super-resolution and photometric 3D-reconstruction. We call this combined approach photometric depth super-resolution. The choice of jointly solving both these classic inverse problems is motivated by the observation that illposedness in depth super-resolution and in photometric 3D-reconstruction have different peculiarities and origins. In depth super-resolution, constraints on high-frequency shape variations are missing (there exist inﬁnitely many ways to interpolate between two measurements), while lowfrequency (e.g., concave-convex or bas-relief) ambiguities ∗Equal contribution • B. Haefner, A. Verma, and D. Cremers are with the Department of Computer Science, Technical University of Munich, 80333, Germany. E-mail: {bjoern.haefner,alok.verma,cremers}@tum.de • S. Peng is with Advanced Digital Sciences Center, University of Illinois at Urbana-Champaign, Singapore, 138602. E-mail: songyou.peng@adsc-create.edu.sg • Y. Qu´eau is with the GREYC laboratory, UMR CNRS 6072, Caen, France. E-mail: yvain.queau@ensicaen.fr arise in photometric 3D-reconstruction. Therefore, the lowfrequency geometric information necessary to disambiguate photometric 3D-reconstruction should be extracted from the low-resolution depth measurements and, symmetrically, the high-resolution photometric clues in the RGB data should provide the high-frequency information required to disambiguate depth super-resolution. One hand thus washes the other: ill-posedness in depth super-resolution is fought using photometric 3D-reconstruction, and vice-versa. As we shall see in Section 2, the photometric depth super-resolution problem comes down to simultaneously inferring high-resolution depth and reﬂectance maps, given the low-resolution depth and the high-resolution RGB images. As depicted in Figure 1, this study explores three different strategies for such a task1. The rest of this paper discusses them by increasing order of efﬁciency which, unfortunately, is inversely proportional to the amount of required resources. 1) If the available resources consist of a single RGB-D frame, then',\n",
       " '1411.7666': '1 Chapter 2. Classical Channels 5 1. As Maps 5 2. As Relations 7 3. As Graphs 10 4. Independence Numbers 13 5. Shannon Capacities 15 6. Chromatic Numbers 17 Chapter 3. General Channels 20 1. As Maps 20 2. As Relations 22 3. As Graphs 24 Chapter 4. Quantum Channels 27 1. As Maps 27 2. As Relations 29 3. As Graphs 33 4. Graph Invariants 36 ii  Chapter 5. My Results 38 1. Slopes/Eigenvalues 38 2. Tropicality/Cyclicality 39 3. Subgraphs/Colors 43 4. Ceilings/Steplogs 46 5. Partitions/Constructions 48 6. Independence/Chromatic 50 7. Corollaries/Conjectures 51 Bibliography 53 iii  Abstract First, I introduce quantum graph theory. I also discuss a known lower bound on the independence numbers and derive from it an upper bound on the chromatic numbers of quantum graphs. Then, I construct a family of quantum graphs that can be described as tropical, cyclical, and commutative. I also deﬁne a step logarithm function and express with it the bounds on quantum graph invariants in closed form. Finally, I obtain an upper bound on the independence numbers and a lower bound on the chromatic numbers of the constructed quantum graphs that are similar in form to the existing bounds. I also show that the constructed family contains graphs of any valence with arbitrarily high chromatic numbers and conclude by it that quantum graph colorings are quite different from classical graph colorings. iv  CHAPTER 1 Introduction There are two halves of the theory behind quantum computers. One of those halves is quantum computation, the quantum equivalent of the work of Turing and others. Included in quantum computation is the study of quantum algorithms, such as Grover’s and Shor’s algorithms, as well as the study of quantum gates and circuits. The other half is quantum information, the quantum equivalent of the work of Shannon and others. Included in quantum information is the quantum codes, such as the Shor and Steane codes, as well as the study of quantum operations and noise. It is within quantum information that this thesis ﬁrmly lies. The tools used in this thesis can be broadly categorized as operator theory, coding theory, or graph theory, corresponding roughly to the ﬁelds of physics, computer science, and mathematics which all contribute to quantum information theory. As such, there are three different stories to tell before I can present my results. There are many equivalent ways to present the principles of quantum mechanics. One such way is as a non-commutative probability theory which is consistent with the Copenhagen interpretation. In quantum probability, a probabilistic system has an algebra of random variables that forms a von Neumann algebra; these algebras were ﬁrst described by von Neumann, who, with Murray, showed that they are generalizations of classical measure spaces [12]. Similarly, Weaver shows that von Neumann algebras can be used to deﬁne a quantum generalization of classical relations [19]. The interpretation of a von Neumann algebra in quantum mechanics is as',\n",
       " '1412.7056': 'In most clustering algorithms, the objects are assumed to be embedded in a normed linear space, and similarity is measured by a distance-like function. Among many diﬀerent options, this can be followed by construction of a weighted graph in which similar points are joined by strong edges. Then, using tools from spectral graph theory, it is possible to ﬁnd the clusters as connected graph components [5]. In contrast, subspace clustering techniques take a diﬀerent perspective on the geometry of clustering. In these approaches, points are assumed to come from a union of subspaces rather than from disjoint, volume-ﬁlling clusters. For subspace clustering methods using spectral graph theory as a ﬁnal step (which many do), any relevant notion of similarity should reﬂect whether points belong to the same subspace. Simple variations on distance are no longer eﬀective. For this problem, a diverse array of subspace clustering methods [29], such as Sparse Subspace Clustering (SSC), can be employed to resolve the clusters. Some even reject outliers [10,13,14,25]. For clustering data with two-way structure, such as images, typical subspace clustering methods must unfold the data or map it to a vector. This approach sacriﬁces the two-way structure, potentially failing to exploit useful information. Outside of subspace clustering, on the other hand, many methods take advantage of multi-way array structure, particularly for dimensionality reduction or ﬁnding the best (single) subspace in which to approximate the data. For examples of these, see [12,11,9,27] and references therein. We know of no work exploiting multi-way structure in techniques similar to subspace clustering, and our goal is to ﬁll that gap. In this paper we present a novel algebraic approach for clustering multi-way data. Whereas existing subspace clustering methods concatenate data as columns of a matrix, our method will group the data into a three-way array (a tensor), clustering slices of the tensor. Using the tensor products and factorizations outlined in [18], we will extend Sparse Subspace Clustering [10] for use on tensor data. Although our strategy could process N-way (N > 2) data by incorporating technical tools in the style of [22], we chose to focus this work on clustering only two-way data. We will demonstrate that this new model is able to achieve higher accuracies than previous solutions, especially for data that has undergone less preprocessing. Before we begin with necessary background in Section 2 we would like to summarize our main contributions below. Our contributions: First, we propose a new algebraic generative model, based on a characterization of third order tensors from [8] as operators, via multiplication called the t-product introduced in [19], on a space of oriented matrices. This model is explained in Sections 2.2.1 and 3. For inference with our model, we propose a novel clustering algorithm in Section 4.1. To characterize the algorithm’s performance, in Section 4.2, in this paper we add to the mathematical framework given in [8',\n",
       " '1505.00670': 'The ImageNet Large Scale Visual Recognition Challenge by Deng et al. (2009) provides more than one million labeled images of 1,000 object categories. The accessibility of a huge amount of well-annotated image data in computer vision rekindles deep convolutional neural networks (CNNs) as a premier learning tool to solve the visual object class recognition tasks, as shown by Krizhevsky et al. (2012); Simonyan and Zisserman (2014); Szegedy et al. (2014). Deep CNNs can perform signiﬁcantly better than traditional shallow learning methods, but usually requires much more training data as was shown by Krizhevsky et al. (2012); Russakovsky et al. (2014). In the medical domain, however, there are no similar large-scale ©2015 Hoo-Chang Shin, Le Lu, Lauren Kim, Ari Seﬀ, Jianhua Yao, Ronald M. Summers. arXiv:1505.00670v1  [cs.CV]  4 May 2015  Hoo-Chang Shin, Le Lu, Lauren Kim, Ari Seff, Jianhua Yao, Ronald M. Summers labeled image datasets available. On the other hand, large collections of radiology images and reports are stored in many modern hospitals’ Picture Archiving and Communication Systems (PACS). The invaluable semantic diagnostic knowledge inhabiting the mapping between hundreds of thousands of clinician-created high quality text reports and linked image volumes remains largely unexplored. One of our primary goals is to extract and associate radiology images with clinically semantic labels via interleaved text/image data mining and deep learning on a large-scale PACS database (∼780K imaging examinations). To the best of our knowledge, this is the ﬁrst reported work performing automated mining and prediction on a hospital PACS database at a very large scale. The Radiology reports are text documents describing patient history, symptoms, image observations and impressions written by board-certiﬁed radiologists. However, the reports do not contain speciﬁc image labels to be trained by a machine learning algorithm. Building the ImageNet database (Deng et al. (2009)) was mainly a manual process: harvesting images returned from Google image search engine according to the WordNet (Miller (1995)) ontology hierarchy and pruning falsely tagged images using crowd-sourcing such as Amazon Mechanical Turk (AMT). This does not meet our data collection and labeling needs due to the demanding diﬃculties of medical annotation tasks and the data privacy reasons. Thus we ﬁrst propose to mine categorical semantic labels using non-parametric topic modeling method – latent Dirichlet Allocation (LDA) by Blei et al. (2003) – to provide a semantic interpretation of a patient image in three levels. While this provides a ﬁrst-level interpretation of a patient image, labeling based on categorization can be nonspeciﬁc. To alleviate the issue of non-speciﬁcity, we further mined speciﬁc disease words in the reports mentioning the images. Feed-forward CNNs were then used to train and predict the presence/absence of the speciﬁc disease categories. Our work has been inspired by the works of Deng et al. (2009); Russakovsky et al. (2014) building very large-scale image databases and the works establishing semantic connections of texts and images by Kulkarni et al. (2013). Please',\n",
       " '1202.3775': 'Statistical independence and conditional independence (CI) are important concepts in statistics, artiﬁcial intelligence, and related ﬁelds (Dawid, 1979). Let X, Y and Z denote sets of random variables. The CI between X and Y given Z, denoted by X ⊥⊥Y |Z, reﬂects the fact that given the values of Z, further knowing the values of X (or Y ) does not provide any additional information about Y (or X). Independence and CI play a central role in causal discovery and Bayesian network learning (Pearl, 2000; Spirtes et al., 2001; Koller and Friedman, 2009). Generally speaking, the CI relationship X ⊥⊥Y |Z allows us to drop Y when constructing a probabilistic model for X with (Y, Z), which results in a parsimonious representation. Testing for CI is much more diﬃcult than that for unconditional independence (Bergsma, 2004). For CI tests, traditional methods either focus on the discrete case, or impose simplifying assumptions to deal with the continuous case – in particular, the variables are often assumed to have linear relations with additive Gaussian errors. In that case, X ⊥⊥Y |Z reduces to zero partial correlation or zero conditional correlation between X and Y given Z, which can be easily tested (for the links between partial correlation, conditional correlation, and CI, see Lawrance (1976)). However, nonlinearity and non-Gaussian noise are frequently encountered in practice, and hence this assumption can lead to incorrect conclusions. Recently, practical methods have been proposed for testing CI for continuous variables without assuming a functional form between the variables as well as the data distributions, which is the case we are concerned with in this paper. To our knowledge, the existing methods fall into four categories. The ﬁrst category is based on explicit estimation of the conditional densities or their variants. For example, Su and White (2008) deﬁne the test statistic as some distance between the estimated conditional densities p(X|Y, Z) and p(X|Y ), and Su and White (2007) exploit the difference between the characteristic functions of these conditional densities. The estimation of the conditional densities or related quantities is diﬃcult, which deteriorates the testing performance especially when the conditioning set Z is not small enough. Methods in the second category, such as Margaritis (2005) and Huang (2010), discretize the conditioning set Z to a set of bins, and transform CI to the unconditional one in each bin. Inevitably, due to the curse of dimensionality, as the conditioning set becomes larger, the required sample size increases dramatically. Methods in the third category, including Linton and Gozalo (1997) and Song (2009), provide slightly weaker tests than that for CI. For instance, the method proposed by Song (2009) tests whether one can ﬁnd some (nonlinear) function h and parameters θ0, such that X and Y are conditionally independent given a single index function λθ0(Z) = h(ZT θ0) of Z. In general, this is diﬀerent from the test for X ⊥⊥Y |Z: to see this',\n",
       " '1803.04687': 'D ATA comes from different sources and in different forms; images, videos, texts and audios. Each of which may complement the other in information content. Thus, multiple data modalities are usually more informative for a task than a single data modality. With the enormous availability of various electronic and digital multimedia devices, huge volumes of multimodal data contents are being generated on the Internet daily. However, for real-world applications, these modalities should be ﬁrst well integrated and appropriately fused to have more comprehensive information contents. Many methods have been developed in multimodal learning to exploit both the different characteristics as well as the shared relationships between different data modalities in order to perform various tasks [2], [10], [29], [43], [63], [65]. One of the rigid milestones in developing many visual-based data applications is scene understanding. It is mainly applied to understand the A. H. Abdulnabi is working with both the Rapid-Rich Object Search (ROSE) Lab at Nanyang Technological University, Singapore, and the Advanced Digital Sciences Center (ADSC), Illinois at Singapore Pt Ltd, Singapore, Email: abrarham001@ntu.edu.sg. B. Shuai is with ROSE, Z. Zuo is with ROSE, L. Chau and G. Wang are with the Department of Electrical and Electronic Engineering, Nanyang Technological University, Singapore, Emails: elpchau@ntu.edu.sg and wanggang@ntu.edu.sg respectively. Address of ADSC: Advanced Digital Sciences Center, 1 Fusionopolis Way, Illinois at Singapore, Singapore 138632. Address of ROSE: The Rapid-Rich Object Search Lab, School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore, 637553. Fig. 1. An example scene image that have both the RGB image and the Depth plane. The corresponding Depth information can be utilized to better differentiate ambiguous appearance in the RGB image. contents of an image or video prior performing the target task (e.g. large-scale video retrieval [29]). Imperatively, scene labeling (i.e; semantic segmentation or image parsing) is a crucial part of understanding an outdoor or indoor captured scene image. The task here is to classify each pixel into its semantic category (belonging to some object or stuff) in an input scene image. In our paper, we tackle the problem of RGB-D indoor scene labeling where we process two different data modalities; RGB color channels and Depth planes. Indoor RGB-D scene labeling is one of the most challenging visual classiﬁcation problems [55], [56]. Many applications are built on understanding the surrounding scenes, e.g. social behavior understanding [49] and objects detection and recognition [70]. This problem is usually addressed as a multimodal learning problem where the task is to exploit and fuse both RGB and Depth modalities to better label each pixel. Depth planes provide informative representation where the RGB representations are ambiguous. For example, Figure 1 show how the depth information can help to distinguish some similar appearance locations in the RGB image. Scene labeling in general is a challenging classiﬁcation problem since the scene image tends to contain multiple messy objects. These',\n",
       " '1503.03438': 'Convolutional networks (convnets) have become increasingly important to artiﬁcial intelligence in recent years, as reviewed by LeCun et al. (2015). The present paper presents a theoretical argument for complex-valued convnets and their remarkable performance; complex-valued convnets turn out to calculate “data-driven multiscale windowed spectra” characterizing certain stochastic processes common in the modeling of time series (such as audio) and natural images (including patterns and textures). We motivate the construction of such multiscale spectra via “local averages of multiwavelet absolute values” or, more generally, “nonlinear multiwavelet packets.” A textbook treatment of all concepts and terms used above and below is given by Mallat (2008). Further information is available in the original work of Daubechies (1992), Meyer (1993), Coifman et al. (1994), Coifman and Donoho (1995), Simoncelli and Freeman (1995), Meyer and Coifman (1997), LeCun et al. (1998), Donoho et al. (2003), Srivastava et al. (2003), Rabiner and Schafer (2007), and Mallat (2008), for example. The work of Haensch and Hellwich (2010), Mallat (2010), Poggio et al. (2012), Bruna and Mallat (2013), Bruna et al. (2015), and Chintala et al. (2015) also develops complex-valued convnets, providing copious applications and numerical experiments. A related, more sophisticated connection (to renormalization group theory) is given by Mehta and Schwab (2014). Our exposition relies on nothing but the basic signal processing treated by Mallat (2008). Via the connections discussed below, the rich, rigorous mathematical analysis surveyed by Daubechies (1992), Meyer (1993), Mallat (2008), and others applies directly to complex-valued convnets. 1  Citing such connections, the present paper’s anonymous reviews suggested viewing complexvalued convnets as a kind of baseline architecture for much of the deep learning reviewed by LeCun et al. (2015). Section 6 presents numerical analyses corroborating this viewpoint. Having such a theoretical basis for deep learning could help in paring down the combinatorial explosion of possibilities for future developments, while probably also illuminating further possibilities. The present paper proceeds as follows: Section 2 reviews stationary stochastic processes and their spectra. Section 3 reviews locally stationary stochastic processes and the connection of their spectra to stages in a complex-valued convnet. Section 4 introduces multiscale (multiple stages in a convnet). Section 5 describes the ﬁtting/learning/training that the connection to convnets facilitates. Section 6 brieﬂy compares on a common benchmark the accuracies for the complexvalued convnets of Chintala et al. (2015) to those for the scattering transforms of Mallat (2010) and for the standard real-valued convnets of Krizhevsky et al. (2012). Section 7 generalizes and summarizes the aforementioned sections. 2 Stationary stochastic processes For simplicity, we ﬁrst limit consideration to the special case of a doubly inﬁnite sequence of nonnegative random variables Xk, where k ranges over the integers. This input data will be the result of convolving an unmeasured independent and identically distributed (i.i.d.) sequence Zk, where k ranges over the integers, with an unknown sequence of real numbers fk, where k ranges over the integers (this la',\n",
       " '1610.08871': 'Object detection has improved signiﬁcantly in recent years, especially as a result of the resurgence of convolutional neural networks (CNNs) and the increase in performance and memory of GPUs. However, in spite of the successes in photobased recognition and detection, research into recognition within styles of images other than natural images (photos) remains limited [1]. We refer to this as the cross-depiction problem: detecting objects regardless of how they are depicted (photographed, painted, drawn, etc.). We believe that cross-depiction recognition is an interesting and open problem. It is interesting because it forces researchers to look beyond the surface appearance of object classes. By analogy, just as a person retains their identity Fig. 1. Detecting people across diﬀerent depictive styles a challenge: here we show some successful detections. arXiv:1610.08871v1  [cs.CV]  27 Oct 2016  2 Nicholas Westlake, Hongping Cai, Peter Hall no matter what clothes they wear, so an object retains its class identity no matter how it is depicted: a dog is a dog whether photographed, painted in oils, or drawn with a stick in the sand. Cross-depiction is a practical problem too: an example is an image search. The world contains images in all sorts of depictions. Any recognition solution that does not generalise across these depictions is of limited power. Yet most current computer vision methods tacitly assume a photographic input, either by design or training. Any model premised on a single depictive style e.g. photos will lack suﬃcient descriptive power for cross-depiction recognition. Therefore, an image search using methods will limit its results to photos and photo-like depictions. In our paper, we talk about natural images (photos) and non-natural images (artwork) as a linguistic convenience. We would argue that this is a false dichotomy: the universe of all images includes images in all possible depictive styles, and there is no particular reason to privilege any one style. Nevertheless, we acknowledge that the distribution of styles is not uniform: photos may be more abundant and certainly are in computer vision datasets such as ImageNet [2]. This creates problems for generalisation: training a detector on photos alone constrains it not only in terms its ability to handle denotational varieties, but projective and pose varieties too, as we discuss later. We present a new dataset, People-Art, which contains photos, cartoons and images from 41 diﬀerent artwork movements. Unlike the Photo-Art dataset [3], which had 50 classes, this dataset has a single class: people. We labelled people since we observe that people occur far more frequently across the wide spectrum of depictive styles than other classes, thus allowing a far greater variety. Detecting people within this dataset is a challenging task because of the huge range of ways artists depict people: from Picasso’s cubism to Disney’s Sleeping Beauty. The best performance on a pre-release of the dataset is 45% average precision (AP), from a CNN that was neither trained nor',\n",
       " '1308.0870': 'Recently, signiﬁcant progress has been made towards the understanding of the theoretical limits of wired and wireless communication networks. Most remarkable advances have been accomplished in two settings: 1) multiple multicasts relay networks, i.e., multihop networks where every destination desires all messages; 2) multiple unicasts over a single hop, where each destination requires a message for its intended source. Other mixed scenarios have also been considered in a less systematic manner, as for example the X channel (where each source has a message for each destination) [1]–[3], or index coding, i.e., a deterministic broadcast channel where each destination is characterized by a set of desired messages and a set of side-information messages [4]. The capacity of multiple multicast networks is exactly known for wired networks [5] and is approximately known within a constant gap for wireless networks [6]. Also, for multiple ﬂows over a single hop, capacity approximations were obtained in the form of degrees of freedom (DoF), generalized DoF (GDoF), and O(1)-gap bounds [7]–[9]. In particular, the concept of interference alignment (IA) was proposed by Cadambe and Jafar [7] to achieve the optimal sum-DoF of the K-user Gaussian Interference Channel (IC) with time-varying coefﬁcients (inﬁnite channel diversity), equal to K/2. Also in the assumption of inﬁnite channel diversity, ergodic IA [10] was shown to achieve the ergodic capacity of time-varying K-user Gaussian ICs within a bounded gap, under certain symmetry conditions on the channel coefﬁcients statistics. In the assumption of inﬁnite channel resolution, a construction known as “real IA” [11], where alignment is achieved by coding over rationally independent basis, was shown to achieve the optimal K/2 sum-DoF of the K-user Gaussian IC with ﬁxed channel coefﬁcients, with probability 1 over the channel coefﬁcients drawn from a continuous distribution. A comprehensive survey of IA is provided in the monograph [12]. Although the case of multiple ﬂows over multiple hops remain widely unsolved in general, several important advances have been made recently. For the case of two ﬂows, the two-hop network given by the concatenation of two two-user interference channels (referred to as the 2 × 2 × 2 IC) has received much attention, being one of the fundamental building blocks to characterize the DoFs of general two ﬂows networks [13]. The optimal sum-DoF of the 2×2×2 Gaussian IC was obtained in [14] using a technique known as aligned interference neutralization, which appropriately combines interference alignment and interference neutralization [15]. Also, a recent extension to the K × K × K Gaussian IC, achieving the optimal DoF equal to K was obtained in [16], using a technique referred to as aligned network diagonalization (AND).  2 In this paper we focus on linear deterministic ﬁnite-ﬁeld interference networks where channel coefﬁcients and the input-output symbols along to the same ﬁnite ﬁeld. These models are different from the “classical” linear deterministic models introduced in [6], where the input/output symbols are vectors over the',\n",
       " '1711.11543': 'The embodiment hypothesis is the idea that intelligence emerges in the interaction of an agent with an environment and as a result of sensorimotor activity. Smith and Gasser [1] Our long-term goal is to build intelligent agents that can perceive their environment (through vision, audition, or other sensors), communicate (i.e., hold a natural language dialog grounded in the environment), and act (e.g. aid humans by executing API calls or commands in a virtual or embodied environment). In addition to being a fundamental scientiﬁc goal in artiﬁcial intelligence (AI), even a small advance towards such intelligent systems can fundamentally change our lives – from assistive dialog agents for the visually impaired, to natural-language interaction with selfdriving cars, in-home robots, and personal assistants. As a step towards goal-driven agents that can perceive, communicate, and execute actions, we present a new AI task – Embodied Question Answering (EmbodiedQA), along ‹Work partially done during an internship at Facebook AI Research. Figure 1: Embodied Question Answering – EmbodiedQA– tasks agents with navigating rich 3D environments in order to answer questions. These embodied agents must jointly learn language understanding, visual reasoning, and navigation to succeed. with virtual environments, evaluation metrics, and a novel deep reinforcement learning (RL) model for this task. Concretely, the EmbodiedQA task is illustrated in Fig. 1 – an agent is spawned at a random location in an environment (a house or building) and asked a question (e.g. ‘What color is the car?’). The agent perceives its environment through ﬁrst-person vision (a single RGB camera) and can perform a few atomic actions: move-tforward, backward, right, leftu and turn-tright, leftu. The goal of the agent is to intelligently navigate the environment and gather the visual information necessary to answer the question. EmbodiedQA is a challenging task that subsumes several fundamental AI problems as sub-tasks. Clearly, the agent must understand language (what is the question asking?) and vision (what does a car look like?), but a successful agent must also learn to perform: Active Perception: The agent may be spawned anywhere in the environment and may not immediately ‘see’ the pixels containing the answer to the visual question (i.e. the car may not be visible). Thus, the agent must move to succeed – controlling the pixels that it will perceive. The agent must learn to map its visual input to the correct action based on its perception of the world, the underlying physical constraints, and its understanding of the question. arXiv:1711.11543v2  [cs.CV]  1 Dec 2017  Common Sense Reasoning: The agent is not provided a ﬂoor-plan or map of the environment, and must navigate from egocentric views alone. Thus, it must learn common sense (where am I? where are cars typically found in a housing compound? and where is the garage with respect to me?) similar to how humans may navigate in a house they have never visited (the car is probably in the garage out',\n",
       " '1711.00811': 'Deep neural networks solve many practical problems both in computer vision via Convolutional Neural Networks (CNNs) (LeCun et al. (1995); Szegedy et al. (2015); He et al. (2016)) and in audio and text processing via Recurrent Neural Networks (RNNs) (Graves et al. (2013); Mikolov et al. (2011); Gers et al. (1999)). However, although many works focus on expanding the theoretical explanation of neural networks success (Martens & Medabalimi (2014); Delalleau & Bengio (2011); Cohen et al. (2016)), the full theory is yet to be developed. One line of work focuses on expressive power, i.e. proving that some architectures are more expressive than others. Cohen et al. (2016) showed the connection between Hierarchical Tucker (HT) tensor decomposition and CNNs, and used this connection to prove that deep CNNs are exponentially more expressive than their shallow counterparts. However, no such result exists for Recurrent Neural Networks. The contributions of this paper are three-fold. 1. We show the connection between recurrent neural networks and Tensor Train decomposition (see Sec. 4); 2. We formulate and prove the expressive power theorem for the Tensor Train decomposition (see Sec. 5), which – on the language of RNNs – can be interpreted as follows: to (exactly) emulate a recurrent neural network, a shallow (non-recurrent) architecture of exponentially larger width is required; 1 arXiv:1711.00811v2  [cs.LG]  7 Feb 2018  Published as a conference paper at ICLR 2018 3. Combining the obtained and known results, we compare the expressive power of recurrent (TT), convolutional (HT), and shallow (CP) networks with each other (see Table 2). G2 G1 G3 Gd f✓(x1) f✓(x2) f✓(x3) f✓(xd) z1 z2 zd−1 ly(X) Figure 1: Recurrent-type neural architecture that corresponds to the Tensor Train decomposition. Gray circles are bilinear maps (for details see Section 4). 2 DEEP LEARNING AND TENSOR NETWORKS In this section, we review the known connections between tensor decompositions and deep learning and then show the new connection between Tensor Train decomposition and recurrent neural networks. Suppose that we have a classiﬁcation problem and a dataset of pairs {(X(b), y(b))}N b=1. Let us assume that each object X(b) is represented as a sequence of vectors X(b) = (x1, x2, . . . xd), xk ∈Rn, (1) which is often the case. To ﬁnd this kind of representation for images, several approaches are possible. The approach that we follow is to split an image into patches of small size, possibly overlapping, and arrange the vectorized patches in a certain order. An example of this procedure is 4 1 3 2 5 … 6 Figure 2: Representation of an image in the form of Eq. (1). A window of size 7 × 7 moves across the image of size 28 × 28 extracting image patches, which are then vectorized and arranged into a matrix of size 49 × 16. presented on Fig. 2. We use lower-dimensional representations of {xk}d k=1. For this we introduce a collection of parameter dependent feature',\n",
       " '1809.08993': 'Research on autonomous vehicles has attracted a large amount of attention in recent years, mainly sparked by the complexity of the problem and the drive to transform the mobility space. One key to success are powerful environment perception systems that allow autonomous systems to understand and act within a human-designed environment. Stringent requirements regarding accuracy, availability, and safety have led to the use of sensor suites that incorporate complimentary sensor types such as camera, LiDAR, and RADAR. Each sensor modality needs to leverage its speciﬁc strengths to contribute to a holistic picture of the environment. ⋆Corresponding author (florian.piewak@daimler.com) ⋆⋆Contributed while with Daimler AG arXiv:1809.08993v2  [cs.CV]  27 Sep 2018  2 Florian Piewak, Peter Pinggera, et al. • road • sidewalk • person • rider • small vehicle • large vehicle • two wheeler • construction • pole • traﬃc sign • vegetation • terrain Fig. 1. Example of a multimodal Stixel scene (right) generated based on a camera image (top left) and a semantic point cloud (bottom left). Note that only object Stixels are visualised. The colors correspond to the Cityscapes semantic class color coding [6]. The sensor output usually involves quantities that are derived from raw measurements, such as detailed semantics [5,22] or object instance knowledge [29,30]. The diﬀerent representations provided by the various sensor types are typically fused into an integrated environment model, for example an occupancy grid map [20], to successfully tackle high-level tasks such as object tracking [27] and path planning [3]. Fusing the massive amounts of data provided by multiple diﬀerent sensors represents a signiﬁcant challenge in a real-time application. As a way out, midlevel data representations have been proposed that reduce the amount of sensor data but retain the underlying information at the same time. A prime example of such a mid-level representation is the so-called Stixel-World [2,21,26,7,13] that provides a compact, yet geometrically and semantically consistent model of the observed environment. Thereby a 3D scene is represented by a set of narrow vertical segments, the Stixels, which are described individually by their vertical extent, geometric surface, and semantic label. The Stixel concept was originally applied to stereo camera data, where the segmentation is primarily based on dense disparity data as well as pixel-level semantics obtained from a deep neural network [26,7,13]. In this paper, we propose to transfer the Stixel concept into the LiDAR domain to develop a compact and robust mid-level representation for 3D point clouds. Moreover, we extend the Stixel-World to a multimodal representation by incorporating both camera and LiDAR sensor data into the model. The speciﬁc combination of the high resolution and semantic detail of RGB imagery with the supreme distance accuracy of LiDAR data in the multimodal Stixel-World results in a very powerful environment representation that outperforms the stateof-the-art (see Fig. 1). Our main contributions can be summarized as follows:  Improved Semantic Stixels 3 Fig. 2. Exa',\n",
       " '1708.06819': 'Few-shot learning aims to alleviate the diﬃculty of learning a classiﬁer from few examples – or even a single example. Traditional classiﬁcation learns from hundreds or thousands of examples of per class. Instead of hoping to learn a classiﬁer that can look at an input and classify it directly, a more robust technique is to provide the network with examples of each class and have it explicitly compare the input to each of the reference objects in each class. This typically takes the form of learning representations for both the reference examples you show the network as well as the query input that you are ultimately classifying. Something of a similarity metric between the representations is then either learned as described by Triantaﬁllou et al. (2017) or an out-of-the-box technique is used more explicitly, as in Vinyals et al. (2016). The reference class with the highest similarity metric to the query image would be the label. However, a practical concern is that the networks generally require all inputs to have the same number of examples per reference class. This is largely unrealistic and unworkable for production systems. Each reference class could have a diﬀerent number of images (for example, a dynamic number of images for each family member in a facial recognition system.) Dynamic input sizing remains a challenging problem for high performance techniques that utilize statically compiled graphs, such as Tensorﬂow and Caﬀe. Clever workarounds have thusly been developed for diﬀerent learning tasks, such as masking in sequence-based learning where sequences of varied length are padded to a ﬁxed length. The network learns c⃝2017 N. Hilliard, N.O. Hodas & C.D. Corley. arXiv:1708.06819v1  [cs.LG]  22 Aug 2017  Dynamic Input Structure and Network Assembly for Few-Shot Learning to monitor for the padding, and it can act accordingly, allowing for variable length sequences to utilize the same network inputs. However, it must explicitly learn to ignore the padding, placing an extra burden on the training process. Our contribution in this paper is a novel technique for a system that leverages dynamic network assembly using shared weights to provide batch-wise size agnosticism in a static graph, meaning the example size changes from batch to batch. We additionally describe a training regimen that can be used to train the network to generalize and maintain similar performance across example sizes. We demonstrate the architecture’s eﬀectiveness on a 1-way classiﬁcation benchmark and compare against ﬁxed-size networks. We show that our contribution produces signiﬁcantly higher performance on test tasks than a traditional static class-size approach. 2. Related Work Since its inception, few-shot learning techniques have been implemented with a variety of architectures and components. For example, Vinyals et al. (2016) implemented one such network using memory augmentation with attention. This builds on advances made by other few-shot systems such as the one developed by Koch (2015) which used a siamese network with two con',\n",
       " '1706.01824': 'Multi-Task Learning (MTL) aims to enhance the overall generalization performance by learning multiple related tasks simultaneously. It has been extensively studied from various points of view [1], [2], [3], [4]. As an example, the common tastes of users (i.e., tasks) with respect to movies (i.e., instances) can be harnessed into a movie recommender system using MTL [5]. Most MTL methods run under the ofﬂine learning setting where the training data for each task is available beforehand. However, ofﬂine learning methods are generally inefﬁcient, since they suffer from a high training cost and poor scalability. This is especially true when it comes to the large-scale streaming data. As a remedy, MTL has been studied under the online setting, in which the model runs over a sequence of data by processing them one by one [6]. After updating the model in each round, the current input will be discarded. As a result, online learning algorithms are efﬁcient and scalable, and have been successfully applied to a number of MTL applications [7], [8], [9], [10], [11]. In this paper, we investigate MTL under the online setting. Existing online MTL methods assume that all tasks are related with each other and simply constrain their relationships via a presumed structure [7], [12]. However, such a constraint may be too restrictive P. Yang and X. Gao are with Computer, Electrical and Mathematical Sciences & Engineering Division at King Abdullah University of Science and Technology, Saudi Arabia. E-mail:{peng.yang.2, xin.gao}@kaust.edu.sa P. Zhao is a senior algorithm expert in Ant Financial Service Group, China. E-mail: peilinzhao@hotmail.com X. Gao and P. Zhao are corresponding authors. and rarely hold in the real-life applications, as the personalized tasks with individual traits often exist [13]. We attempt to address this drawback through a creative formulation of online MTL that consists of two components: the ﬁrst component captures a lowrank correlative structure over the related tasks, while the second one represents the personalized patterns of individual tasks. Speciﬁcally, our algorithm learns a weight matrix which is decomposed into two components as aforementioned. A nuclear norm regularization is imposed on the ﬁrst component to induce a low-rank correlative structure of the related tasks. A group lasso penalty is applied onto the second component of all individual tasks to identify the outliers. Next, we apply an online projected gradient scheme to solve this non-smooth problem with a closed-form solution for the correlative and personalized components. This gives our algorithm two advantages: 1) it is efﬁcient to make predictions and update models in a real-time manner; 2) it can achieve a good trade-off between the common and personalized structures. We provide a theoretical evaluation for our algorithm by giving a proof that our algorithm can achieve a sub-linear regret compared to the best linear model in hindsight. Although our algorithm achieves good performa',\n",
       " '1706.05721': 'Deep convolutional neural networks have attracted enormous attention in medical image segmentation as they have shown superior performance compared to conventional methods in several applications. This includes automatic segmentation of brain lesions [2,10], tumors [9,15,21], and neuroanatomy [14,22,3], using voxelwise network architectures [14,9,17], and more recently using 3D voxelwise networks [3,10], and fully convolutional networks (FCNs) [4,13,17]. Compared to voxelwise methods, FCNs are fast in testing and training, and use the entire samples to learn local and global image features. On the other hand, voxelwise networks may use a subset of samples to reduce data imbalance issues and increase eﬃciency. Data imbalance is a common issue in medical image segmentation. For example in lesion detection the number of non-lesion voxels is typically > 500 times ⋆Corresponding author: S.S.M.Salehi (email: ssalehi@ece.neu.edu). arXiv:1706.05721v1  [cs.CV]  18 Jun 2017  larger than the number of diagnosed lesion voxels. Without balancing the labels the learning process may converge to local minima of a sub-optimal loss function, thus predictions may strongly bias towards non-lesion tissue. The outcome will be high-precision, low-recall segmentations. This is undesired especially in computer-aided diagnosis or clinical decision support systems where high sensitivity (recall) is a key characteristic of an automatic detection system. A common approach to account for data imbalance, especially in voxelwise methods, is to extract equal training samples from each class [20]. The downsides of this approach are that it does not use all the information content of the images and may bias towards rare classes. Hierarchical training [5,21,20] and retraining [9] have been proposed as alternative strategies but they can be prone to overﬁtting and sensitive to the state of the initial classiﬁers [10]. Recent training methods for FCNs resorted to loss functions based on sample re-weighting [2,10,12,16,18], where lesion regions, for example, are given more importance than non-lesion regions during training. In the re-weighting approach, to balance the training samples between classes, the total cost is calculated by computing the weighted mean of each class. The weights are inversely proportional to the probability of each class appearance, i.e. higher appearance probabilities lead to lower weights. Although this approach works well for some relatively unbalanced data like brain extraction [17] and tumor detection [15], it becomes diﬃcult to calibrate and does not perform well for highly unbalanced data such as lesion detection. To eliminate sample re-weighting, Milletari et. al. proposed a loss function based on the Dice similarity coeﬃcient [13]. The Dice loss layer is a harmonic mean of precision and recall thus weighs false positives (FPs) and false negatives (FNs) equally. To achieve a better tradeoﬀbetween precision and recall (FPs vs. FNs), we propose a loss layer based on the Tversky similarity index [19]. Tversky index is a generalization of the Dice similarity coeﬃcient',\n",
       " '1711.04951': 'POS tagging is one of the most fundamental natural language processing (NLP) tasks. In English where white space is a strong indicator of word boundaries, POS tagging is an important first step towards many other NLP tasks. However, white space when written in Vietnamese is also used to separate syllables that constitute words. So for Vietnamese NLP, word segmentation is referred to as the key first step (Dien et al., 2001). When applying POS tagging to real-world Vietnamese text where gold word-segmentation is not available, the pipeline strategy is to first segment the text by using a word segmenter, and then feed the word-segmented text—which is the output of the word segmenter—as the input to a POS tagger. For example, given a written text “thuế thu nhập cá nhân” (individualcá_nhân incomethu_nhập taxthuế) consisting of 5 syllables, the word segmenter returns a two-word phrase “thuế_thu_nhập cá_nhân.”1 Then given the input segmented text “thuế_thu_nhập cá_nhân”, the POS tagger returns “thuế_thu_nhập/N cá_nhân/N.” A class of approaches to POS tagging from unsegmented text that has been actively explored in other languages, such as in Chinese and Japanese, is joint word segmentation and POS tagging (Zhang and Clark, 2008). A possible joint strategy is to assign a combined segmentation and POS tag to each syllable (Kruengkrai et al., 2009). For example, given the input text “thuếthu nhập cá nhân”, the joint strategy would produce “thuế/BN thu/I-N nhập/I-N cá/B-N nhân/I-N”, where B refers to the beginning of a word and I refers to the inside of a word. Shao et al. (2017) showed that this joint strategy gives SOTA results for Chinese POS tagging by utilizing a BiLSTM-CNNCRF model (Ma and Hovy, 2016). In this paper, we present the first empirical study comparing the joint and pipeline strategies for Vietnamese POS tagging from unsegmented text. In addition, we make a comparison between SOTA feature-based and neural networkbased models, which, to the best of our knowledge, has not done in any prior work on Vietnamese. On the benchmark Vietnamese treebank (Nguyen et al., 2009), we show that the pipeline strategy produces better scores than the joint strategy. We also show that the highest tagging accuracy is obtained by using a traditional feature-based model rather than neural network-based models. 2 Related work 2.1 Word segmentation Nguyen et al. (2006), Dinh and Vu (2006) and 1In the traditional underscore-based representation in Vietnamese word segmentation (Nguyen et al., 2009), white space is only used to separate words while underscore is used to separate syllables inside a word. arXiv:1711.04951v1  [cs.CL]  14 Nov 2017  Tran et al. (2010) considered the Vietnamese word segmentation task as a sequence labeling task, using either a CRF, SVM or MaxEnt model to assign each syllable a segmentation tag such as B or I. In',\n",
       " '1807.06722': 'A dramatic hype in the success of machine learning (ML) models achieving the human level performance in many different areas led to a great need of deploying these systems in real world applications. The ongoing research aims to produce autonomous end to end systems which will perceive, observe the surrounding, learn from the data and surrounding, and take a decision on training data observation. However, the employability of these systems is greatly limited by the model’s inability to explain the decisions. In fact, the article 13 of General Data Protection Regulation (GDPR) mentions about the right to be informed of each end user of the data. This implies that the models which use personal data of the users to make some decisions about the relevant person, for instance in getting a bank loan or deciding if the person to be given a speciﬁc treatment or not, the user has a full right of understanding how and why the model came across a speciﬁc decision. So the issue of interpretability is very important to be considered in future machine learning algorithms. “Single evaluation metric” is an incomplete description of the most real-world tasks which is the basis for all machine learning techniques. For instance, our goal in lending a loan money is to reduce the loan default ratio as well as not to discriminate against anyone on the basis of the race or area they are living in. Mostly machine learning techniques only optimize the loan default metric and does not care about the other factors like discrimination. Therefore, there is a need to include other important factors in optimization of ML techniques one of which is interpretability. ML techniques are frequently used in scientiﬁc ﬁelds to classify or predict, so they must answer the “how” and “why” questions to be coherent with the science goals. Interpretability will greatly help us in reducing data bias, making safe ML algorithms, debugging the safety holes and managing social interactions. There is an overview of making the traditional classiﬁcation more comprehensible and discussing the fact that interpretability cannot be deﬁned monotonically but rather it is a multi-dimensional concept[Freitas, 2014] 1.1 Interpretability if seen from the “model” point of view Survey of the literature for machine learning model interpretability reveals that there is no agreed upon universal definition for it, and people use it in their own context and for the speciﬁc type of application or model. The interpretability refers to multiple concepts and contexts. In terms of machine learning, interpretability can be divided into two streams, either the model is interpretable itself or some other technique is applied on the black box model to extract interpretations. Interpretable models are those which are intrinsically interpretable in terms of the weights or parameters. We often ﬁnd a claim in the literature survey for machine learning that linear models are more interpretable than the deep learning models[Lou et al., 2012',\n",
       " '1811.10105': 'We consider the problem of stochastic optimization min w∈Rd {F(w) = E[f(w; ξ)]} , (1) where ξ is a random variable and f has a Lipschitz continuous gradient. One of the most popular applications of this problem is expected risk minimization in supervised learning. In this case, random variable ξ represents a random data sample (x, y), or a set of such samples {(xi, yi)}i∈I. We can consider a set of realizations {ξ[i]}n i=1 of ξ corresponding to a set of random samples {(xi, yi)}n i=1, and deﬁne fi(w) := f(w; ξ[i]). Then the sample average approximation of F(w), known as empirical risk in supervised CONTACT Lam M. Nguyen. Email: LamNguyen.MLTD@ibm.com arXiv:1811.10105v2  [math.OC]  27 Aug 2020  learning, is written as min w∈Rd ( F(w) = 1 n n X i=1 fi(w) ) . (2) Throughout the paper, we assume the existence of unbiased gradient estimator, that is E[∇f(w; ξ)] = ∇F(w) for any ﬁxed w ∈Rd. In addition we assume that there exists a lower bound of function F. In recent years, a class of variance reduction methods [1, 3, 5, 6, 11, 18] has been proposed for problem (2) which have smaller computational complexity than both, the full gradient descent method and the stochastic gradient method. All these methods rely on the ﬁnite sum form of (2) and are, thus, not readily extendable to (1). In particular, SVRG [3] and SARAH [11] are two similar methods that consist of an outer loop, which includes one exact gradient computation at each outer iteration and an inner loop with multiple iterative stochastic gradient updates. The only diﬀerence between SVRG and SARAH is how the iterative updates are performed in the inner loop. The advantage of SARAH is that the inner loop itself results in a convergent stochastic gradient algorithm. Hence, it is possible to apply only one-loop of SARAH with suﬃciently large number of steps to obtain an approximately optimal solution (in expectation). The convergence behavior of one-loop SARAH is similar to that of the standard stochastic gradient method [11]. The multiple-loop SARAH algorithm matches convergence rates of SVRG in the strongly convex case, however, due to its convergent inner loop, it has an additional practical advantage of being able to use an adaptive inner loop size, as was demonstrated in [11] for details). A version of SVRG algorithm, SCSG, has been recently proposed and analyzed in [7, 8]. While this method has been developed for (2) it can be directly applied to (1) because the exact gradient computation is replaced with a mini-batch stochastic gradient. The size of the inner loop of SCSG is then set to a geometrically distributed random variable with distribution dependent on the size of the mini-batch used in the outer iteration. In this paper, we propose and analyze an inexact version of SARAH (iSARAH) which can be applied to solve',\n",
       " '1203.4867': 'S INCE the introduction of the amplify-and-forward (AF) relay scheme, it has been studied in the context of cooperative communication [1]-[4]. It is an interesting technique from the practical standpoint because the complexity and cost of relaying, always an issue in designing cooperative networks, is minimal for AF relay networks. As the simplest coding scheme, AF is also used to estimate the network capacity of relay networks. Obviously, the achievable rate of AF scheme can be viewed as a lower bound to the network capacity. In addition to its simplicity, AF is known to be the optimal relay strategy in many interesting cases [5]-[7]. Gastpar and Vetterli [7] have shown that for a two-hop network with AF relays, the cut-set bound of the network capacity can be achieved in the limit of a large number of relays. This work was supported by by grants from the National Natural Science Foundation of China (60832001). The material in this paper was presented in part at IEEE International Symposium on Information Theory, St. Petersburg, Russia, Aug. 2011, the 7th Asia Europe Workshop on Concepts in Information theory, Boppard, Germany, Jul. 2011, and 2012 Information Theory and Applications Workshop, San Diego, Feb. 2012. The authors are with the Key Lab. of ISN, Xidian University, Xi’an, China e-mail: {liuby, caining}@mail.xidian.edu.cn. Network coding [9] is a novel and promising design paradigm for wired communication networks. As opposite to the conventional routing operation, network coding allows the intermediate relays processing the received packets to reduce the amount of transmissions and thus improves the total throughput of the network. Li et al. [8] have shown that linear network coding can achieve the multicast capacity [9] in a noiseless network. This result indicates that to send out a linear combination of the incoming packets at each node is sufﬁcient to obtain the optimal capacity performance. Linear network coding has also been studied in [10] from an algebraic perspective. Each destination node effectively obtains source information multiplied by a transfer matrix consisting of global encoding kernels on the incoming edges of it, and can recover the original data provided that the matrix is invertible. Applying the principle of network coding to wireless communication networks has recently received tremendous attention from the research community. AF relay scheme allows one to exploit the broadcast nature of the wireless medium and to introduce the concept of network coding into physical layer. Katti et al. [11] have studied an AF-based analog network coding (ANC) scheme. As opposite to the traditional approach of wireless communications, analog network coding fully use the interference rather than avoiding it. This technique signiﬁcantly improves the network throughput in many scenarios. Since then, many works have been focused on the design of ANC relay schemes both for one-way and two-way relay channels [12]-[17]. In [15] Mari´c et al. have studied a multi-hop ANC scheme for a layered relay',\n",
       " '1808.04189': 'When disaster strikes, news and social media are invaluable sources of information, allowing humanitarian organizations to rapidly mitigate crisis situations and save lives (Vieweg et al., 2010; Neubig et al., 2011; Starbird et al., 2012). However, language barriers looms large over these efforts, especially when disasters occur in parts of the world that use less common languages. In these cases, machine translation (MT) technology can be a valuable tool, with one widely-heralded success story being the deployment of Haitian Creoleto-English translation systems during the earthquakes in Haiti (Lewis, 2010; Munro, 2010). However, data-driven MT systems, particularly neural machine translation (NMT; Kalchbrenner 1Code to reproduce experiments at https://github. com/neubig/rapid-adaptation and Blunsom (2013); Bahdanau et al. (2015)), require large amounts of training data, and creating high-quality systems in low-resource languages (LRLs) is a difﬁcult challenge where research efforts have just begun (Gu et al., 2018). Another hurdle, which to our knowledge has not been covered in previous research, is the time it takes to create such a system. In a crisis situation, time is of the essence, and systems that require days or weeks of training will not be desirable or even feasible. In this paper we focus on the question: how can we create MT systems for new language pairs as accurately as possible, and as quickly as possible? To examine this question we propose NMT methods at the intersection of cross-lingual transfer learning (Zoph et al., 2016) and multilingual training (Johnson et al., 2016), two paradigms that, to our knowledge, have not been used together in previous work. Our methods, laid out in §2 follow the process of training a seed model on a large number of languages, then ﬁne-tuning the model to improve its performance on the language of interest. We propose a novel method of similar-language regularization (SLR) where training data from a second similar languages is used to help prevent over-ﬁtting to the small LRL dataset. In the experiments in §3, we attempt to answer two questions: (1) Which method of creating multilingual systems and adapting them to an LRL is the most effective way to increase accuracy? (2) How can we create the strongest system possible with a bare minimum of training time? The results are sometimes surprising – we ﬁrst ﬁnd that a single monolithic model trained on 57 languages can achieve BLEU scores as high as 15.5 with no training data in the new source language whatsoever. In addition, the proposed method starting with a universal model then ﬁne-tuning with the SLR proves most effective, achieving gains of 1.7 arXiv:1808.04189v1  [cs.CL]  13 Aug 2018  BLEU points averaged over several language pairs compared to previous methods adapting to only the LRL. 2 Training Paradigms In this paper, we consider the setting where we have a source LRL of interest, and',\n",
       " '1703.00099': 'The most familiar communication setting for people is talking to another human. Therefore, normal users would transfer their human-human behavior patterns and expectations to interactions with a system. For example, though users quickly learned that Microsoft Cortana (a personal assistant) could not handle social content, 30% of the total user utterances addressing it are social content [Jiang et al., 2015]. Therefore, one possible way to improve conversational system performance is to imitate human behaviors. Countless observations suggest that human conversations usually interleave social content with task content [Schegloff, 1968]. For example, we usually open a conversation with “How are you doing?”; we also divert to social topics during meetings; and we would most likely end our workday conversations with chitchat of our weekend plans. However, traditional conversational systems are mainly task-oriented. These systems can complete tasks such as booking airline tickets [Zue et al., 1994], searching for bus information [Raux et al., 2005], and making restaurant reservations [Jurcıcek et al., 2011]. These systems do not involve social content mainly because the task is relatively simple and the user intention and system capability are well calibrated. To move our current systems to tackle tasks that are more complex and especially those where most users do not have clear intentions, we propose a dialog framework to fuse task and non-task conversation content. To achieve the content transition smoothness, we trained dialog policies using reinforcement learning algorithms. We built an example dialog system, a movie promotion system that promotes a speciﬁc movie according to users’ interests and uses social conversation to engage users to complete the task. There are several types of audience research conducted by ﬁlm distributors in connection with domestic theatrical releases [Martin, 2002]. Such audience research can cost $1 million per movie, especially when scores of TV advertisements are tested and retested. Therefore, we argue that having conversational system to elicit audience information voluntarily to replace paid surveys would reduce the cost and improve the survey quality. We published the source code of the software implementation of the framework, an example movie promotion system, and the conversation data collected with human users.1 The framework is general and applicable in different domains, such as political surveying, language learning, and public health education. The theoretical framework and the software implementation enables researchers and developers to build example dialog systems in different domains, hopefully leading to big impact beyond discourse and dialog research. 2 Related Work Current task-oriented dialog systems focus on completing a task together with the user. They can perform bus information search [Raux et al., 2005], ﬂight booking [Zue et al., 1994], direction giving [Yu et al., 2015a], etc. However, these systems can only focus on one task at a time. The famous personal assistants, such as Apple’s Siri are composed of many of these single-task systems. These single-task systems’ underlying mechanisms are mainly frame',\n",
       " '1510.01032': 'Most current speech processing systems rely on a deep architecture to classify speech frames into subword units (often phone states). This approach still relies on frame-level independence assumptions as well as a pronunciation lexicon for breaking up words into their subword constituents. As an alternative, some researchers [1–7] have started to reconsider using whole words as the basic modelling unit. Some of the earliest speech recognition systems were based on template-based whole-word modelling [8]. This idea has been revisited in modern template-based automatic speech recognition (ASR) systems [1,2], as well as modern speech indexing applications such as query-by-example search [9, 10]. These systems typically use dynamic time warping (DTW) to quantify the similarity of phone or word segments of variable length. Recent work has also considered frame-level embeddings which map acoustic features to a new frame-level representation that is tailored to word discrimination when combined with DTW [11–13]. DTW, however, has known inadequacies [14] and is quadratic-time in the duration of the segments. Levin et al. [3] proposed a segmental approach where an arbitrarylength speech segment is embedded in a ﬁxed-dimensional space such that segments of the same word type have similar embeddings. Segments can then be compared by simply calculating a distance in the embedding space, a linear time operation in the embedding dimensionality. Several approaches were developed in [3], and in [15] these were successfully applied in a query-by-example search system. This research was supported by NSF grant IIS-1321015. The opinions expressed in this work are those of the authors and do not necessarily reﬂect the views of the funding agency. HK is funded by a Commonwealth Scholarship. Bengio and Heigold [4] similarly used whole-word ﬁxeddimensional representations in a segmental ASR lattice rescoring system. Their acoustic embeddings are obtained from a convolutional neural network (CNN), trained with a combination of a word classiﬁcation and a ranking loss. When combining the hypotheses of the baseline system with the embedding-based scores, ASR performance was improved. A similar approach was followed in [5], where long short-term memory (LSTM) networks were used to obtain wholeword embeddings for a query-by-example search task. Finally, Maas et al. [6] trained a regression CNN that reconstructs a semantic word embedding from acoustic speech input; these features were used in a segmental conditional random ﬁeld ASR system. In this paper we compare several CNN-based approaches to each other and to the best approach of Levin et al. [3], on a word discrimination task. This task has been used in several other studies [11,12,16] to assess the accuracy of acoustic embedding approaches without the need to train a complete recognition or search system. Building on ideas from earlier CNN-based approaches, we propose new networks that make use of weaker supervision in the form of known word pairs. The approach is based on Siamese networks: tied',\n",
       " '1804.07274': 'Conjunctive query (CQ) answering over expressive Description Logic (DL) ontologies is a key reasoning task which remains unsolved for many practical purposes. Indeed, answering CQs over DL ontologies is quite intricate and often of high computational complexity [4, 8, 16]. Nevertheless, CQ answering over a major class of DLs, the so-called Horn DLs, can in some cases be addressed via application of the chase algorithm, a technique where all relevant consequences of an ontology are precomputed, allowing queries to be directly evaluated over the materialized set of facts. However, the chase is not guaranteed to terminate for all ontologies, and checking whether it does is not a straightforward procedure. It is thus an ongoing research endeavor to establish so-called acyclicity conditions; i.e., suﬃcient conditions which ensure termination of the chase. The main contribution of this paper is the deﬁnition of restricted chase acyclicity (RCAn), a novel acyclicity condition for Horn-SRIQ ontologies (the DL Horn-SRIQ may be informally described as the logic underpinning the deterministic fragment of OWL DL [9] minus nominals). If an ontology is proven to be RCAn, then n-cyclic terms do not occur during the computation of the chase of such ontology and thus the chase is guaranteed to terminate. In contrast with existing acyclicity notions [6] which deal with termination of the unrestricted, i.e. oblivious, chase of arbitrary sets of existential rules, we ⋆This is a post-peer-review, pre-copyedit version of an article published at the 15th International Semantic Web Conference (ISWC 2016). The ﬁnal authenticated version is available online at: http://dx.doi.org/10.1007/978-3-319-46523-4_5.  restrict our attention to the language Horn-SRIQ and seek to achieve termination of the restricted chase algorithm [3]; this is a special variant of the standard chase in which the inclusion of further terms to satisfy existential restrictions is avoided if such restrictions are already satisﬁed, and equality is dealt with via renaming. By considering such a chase algorithm we are able to devise acyclicity conditions which are more general than any other of the notions previously described. On the theoretical side, we show that RCAn is more general than modelfaithful acyclicity (MFA) provided n is suﬃciently large (linear in the size of ontology). As shown in [6], this is one of the most general acyclicity conditions for ontologies described to date, as it encompasses many other existing notions such as joint acyclicity [12], super-weak acyclicity [14] or the hybrid acyclicity notions presented in [2]. Furthermore, we show that deciding RCAn membership is not harder than deciding MFA membership. On the practical side, we empirically show that (i) RCAn characterizes more real-world ontologies as acyclic than MFA. Furthermore, we demonstrate that (ii) the speciﬁc type of acyclicity captured by RCAn results in a more eﬃcient reasoning procedure. This is because acyclicity is still preserved in the case when employing renaming techniques when reasoning in the presence',\n",
       " '1504.07339': 'Many object detection solutions can be taken as the combinations of the feature extractor and classiﬁer. Combinations such as Haar-like feature with boosting [49], HOG feature with SVM [9], multiple channel features with boosting [11] and ﬁne-tuned high-level CNN features with SVM [21] have largely improved the object detection. Among these combinations, the multiple channel features with boosting and the ﬁne-tuned high-level CNN features with SVM [21] show the most promising performances on various detection tasks. The multiple channel features approach can be seen as an improved version of the Viola-Jones framework [49] with carefully hand-crafted channel feature representation and more sophisticated boosting algorithm. Multiple channel features ﬁrst showed great performance in pedestrian detection [12], and was later generalized to face detection [50], edge detection [15] and object proposal generation [55]. Recent improvements are gained by applying learned or sophisticated hand-crafted ﬁlters on the HOG+LUV channels [39,53]. Besides the accuracy, it typically runs at realtime speed and has very few parameters. Current bottleneck mainly lies in the representation capacity of the handcrafted feature representation since the performance saturates as we add more and more hand-crafted ﬁlters (from tens to hundreds then to thousands) on the channel features. The ﬁne-tuned high-level CNN feature with SVM has recently shown extreme power [21, 40] in challenging tasks. Typically, a CNN model previously trained on ImageNet classiﬁcation task is ﬁne-tuned for new task and then the mid-level or high-level features of the CNN are extracted and fed into a SVM classiﬁer. Owing to its large improvements in image classiﬁcation, the learned feature hierarchies also set up new records in other vision tasks, like object detection [21], semantic segmentation [25] and ﬁnegrained category detection [51]. The main advantage of this kind of approach is that the CNN has large capacity to handle large-scale training data and the learning process is endto-end. However, currently CNN is often accompanied by huge computation complexity in inference and learning, and the model size is usually large (e.g., more than 500MB for widely used VGG net [45]). In practice, we always desire for better performance and lower computation/storage cost. This motivates us to build a bridge between the above two approaches and gain beneﬁts from their respective advantages at the same time. Speciﬁcally, we extend the multiple channel features to low-level feature maps transferred from a CNN model trained on ImageNet image classiﬁcation task, or equivalently speaking, replace the high-level connections in CNN with a boosting forest. The advantages are twofold: the transferred feature maps from CNN improve the representative capacity in channel features, while the boosting forest absolves the painstaking ﬁne-tuning of high-level connections in CNN during the adaptation to various classiﬁcation/regression problems. We name the new method as 1 arXiv:1504.07339v3',\n",
       " '1807.11622': 'Reinforcement learning (RL) tackles sequential decision making problems by formulating them as tasks where an agent must learn how to act optimally through trial and error interactions with the environment. The goal in these problems is to maximize the (discounted) sum of the numerical reward signal observed at each time step. Because the actions taken by the agent inﬂuence not just the immediate reward but also the states and associated rewards in the future, sequential decision making problems require agents to deal with the trade-off between immediate and delayed rewards. Here we focus on the problem of exploration in RL, which aims to reduce the number of samples (i.e., interactions) an agent needs in order to learn to perform well in these tasks when the environment is initially unknown. Surprisingly, the most common approach in the ﬁeld is to select exploratory actions uniformly at random, with even high-proﬁle success stories being obtained with this strategy (e.g., Tesauro 1995; Mnih et al. 2015). However, random exploration often fails in environments with sparse rewards, Copyright c⃝2020, Association for the Advancement of Artiﬁcial Intelligence (www.aaai.org). All rights reserved. that is, environments where the agent observes a reward signal of value zero for the majority of states. In this paper we introduce an approach for exploration in RL based on the successor representation (SR; Dayan 1993). The SR is a representation that generalizes between states using the similarity between their successors, that is, the states that follow the current state given the agent’s policy. The SR is deﬁned for any problem, it can be learned with temporal-difference learning and, as we discuss below, it can be seen as implicitly estimating the transition dynamics of the environment. The main contribution of this paper is to show that the norm of the SR can be used as an exploration bonus. We perform an extensive empirical evaluation to demonstrate this and we introduce the substochastic successor representation (SSR) to also understand, theoretically, the behavior of such a bonus. The SSR behaves similarly to the SR but it is more amenable to theoretical analyses. We show that the SSR implicitly counts state visitation, suggesting that the exploration bonus obtained from the SR, while it is being learned, might also be incorporating some notion of state visitation counts. We demonstrate this intuition empirically and we use this result to introduce algorithms that, in the tabular case, perform as well as traditional approaches with PAC-MDP guarantees. Finally, we extend the idea of using the norm of the SR as an exploration bonus to the function approximation case, designing a deep RL algorithm that achieves state-of-the-art performance in hard exploration Atari 2600 games when in a low sample-complexity regime. The proposed algorithm is also simpler than traditional baselines such as pseudo-count-based methods because it does not require domain-speciﬁc density models (Bellemare et al. 2016',\n",
       " '1309.6301': '2 1. Introduction In the past few decades, linear inverse problems have attracted a lot of attention in a wide range of areas, such as statistics, machine learning, signal processing, and compressive sensing, to name a few. The typical forward model is y = Ax + n, (1) where y ∈Rm is the measurement vector, x ∈Rn the original signal to be recovered, A ∈Rm×n is a known sensing matrix, and n ∈Rm is noise (usually assumed to be white and Gaussian). In most cases of interest, A is not invertible (e.g., because m < n), making (1) an ill-posed problem (even in the absence of noise), which can only be addressed by using some form of regularization or prior knowledge about the unknown x. Classical regularization formulations seek solutions of problems of the form min x f(x) + λ r(x) (2) or one of the equivalent (under mild conditions) forms min x r(x) s.t. f(x) ≤ε or min x f(x) s.t. r(x) ≤ϵ, (3) where, typically, f(x) = 1 2 ∥y −Ax∥2 2 is the data-ﬁdelity term (under a white Gaussian noise assumption), r(x) is the regularizer that enforces certain properties on the target solution, and λ, ε, and ϵ are non-negative parameters. A type of prior knowledge that has been the focus of much recent attention (namely with the advent of compressive sensing – CS – [10], [22]) is sparsity, i.e., that a large fraction of the components of x are zero [26]. The ideal regularizer encouraging solutions with the smallest possible number of nonzero entries is rℓ0(x) = ∥x∥0 (which corresponds to the number of non-zero elements of x), but the resulting problem is of combinatorial nature and known to be NP-hard [12], [40]. The LASSO (least absolute shrinkage and selection operator) [52] uses the ℓ1 norm, rLASSO (x) = ∥x∥1 = P i |xi|, is arguably the most popular sparsity-encouraging regularizer. The ℓ1 norm can be seen as the tightest convex approximation of the ℓ0 “norm” (it’s not a norm) and, under conditions that are object of study in CS [11], yields the same solution. Many variants of these regularizers have been proposed, such as ℓp (for p ∈[0, 1]) “norms” [15, 17], and reweighted ℓ1 [13, 56, 61] and ℓ2 norms [20, 56, 16].  1 INTRODUCTION 3 1.1. Group-sparsity-inducing Regularizers In recent years, much attention has been paid not only to the sparsity of solutions but also to the structure of this sparsity, which may be relevant in some problems and which provides another avenue for inserting prior knowledge into the problem. In particular, considerable interest has been attracted by group sparsity [60], block sparsity [27], or more general structured sparsity [3], [33], [38]. A classic model for group sparsity is the group LASSO (gLASSO) [60], where the regularizer is the so-called ℓ1,2 norm [47], [36] or the ℓ1,∞norm [47], [37',\n",
       " 'cs/0509044': 'Error correcting codes which employ iterative decoding algorithms are now considered state of the art in the ﬁeld of low-complexity coding techniques. By now, there is a large collection of families of iteratively decoded codes including low-density parity-check (LDPC), turbo, repeat-accumulate and product codes; all of them demonstrate a rather small gap (in rate) to capacity with feasible complexity. The study of capacity-achieving (c.a.) sequences of LDPC ensembles for the binary erasure channel (BEC) was initiated by Luby et al. [1] and Shokrollahi [2]. They show that it is possible to closely approach the capacity of an erasure channel with a simple iterative procedure whose complexity is linear in the block length of the code [1, 2]. Following these works, Oswald and Shokrollahi presented in [3] a systematic study of c.a. degree distributions for sequences of ensembles of LDPC codes whose transmission takes place over a BEC. Jin et al. introduced irregular repeat-accumulate (IRA) codes and presented a c.a. sequence of systematic IRA (SIRA) ensembles [4]. A new sequence of c.a.  SIRA codes with lower complexity was also introduced in [5]. All of the aforementioned codes have one major drawback; their decoding complexity scales like the log of the inverse of the gap (in rate) to capacity, which becomes unbounded as the gap to capacity vanishes [5, 6, 7]. In a previous paper [8], Pﬁster, Sason and Urbanke presented for the ﬁrst time two sequences of ensembles of non-systematic IRA (NSIRA) codes which asymptotically (as their block length goes to inﬁnity) achieve capacity on the BEC with bounded complexity per information bit. The new bounded complexity result in [8] is achieved by puncturing bits and allowing in this way a suﬃcient number of state nodes in the Tanner graph representing the codes. We note that for ﬁxed complexity, the new codes in [8] eventually (for large enough block length) outperform any code proposed so far. However, the convergence speed to the ultimate performance limit happens to be quite slow, so for small to moderate block lengths, the new codes are not record breaking. In this paper, we are interested in constructing c.a. codes on the BEC with bounded complexity per information bit which are also systematic codes. We would also like these codes to perform well at moderate block lengths and have low error ﬂoors. To this end, we make use of a new channel coding scheme, called “Accumulate-Repeat-Accumulate” (ARA) codes, which was recently introduced by Abbasfar, Divsalar, and Yao [9]. These codes are systematic and have both outstanding performance, as exempliﬁed in [9, 10, 11], and a simple linear-time encoding. After deﬁning an appropriate ensemble of irregular ARA codes, we construct a number of c.a. degree distributions. Simulations show that some of these ensembles perform quite well on the BEC at moderate block lengths. Therefore, we expect that irregular ARA codes optimized for general channels might also perform well at moderate block lengths. Along the wa',\n",
       " '1711.10337': 'Generative adversarial networks (GAN) are a powerful subclass of generative models and were successfully applied to image generation and editing, semi-supervised learning, and domain adaptation [22, 27]. In the GAN framework the model learns a deterministic transformation G of a simple distribution pz, with the goal of matching the data distribution pd. This learning problem may be viewed as a two-player game between the generator, which learns how to generate samples which resemble real data, and a discriminator, which learns how to discriminate between real and fake data. Both players aim to minimize their own cost and the solution to the game is the Nash equilibrium where neither player can improve their cost unilaterally [9]. Various ﬂavors of GANs have been recently proposed, both purely unsupervised [9, 1, 10, 5] as well as conditional [20, 21]. While these models achieve compelling results in speciﬁc domains, there is still no clear consensus on which GAN algorithm(s) perform objectively better than others. This is partially due to the lack of robust and consistent metric, as well as limited comparisons which put all algorithms on equal footage, including the computational budget to search over all hyperparameters. Why is it important? Firstly, to help the practitioner choose a better algorithm from a very large set. Secondly, to make progress towards better algorithms and their understanding, it is useful to clearly assess which modiﬁcations are critical, and which ones are only good on paper, but do not make a signiﬁcant difference in practice. The main issue with evaluation stems from the fact that one cannot explicitly compute the probability pg(x). As a result, classic measures, such as log-likelihood on the test set, cannot be evaluated. Consequently, many researchers focused on qualitative comparison, such as comparing the visual quality of samples. Unfortunately, such approaches are subjective and possibly misleading [8]. As a remedy, two evaluation metrics were proposed to quantitatively assess the performance of GANs. Both assume access to a pre-trained classiﬁer. Inception Score (IS) [24] is based on the fact that a good model should generate samples for which, when evaluated by the classiﬁer, the class distribution has low entropy. At the same time, it should produce diverse samples covering all classes. In contrast, ⋆Indicates equal authorship. Correspondence to {lucic,kkurach}@google.com. 32nd Conference on Neural Information Processing Systems (NIPS 2018), Montréal, Canada. arXiv:1711.10337v4  [stat.ML]  29 Oct 2018  Fréchet Inception Distance is computed by considering the difference in embedding of true and fake data [11]. Assuming that the coding layer follows a multivariate Gaussian distribution, the distance between the distributions is reduced to the Fréchet distance between the corresponding Gaussians. Our main contributions: (1) We provide a fair and comprehensive comparison of the state-of-the-art GANs, and empirically demonstrate that nearly all of them can reach similar values of FID, given a high enough computational budget. (2) We provide strong empirical evidence2 that to compare GANs it is necessary to report a summary',\n",
       " '1411.3229': 'Correlative microscopy is an integration of diﬀerent microscopy technologies including conventional light, confocal and electron transmission microscopy [6]. Correlative microscopic images usually involve linear or non-linear distortions which are caused by the diﬀerences between imaging systems and processing steps. Therefore, the ﬁrst step of most correlative microscopy based applications is to do registration between two or more microscopic images. An example of correlative microscopic images is presented in Fig. 1. arXiv:1411.3229v2  [cs.CV]  13 Jan 2015  2 Tian Cao, Christopher Zach, Marc Niethammer and etc. Image registration estimates space transformations between images (to align them) and is an essential part of many image analysis approaches. The registration of correlative microscopic images is very challenging: images should carry distinct information to combine for example knowledge about protein locations (using ﬂuorescence microscopy) with high-resolution structural data (using electron microscopy). However, this precludes the use of simple alignment measures such as the sum of squared intensity diﬀerences because intensity patterns do not correspond well or a multi-channel image has to be registered to a gray-valued image. Furthermore, because they operate near or beyond the boundaries of what is measurable, each type of microscopy introduces artifacts into the image that it produces: confocal microscopes convolve the specimen ﬂuorophore distribution with the point-spread-function of their lens system, and scanning electron microscopes produce brighter images near negative surface curvature (as well as volumetric eﬀects), which should ideally be considered when computing alignments. In this report, I introduce two methods of image registration for correlative microscopy based on ﬁducials and images respectively. The ﬁrst method involves automatic landmark based registration. We extract landmarks based on the ﬁducials and compute the matching landmarks in both images. The transformation matrix is estimated from the corresponding landmarks. We also apply a least-squares matching to the initial alignment of the landmarks to get a better registration result. The second method is inspired by the image analogies approach [12]. We extend the image analogies using a sparse representation model. This report is organized as follows. First, I brieﬂy introduce some related work in Sec. 2. Then I describe the automatic landmark based image registration for correlative microscopy in Sec. 3. and the image analogies method with sparse coding and the numerical solutions in Sec. 4. The image registration results are shown in Sec. 5. The conclusion and future work are discussed in Sec. 6. (a) Confocal Microscopic Image (b) Resampling of Boxed Region in Confocal Image (c) TEM Image Fig. 1: Example of Correlative Microscopy. The goal is to align (b) to (c).  Multi-modal Image Registration for Correlative Microscopy 3 2 Related Work 2.1 Multi-modal Image Registration for Correlative Microscopy One possible solution of image registration for correlative microscopy is to perform landmark-based alignment. Landmarks can be manually speciﬁed [15] or automatically extracted [21]. The alignment can be greatly simpliﬁed by adding ﬁducial markers (e.g., some form of beads',\n",
       " '1203.5602': 'Cooperation and secrecy are two important concepts which have been widely studied in wireless communications. Due to the broadcast nature of radio propagation, wireless transmissions can be overheard by multiple unintended receivers. Such broadcasting nature facilitates cooperation by allowing neighbor users to intelligently exploit the over-heard information but also leads to a serious security problem such as eavesdropper attacking. Wyner studied the eavesdropping attack from an information theoretic aspect by introducing the concept of wire-tap channel in [1]. Under the assumption that the wiretapper channel (source-to-wiretapper) is a degraded version of the main channel (source-to-destination), the secrecy capacity was established based on the rate-equivocation region concept. Csiz´ar and K¨orner extended this degraded channel to the general wiretapper channel setup without any special assumptions, and found the secrecy capacity in [2]. Recently, more types of multiuser networks have been studied in the context of secrecy communications. Peng Xu and Xuchu Dai are with Dept. of Electronic Engineering and Information Science , University of Science and Technology of China, P.O.Box No.4, 230027, Hefei, Anhui, China. Zhiguo Ding is with School of Electrical, Electronic, and Computer Engineering Newcastle University, UK. Kin Leung is with Department of Electrical and Electronic Engineering, Imperial College, London, UK. Submitted to IEEE Transaction on Information Theory at 14 March 2012.  2 The multiple access wiretapper channel (MAC-WT) is considered in [3], [4], where an external passive wiretapper was included. The multiple access channel with conﬁdential messages (MAC-CM) is studied in [5], [6], where the source terminals act as eavesdroppers to each other. The works in [7], [8] investigate the broadcast channel with conﬁdential messages (BC-CM) where both receivers wish to keep their message secret from the others. Similarly, [7], [9] considered the interference channel (IC), where the former treated each unintended receiver as an eavesdropper and the latter introduced an external eavesdropper. To further enhance the secrecy level in the above mentioned channel models, user cooperation has been considered in [4], [7], [10]–[17], where [10]–[14] consider the untrusted helper scenario in which the relay node acts both a helper and an eavesdropper, and [4], [7], [15]–[17] consider cooperative communication systems with an external eavesdropper. Particularly for the latter scenario with a dedicated relay, such as the work in [4], [15], [16] where the relay does not have its own message to be sent or received, so-called interference-assisted schemes that involve cooperative jamming [4] and noisy forward (NF) [15] techniques have been proved to be particularly useful to increase secrecy. The basic idea of these strategies is to allow the relay to send codewords (or even pure noisy) which are independent to the source message in order to confuse the eavesdropper. The work in [16] can be viewed as a generalization of this type of interference strategies for a wiretap channel with a helping interferer (WT-HI). On the other hand, [15] extended some classical relay',\n",
       " '1710.02909': 'To build a visual recognition system for any application these days, one’s ﬁrst inclination is to turn to the most recent machine learning breakthrough from the area of deep learning, which no doubt has been enabled by access to millions of training images from the Internet. But there are many circumstances where such an approach cannot be used as an off-the-shelf component to assemble the system we desire, because even the largest training dataset does not take into account all of the artifacts that can be experienced in the environment. As computer vision pushes further into real-world applications, what should a software system that * denotes equal contribution Figure 1: (Top) In principle, image restoration and enhancement techniques should improve visual recognition performance by creating higher quality inputs for recognition models. This is the case when a Super Resolution Convolutional Neural Network [7] is applied to the image in this panel. (Bottom) In practice, we often see the opposite effect — especially when new artifacts are unintentionally introduced, as in this application of Deep Deblurring [43]. We describe a new video dataset (Sec. 3) for the study of problems with algorithm and data interplay (Sec. 6) like this one. can interpret images from sensors placed in any unrestricted setting actually look like? First, it must incorporate a set of algorithms, drawn from the areas of computational photography and machine learning, into a processing pipeline that corrects and subsequently classiﬁes images across time and space. Image restoration and enhancement algorithms that remove corruptions like blur, noise, and mis-focus, or manipulate images to gain resolution, change perspective, and compensate for lens distortion are now commonplace in photo editing tools. Such operations are necessary to improve the quality of raw images that are otherwise unacceptable for recogniarXiv:1710.02909v2  [cs.CV]  7 Feb 2018  tion purposes. But they must be compatible with the recognition process itself, and not adversely affect feature extraction or classiﬁcation (Fig. 1). Remarkably, little thought has been given to image restoration and enhancement algorithms for visual recognition — the goal of computational photography thus far has simply been to make images look appealing after correction [60, 3, 46, 17, 43]. It remains unknown what impact many transformations have on visual recognition algorithms. To begin to answer that question, exploratory work is needed to ﬁnd out which image pre-processing algorithms, in combination with the strongest features and supervised machine learning approaches, are promising candidates for different problem domains. One popular problem that contains imaging artifacts typically not found in computer vision datasets crawled from the web is the interpretation of images taken by aerial vehicles [47, 38]. This task is a key component of a number of applications including robotic navigation, scene reconstruction, scientiﬁc study, entertainment, and visual surveillance. Images captured from aerial vehicles tend to present a wide variety of artifacts and optical',\n",
       " '1808.03246': 'Simulators are an essential for the development of robot systems. An important class of systems in robotics is well approximated by rigid-body dynamics; relatively mature, fast, and general-purpose simulators have been developed for these systems. These simulators (e.g., ODE [1], Bullet [2], MuJoco [3]) rely on approximate and efﬁcient dynamics models and do not reason about uncertainty explicitly. These simulators are an important tool, yet their practicality has been limited due to discrepancies between their predictions and real-world observations. A major source of mismatches is the contact models used in these simulators. Contact is a complex physical interaction with near impulsive forces over a small duration of time that involves local deformations and vibrations. Matters are complicated by the sensitivity of contact outcomes to initial conditions. These models are coarse approximations to contact, and recent studies ([4], [5], [6]) have shown the discrepancies between their predictions and real-world data. Further, Fazeli et al. [6] showed that there exist real-world contact outcomes which the models are unable to predict for any choice of their parameters. This suggests that generating uncertainty by deﬁning distributions over contact parameters does not yield a sufﬁciently rich and descriptive distribution over outcomes. In this study, we provide a framework for augmenting analytical motion models with empirical data that has higher accuracy while capturing uncertainty in predictions. We achieve this by using a novel type of recurrent neural networks, 1 A. Ajay, J. Wu, L. P. Kaelbling, and J. B. Tenenbaum are with the Computer Science and Artiﬁcial Intelligence Laboratory at Massachusetts Institute of Technology, Cambridge, MA, USA 2 N. Fazeli, M. Bauza, and A. Rodriguez are with the Department of Mechanical Engineering at Massachusetts Institute of Technology, Cambridge, MA, USA Fig. 1: The motion of an object being pushed appears stochastic and possibly multi-modal due to imperfections in contact surfaces, non-uniform coefﬁcient of friction, stick/slip transitions, and micro surface interactions. In this study, we propose to augment analytical models to more accurately predict such outcomes while reasoning about uncertainty. namely decoupled conditional variational recurrent neural nets, to learn the residual errors made by the analytical models. Once the neural networks are trained, they can correct model predictions and provide distributions over possible outcomes. We demonstrate the efﬁcacy of the data-augmented stochastic simulation framework in two cases: 1) a toy bouncing ball problem, and 2) planar pushing with a single point pusher using the empirical dataset from Yu et al. [5]. First, we use the toy problem to illustrate the implementation and details of the proposed model in simulation. We then move to the experimental planar pushing dataset to demonstrate the ability of the approaches to capture real-world data. We show that the data-augmented model outperforms its purely analytical and purely data-driven counterparts. Further, we demonstrate that this approach is data-efﬁcient, as learning residuals is an easier and better formulated problem than learning full motion models. Experiments also suggest that the',\n",
       " '1812.07484': 'Nearest neighbor search is a common component of algorithms and pipelines in areas such as machine learning [5,17], computer vision [1] and robotics [11]. In modern applications the search is typically performed in high-dimensional spaces (100–10000 dimensions) over large data sets. An exhaustive k-nearest neigbor (k-NN) search is often prohibitively slow in applications which either require real-time responses (see e.g. [17]) or run on a resource-constrained device (see e.g. [11]). Hence, approximate nearest neighbor (ANN) search is often used instead. ANN algorithms ﬁrst build an index in an oﬄine phase, after which the index can be used to perform k-NN queries in sublinear time in an online phase. Most of the eﬃcient algorithms fall into one of four categories: product quantization (PQ) [8], locality-sensitive hashing (LSH) [7,4], graph-based methods [10], and tree-based methods [14,13]. Because ANN algorithms are typically used as an auxiliary component of a pipeline, it can be important for a user that an algorithm requires minimal handtuning, especially if the type or size of the data can vary signiﬁcantly. However, arXiv:1812.07484v1  [cs.DS]  18 Dec 2018  2 E. Jääsaari et al. ANN algorithms typically have several hyperparameters which need to be tuned by a time-consuming grid search to achieve a given accuracy level or search time. This problem is solved by an autotuning algorithm where the user speciﬁes an accuracy level, and the tuning algorithm ﬁnds the optimal hyperparameter values. Previously, autotuning methods have been proposed for VP-trees [18], multi-probe LSH [4], k-means trees and RKD trees [13]. In this paper, we propose an autotuning method that is signiﬁcantly faster than these methods. Our approach is based on exploiting the structure of randomized spacepartitioning trees [14,13,3,6]. ANN algorithms based on randomized space-partitioning trees have been used recently for example in machine translation [5], object detection [1] and recommendation engines [17]. Trees have several advantages: they are fast in high-dimensional spaces (see e.g. experiments in [13,6]); they are simple to implement; they support easy insertion and deletion of points and they are independent, making the parallel implementation trivial. Also of great importance to us is that the structure of a tree-based index can be exploited to speed up the hyperparameter tuning. Several types of randomized space-partitioning trees have been proposed for ANN search. Randomized k-d (RKD) trees [14] with a priority queue search are used in the popular open-source library FLANN [13]. Random projection (RP) trees [3] with a voting search have a stronger empirical performance than RKD trees with a priority queue search [6]. However, a single principal component (PCA) tree has been found to be more accurate than a single RP tree [16]. The PCA tree has two problems: it is not randomized, and indexing is slow. To solve these problems, we design a randomized variant of the PCA tree. Typically',\n",
       " '1503.04371': 'A. Uniform random number generation (URNG) Uniform random number generation is one of important tasks for information theory as well as secure communication. When a non-uniform random number is generated subject to independent and identical distribution and the source distribution is known to PX, we can convert it to the uniform random number, whose optimal conversion rate is known to be the entropy H(PX) [2]. Vembu and Verd´u [3] extended this problem to the general information source. Applying their result to the Markovian source, we ﬁnd that the optimal conversion rate is the entropy rate. On the other hand, many researchers in information theory are attracted by non-asymptotic analysis recently [4], [5], [6]. Since all of realistic situations are non-asymptotic, it is strongly desired to evaluate the performance of a protocol in the non-asymptotic setting. In the case of uniform random number generation, we need to consider two issues: A1) How to quantitatively guarantee the security for ﬁnite block length n. As the criterion, we employ the variational distance criterion because it is universal composable[7]. A2) How to implement the extracting method efﬁciently. This paper was presented in part at 2014 Information Theory and Applications Workshop [1]. The ﬁrst author is with the Graduate School of Mathematics, Nagoya University, Japan. He is also with the Centre for Quantum Technologies, National University of Singapore, Singapore. e-mail:masahito@math.nagoyau.ac.jp The second author is with the Department of Computer and Information Sciences, Tokyo University of Agriculture and Technology, Koganei, Tokyo, Japan. He was with the Department of Information Science and Intelligent Systems, University of Tokushima, Tokushima, Japan. e-mail:e-mail: shunwata@cc.tuat.ac.jp Manuscript received ; revised Fortunately, the latter problem has been solved by employing universal2 hash functions, which can be constructed by combination of Toeplitz matrix and the identity matrix [8]. This construction has small amount of complexity and was implemented in a real demonstration [9], [10]. Recently, the paper [11] proposed a new class of hash functions, ε-almost dual universal hash functions, and the paper [10] proposed more efﬁcient hash functions belonging to this new class. Hence, it is needed to solve the ﬁrst problem. So far, with a huge size n, quantitative evaluation of the security has been done only for the i.i.d. source [8], [12]. However, the source is not necessarily i.i.d. in the real world, and it is necessary to develop a technique to evaluate the security for non i.i.d. source. As a ﬁrst step of this direction of research, we consider the Markov source in this paper. In the following, we explain difﬁculties to extend the existing results for the i.i.d. source to the Markov source. Although it is not stated explicitly in any literatures, we believe that there are two important criteria for non-asymptotic bounds: B1) Computational complexity, and B2) Asymptotic optimality. Let us ﬁrst consider the',\n",
       " '1203.2936': 'The least absolute shrinkage and selection operator (LASSO) is the de facto standard algorithm for regression [1]. LASSO estimates sparse linear models by minimizing the empirical data error via: bxLASSO = arg min n ∥y −Φx∥2 2 : ∥x∥1 ≤λ o , (1) where ∥· ∥r is the ℓr-norm. In (1), Φ ∈Rm×n is the sensing matrix, y ∈Rm are the responses (or observations), x ∈Rn is the loading vector and λ ∈R++ governs the sparsity of the solution. Along with many efﬁcient algorithms for its solution, the LASSO formulation is now backed with a rather mature theory for the generalization of its solutions as well as its variable selection consistency [2]–[5]. While the long name attributed to (1) is apropos,1 it does not capture the LASSO’s arbitrariness in subset selection via shrinkage to best explain the responses. In fact, this uninformed selection process not only prevents interpretability of results in many problems, but also fails to exploit key prior information that could radically improve learning performance. Based on this premise, approaches to guide the selection process of the LASSO are now aplenty. Surprisingly, while the prior information in many regression problems generate fundamentally discrete constraints (e.g., on the sparsity patterns or the support of the LASSO solution), the majority of the existing approaches that enforce such constraints in selection are inherently continuous. For instance, a prevalent approach is to tailor a sparsity inducing norm to the constraints on the support set (c.f., [6]). That is, we create a structured convex norm by mixing basic norms with weights over pre-deﬁned groups or using the Lov´asz extension of non-decreasing submodular set functions of the support. As many basic norms have well-understood behavior in sparse selection, reverse engineering such norms is quite intuitive. While such structure inducing, convex norm-based approaches on the LASSO are impressive, our contention in this paper is that, in order to truly make an impact in structured sparsity problems, we must fully leverage explicitly combinatorial approaches to guide LASSO’s subset selection process. To achieve this, we show how Euclidean projections with structured sparsity constraints correspond to an integer linear program (ILP), which can be exactly or approximately solved subject to matroid (via the greedy algorithm), and certain linear inequality constraints (via convex relaxation or multi-knapsack solvers). A key actor in this process is a polynomial-time combinatorial algorithm that goes beyond simple selection heuristics towards provable solution quality as well as runtime/space bounds. Furthermore, we introduce our combinatorial selection and least absolute shrinkage (CLASH) operator and theoretically characterize its estimation guarantees. CLASH enhances the model-based compressive sensing (model-CS) framework [7] by combining ℓ1-norm and combinatorial constraints on the regression vector. Therefore, CLASH uses a combination of shrinkage and hard thresholding operations to signiﬁcantly outperform the model-CS approach, LASSO, or continuous structured sparsity approaches in learning performance of sparse linear models. Furthermore, CLASH establishes a regression framework where the underlying tractability of',\n",
       " '1309.7109': 'FAILED',\n",
       " '1404.4108': 'Consider a Machine Learning Service Provider (MLSP) designed to rapidly create highly accurate learners for a never-ending stream of new tasks. Different clients, for example a social networking site or video surveillance company, could ask the MLSP to design a stream of different face recognition agents, each achieving recognition of a different set of target individuals. In such a setting, it is necessary to quickly produce a task-speciﬁc learner that can be trained from very few labeled samples (e.g. examples of the target face). Learning from few labeled samples has been known to arise in many tasks for which data is expensive to label (e.g., medical images) or slow to collect (e.g., human computer interaction). In general, there are three paths towards acceptable performance for learning from few samples: 1. Using domain knowledge. 2. Using unlabeled samples. 3. Using labeled samples from a different, but related task. Bayesian methods [1] have typically focused on the ﬁrst option, using knowledge of structure in the target task to bias search towards better hypotheses. Other methods, like manifold regularization [2], blend the ﬁrst and second options by combining domain knowledge, through an engineered distance metric/kernel, and unlabeled samples. Meanwhile, the representation learning community has pursued the second option, producing a number of methods like Deep Boltzmann Machines [3], Stacked Denoising Autoencoders [4], and Sparse Coding [5] that have proven effective for transfer from unlabeled data to tasks with few labeled samples. While methods based on options (1) and (2) work well for a variety of tasks, they typically ignore the existence of large amounts of labeled data from different, but possibly related tasks, that may provide signiﬁcant information about the task-of-interest (called target task). The transfer learning community has explored this idea through a variety of methods, often termed “supervised transfer”. The most common tools for supervised transfer come from multitask learning [6], in which a ﬁxed 1 arXiv:1404.4108v2  [cs.LG]  9 Jul 2014  set of tasks is given a priori and the learner seeks a model that can generalize well to new samples from the given tasks. While multitask learning has been effective in many situations, it falls short in environments where new tasks are constantly arriving and one seeks to generalize well to new tasks, as is the case for our MLSP. This latter type of transfer is generally referred to as inductive bias learning [7], lifelong learning [8], learning to learn [9], or never ending learning [10], among other names. Our work focuses on this setting. In this paper, we present a method to learn in an environment of streaming tasks, like that faced by our MLSP. Our method operates on two components: a parametric representation (shared between tasks) and a collection of parametric function approximators (one per task). We aim to learn the parameters of the representation such that its output would be a more effective input to new function approximators. Our method, called LeaDR (Learning Discriminative Representations',\n",
       " '1801.00406': 'FAILED',\n",
       " '1801.02101': 'Handheld, portable Confocal Laser Endomicroscopy (CLE) is being explored for neurosurgery of brain tumors because of its ability to image histopathological features of the tissue in real time during surgery. CLE provides for the ﬁrst time imaging during brain tumor surgery at cellular resolution, and thus a signiﬁcant technology advancement for precision brain tumor surgery toward surgery on a cellular resolution.1,2 A wide range of ﬂuorophores are able to be used for CLE in gastroenterology, but ﬂuorophore options are limited for in vivo human brain use.3,4 In addition, motion and blood artifacts that are present in many of the images acquired with CLE using ﬂuorescein sodium are a barrier for delivering the instruments potential beneﬁts to the surgeon. It takes time for the surgeon or pathologist to ﬁnd and exclude the nondiagnostic frames and focus on diagnostic ones during the operation to make the intraoperative diagnosis.5 In a previous study5 our lab showed that about half of the images acquired were nondiagnostic due to abundance of motion and blood artifacts or lack of histopathological features. Figures 1 and 2 show some examples of the diagnostic and nondiagnostic CLE images from our database. Further author information: (Send correspondence to M.I) M.I.: E-mail: mizadyya@asu.edu arXiv:1801.02101v1  [cs.CV]  6 Jan 2018  (a) (b) (c) (d) (e) (f) (g) (h) Figure 1. Nondiagnostic CLE images. Nondiagnostic images were detected through subjective evaluation done by experts. (b,e) show motion artifact and (h) shows motion artifact. Other images lack the suﬃcient histopathological information required for a conﬁdent diagnosis. In our study we tried to classify the CLE images acquired from diﬀerent brain tumors during surgery, using convolutional neural networks. First, we used subjective assessment to ﬁnd the diagnostic CLE brain tumor images. Then, we used convolutional neural networks for making our models. We divided our data into training, validation and test sections to ﬁrst train and validate the model and then test its performance on test images. We trained diﬀerent CNN architectures and showed which one has better performance and is potentially a better candidate for this task. Finally, we compared our model performance with the results achieved from conventionally used entropy-based method. 2. METHODS At this part we’ll ﬁrst explain a little about CLE and how the images were acquired. Then, we’ll cover the mathematical methods for the CNNs used in our work. 2.1 Image Acquisition The CLE (Optiscan 5.1, Optiscan Pty, Ltd.) image acquisition system consists of a handheld miniaturized optical laser scanner designed as a rigid probe with a 6.3 mm outer diameter and a working length of 150 mm. A 488 nm diode laser provided incident excitation light, and ﬂuorescent emission was detected at 505-585 nm using a band-pass ﬁlter, via a single optical ﬁber acting as both the excitation pinhole and the detection pinhole for confocal isolation of the focal plane. The detector signal was digitized synchronously with the scanning',\n",
       " '1105.3416': 'In this paper, we present the ﬁrst implementation of physical-layer network coding (PNC) on the software radio platform. We believe this prototyping eﬀort moves the Email addresses: ll007@ie.cuhk.edu.hk (Lu Lu), postman511@gmail.com (Taotao Wang), soung@ie.cuhk.edu.hk (Soung Chang Liew), zsl@szu.edu.cn (Shengli Zhang) Preprint submitted to Physical Communication May 28, 2018  concept of PNC a step toward reality. Our implementation work also exposes and raises some interesting issues for further research. PNC, ﬁrst proposed in [1], is a subﬁeld of network coding [2] that is attracting much attention recently. The simplest system in which PNC can be applied is the twoway relay channel (TWRC), in which two end nodes A and B exchange information with the help of a relay node R in the middle, as illustrated in Fig. 1. Compared with the conventional relay system, PNC could double the throughput of TWRC by reducing the needed time slots for the exchange of one packet from four to two [1]. In PNC, in the ﬁrst time slot, end nodes A and B send signals simultaneously to relay R; in the second phase, relay R processes the superimposed signals and maps them to a network-coded packet for broadcast back to the end nodes. From the network-coded packet, each end node then makes use of its self information to extract the packet from the other end node [1, 3, 4]. Prior to this paper, only a simpliﬁed version of PNC, called analog network coding (ANC) [5], has been successfully implemented. The advantage of ANC is that it is simple to implement; the disadvantage, on the other hand, is that the relay ampliﬁes the noise along with the signal before forwarding the signal, causing error propagation. To our best knowledge, the implementation of the original PNC based on XOR mapping as in [1] has not been demonstrated, even though it could have signiﬁcantly better performance. A reason is that the implementation of XOR PNC poses a number of challenges. For example, the relay must be able to deal with symbol and carrier-phase asynchronies of the simultaneous signals received from the two end nodes, and the relay must perform channel estimation before detecting the signals. This paper presents a PNC implementation in the frequency domain, referred to as FPNC, to tackle these challenges. In particular, FPNC is based on OFDM, and XOR mapping is performed on OFDM samples in each subcarrier rather than the samples in the time domain. We implement FPNC on the universal soft radio peripheral (USRP) platform. Our implementation requires only moderate modiﬁcations of the packet preamble design of 802.11a/g OFDM PHY. With the help the cyclic preﬁx (CP) in OFDM, symbol asynchrony and the multi-path fading eﬀects can be dealt with in a similar fashion. Our experimental results show that symbol-synchronous and symbol-asynchronous FPNC have nearly the same BER performance, for both channel-coded and unchannel-coded FPNC. End Node  A',\n",
       " '1708.00187': 'Interlacing technique has been widely used in the past few decades for television broadcast and video recording, in both analog and digital ways. Instead of capturing all N scanlines for each frame, only N/2 odd numbered scanlines are captured for the current frame (Fig. 2(a), upper), and the other N/2 even numbered scanlines are captured for the following frame (Fig. 2(a), lower). It basically trades the frame resolution for the frame rate, in order to double the perceived frame rate without increasing the bandwidth. Unfortunately, since the two half frames are captured in different time instances, there are significant visual artifacts such as line flickering and “serration” on the silhouette of moving objects (Fig. 2(b)), when the odd and even fields are interlaced displayed. The degree of “serration” depends on the motion of objects and hence is spatially varying. This makes deinterlacing (removal of interlacing artifacts) an ill-posed problem. Many deinterlacing methods have been proposed to suppress the visual artifacts. A typical approach is to reconstruct two full frames from the odd and even half frames independently (Fig. 2(c)). However, the result is usually unsatisfactory, due to the large information loss (50% loss) [5, 20, 21]. Higher-quality reconstruction can be obtained by first estimating object motion [10, 14, 17]. However, motion estimation from half interlacing frames are not reliable, and also computationally expensive. Hence, they are seldomly used in practice, let alone real-time applications. In this paper, we propose the first deep convolutional neural networks (DCNNs) method tailormade for the video deinterlacing problem. To our best knowledge, no DCNN-based deinterlacing method exists. One may argue that existing DCNN-based methods for interpolation or super-resolution [4, 15] can be applied to reconstruct the full frames from the half frames, in order to solve the deinterlacing problem. However, such naive approach lacks of utilizing the temporal information between the odd and even half frames, just like the existing intra-field deinterlacing methods [5, 20]. Moreover, arXiv:1708.00187v1  [cs.CV]  1 Aug 2017  (a) Two half frames (b) Interlaced frame (c) Deinterlaced results (ELA) Fig. 2. (a) Two half fields are captured in two distinct time instances. (b) The interlaced display exhibits obvious artifacts on the silhouette of moving car. (c) Two full frames reconstructed from the two half frames independently with an intra-field deinterlacing method ELA [5]. this naive approach follows the conventional translation-invariant assumption. That means, all pixels in the output full frames are processed with the same set of convolutional filters, even though half of the scanlines (odd/even numbered) actually exist in the input half frames. Fig. 3(b) shows a full frame, reconstructed by the state-of-the-art DCNN-based super-resolution method, SRCNN [4], exhibiting obvious halo artifact. Instead of replacing the potentially error-contaminated pixels from the convolutional filtering with the groundtruth pixels in the input half frames and leading to visual artifacts (Fig. 3(c)), we argue that we should only reconstruct the',\n",
       " '1809.05375': 'Whilst deep neural networks have shown record-breaking performance on complex machine learning tasks over the past few years, exceeding human performance levels in certain cases, most deep models heavily rely on large quantities of annotated data for individual tasks, which is often expensive to obtain. A common solution is to augment smaller datasets by creating new training samples from existing ones via label-preserving transformations [39]. Data augmentation imparts prior knowledge to a model by explicitly teaching invariance to possible transforms that preserve semantic content. This is done by applying said transform to the original training data, producing new samples whose labels are known. For example, horizontal ﬂipping is a popular data augmentation technique [18], as it clearly does not change the corresponding class label. The most prevalent forms of image-based data augmentation include geometric distortions such as random cropping, zooming, rotation, ﬂipping, linear intensity scaling and elastic deformation. Whilst these are successful at teaching rotation and scale invariance to a model, what of color, texture and complex illumination variations? Tobin et al. [33] show that it is possible for an object detection model to generalize from graphically rendered virtual environments to the real world, by randomizing color, texture, illumination and other aspects of the virtual scene. It is interesting to note that, rather than making the virtual scene as realistic as possible, they attain good generalization by using an unrealistic but diverse set of Preprint. Work in progress. arXiv:1809.05375v2  [cs.CV]  12 Apr 2019  Figure 1: Style augmentation applied to an image from the Ofﬁce dataset [24] (original in top left). Shape is preserved but the style, including texture, color and contrast are randomized. random textures. In contrast, Atapour & Breckon [1] train on highly photorealistic synthetic images, but ﬁnd that the model generalizes poorly to data from the real world. They are able to rectify this by using CycleGAN [44] and fast neural style transfer [17] to transform real world images into the domain of the synthetic images. These results together suggest that deep neural networks can overﬁt to subtle differences in the distribution of low-level visual features, and that randomizing these aspects at training time may result in better generalization. However, in the typical case where the training images come not from a renderer but from a camera, this randomization must be done via image manipulation, as a form of data augmentation. It is not clear how standard data augmentation techniques could introduce these subtle, complex and ill-deﬁned variations. Neural style transfer [9] offers the possibility to alter the distribution of low-level visual features in an image whilst preserving semantic content. Exploiting this concept, we propose Style Augmentation, a method to use style transfer to augment arbitrary training images, randomizing their color, texture and contrast whilst preserving geometry (see Figure 1). Although the original style transfer method was a slow optimization process that was parameterized by a target style image [9], newer approaches require only a',\n",
       " '1710.00555': 'Nanoscale molecular communication has garnered signiﬁcant interest in recent times towards addressing challenging problems in biomedical, industrial, and surveillance scenarios [1], [2]. This has lead to the development of novel applications such as efﬁcient drug delivery and human body monitoring, using communicating nano-robots [3]–[5]. In contrast to active molecular communication (AMC)-based systems such as molecular motors and protein ﬁlaments, the molecules in diffusion-based passive molecular communication (PMC) systems propagate via Brownian motion in a ﬂuidic medium without requiring additional infrastructure or external energy [1], [2]. Several research efforts [6]–[17] have been devoted to exploring various aspects such as developing channel models, estimating the channel as well as analyzing the performance of diffusion based molecular systems. It has been shown in [18] that the molecular concentration decays inversely as the cube of the distance between the transmitter and receiver nanomachines, which severely limits the performance Neeraj Varshney, Adarsh Patel and Aditya K. Jagannatham are with the Department of Electrical Engineering, Indian Institute of Technology Kanpur, Kanpur UP 208016, India (e-mail:{neerajv; adarsh; adityaj}@iitk.ac.in). Pramod K. Varshney is with the Department of Electrical Engineering & Computer Science, Syracuse University, Syracuse, NY 13244, USA (email:varshney@syr.edu). of such systems. Relay-assisted cooperative communication has been shown to successfully overcome this impediment by signiﬁcantly enhancing the communication range. This leads to a substantial improvement in the end-to-end reliability of communication, thus making it a very promising technology for such systems [19]. However, the decoding accuracy at the destination in relay-assisted molecular communication depends critically on the detection performance of the intermediate cooperative nanomachine(s) that act as relays. The end-to-end performance can further deteriorate due to other degrading effects such as inter-symbol interference (ISI), multi-source interference (MSI), and counting errors at the cooperative as well as destination nanomachines [20]. ISI at the receiving nanomachine arises due to Brownian motion, which results in the molecules emitted by the transmitting nanomachine at the beginning of given time slot arriving stochastically in subsequent time-slots. On the other hand, MSI arises from the transmissions of other sources using the same type of molecules. Some works in the existing literature [21]– [29] propose techniques for receiver design and detection for direct source-destination diffusive molecular communication. However, to the best of our knowledge, none of the works in the existing literature have analyzed the impact of detection performance of the intermediate cooperative nanomachine(s) on the end-to-end performance of the relay-assisted dual and multi-hop molecular communication in the presence of ISI, MSI, and counting errors and is, one of the central aims of the work presented in this paper. Next, we present a detailed overview and comparative survey of related works in the existing literature on relay-assisted molecular communication. A. Related Work Some works in the existing literature have analyzed the performance of single relay-assisted molecular communication systems. In [30',\n",
       " '1112.6384': 'FAILED',\n",
       " '1212.6643': 'In the past, rate distortion (or distortion rate) functions and ﬁltering theory have evolved independently. Speciﬁcally, classical rate distortion function (RDF) addresses the problem of reproduction of a process subject to a ﬁdelity criterion without much emphasis on the realization of the reproduction conditional distribution via causal1 operations. On the other hand, ﬁltering theory is developed by imposing real-time realizability on estimators with respect to measurement data. Speciﬁcally, least-squares ﬁltering theory deals with the characterization of the conditional distribution of the unobserved process given the measurement data, via a stochastic diﬀerential equation which causally depends on the observation data [2]. Although, both reliable communication and ﬁltering (state estimation for control) are concerned with the reproduction of processes, the main underlying assumptions characterizing them are diﬀerent. Historically, the work of R. Bucy [3] appears to be the ﬁrst to consider the direct relation between distortion rate function and ﬁltering, by carrying out the computation of a realizable distortion rate function with square criteria for two samples of the Ornstein-Uhlenbeck process. The work of A. K. Gorbunov and M. S. Pinsker [4] on ϵ-entropy deﬁned via a causal constraint on the reproduction distribution of the RDF, although not directly related to the realizability question pursued by Bucy, computes the nonanticipative RDF for stationary Gaussian processes via power spectral densities. Recently, the authors in [5] investigated relations between ﬁltering theory and RDF deﬁned via mutual information using the topology of weak∗convergence on appropriate deﬁned spaces. The derivations of the results in [5] require elaborate arguments. The objective of this paper is to further investigate the connection between nonanticipative rate distortion theory and ﬁltering theory for general distortion functions and random processes on abstract Polish spaces using the topology of weak convergence. Moreover, instead of mutual information we invoke directed information with an inherent causality, which deﬁnes the reproduction conditional distribution. Further, the connection is established via optimization of directed information [6] over the space of conditional distributions which satisfy an average distortion constraint. In comparison 1The terms causal and nonanticipative are used interchangeably with the same meaning for conditional distributions. 2  to [5], we impose natural technical assumptions to obtain analogous results under the topology of weak convergence of probability measures, by using Prohorov’s theorem without introducing new spaces as done in [5]. We also present a new example to illustrate the realization of the ﬁlter via nonanticipative RDF. Speciﬁcally, we consider a multidimensional partially observable source, we compute the nonanticipative RDF, and we show how to realize it over a scalar additive Gaussian noise channel showing that linear encoder strategies are optimal. This example is new and it is considered as an open problem in information theory [7]. The main results discussed in this paper are the following. (1) Existence of optimal reproduction distribution minimizing directed information using the topology of weak convergence of probability measures on Polish spaces; (2) example of a multidimensional source',\n",
       " '1307.2482': 'A. Motivation We study distributed optimization over a N-node, connected, undirected network G = (V, E), with V the set of nodes and E the set of edges. Node i has private cost function fi(x), fi : Rd →R. We focus on iterative, distributed algorithms that solve the unconstrained problem: minimize f(x) := PN i=1 fi(x), (1) while each node i communicates only with its neighbors. This is the setup in many applications, e.g., distributed inference, [1], or distributed source localization, [2], in sensor networks. A popular approach to solve (1), e.g., [3], [4], [5], [6], [7], is through the augmented Lagrangian (AL) dual. The approach assigns a local copy xi ∈Rd of the global variable x in (1) to each node i, introduces the edge-wise constraints p Wij(xi − xj) = 0, ∀{i, j} ∈E,1 and forms an AL dual function by dualizing these constraints and adding the quadratic penalty ρ 2 P {i,j}∈E, i≤j Wij∥xi −xj∥2, see, e.g., [8], Section V, for The work of the ﬁrst and third authors was supported by: the Carnegie Mellon|Portugal Program under a grant from the Fundac¸˜ao de Ciˆencia e Tecnologia (FCT) from Portugal; by FCT grants CMU-PT/SIA/0026/2009, FCT PTDC/EMS-CRO/2042/2012, and SFRH/BD/33518/2008 (through the Carnegie Mellon|Portugal Program managed by ICTI); by ISR/IST plurianual funding (POSC program, FEDER), and the work of the ﬁrst and second authors was funded by AFOSR grant FA95501010291 and by NSF grant CCF1011903, while the ﬁrst author was a doctoral or postdoctoral student within the Carnegie Mellon|Portugal Program. D. Jakoveti´c is with University of Novi Sad, BioSense Center, 21000 Novi Sad, Serbia. J. M. F. Moura is with Department of Electrical and Computer Engineering, Carnegie Mellon University, Pittsburgh, PA 15213, USA. J. Xavier is with Instituto de Sistemas e Rob´otica (ISR), Instituto Superior T´ecnico (IST), University of Lisbon, 1049-001 Lisbon, Portugal. Authors e-mails: djakovet@uns.ac.rs, moura@ece.cmu.edu, jxavier@isr.ist.utl.pt. 1We include also self-edges, i.e., {i, i} ∈E, ∀i. details2. Denote by λij ∈Rd the dual variable that corresponds to the constraint on the edge {i, j}. Introducing the per-node aggregate dual variables µi := P j∈Oi p Wijλijsign(j −i), where Oi is the node i’s neighborhood (including i), one obtains the following dual method to solve (1): ( x1(k + 1), · · · , xN(k + 1) ) = argmin(x1,··· ,xN)∈RdN La (x1, · · · , xN; µ1(k), · · · , µN(k)) (2) µi(k + 1) = µi(k) + α X j∈Oi Wij (xi(k + 1) −xj(k + 1)) , (3) where α > 0 is the (dual) step-size, and La : RdN × RdN → R, is the AL function: La(x1, · · · , xN; µ1, · · · , µN ) = N X i=1 fi(xi) + N X i=1 µ⊤ i xi + ρ 2 X {i,j}∈E, i≤j Wij ∥xi −xj∥2. (4',\n",
       " '1708.02863': 'General object detection requires to accurately locate and classify all targets in the image or video. Compared to speciﬁc object detection, such as face, pedestrian and vehicle detection, general object detection often faces more challenges due to the large inter-class appearance differences. The variations arise not only from changes in a va1https://github.com/tshizys/CoupleNet Local part confidence  Global confidence  sofa:0.08 sofa:0.45 PSRoI pooling RoI pooling sofa sofa:0.78 Figure 1. A toy example of object detection by combing local and global information. Only considering the local part information or global structure leads to low conﬁdence score. By coupling the two kinds of information together, we can detect the sofa accurately with a conﬁdence score of 0.78. Best viewed in color. riety of non-rigid deformations, but also due to the truncations, occlusions and inter-class interference. However, no matter how complicated the objects are, when humans identify a target, the recognition of object categories is subserved by both a global process that retrieves structural information and a local process that is sensitive to individual parts. This motivates us to build a detection model that fused both global and local information. With the revival of Convolutional Neural Networks [15] (CNN), CNN-based object detection pipelines [8, 9, 16, 21] have been proposed consecutively and made impressive improvements in generic benchmarks, e.g. PASCAL VOC [5] and MS COCO [17]. As two representative region-based CNN approaches, Fast/Faster R-CNN [8, 21] uses a certain subnetwork to predict the category of each region proposal while R-FCN [16] conducts the inference with the positionsensitive score maps. Through removing the RoI-wise subnetwork, R-FCN has achieved higher detection speed while keeping the detection performance. However, the global 1 arXiv:1708.02863v1  [cs.CV]  9 Aug 2017  structure information is ignored by the PSRoI pooling. As shown in Figure 1, using PSRoI pooling to extract local part information for ﬁnal object category prediction, R-FCN leads to a low conﬁdence score of 0.08 for the sofa detection since the local responses of sofa are disturbed by a women and a dog (they are also the categories that need to be detected). Conversely, the global structure of sofa could be extracted by the RoI pooling, but the conﬁdence score is 0.45, which is also very low for the incomplete structure of sofa. By coupling the global conﬁdence with the local part conﬁdence together, we can obtain a more reliable prediction with the conﬁdence score of 0.78. In fact, the idea of fusing global and local information together is widely used in lots of visual tasks. In ﬁngerprint recognition, Gu et al. [10] combined the global orientation ﬁeld and local minutiae cue to largely improve the performance. In clique-graph matching, Nie et al. [19] proposed a clique-graph matching method by preserving global cliqueto-clique correspondence',\n",
       " '1510.00252': 'F OR decades, researchers have studied wireless multipleinput multiple-output (MIMO) systems in an effort to provide higher capacity gains and better link reliability [2]. Attempts to improve MIMO techniques were ﬁrst conducted with single-user (SU) setups, later evolving into multi-user MIMO (MU-MIMO) systems. A transmitter in a MIMO system has to acquire channel state information (CSI) to provide beamforming gains in SU-MIMO systems, and multiplexing gains in MU-MIMO systems [3]. To achieve the theoretical bound of the MIMO broadcast channel where multiple antennas are deployed at both transmitter and various receivers, [4], [5] proposed simple zero-forcing (ZF)-based linear algorithms with limited feedback. The authors in [6] proved that a simple linear beamforming technique, referred to as coordinated beamforming, could asymptotically reach the sum capacity performance of dirty paper coding (DPC). To support the exponentially increased mobile data trafﬁc of the present, a need has now arisen for new techniques that go beyond conventional MIMO systems; such techniques must T. Kwon, Y.-G. Lim, and C.-B. Chae are with the School of Integrated Technology, Yonsei University, Korea (E-mail: {th kwon, yglim, cbchae}@yonsei.ac.kr). B.-W. Min is with the Department of Electrical and Electronic Engineering, Yonsei University, Korea (E-mail: bmin@yonsei.ac.kr). This work was in part supported by the MSIP (Ministry of Science, ICT and Future Planning), Korea, under the “IT Consilience Creative Program” (IITP-2015-R0346-15-1008) supervised by the IITP (Institute for Information & Communications Technology Promotion) and ICT R&D program of MSIP/IITP [B0126-15-1017]. Part of this work was presented in [1]. be able to provide at least 1,000 times more capacity gains than current systems [7]. Among the various candidates for such a technique, a massive MIMO has been considered a promising one for 5G wireless communication systems [8]– [11]. By using a large amount of antennas (64 or more) at the base stations (BSs), a signiﬁcant improvement in the network capacity and energy efﬁciency using ZF or maximum ratio transmission/combining (MRT/MRC) can be expected [12]– [15]. With inaccurate CSI, however, the sum rate performance of a massive MIMO system may be saturated [16]. Therefore, an efﬁcient channel-training and feedback method has to be carefully designed in massive MIMO systems. While the beneﬁts of lower training overhead are more evident in a time division duplexing (TDD) massive MIMO system [17], most commercial cellular systems use the frequency division duplexing (FDD) mode, which offers more beneﬁts than the TDD mode, especially in macro-cell environments [18]. In FDD massive MIMO systems, channel reciprocity does not hold and the receiver has to feed-back CSI to construct precoding vectors [19]. To maintain a certain level of CSI quantization loss, increasing feedback overhead is inevitable [20]. Consequently, massive MIMO systems, with their very large antenna arrays at the BSs, struggle to provide feedback without compression. Researchers have tried to alleviate this feedback',\n",
       " '1712.00846': 'Human trafﬁcking has seen increasing media attention and government focus in recent years due to its pervasiveness and insidious nature (Austin and Farrell 2017). It is also characterized by a signiﬁcant Web presence, with trafﬁckers often advertising their victims on public platforms such as backpage.com (Szekely et al. 2015). Forums and review sites also contain discussions by ‘clients’ about (potentially trafﬁcked) escorts, and other aspects of their experiences, such as the youth of, and services provided by, the escort. The high prevalence of online sex advertisements (ads) and reviews, even on the Open Web, was a motivating fac- ∗This work was done when the author was at the NASA Jet Propulsion Laboratory, Pasadena, CA, USA. Copyright c⃝2018, Association for the Advancement of Artiﬁcial Intelligence (www.aaai.org). All rights reserved. tor in the creation of the DARPA Memex1 program, under which this work was funded and conducted over a period of three years. Memex was designed to advance the stateof-the-art in building domain-speciﬁc search systems over massive Web corpora, especially in difﬁcult domains like human trafﬁcking. Various Memex-funded systems can be integrated to build end-to-end domain-speciﬁc search systems, starting from domain modeling and discovery (including crawling the Web for relevant pages), knowledge graph construction, machine learning and information retrieval (Szekely et al. 2015), (Kejriwal and Szekely 2017), (Krishnamurthy et al. 2016), (Shin et al. 2015). An important inferential problem that needs to be addressed at scale in this pipeline is to detect potential trafﬁcking activity by assigning a risk score to a set of advertisements, usually collected by an investigative expert like a law enforcement ofﬁcial. In the simplest case, the risk score is a binary ﬂag, with 1 indicating that the ads in the set warrant further trafﬁcking-related investigation. Intuitively, a set represents an informal version of a ‘case study’ that, for reasons grounded in real-world activities like tip-offs from contacts in the ﬁeld, arrest records or exploratory search, has come to the attention of an ofﬁcial. While a single ad is often not useful by itself, intriguingly, when considered in aggregate, even a small set of ads in the case study can provide subtle clues indicating trafﬁcking, rather than voluntary escort activities. For example, there may be evidence in one of the ads that an escort is underage or is advertising sex services that are risky and unusual relative to the domain. There may also be evidence of movement between cities, or in the case of brothels often fronting as Asian massage parlors, ethnicity-related clues. The problem of trafﬁcking detection, even by a human carefully analyzing the case study, is further compounded by the fact that ads in such case studies tend to be related only latently, and the relation itself can be subtle. In most cases, the assumption in identifying trafﬁcking-related case studies is that escorts represented in the case study ads',\n",
       " '1403.1497': 'One of the most remarkable aspects of human intelligence is its adaptation to new situations, new tasks and new environments. To fulﬁll the dream of Artiﬁcial Intelligence and to build truly Autonomous Intelligent Agents (Robots included), it is necessary to develop systems that can adapt to new situations by learning fast how to behave or how to modify their previous knowledge. Consequently, learning has taken an important role in the development of such systems. This paradigm shift has been motivated by the limitations 1Draft v0.7 18Dec2013 of other approaches to cope with complex open-ended problems and fostered by the progress achieved in the ﬁelds of statistics and machine learning. Since tasks to be learned are becoming increasingly complex, have to be executed in ever changing environments and may involve interactions with people or other agents, learning agents are faced with situations that require either a lot of data to model and cover high dimensional spaces and/or a continuous acquisition of new information to adapt to novel situations. Unfortunately, data is not always easy and cheap, but often requires a lot of time, energy, computational or human resources and can be argued to be a limiting factor in the deployment of systems where learning is a key factor. Consider for instance a robot learning from data obtained during operation. It is common to decouple the acquisition of training data from the learning process. However, the embodiment in this type of systems provides a unique opportunity to exploit an active learning (AL) 2 approach (AL)(Angluin, 1988; Thrun, 1995; Settles, 2009) to guide the robot actions towards a more eﬃcient learning and adaptation and, consequently, to achieve a better performance more rapidly. The robot example illustrates the main particularity of learning for autonomous agents: the abstract learning machine is embodied in a (cyber) physical environment and so it needs to ﬁnd the relevant information for the task at hand by itself. Although these ideas have been around for more than twenty years (Schmidhuber, 1991b; Thrun, 1992; Dorigo and Colombetti, 1994; Aloimonos et al., 1988), in the last decade there 2Active learning can also be used to describe situations where the student is involved in the learning process as opposed to passively listening to lectures, see for instance (Linder et al., 2001). 1 arXiv:1403.1497v1  [cs.AI]  6 Mar 2014  has been a renewed interest from diﬀerent perspectives in actively gathering data during autonomous learning. Broadly speaking, the idea of AL is to use the current knowledge the system has about the task that is currently being learned to select the most informative data to sample. In the ﬁeld of machine learning this idea has been envigorated by the existence of huge amounts of unlabeled data freely available on the internet or from other sources. Labeling such data is expensive as it requires the use of experts or costly procedures. If similar accuracy can be obtained',\n",
       " '1812.01593': 'Semantic segmentation is the task of dense per pixel predictions of semantic labels. Large improvements in model accuracy have been made in recent literature [44, 14, 10], in part due to the introduction of Convolutional Neural Networks (CNNs) for feature learning, the task’s utility for selfdriving cars, and the availability of larger and richer training datasets (e.g., Cityscapes [15] and Mapillary Vista [32]). While these models rely on large amounts of training data to achieve their full potential, the dense nature of semantic segmentation entails a prohibitively expensive dataset annotation process. For instance, annotating all pixels in a 1024 × 2048 Cityscapes image takes on average 1.5 hours ∗indicates equal contribution. Joint Propagation Video  Prediction It+1 ͠ It+2 It Lt+1 Lt+2 Lt … Boundary Label  Relaxation Augmented Training Set  Segmentation Network Video  Prediction Joint Propagation ͠ ͠ ͠ Figure 1: Framework overview. We propose joint image-label propagation to scale up training sets for robust semantic segmentation. The green dashed box includes manually labelled samples, and the red dashed box includes our propagated samples. T is the transformation function learned by the video prediction models to perform propagation. We also propose boundary label relaxation to mitigate label noise during training. Our framework can be used with most semantic segmentation and video prediction models. [15]. Annotation quality plays an important role for training better models. While coarsely annotating large contiguous regions can be performed quickly using annotation toolkits, ﬁnely labeling pixels along object boundaries is extremely challenging and often involves inherently ambiguous pixels. Many alternatives have been proposed to augment training processes with additional data. For example, Cords et al. [15] provided 20K coarsely annotated images to help train deep CNNs, an annotation cost effective alternative used by all top 10 performers on the Cityscapes benchmark. Nevertheless, coarse labeling still takes, on average, 7 minutes per image. An even cheaper way to obtain more labeled samples is to generate synthetic data [35, 36, 18, 47, 45]. However, model accuracy on the synthetic data often does not generalize to real data due to the domain gap between synthetic and real images. Luc et al. [28] use a state-of-theart image segmentation method [42] as a teacher to generate extra annotations for unlabelled images. However, their performance is bounded by the teacher method. Another approach exploits the fact that many semantic segmentation datasets are based on continuous video frame 1 arXiv:1812.01593v3  [cs.CV]  3 Jul 2019  sequences sparsely labeled at regular intervals. As such, several works [2, 9, 31, 16, 33] propose to use temporal consistency constraints, such as optical ﬂow, to propagate ground truth labels from labeled to unlabeled frames. However, these methods all have different drawbacks which we will describe in Sec. 2. In this work, we propose to utilize video prediction models to efﬁciently create more training samples (image-label pairs) as shown in Fig. 1. Given a sequence of video frames having labels for only a subset of the frames in the sequence',\n",
       " '1102.3493': 'Recent trends in distributed storage systems have been toward the use of commodity hardware as storage nodes, where nodes may be individually unreliable. Such systems can still be feasible for large-scale storage as long as there is overall reliability of the entire storage system. Recent research in distributed storage systems has focused on using techniques from coding theory to increase storage efﬁciency, without sacriﬁcing system reliability and node repairability [1]. In this work, we consider storage systems where failed storage nodes must be quickly replaced by replacement nodes. To achieve short downtimes, we consider techniques where the repair of a particular node (i.e., by obtaining replacement data) is via contacting multiple non-failed nodes in parallel—where each contacted node contributes only a small portion of the replacement data. Such replacement strategies have been studied in the context of both functional repair [1]—where replacement nodes serve functionally for overall data recovery—and exact repair—where replacement nodes must be exact copies of the failed node. We build upon the work of El Rouayheb and Ramchandran [2], who propose a storage system allowing for exact repair. Using the idea of Steiner systems [3], the authors design distributed storage systems with the desired redundancy and repairability properties—where even though each storage node is responsible for storing multiple data chunks, replacement of any failed node is always possible by obtaining only a single data chunk from each of several non-failed nodes. In systems where multiple nodes can be read in parallel, then such a scheme ensures high availability, even in the presence of node failures. Moreover, since the scheme described in [2] stores data in an uncoded manner, for computing applications the storage nodes may also serve as processing nodes. A Steiner system S(t, k, v) speciﬁes a distribution of v elements into blocks of size k such that the maximum number of overlapping elements between any two blocks is t −1 (so if t = 2, then no two blocks can share any pairs of elements1). For instance, Example 1 shows a Steiner system and the resulting distribution of data chunks to storage nodes. Example 1. Consider a distributed storage system to store 9 total data chunks, where each chunk is stored within storage nodes that can hold 3 chunks each. Then it is possible to distribute the chunks across 12 nodes, where every chunk has exactly 4 replicas and any two distinct nodes share at most only one overlapping chunk. This is shown in Figure 1. b0 b1 b2 b3 b4 b5 b6 b7 b8 b9 b10 b11 0 1 2 0 3 6 0 4 8 0 5 7 1 3 8 1 4 7 1 5 6 2 3 7 2 4 6 2 5 8 3 4 5 6 7 8 Fig. 1. Storage design from Steiner system S(2, 3, 9); same as [2, Fig. 6(a)]. In most practical distributed storage systems, however, it is often desirable for the',\n",
       " '1611.03473': '1.1 Background and Overview For the unsupervised estimation problems considered here, the input is a probability distribution which is accessed via a sampling oracle, i.e., an oracle that provides i.i.d. samples from the underlying distribution. Statistical Query (SQ) algorithms are a restricted class of algorithms that are only allowed to query expectations of functions of the distribution rather than directly access samples. This class of algorithms is quite broad: a wide range of known algorithmic techniques in machine learning are known to be implementable using SQs. These include spectral techniques, moment and tensor methods, local search (e.g., Expectation Maximization), and many others (see, e.g., [CKL+06, FGR+13] for a detailed discussion). Moreover, for the unsupervised learning problems studied in this paper, all known algorithms with non-trivial performance guarantees are SQ or are easily implementable using SQs. A number of techniques have been developed in information theory and statistics to characterize the sample complexity of inference tasks. These involve both techniques for proving sample complexity upper bounds (e.g., VC dimension, metric/bracketing entropy) and information-theoretic lower bounds (e.g., Fano and Le Cam methods). On the other hand, computational lower bounds have been much more scarce in the unsupervised setting. Perhaps surprisingly, it is possible to prove unconditional lower bounds on the computational complexity of any SQ algorithm that solves a given learning problem. Given the ubiquity and generality of SQ algorithms, an SQ lower bound provides strong evidence of the problem’s computational intractability. In this paper, we describe a general technique that yields the ﬁrst Statistical Query lower bounds for a range of fundamental high-dimensional learning problems involving Gaussian distributions. Such problems are ubiquitous in applications across the data sciences and have been intensely investigated by different communities of researchers for several decades. Our main results are for the problems of (1) learning Gaussian mixture models (GMMs), and (2) robust (agnostic) learning of a single unknown Gaussian distribution. In particular, we show a super-polynomial gap between the (information-theoretic) sample complexity and the computational complexity of any Statistical Query algorithm for these problems. In more detail, our SQ lower bound for Problem (1) is qualitatively matched by known learning algorithms for GMMs (all of which can be implemented as SQ algorithms). For Problem (2), we give a new (SQ) algorithm in this paper whose running time nearly matches our SQ lower bound. Our SQ lower bounds are attained via a uniﬁed moment-matching technique that is useful in other contexts and may be of broader interest. Our technique yields nearly-tight lower bounds for a number of related unsupervised estimation problems. Speciﬁcally, for the problems of (3) robust covariance estimation in spectral norm, and (4) robust sparse mean estimation, we establish a quadratic statistical–computational tradeoff for SQ algorithms, matching known upper bounds. Finally, we use our technique to obtain tight sample complexity lower bounds for high-dimensional testing problems. Speciﬁcally, for the classical problem of',\n",
       " '1403.3378': 'Our interest is in deriving interpretable predictive classiﬁcation models for use with imbalanced data. Data classiﬁcation problems having imbalanced (also called “unbalanced”) class distributions appear in many domains, ranging from mechanical failure detection or fault detection, to fraud detection, to text and image classiﬁcation, to medical disease prediction or diagnosis. Imbalanced data cause typical machine learning methods to produce trivial results, that is, classiﬁers that only predict the majority class. One cannot optimize vanilla classiﬁcation accuracy and use standard classiﬁcation methods when working with imbalanced data. This is explained nicely by Chawla, Japkowicz, and Kolcz (Chawla, Japkowicz, and Kotcz 2004) who write: “The class imbalance problem is pervasive and ubiquitous, causing trouble to a large segment of the data mining community.” In order for the models we derive to be interpretable to human experts, our classiﬁers are formed as a union of axis parallel rectangles around the positive (minority class) examples, and we call such classiﬁers box drawing classiﬁers. These are “disjunctions of conjunctions” 0 50 100 0 20 40 60 80 100 dimension 1 dimension 2 Figure 1: Example of box drawing classiﬁer. where each conjunction is a box. An example of a box drawing classiﬁer we created is in Figure 1, exemplifying our goal to classify the positive examples correctly even if they are scattered within a sea of negative examples. Our classiﬁers are regularized in several ways, to prefer fewer boxes and larger boxes. We take two polar approaches to creating box drawing classiﬁers, where the ﬁrst is an exact method, based on mixed integer programming (MIP). This method, called Exact Boxes can be used for small to medium sized datasets, and provides a gold standard to compare with. If we are able to make substantial approximations and still obtain performance close to that of the gold standard, our approximations would be justiﬁed. Our second method, Fast Boxes makes such an approximation. Fast boxes takes the approach of characterize then discriminate, where we ﬁrst characterize the positive (minority) class alone, and then bring in the negative examples to form decision boundaries around each clusters of positives. This approach has signiﬁcant computational advantages, in that using just the minority class in the ﬁrst step requires a small fraction of the data, assuming a high imbalance ratio. Also by creating  decision boundaries locally in the second step, the number of examples involved in each classiﬁer is smaller; further, creating each classiﬁer separately allows computations to be made parallel, though since the computation for each decision boundary is analytical, that may not be necessary for many datasets. The computation is analytical because there is a closed form solution for the placement of the decision boundary. Thus, the discriminate step becomes many parallel local analytical calculations. This is much simpler and scalable than, for instance, a decision tree that chooses splits greedily and fails to scale with dimension and large number of observations. We make several experimental',\n",
       " '1708.02973': 'Visual Object Tracking (VOT) is a fundamental problem in vision. We consider the single object tracking task, where an object is identiﬁed in the ﬁrst video frame and should be tracked in subsequent frames, despite large appearance changes due to object scaling, occlusion, and so on. VOT is the basic building block of many time-critical systems such as video surveillance and autonomous driving. Thus it is important for a visual tracker to meet the strict constraints of time and computational budget, especially on mobile or embedded computing architectures where real-time analysis perception is often required. Although much progress has been made in the tracking literature, there still exist tremendous challenges in Output at this layer or forward to the next layer Deep convolutional layers Agent Template frame Current frame Pixel layer + correlation filters Easy frame Hard frame Figure 1. Learning policies for adaptive tracking with deep feature cascades. The agent decides whether we can accurately locate objects on an early layer of the cascade. This avoids the need to always wait for the last layer to make decisions, saving a substantial amount of feed-forwarding time. designing a tracker that has both high accuracy and high speed. Real-time tracking methods like TLD [21] and correlation ﬁlters [19] usually rely on low-level features that are not descriptive enough to disambiguate target and background. Several recent works [15, 27, 11, 31, 10] overcome this limitation by learning correlation ﬁlters on hierarchical deep features, but the real-time capacity largely fades away. Other deep trackers [41, 30, 40] take full advantage of the end-to-end learning, and ﬁne-tune the deep network online to achieve top performance. However, even on a high-end GPU, the speed of such trackers is usually around 1 fps which is too slow for practical use. Two recent deep trackers [3, 18] signiﬁcantly boost their speed by deploying ﬁxed convolutional networks without any online learning. During tracking, the pre-trained network is simply traversed in a feed-forward pass for similarity evaluation or location regression, allowing to track objects at real-time speeds on GPU. Nevertheless, on a modern CPU, smartphone or tablet with much less computing power, such deep trackers can only process a couple of frames per second, far below the normal video frame-rate 30 fps. Obviously, the major computational burden comes from the forward pass through the entire network, and can 1 arXiv:1708.02973v2  [cs.CV]  13 Sep 2017  be larger with deeper architectures. We aim to improve both the accuracy and speed of deep tracking, instead of trading off the quality for speed by e.g. using compressed models [1]. We propose to learn to speed up deep trackers in an adaptive manner. Our adaptive approach builds on the observation that the tracking complexity varies across frames. For example, it is usually effective to',\n",
       " '1612.00576': 'Automatic image captioning is a fundamental task that couples visual and linguistic learning. Recently, models incorporating recurrent neural networks (RNNs) have demonstrated promising results on this challenging task (Vinyals et al., 2015; Fang et al., 2015; Devlin et al., 2015), leveraging new benchmark datasets such as the MSCOCO dataset (Lin et al., 2014). However, these datasets are generally only concerned with a relatively small number of objects and interactions. UnsurInput image containing  previously unseen object  (‘suitcase’) CNN-RNN Captioning  Model A cat sitting inside of a suitcase. cat, suitcase,  inside Constrained Beam Search Beam Search A cat sitting on top of a refrigerator. Image Tags Figure 1: We successfully caption images containing previously unseen objects by incorporating semantic attributes (i.e., image tags) during RNN decoding. Actual example from Section 4.2. prisingly, models trained on these datasets do not generalize well to out-of-domain images containing novel scenes or objects (Tran et al., 2016). This limitation severely hinders the use of these models in real world applications dealing with images in the wild. Although available image-caption training data is limited, many image collections are augmented with ground-truth text fragments such as semantic attributes (i.e., image tags) or object annotations. Even if these annotations do not exist, they can be generated using (potentially task speciﬁc) image taggers (Chen et al., 2013; Zhang et al., 2016) or object detectors (Ren et al., 2015; Krause et al., 2016), which are easier to scale to new concepts. In this paper our goal is to incorporate text fragments such as these during caption generation, to improve the quality of resulting captions. This goal poses two key challenges. First, RNNs are generally opaque, and difﬁcult to inﬂuence at test time. Second, text fragments may include words arXiv:1612.00576v2  [cs.CV]  19 Jul 2017  that are not present in the RNN vocabulary. As illustrated in Figure 1, we address the ﬁrst challenge (guidance) by using constrained beam search to guarantee the inclusion of selected words or phrases in the output of an RNN, while leaving the model free to determine the syntax and additional details. Constrained beam search is an approximate search algorithm capable of enforcing any constraints over resulting output sequences that can be expressed in a ﬁnite-state machine. With regard to the second challenge (vocabulary), empirically we demonstrate that an RNN can successfully generalize from similar words if both the input and output layers are ﬁxed with pretrained word embeddings and then expanded as required. To evaluate our approach, we use a held-out version of the MSCOCO dataset. Leveraging image tag predictions from an existing model (Hendricks et al., 2016) as constraints, we demonstrate state of the art performance for out-of-domain image captioning, while simultaneously improving the performance of the base model on indomain data. Perhaps surprisingly, our results signiﬁcantly outperform approaches that incorporate the same',\n",
       " '1606.05681': 'A high volume of digital data drives rapid development of analysis methods providing more eﬀective tools to obtain data insights. The key data analysis areas of research are regression, classiﬁcation, and clustering [8, 35, 30, 17, 20, 32]. Clustering aims at generating meaningful groups (clusters) of points in the provided dataset. The measure of meaningfulness of groups depends on the application and is problem-speciﬁc [12]. However, the general idea behind any measure of meaningfulness is that points within any particular cluster are as similar as possible to each other, and at the same time, points that belong to diﬀerent clusters are as diﬀerent as possible from each other. The clustering methods can be characterised, among others, by the type of results they produce. One of the classic types is Flat Clustering that organises points into a predeﬁned number of clusters where the only relation between clusters is spacial. The most popular ﬂat clustering method is k-means [37, 15], where the number of clusters is deﬁned by one of the input parameters. Another clustering type, called Hierarchical Clustering (HC) or Hierarchical Cluster Analysis (HCA), produces several ﬂat clustering solutions that are organised into a tree structure called dendrogram (a diagram representing a tree). In the dendrogram every node represents a cluster, and the tree structure indicates parent-child relations between clusters which don’t exist in ﬂat clustering. To obtain a ﬂat clustering from a dendrogram, it has to be cut. The ﬁnal (ﬂat) solution can have a diﬀerent number of clusters depending on where (at which level of the dendrogram) the cut is performed. The obtained ﬂat clustering always cover all the observations from the input set as no data points are left in parent nodes. Hierarchical Clustering methods do not need to specify the number of clusters beforehand; this number is determined by the height where the dendrogram is cut. Since dendrograms have a partial order relation (hierarchical relation) between nodes, they provide insights into how the process of clustering was performed. By comparing diﬀerent cuts of the same dendrogram, it can also give a view on the clustering from the perspective of diﬀerent granularities (diﬀerent number of clusters in the ﬂat solution). One of the examples of hierarchical clustering is Agglomerative Hierarchical Clustering [10, 6]. For a variety of reasons, clustering methods, in general, still have some weaknesses [4]. From the perspective of this article the interest is in the weaknesses of hierarchical methods where the primary issue is a semantic gap between how humans perceive hierarchies and results produced by Hierarchical Clustering methods. Human perception describes hierarchical data (e.g., [31]) as possessing the following properties: 1. the data can be present in any node in the hierarchy and belongs to that node without being propagated to the child clusters; and 2. the data in the child groups should represent equal or more precise concepts than the data in the corresponding parent that should resemble more general concepts',\n",
       " '1711.09357': 'Abstractive text summarization is the task of generating a short and concise summary that captures the salient ideas of the source text. The generated summaries potentially contain new phrases and sentences that may not appear in the source text. In the past decades, a ﬂurry of studies have been conducted on abstractive text summarization (Nallapati et al. 2016; See, Liu, and Manning 2017; Paulus, Xiong, and Socher 2017). Despite the remarkable progress of previous studies, abstractive summarization is still challenged by (i) Neural sequence-to-sequence models tend to generate trivial and generic summary, often involving high-frequency phrases; (ii) The generated summaries have limited grammaticality and readability; (iii) In most previous work the standard sequence-to-sequence models are trained to predict the next word in summary using the maximumlikelihood estimation (MLE) objective function. However, this strategy has two major shortcomings. First, the evaluation metric is different from the training loss. Second, the input of the decoder in each time step is often from the true summary during the training. Nevertheless, in the testing phase, the input of the next time step is the previous word ∗The work was partially supported by CAS Pioneer Hundred Talents Program and the MOE Key Laboratory of Machine Perception at Peking University under grant number K-2017-02. Q. Qu is the corresponding author. Copyright c⃝2018, Association for the Advancement of Artiﬁcial Intelligence (www.aaai.org). All rights reserved. 1Supplemental material: http://likicode.com/textsum/ generated by the decoder. This exposure bias leads to error accumulation at test time. To address the above challenge, in this paper, we propose an adversarial framework to jointly train a generative model G and a discriminative model D. Speciﬁcally, the generator G takes the original text as input and generate the summary. We use reinforcement learning (i.e., policy gradient) to optimize G for a highly rewarded summary. Thus, it effectively bypasses exposure bias and non-differentiable task metrics issues. We implement the discriminator D as a text classiﬁer that learns to classify the generated summaries as machine or human generated. The generator G and the discriminator D are optimized with a minimax two-player game. The discriminator D tries to distinguish the ground truth summaries from the generated summaries by the generator G, while the training procedure of generator G is to maximize the probability of D making a mistake. Thus, this adversarial process can eventually adjust G to generate plausible and high-quality abstractive summaries. Our model Similar to the standard training strategy (Goodfellow et al. 2014), we simultaneously train two models in an adversarial manner: a generative model G and a discriminative model D. We ﬁrst pre-train the generative model by generating summaries given the source text. Then we pre-train the discriminator by providing positive examples from the human-generated summaries and the negative examples produced from the pre-trained generator. After the pre-training, the generator and discriminator are trained',\n",
       " '1706.08564': 'Pedestrian detection from an image is a core capability of computer vision, due to its applications such as autonomous driving and robotics [14]. It is also a long-standing vision problem because of its distinct challenges including low resolution, occlusion, cloth variations, etc [30]. There are two central approaches for detecting pedestrians: object detection [2, 29] and semantic segmentation [4, 5]. The two approaches are highly related by nature but have their own strengths and weaknesses. For instance, object detection is designed to perform well at localizing distinct objects but typically provides little information on object boundaries. In contrast, semantic segmentation does well at distinguishing pixel-wise boundaries among classes but struggles to separate objects within the same class. Intuitively, we expect that knowledge from either task will make the other substantially easier. This has been Figure 1. Detection results on the Caltech test set (left), feature map visualization from the RPN of conventional Faster R-CNN (middle), and feature map visualization of SDS-RCNN (right). Notice that our feature map substantially illuminates the pedestrian shape while suppressing the background region, both of which make positive impact to downstream pedestrian detection. demonstrated for generic object detection, since having segmentation masks of objects would clearly facilitate detection. For example, Fidler et al. [13] utilize predicted segmentation masks to boost object detection performance via a deformable part-based model. Hariharan et al. [18] show how segmentation masks generated from MCG [1] can be used to mask background regions and thus simplify detection. Dai et al. [6] utilize the two tasks in a 3-stage cascaded network consisting of box regression, foreground segmentation, and classiﬁcation. Their architecture allows each task to share features and feed into one another. In contrast, the pairing of these two tasks is rarely studied in pedestrian detection, despite the recent advances [2, 21, 29]. This is due in part to the lack of pixel-wise annotations available in classic pedestrian datasets such as Caltech [8] and KITTI [14], unlike the detailed segmentation labels in the COCO [22] dataset for generic object detection. With the release of Cityscapes [5], a high quality dataset for urban semantic segmentation, it is expected that substantial research efforts will be on how to leverage semantic segmentation to boost the performance of pedestrian detection, which is the core problem to be studied in this paper. Given this objective, we start by presenting a competitive two-stage baseline framework of pedestrian detection deriving from RPN+BF [29] and Faster R-CNN [23]. We contribute a number of key changes to enable the secondstage classiﬁer to specialize in stricter supervision and additionally fuse the reﬁned scores with the ﬁrst stage RPN. These changes alone lead to state-of-the-art performance on arXiv:1706.08564v1  [cs.CV]  26 Jun 2017  the Caltech benchmark. We further present a simple, but surprisingly powerful, scheme to utilize multi-task learning on pedestrian detection and semantic segmentation',\n",
       " '1712.02743': 'When selecting a supervised machine learning technique, we are led by multiple and often conﬂicting criteria. These include: how accurate is the resulting model? How much training data is needed to achieve a given level of accuracy? How interpretable is the model? How big is the computational effort at train time? And at test time? How well does the implementation map to the available hardware? These days, neural networks have superseded all other approaches in terms of achievable accuracy of the predictions; but state of the art networks are not easy to interpret, are fairly hungry for training data, often require weeks of GPU training and have a computational and memory footprint that rules out their use on small embedded devices. Decision trees achieve inferior accuracy, but are fundamentally more frugal. Both neural networks and decision trees are composed of basic computational units, the perceptrons and nodes, respectively. A crucial difference between the two is that in a standard neural network, all units are being evaluated for every input; while in a decision tree with I inner split nodes, only O(log I) split nodes are visited. That is, in a decision tree, a sample is routed along a single path from the root to a leaf, with the path conditioned on the sample’s features. It is this sparsity of the sample-dependent computational graph that piques our interest in decision trees; but we also hope to proﬁt from their ability to learn their comparatively few parameters from a small training set, and their relative interpretability. One hallmark of neural networks is their ability to learn a complex combination of many elementary decisions jointly, by end-to-end training using backpropagation. This is a feature that has so far been missing in deterministic decision trees, which are usually constructed greedily without subsequent tuning. We here propose a mechanism to remedy this deﬁcit. 1.1. Contributions • We propose a decision tree whose internal nodes are probabilistic and hence differentiable at train time. As a consequence, we are able to train the internal nodes jointly in an end-to-end fashion. This is true for linear nodes, but the property is maintained for more complex nodes, such as small Convolutional Neural Networks (CNNs) (section 3.4). • We derive an expectation-maximization style algorithm for ﬁnding the optimal parameters in a split node (section 3.3). We develop a probabilistic split criterion that generalizes the long-established information gain [23]. The proposed criterion is asymptotically identical to information gain in the limit of very steep non-linearities, but allows to better model class overlap in the vicinity of a split decision boundary (section 3.2). • We demonstrate good results by making the nodes deterministic at test time, sending each sample along a 1 arXiv:1712.02743v1  [stat.ML]  7 Dec 2017  unique path of only O(log I) out of the I inner nodes in a',\n",
       " '1702.04858': 'Person Re-IDentiﬁcation (Re-ID) plays an important role in video surveillance for public safety [1]. However, it is a challenging problem since person images are usually with low resolution and partial occlusion and contain large intra-class variations of illumination, viewpoint and pose. See Fig. 1 for some person image examples. Terefore, how to develop an effective person Re-ID method becomes a very desirable topic. The two fundamental problems critical for person Re-ID are feature representation and similarity metric. For feature This work was supported in part by the Scientiﬁc Research Funds of Huaqiao University under the Grant 16BS108, in part by the National Natural Science Foundation of China under the Grants 61602191, 61375037, 61473291, 61572501, 61502491, 61572536, 61372107 and 61401167, in part by the Natural Science Foundation of Fujian Province under the Grant 2016J01308, in part by the Opening Project of Sate Key Laboratory of Digital Publishing Technology under the Grant FZDP2015-B-001, in part by the Zhejiang Open Foundation of the Most Important Subjects, in part by the High-Level Talent Project Foundation of Huaqiao University under the Grants 14BS201 and 14BS204. Jianqing Zhu, Canhui Cai and LiXin Zheng are with the College of Engineering, Huaqiao University, Quanzhou, Fujian 362021, China and Fujian Provincial Academic Engineering Research Centre in Industrial Intellectual Techniques and Systems (e-mail: {jqzhu, chcai}@hqu.edu.cn and zlxgxy@qq.com). Huanqiang Zeng (corresponding author) is with the College of Information Science and Engineering, Huaqiao University, Xiamen, Fujian 361021, China (e-mail: zeng0043@hqu.edu.cn). Shengcai Liao and Zhen Lei are with the Center for Biometrics and Security Research and National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China (e-mail: {scliao, zlei}@cbsr.ia.ac.cn). Fig. 1. Example pairs of images from the QMUL GRID [1], VIPeR [2] and CUHK03 [3] databases. Images in the same column represent the same person captured under different cameras. representation, there are Fisher vectors (LDFV) [4], bioinspired features (kBiCov) [5], symmetry-driven accumulated local features (SDALF) [6], structural constraints enhanced feature accumulation (SCEFA) [7], color invariant signature [8], salience matching [9, 10], ensemble of local features (ELF16) [11], mid-level learning features [12] and convolutional neural network learning features [13], and so on. For similarity metrics, many machine learning algorithms are developed to calculate the similarity between a person image pair, such as ranking support vector machine (Ranking SVM) [14], partial least square (PLS) [15], Boosting [16], multi-task learning [17, 18], metric learning [19–27] and convolutional neural networks (CNNs) [28–37]. Note that the metric learning and CNN based person Re-ID methods are the most popular methods, which will be highlighted as follows. The metric learning based person Re-ID methods [22– 27] learn a matrix with d × d parameters to calculate the Mahalanobis distance between two d dimensional hand-crafted features as the similarity measurement between two person images. However, they are pron',\n",
       " '1611.05720': 'Deep metric embedding has attracted increasing attention for various tasks , such as visual product search [6, 18, 23, 27, 35], face recognition [21, 32, 41, 4], local image descriptor learning [9, 2, 12, 24], person/vehicle reidentiﬁcation [22, 7, 43, 17], zero-shot image classiﬁcation [19, 45, 5], ﬁne-grained image classiﬁcation [8, 40, 44] and object tracking [14, 33]. Although deep metric embedding is modiﬁed into different forms for various tasks, it shares the same objective to learn an embedding space ∗Corresponding author : Chao Zhang. 1 query image easy positive images hard positive images semi-hard positive images Figure 1. Illustration of samples with different hard levels: A query image is shown at the center, while other images from the same category (Nissan 240X Coupe 1998 from CARS196 [11]) are used to form positive pairs with the query image. that pulls similar images closer and pushes dissimilar images far away. Typically, the target embedding space is learned with a convolutional neural network equipped with contrastive/triplet loss. Different from the traditional classiﬁcation based models, the models of deep metric embedding consider two images (a pair) or three images (a triplet) as a training sample. Thus N images can generate O(N 2) or O(N 3) samples. It becomes impossible to consider all samples even for a moderate number of images. Fortunately, not all samples are equally informative to train a model, which inspires many recent works to mine hard examples for training [8, 24, 39]. However, the hard level of a sample is deﬁned relative to a model. Then samples can be divided into different hard levels as illustrated in Figure 1. For a complex model, most samples will be treated as easy ones, and the model converges fast but is prone to overﬁtting. While for a simple model, most samples will be treated as hard ones and cannot arXiv:1611.05720v2  [cs.CV]  1 Aug 2017  Shared  G1 G2 G3 G1 G2 G1 F1 F2 F3 Shared Loss Loss Loss … … … … Cascaded-Network-Structure Hard Sample Mining Data Sampler Figure 2. Hard-Aware Deeply Cascaded Embedding : We will train the ﬁrst model with all the pairs, the second model with the semihard samples which are selected by the above model, the third model with the remained hard samples selected by the second model. Our framework support any K cascaded models. We plot the case=3 for convenience. G1, G2, G3, F1, F2, F3 are the computation blocks in Convolutional Neural Networks. fully beneﬁt from hard example mining. It would be ideal to deﬁne a model with the just right complexity to mine hard examples adequately, which is an open problem itself. To alleviate the above problem, we ensemble a set of models with different complexities in a cascaded manner and mine hard examples adaptively, which is schematically illustrated in Figure 2. The most simple model is implemented by a shallow network, while complex models are implemented',\n",
       " '1711.03985': 'The need for novel healthcare solutions and continuous efforts in understating the biological bases of pathologies have pushed extensive research in the Biological Sciences over the last two centuries [1]. Recent technological advancements in Life Sciences opened up possibilities not only to study Biological systems from a holistic perspective but provided unprecedented access to the molecular details of the living organisms [2,3]. Novel tools for DNA sequencing [4], gene expression [5], bioimaging [6], neuroimaging [7], and brain-machine interfaces [8] are now available to the scientific community. However, considering the inherent complexity of the biological systems together with the high-dimensionality, diversity, and noise contaminations, inferring 1/33 arXiv:1711.03985v2  [cs.LG]  7 Jan 2018  meaningful conclusion from these data is a huge challenge [9]. Therefore, novel instruments are required to process and analyze biological big data that must be robust, reliable, reusable, and accurate [10]. This encouraged numerous scientists from life and computing sciences disciplines to embark in a multidisciplinary approach to demystify functions and dynamics of living organisms with remarkable progress to biological and biomedical research [11]. Thus, many techniques of Artificial Intelligence (AI), in particular machine learning (ML), have been proposed over time to facilitate recognition, classification, and prediction of patterns in biological data [12]. The conventional ML techniques can be broadly categorized in two large sets – supervised and unsupervised. The methods pertaining to the supervised learning paradigm classify objects in a pool using a set of known annotations/ attributes/ features. Instead, the unsupervised learning techniques form groups/ clusters among the objects in a pool by identifying their similarity and then use them for classifying the unknowns. Also, the other category, reinforcement learning (RL), allows a system to learn from the experiences it gains through interacting with its environment (see section 1.2 for details). Popular supervised methods include: Artificial Neural Network (ANN) [13] and its variants, Support Vector Machines [14] and linear classifiers [15], Bayesian Statistics [16], k-Nearest Neighbors [17], Hidden Markov Model [18], and Decision Trees [19]. Also, popular unsupervised methods include: Autoencoders [20], Expectation Maximization [21], Self-Organizing Maps [22], k-Means [23], and Fuzzy [24] and Density-based [25] clustering. Figure 1 A possible representation of the DL, RL, and deep RL frameworks for biological applications. A–F. The popular DL architectures. G. Schematic diagram of the learning framework as a part of Artificial Intelligence (AI). Broadly, AI can be thought to have evolved parallelly in two main directions– Expert Systems (ES) and ML. ES takes expert decisions from given factual data using rule based inferences. ML extracts features from data mainly through statistical modeling and provides predictive output when applied to unknown data. DL, being a sub-division of ML, extracts more abstract features from a larger set of training data mostly in a hierarchical fashion resembling the working principle of our brain. The other sub-division, RL, provides a software agent which gathers experience based on interactions with the',\n",
       " '1805.09927': 'Relation extraction is a core task in information extraction and natural language understanding. The goal of relation extraction is to predict relations for entities in a sentence (Zelenko et al., 2003; Bunescu and Mooney, 2005; GuoDong et al., 2005). For example, given a sentence Negative set Positive set False Positive Negative set Positive set False Positive Policy Based Agent Policy Gradient Training Redistribute Training Dataset 𝑅𝑒𝑤𝑎𝑟𝑑 𝐴𝑐𝑡𝑖𝑜𝑛 Classifier 𝑇𝑟𝑎𝑖𝑛 Figure 1: Our deep reinforcement learning framework aims at dynamically recognizing false positive samples, and moving them from the positive set to the negative set during distant supervision. “Barack Obama is married to Michelle Obama.”, a relation classiﬁer aims at predicting the relation of “spouse”. In downstream applications, relation extraction is the key module for constructing knowledge graphs, and it is a vital component of many natural language processing applications such as structured search, sentiment analysis, question answering, and summarization. A major issue encountered in the early development of relation extraction algorithms is the data sparsity issue—It is extremely expensive, and almost impossible for human annotators to go through a large corpus of millions of sentences to provide a large amount of labeled training instances. Therefore, distant supervision relation extraction (Mintz et al., 2009; Hoffmann et al., 2011; Surdeanu et al., 2012) becomes popular, because it uses entity pairs from knowledge bases to select a set of noisy instances from unlabeled data. In recent years, neural network approaches (Zeng et al., 2014, 2015) have been proposed to train the relation extractor under these noisy conditions. To suppress the noisy(Roth et al., 2013), recent studarXiv:1805.09927v1  [cs.CL]  24 May 2018  ies (Lin et al., 2016) have proposed the use of attention mechanisms to place soft weights on a set of noisy sentences, and select samples. However, we argue that only selecting one example or based on soft attention weights are not the optimal strategy: To improve the robustness, we need a systematic solution to make use of more instances, while removing false positives and placing them in the right place. In this paper, we investigate the possibility of using dynamic selection strategies for robust distant supervision. More speciﬁcally, we design a deep reinforcement learning agent, whose goal is to learn to choose whether to remove or remain the distantly supervised candidate instance based on the performance change of the relation classiﬁer. Intuitively, our agent would like to remove false positives, and reconstruct a cleaned set of distantly supervised instances to maximize the reward based on the classiﬁcation accuracy. Our proposed method is classiﬁer-independent, and it can be applied to any existing distant supervision model. Empirically, we show that our method has brought consistent performance gains in various deep neural network based models, achieving strong performances on the widely used New York Times dataset (Riedel et al., 2010). Our contributions are three-fold: • We propose a novel',\n",
       " '1804.03635': 'Malware, or malicious software, is a key element of cyberattacks that damages companies and individuals worldwide and beneﬁts criminals. Nowadays, malware is concealed using obfuscation, encryption, anti-emulation and other techniques, making detection of malware signiﬁcantly harder. Classifying whether a previously unseen ﬁle is a malware or a benign program is an important challenge for cybersecurity companies. Employing machine learning methods for this problem is a promising area of research. The two broad classes of malware analysis techniques are static and dynamic. The former’s methods operate on raw binary ﬁles, leading to signiﬁcant issues with analysis of encrypted and obfuscated ﬁles. The latter’s approach consists of executing the binary ﬁle in a controlled environment and monitoring its behavior. The dynamic approach is more timeand resource-consuming, but it provides higher accuracy. Behavior monitoring results can typically be presented as a log of the observed system events or API calls (function name, arguments, and, optionally, a return value). Currently, the most popular approach for feature extraction from such logs is to construct a set of different indicator features such as n-grams of events or links between APIs and their arguments (Bayer et al. (2009); Berlin et al. (2015); Huang & Stokes (2016); Salehi et al. (2017)). Some other classiﬁcation methods apply recurrent neural networks to a sequence of notes in a log (Pascanu et al. (2015); Kolosnjaji et al. (2016)). However, the latter approach is sensitive to the mixing of lines in a log caused by multiprocessing, intentional obfuscation by malware, and difference in the execution environments. In this paper we propose a new feature extraction technique for logs that is based on speciﬁc behavior graphs. We consider a graph as a union of behavior patterns (speciﬁc subgraphs) and construct a feature representation of a log by combining feature vectors of these patterns. To extract a compact and meaningful continuous feature representation for behavior patterns, we train an autoencoder. In the experiments, we show that the log representation constructed by our technique provides high classiﬁcation accuracy on a large real-world dataset. In addition, we illustrate the ability of our model to automatically capture interpretable structure in the space of pattern parts similarly to the word2vec model (Mikolov et al. (2013)). 2 FEATURE REPRESENTATION FOR LOGS In this paper, a log means a sequence of all system events that occurred during program execution alongside with their arguments. A toy example of such a log is presented in Figure 1a. Each line of 1 arXiv:1804.03635v1  [cs.CR]  10 Apr 2018  Workshop track - ICLR 2017 … Modify(‘notepad.exe’) Create(‘config.xml’) Modify(‘config.xml’) Create(‘doc1.rtf’) Modify(‘doc1.rtf’) Create(‘list.rtf’) Modify(‘list.rtf’) Delete(‘doc1.rtf’) Delete(‘list.rtf’) … (a) Example of a log. Delete Create Modify list.rtf notepad.exe config.xml doc1.rtf (b) Behavior graph. Modify Create, Modify Create, Modify, Delete ‘notepad.exe’ ‘config.xml’ ‘doc1.rtf’, ‘list.rtf’ Modify Create, Modify Create, Modify, Delete ‘notepad’, ‘.’, ‘exe’ ‘config’, ‘.’, ‘xml’ ‘doc1’, ‘list’, ‘.’, ‘rtf',\n",
       " '1603.06598': 'In recent years, transition-based dependency parsers powered by neural network scoring functions have dramatically increased the state-of-theart in terms of both speed and accuracy (Chen and Manning, 2014; Alberti et al., 2015; Weiss et al., 2015). Similar approaches also achieve state-ofthe-art in other NLP tasks, such as constituency parsing (Durrett and Klein, 2015) or semantic role labeling (FitzGerald et al., 2015). These approaches all share a common principle: replace hand-tuned conjunctions of traditional NLP feature templates with continuous approximations learned by the hidden layer of a feed-forward network. ∗Research conducted at Google. However, state-of-the-art dependency parsers depend crucially on the use of predicted part-ofspeech (POS) tags. In the pipeline or stacking (Wolpert, 1992) method, these are predicted from an independently trained tagger and used as features in the parser. However, there are two main disadvantages of a pipeline: (1) errors from the POS tagger cascade into parsing errors, and (2) POS taggers often make mistakes precisely because they cannot take into account the syntactic context of a parse tree. The POS tags may also contain only coarse information, such as when using the universal tagset of Petrov et al. (2011). One approach to solve these issues has been to avoid using POS tags during parsing, e.g. either using semi-supervised clustering instead of POS tags (Koo et al., 2008) or building recurrent representations of words using neural networks (Dyer et al., 2015; Ballesteros et al., 2015). However, the best accuracy for these approaches is still achieved by running a POS tagger over the data ﬁrst and combining the predicted POS tags with additional representations. As an alternative, a wide range of prior work has investigated jointly modeling both POS and parse trees (Li et al., 2011; Hatori et al., 2011; Bohnet and Nivre, 2012; Qian and Liu, 2012; Wang and Xue, 2014; Li et al., 2014; Zhang et al., 2015; Alberti et al., 2015). However, these approaches typically require sacriﬁcing either efﬁciency or accuracy compared to the best pipeline model, and often they simply re-rank the predictions of a pipelined POS tagger. In this work, we show how to improve accuracy for both POS tagging and parsing by incorporating stacking into the architecture of a feed-forward network. We propose a continuous form of stacking that allows for easy backpropagation down the pipeline across multiple tasks, a process we call arXiv:1603.06598v2  [cs.CL]  8 Jun 2016  Backpropagation Task A Task B Traditional Stacking Stack-propagation Task A Task B Figure 1: Traditional stacking (left) vs. Stack-propagation (right). Stacking uses the output of Task A as features in Task B, and does not allow backpropagation between tasks. Stack-propagation uses a continuous and differentiable link between Task A and Task B, allowing for backpropagation from Task B into Task A’s model. Updates to Task A act as regularization on the',\n",
       " '1405.3224': 'A/B Testing is a popular procedure used, for instance, for website optimization: two versions of a webpage, say A and B, are empirically compared by being presented to users. Each user only sees one of the two versions, and the goal is to determine which version is preferable. We assume that the users provide a real-valued index of the quality of the pages, which is modeled by probability distributions νA and νB, with respective means µA and µB. For example, a standard objective is to determine which webpage has the highest conversion rate (probability that a user actually becomes a customer) by receiving binary feedback from the users. Methods for A/B Testing are often viewed as statistical tests of the hypothesis H0 : (µA ≤ µB) against H1 : (µA > µB). One may consider either classical tests, based on a number of samples nA and nB from each distribution ﬁxed before the experiment, or sequential tests, based on paired samples (Xs, Ys) of νA, νB and in which a randomized stopping rule determines when the experiment is to be terminated. In both of these test settings, the sampling schedule is determined in advance, which is a possible source of sub-optimality as A/B Testing algorithms could take advantage of past observations to provide a smarter choice of the page to be displayed to the next user. In the sequel, we investigate whether A/B Testing could beneﬁt from an adaptive sampling schedule. Ignoring the possible long-term effects on users of presenting one or the other option, we consider it as a particular instance of best arm identiﬁcation in a two-armed bandit model. c⃝2014 E. Kaufmann, O. Capp´e & A. Garivier. arXiv:1405.3224v2  [math.ST]  24 Feb 2015  KAUFMANN CAPP´E GARIVIER A two-armed bandit model consists of two unknown probability distributions on R, ν1 and ν2, sometimes referred to as arms or options (webpages in our motivating example). Arm a has expectation µa. At each time t = 1, 2, . . . , an agent chooses an option At ∈{1, 2} and receives an independent draw Zt of the corresponding arm νAt. We denote by Pν (resp. Eν) the probability law (resp. expectation) of the corresponding process (Zt). We assume that the bandit model ν = (ν1, ν2) belongs to a class M such that for all ν ∈M, µ1 ̸= µ2. In order to identify the best arm, that is the arm a∗with highest expectation, the agent must use a strategy deﬁning which arms to sample from, when to stop sampling, and which arm ˆa to choose. The sampling rule determines how, at time t, the arm At is chosen based on the past observations; in other words, At is Ft−1– measurable, with Ft = σ(A1, Z1, . . . , At, Zt). The stopping rule τ is a stopping time with respect to (Ft)t∈N satisfying Pν(τ < +∞) = 1. The recommendation rule is a Fτ-measurable random arm ˆa ∈{1, 2}. This triple ((At), τ, ˆa) entirely determines the',\n",
       " '1806.08730': 'We introduce the Natural Language Decathlon (decaNLP) in order to explore models that generalize to many different kinds of NLP tasks. decaNLP encourages a single model to simultaneously optimize for ten tasks: question answering, machine translation, document summarization, semantic parsing, sentiment analysis, natural language inference, semantic role labeling, relation extraction, goal oriented dialogue, and pronoun resolution. We frame all tasks as question answering [Kumar et al., 2016] by allowing task speciﬁcation to take the form of a natural language question q: all inputs have a context, question, and answer (Fig. 1). Traditionally, NLP examples have inputs x and outputs y, and the underlying task t is provided through explicit modeling constraints. Meta-learning approaches include t as additional input [Schmidhuber, 1987, Thrun and Pratt, 1998, Thrun, 1998, Vilalta and Drissi, 2002]. Our approach does not use a single representation for any t, but instead uses natural language questions that provide descriptions for underlying tasks. This allows single models to effectively multitask and makes them more suitable as pretrained models for transfer learning and meta-learning: natural language questions allow a model to generalize to completely new tasks through different but related task descriptions. We provide a set of baselines for decaNLP that combine the basics of sequence-to-sequence learning [Sutskever et al., 2014, Bahdanau et al., 2014, Luong et al., 2015b] with pointer networks [Vinyals et al., 2015, Merity et al., 2017, Gülçehre et al., 2016, Gu et al., 2016, Nallapati et al., 2016], adPreprint. Work in progress. arXiv:1806.08730v1  [cs.CL]  20 Jun 2018  Question Examples Context Answer Question Context Answer Susan What is a major importance  of Southern California in relation  to California and the US? …Southern California is a major  economic center for the state  of California and the US.…  major economic center  What is the translation from English to German? Der Großteil der  Erde ist Meerwasser What is the  summary? Harry Potter star Daniel  Radcliﬀe gains access to a  reported £320 million fortune… Hypothesis: Product and geography are what make cream  skimming  work. Entailment, neutral,  or contradiction? Premise: Conceptually cream  skimming has two basic   dimensions — product and geography.  Entailment Is this sentence  positive or negative? A stirring, funny and ﬁnally  transporting re-imagining of Beauty and the Beast and  1930s horror ﬁlm. positive What has something  experienced? Areas of the Baltic that have  experienced eutrophication. eutrophication Who is the illustrator of Cycle of the Werewolf? Cycle of the Werewolf is a short novel by Stephen King, featuring illustrations by comic book artist Bernie Wrightson. Bernie Wrightson What is the change in  dialogue state? Are there any Eritrean  restaurants in town? food: Eritrean What is the translation  from English to SQL? The table has column names… Tell me what the notes  are for South Australia SELECT notes from table  WHERE  ‘Current Slogan’ =  ‘South Australia’ Who had given help?  Susan or Joan? Joan made sure to thank  Susan for all the help  she had given. Most of the planet is  ocean water. Harry Potter',\n",
       " '1506.02222': 'Long known for its consistency, simplicity and optimality under mild conditions, ordinary least squares (OLS) is the most widely used technique for ﬁtting linear models. Developed originally for ﬁtting ﬁxed dimensional linear models, unfortunately, classical OLS fails in high dimensional linear models where the number of predictors p far exceeds the number of observations n. To deal with this problem, Tibshirani (1996) proposed ℓ1-penalized regression, a.k.a, lasso, which triggered the recent overwhelming exploration in both theory and methodology of penalization-based methods. These methods usually assume that only a small number of coeﬃcients are nonzero (known as the sparsity assumption), and minimize the same least squares loss function as OLS by including an additional penalty on the coeﬃcients, with the typical choice being the ℓ1 norm. Such “penalization” constrains the solution space to certain directions favoring sparsity of the solution, and thus overcomes the non-unique issue with OLS. It yields a sparse solution and achieves model selection consistency and estimation consistency under certain conditions. See Zhao and Yu (2006); Fan and Li (2001); Zhang (2010); Zou and Hastie (2005). 1 arXiv:1506.02222v5  [stat.ME]  16 Jun 2016  Despite the success of the methods based on regularization, there are important issues that can not be easily neglected. On the one hand, methods using convex penalties, such as lasso, usually require strong conditions for model selection consistency (Zhao and Yu, 2006; Lounici, 2008). On the other hand, methods using non-convex penalties (Fan and Li, 2001; Zhang, 2010) that can achieve model selection consistency under mild conditions often require huge computational expense. These concerns have limited the practical use of regularized methods, motivating alternative strategies such as direct hard thresholding (Jain et al., 2014). In this article, we aim to solve the problem of ﬁtting high-dimensional sparse linear models by reconsidering OLS and answering the following simple question: Can ordinary least squares consistently ﬁt these models with some suitable algorithms? Our result provides an aﬃrmative answer to this question under fairly general settings. In particular, we give a generalized form of OLS in high dimensional linear regression, and develop two algorithms that can consistently estimate the coeﬃcients and recover the support. These algorithms involve least squares type of ﬁtting and hard thresholding, and are non-iterative in nature. Extensive empirical experiments are provided in Section 4 to compare the proposed estimators to many existing penalization methods. The performance of the new estimators is very competitive under various setups in terms of model selection, parameter estimation and computational time. 1.1 Related Works The work that is most closely related to ours is Yang et al. (2014), in which the authors proposed an algorithm based on OLS and ridge regression. However, both their methodology and theory are still within the ℓ1 regularization framework, and their conditions (especially their C-Ridge and C-OLS conditions) are overly strong and can be easily violated in practice. Jain et al. (2014) proposed an iterative hard',\n",
       " '1602.06979': 'Language is rich in subtle signals. The previous sentence, for example, conveys connotations of wealth (“rich”), cleverness (“subtle”), communication (“language”, “signals”), and positive sentiment (“rich”). A growing body of work in humancomputer interaction, computational social science and social computing uses tools to identify these signals: for example, detecting emotional contagion in status updates [19], linguistic correlates of deception [31], or conversational signs of betrayal [30]. As we gain access to ever larger and more diverse datasets, it becomes important to scale our ability to conduct such analyses with breadth and accuracy. High quality lexicons allow us to analyze language at scale and across a broad range of signals. For example, researchers often use LIWC (Linguistic Inquiry and Word Count) to analyze social media posts, counting words in lexical categories like sadness, health, and positive emotion [33]. LIWC offers many advantages: it is fast, easy to interpret, and extensively validated. Researchers can easily inspect and modify arXiv:1602.06979v1  [cs.CL]  22 Feb 2016  Figure 2. Empath learns word embeddings from 1.8 billion words of ﬁction, makes a vector space from these embeddings that measures the similarity between words, uses seed terms to deﬁne and discover new words for each of its categories, and ﬁnally ﬁlters its categories using crowds. the terms in its categories — word lists that, for example, relate “scream” and “war” to the emotion anger. But like other popular lexicons, LIWC is small: it has only 40 topical and emotional categories, many of which contain fewer than 100 words. Further, many potentially useful categories like violence or social media don’t exist in current lexicons, requiring the ad hoc curation and validation of new gold standard word lists. Other categories may beneﬁt from updating with modern terms like “paypal” for money or “selﬁe” for leisure. To address these problems, we present Empath: a living lexicon mined from modern text on the web. Empath allows researchers to generate and validate new lexical categories on demand, using a combination of deep learning and crowdsourcing. For example, using the seed terms “twitter” and “facebook,” we can generate and validate a category for social media. Empath also analyzes text across 200 builtin, pre-validated categories drawn from existing knowledge bases and literature on human emotions, like neglect (deprive, refusal), government (embassy, democrat), strength (tough, forceful), and technology (ipad, android). Empath combines modern NLP techniques with the beneﬁts of handmade lexicons: its categories are transparent word lists, easily extended and fast. And like LIWC (but unlike other machine learning models), Empath’s contents are validated by humans. While Empath presents an approach that can be trained on any text corpora, in this paper we use 1.8 billion words of modern amateur ﬁction. Why would ﬁction be the right tool to train an externally-valid measure of topical and emotional categories? General web text suffers from sparsity when learning categorie',\n",
       " '1701.08118': 'Social media are sometimes used to disseminate hateful messages. In Europe, the current surge in hate speech has been linked to the ongoing refugee crisis. Lawmakers and social media sites are increasingly aware of the problem and are developing approaches to deal with it, for example promising to remove illegal messages within 24 hours after they are reported (Titcomb, 2016). This raises the question of how hate speech can be detected automatically. Such an automatic detection method could be used to scan the large amount of text generated on the internet for hateful content and report it to the relevant authorities. It would also make it easier for researchers to examine the diffusion of hateful content through social media on a large scale. From a natural language processing perspective, hate speech detection can be considered a classiﬁcation task: given an utterance, determine whether or not it contains hate speech. Training a classiﬁer requires a large amount of data that is unambiguously hate speech. This data is typically obtained by manually annotating a set of texts based on whether a certain element contains hate speech. The reliability of the human annotations is essential, both to ensure that the algorithm can accurately learn the characteristics of hate speech, and as an upper bound on the expected performance (Warner and Hirschberg, 2012; Waseem and Hovy, 2016). As a preliminary step, six annotators rated 469 tweets. We found that agreement was very low (see Section 3). We then carried out group discussions to ﬁnd possible reasons. They revealed that there is considerable ambiguity in existing deﬁnitions. A given statement may be considered hate speech or not depending on someone’s cultural background and personal sensibilities. The wording of the question may also play a role. We decided to investigate the issue of reliability further by conducting a more comprehensive study across a large number of annotators, which we present in this paper. Our contribution in this paper is threefold: • To the best of our knowledge, this paper presents the ﬁrst attempt at compiling a German hate speech corpus for the refugee crisis.1 • We provide an estimate of the reliability of hate speech annotations. • We investigate how the reliability of the annotations is affected by the exact question asked. 1Available at https://github.com/UCSM-DUE/ IWG_hatespeech_public arXiv:1701.08118v1  [cs.CL]  27 Jan 2017  2 Hate Speech For the purpose of building a classiﬁer, Warner and Hirschberg (2012) deﬁne hate speech as “abusive speech targeting speciﬁc group characteristics, such as ethnic origin, religion, gender, or sexual orientation”. More recent approaches rely on lists of guidelines such as a tweet being hate speech if it “uses a sexist or racial slur” (Waseem and Hovy, 2016). These approaches are similar in that they leave plenty of room for personal interpretation, since there may be differences in what is considered offensive. For instance, while the utterance “the refugees will live off our money” is clearly',\n",
       " '1808.03114': 'While most of the latest breakthroughs in deep learning have been achieved by means of supervised algorithms, these algorithms have one essential limitation: they require large amounts of labeled training data. When learning image classiﬁcation tasks, this means that a large set of correctly labeled images needs to be available [NOPF10, PTPP06]. Since the labeling process is timeconsuming and labor-intensive, acquiring labeled training data is, however, a cumbersome process. To speed this process up, labeling is often outsourced to less experienced annotators or crowd workers, for instance via Amazon’s Mechanical Turk [KLA17, RYHH10]. In the context of deep learning, crowd workers are human labor, getting paid for labeling large data sets. Sometimes, even automatic label assignment tools are used [UCOT11]. Unfortunately, such a label acquisition process usually leads to noisy labels, i.e., a training data set which contains many wrongly assigned labels. This can compromise training results [ZBH∗16]. Thus, to be able to beneﬁt from these approaches for training data acquisition, dedicated quality control mechanisms must be in place. To address the problem of noisy labels, we propose a classiﬁerguided visual correction approach, which combines automatic error detection with interactive visual error correction (see Figure 1). To enable the automatic detection, we have systematically categorized error types, that can be potentially present in noisy label data sets. Our categorization led to three such error types: Class Interpretation Errors, Instance Interpretation Errors, and Similarity Errors. Tailored towards these error types, we further introduce detection measures, which are based on the classiﬁer’s response. Therefore, we ﬁrst train with the potentially noisy labels, and subsequently classify all training and validation images with the trained classiﬁer. The classiﬁer’s response can then be analyzed using our error detection measures to guide the user to potential errors. These potential errors are visualized in a way that supports an interactive visual correction. To visually guide the user during the correction, we propose to employ linked list visualizations with importance sorting. By using our approach, the number of required inspections is bound by – and usually much lower than – the classiﬁcation error, i.e., for a classiﬁer that reaches an accuracy of 92%, only 8% of the data has to be reviewed at maximum. While this is the upper bound for investigated training samples per iteration, all samples that have already been inspected can additionally be ignored in the error detection process in future iterations. This means that for each subsequent iteration of data-cleanup, only those samples where the classiﬁer disagrees with the label and that have not been already revisited need to be reviewed. Without our classiﬁer-guided approach, instead, an inspection of the entire labeled data set would be necessary. c ⃝2020 The Author(s) arXiv:1808.03114v4  [cs.CV]  6 Apr 2020  A. Bäuerle, H. Neumann, and T. Ropinski / Classiﬁer-Guided Visual Correction Figure 1: We propose a classiﬁer-guided Automatic Error Detection for noisy',\n",
       " '0807.2724': 'While the sum capacity of the single-user MIMO pointto-point link can be expressed semi-analytically in closed form [1], the simplest multi-user setup with single antenna terminals already allows for the presumption that this will remain infeasible in the broadcast and multiple access channel irrespective of whether linear or nonlinear ﬁltering is considered. Fortunately, the high signal-to-noise ratio regime is an exception to this deﬂating circumstance, since there, asymptotic results on the sum capacity have been discovered for dirty paper coding and partly for linear ﬁltering. A. Literature Overview The single user point-to-point MIMO case was treated in [2], [3], where the Grant-Gauthier lower bound on the mutual information, that becomes asymptotically tight, was decomposed into a supremum capacity term, an instantaneous SNR effect term, and an instantaneous capacity degradation term due to the eigenvalue spread. Outage capacity and throughput of a fading point-to-point MIMO system are analyzed in [4]. The ﬁrst high-SNR sum capacity analysis of the point-to-multipoint broadcast channel appeared in [5], where single-antenna receivers were considered. Therein, the afﬁne approximation of the sum capacity introduced in [6] and elaborately discussed in [7] was utilized. First, [5] shows that the single-antenna broadcast channel has the same asymptotic sum-capacity as the corresponding point-to-point MIMO link with cooperating receive antennas, and second, how the power offset term in the broadcast channel looks like. Furthermore, the instantaneous and ergodic spectral efﬁciency loss of linear zero-forcing beamforming with respect to DPC was derived in [5], again for single antenna receivers. The extension to multi-antenna receivers was presented in [8], [9], where the asymptotic equivalence of the nonlinear dirty paper coding sum capacity in the broadcast channel and the sum capacity of the equivalent point-to-point MIMO link with cooperating receivers was proven to hold in the multi-antenna case. Out of the class of linear precoding schemes, zero-forcing and block-diagonalization are considered. However, only ergodic statements for the asymptotic sum rate and the asymptotic rate loss with respect to dirty paper coding are derived, and a very special fading model is a key prerequisite for the presented results. Expressions for the instantaneous rate loss are not possible. Moreover, it is neither known yet, whether block-diagonalization is the asymptotically optimum transmission strategy or not in the broadcast channel when linear ﬁltering is considered, nor how the optimum blockdiagonalizing precoder looks like. B. Contributions The main contributions of this paper are summarized in the following list: 1) The derivation of the maximum weighted sum rate asymptotically achievable with linear ﬁltering. 2) A closed form expression for the asymptotic rate loss of linear ﬁltering with respect to dirty paper coding for any antenna conﬁguration at the base and the mobiles. 3) A closed form solution of the covariance matrices in the dual uplink achieving this maximum weighted sum rate. 4) We prove, that block diagonalization is asymptotically optimum in the broadcast channel',\n",
       " '1806.02514': 'Recently, the escalating demands for high data transmission, which is one of the key requirements of the ﬁfth-generation (5G) wireless communication systems, have triggered and attracted tremendous interests from both academia and industry, e.g. [3]–[21]. To meet the ultra-high data rate requirement of emerging applications, millimeter wave (mmWave) massive multiple-input multiple-output (MIMO) systems have been proposed [22], [23]. Speciﬁcally, mmWave massive MIMO cellular systems provide a huge trunk of the unlicensed bandwidth of the order of gigahertz to achieve ultra-high data rate communication. In practice, to strike a balance between Part of this manuscript has been accepted and presented at the IEEE ICC 2018 [1]. L. Zhao, Z. Wei, D. W. K. Ng, and J. Yuan are with the School of Electrical Engineering and Telecommunications, University of New South Wales, Sydney, NSW 2052, Australia (Email: lou.zhao@unsw.edu.au; zhiqiang.wei@unsw.edu.au; w.k.ng@unsw.edu.au; j.yuan@unsw.edu.au). M. C. Reed is with the School of Engineering and Information Technology, University of New South Wales, Australian Defence Force Academy, Canberra, ACT 2610, Australia (Email: mark.reed@unsw.edu.au). This work was supported by the Australia Research Council Discovery Project under Grant DP160104566. D. W. K. Ng is supported by the Australian Research Council’s Discovery Early Career Researcher Award funding scheme (DE170100137). the data rate, hardware cost1, system complexity, and power consumption, hybrid mmWave MIMO systems are proposed for practical implementation [8], [18], [22], [24]. Due to the hybrid MIMO structure, the required number of radio frequency (RF) chains equipped at a base station (BS) and users are much smaller than the number of antennas equipped at the BS and users. Thus, both the hardware cost and the energy consumption of hybrid mmWave massive MIMO systems can be reduced signiﬁcantly compared to the conventional fully digital mmWave massive MIMO structure, e.g. [7], [8]. Furthermore, the severe propagation path loss of mmWave channels between the transceivers can be compensated by forming a highly directional information beam enabled by the massive numbers of antennas. On the other hand, as required by 3GPP new radio (NR), the BSs of mmWave network systems is ultra-densely deployed with small cell radius for improving the network coverage and to meet the data rate requirement of the enhanced Mobile BroadBand (eMBB) applications (the peak data rate is 10 Gbps and the minimum is 100 Mbps2) [25], [26]. The ultradense mmWave network facilitates the reuse of the same piece of spectrum across a large geographic area3 for achieving a high network spectral efﬁciency [27] and reducing the severe large-scale propagation path loss by shortening the distances between transceivers [12], [28]. In practice, the interference received at the desired user in ultra-dense mmWave network systems originates from two sources, as illustrated in Fig. 3 of [28]: interference among different BSs and interference within the desired cell. It is mentioned in [12] that, mmWave beams are highly directional, which completely changes the interfer',\n",
       " '1103.0999': 'Finding the capacity as well as the code construction for the multi-user wireless networks are generally open problems. Even the relatively simple relay network with one source, one sink, and one relay, has not been fully characterized. There are two sources of disturbances in multi-user wireless networks – channel noise and interference among users in the network. In order to better approximate the Gaussian multi-user wireless networks, [1][2] proposed a binary linear Manuscript received on ..., and revised on .... The material in this paper was presented at the Information Theory and Applications Workshop (ITA), San Diego, CA, January 2010; and at the 2010 Allerton Conference on Communication, Control, and Computing, Urbana-Champaign, IL, September 2010. M. Kim and M. M´edard are with the Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, Cambridge, MA 02139 USA (e-mail: minjikim@mit.edu; medard@mit.edu). E. Erez and E. M. Yeh are with the Department of Electrical Engineering, Yale University, New Haven, CT 06511 USA (e-mail: elona.erez@yale.edu; edmund.yeh@yale.edu). deterministic network model (known as the ADT model), which takes into account the multi-user interference but not the noise. A node within the network receives the bit if the signal is above the noise level; multiple bits that simultaneously arrive at a node are superposed. References [1][2] showed that, for a multicast connection where a single source wishes to transmit the same data to a set of destinations, the achievable rate is equal to the minimal cut between the source and any of the destinations. Note that min-cut of an ADT network may not equal to the graph theoretical cut value, as we shall discuss in Section V. In addition, they showed that the minimal cut between the source and a destination is equal to the minimal rank of incidence matrices of all cuts between the two nodes. This can be viewed as the equivalent of the Min-cut Max-ﬂow criterion in the network coding for wireline networks [3][4]. It has been shown that for several networks, the gap between the capacity of the deterministic ADT model and that of the corresponding Gaussian network is bounded by a constant number of bits, which does not depend on the speciﬁc channel fading parameters [1][5][6]. In this paper, we make a connection between the ADT network and network coding – in particular, algebraic network coding introduced by Koetter and M´edard [4]. This paper is based on work from [7][8][9]. Other approaches to operations in high SNR networks have been proposed [10], however, we do not compare these different approaches but build upon the given model proposed by [1][2]. We show that the ADT network problems, including that of computing the min-cut and constructing a code, can be captured by the algebraic network coding framework. In the context of network coding, [4] showed that the solvability of the communication problem [3] is equivalent',\n",
       " '1901.07441': 'Chest x-rays are essential for both the screening and the diagnosis of pulmonary, cardiovascular, bone and other thoracic disorders. The adequate interpretation of the radiographic ﬁndings requires medical training acquired over many years, with radiologists being the most qualiﬁed professionals in this ﬁelds. Due to increasing workload pressures, many radiologists today have to read more than 100 x-ray studies daily. Therefore, automated tools trained to predict the risk of speciﬁc abnormalities given a particular x-ray image have the potential to support the reading workﬂow of the radiologist. Those tools could be used to enhance the conﬁdence of the radiologist or prioritize the reading list where critical cases would be read ﬁrst. Decision support systems (DSS) designed as tools to assist in the clinical interpretation of chest x-rays would therefore fulﬁll an unmet need. Deep learning techniques are currently obtaining promising results and perform extremely well in a variety of sophisticated tasks [1], especially those related to computer vision, often equaling or exceeding human performance [2]. The application of deep neural networks to medical imaging and chest radiographs in particular, has become a growing arXiv:1901.07441v2  [eess.IV]  7 Feb 2019  PADCHEST PREPRINT - FEBRUARY 8, 2019 area of research in recent years [3]. For instance, [4] trained a Convolutional Neural Network (CNN) to classify and localize 8 pathologies using the chest x-ray database (ChestX-Ray8) which comprised 108,948 frontal-view x-ray images of 32,717 different patients. Using the same repository, [5] extended the annotations to 14 different pathologies (ChestX-Ray14) and designed a model with a deeper CNN architecture to classify images as 14 pathological entities. This method was reported to obtain greater diagnostic efﬁciency in the detection of pneumonias when compared to that of radiologists. [6] proposed the attention guided CNN to help combine global and local information in order to improve recognition performance. Chest-XRay14 was also employed by [7] to design a network architecture that combines text and image with attention mechanisms capable of generating text that describes the image, while [8] introduced a hierarchical model of Recurrent Neural Networks (RNN) with which to generate long paragraphs from the images and obtain semantically linked phrases for the same purpose. Despite claims that they achieve and/or surpass physician-level performance, current deep learning models for the classiﬁcation of pathologies using chest x-rays are proving not to be generalizable across institutions and not yet ready for adoption in real-world clinical settings [9]. Moreover, warnings of potential unintended consequences of their use are discussed by [10]. It is unclear how to extend the signiﬁcant success in computer vision using deep neural networks to the medical domain [11]. Open questions concerning medical radiology datasets that still need to be addressed are: • How to annotate the huge amount of medical images required by deep learning models [11] and meet the required quality. Large-scale crowd-sourced hand-annotation which has proved successful in the general domain, e.g. ImageNet [12',\n",
       " '1802.00434': 'This work aims at pushing further the envelope of human understanding in images by establishing dense correspon1Rıza Alp G¨uler was with Facebook AI Research during this work. dences from a 2D image to a 3D, surface-based representation of the human body. We can understand this task as involving several other problems, such as object detection, pose estimation, part and instance segmentation either as special cases or prerequisites. Addressing this task has applications in problems that require going beyond plain landmark localization, such as graphics, augmented reality, or human-computer interaction, and could also be a stepping stone towards general 3D-based object understanding. The task of establishing dense correspondences from an image to a surface-based model has been addressed mostly in the setting where a depth sensor is available, as in the Vitruvian manifold of [41], metric regression forests [33], or the more recent dense point cloud correspondence of [44]. By contrast, in our case we consider a single RGB image as input, based on which we establish a correspondence between surface points and image pixels. Several other works have recently aimed at recovering dense correspondences between pairs [3] or sets of RGB images [48, 10] in an unsupervised setting. More recently, [42] used the equivariance principle in order to align sets of images to a common coordinate system, while following the general idea of groupwise image alignment, e.g. [23, 21]. While these works are aiming at general categories, our work is focused on arguably the most important visual category, humans. For humans one can simplify the task by exploiting parametric deformable surface models, such as 1 arXiv:1802.00434v1  [cs.CV]  1 Feb 2018  Surface Correspondence TASK 2: Marking Correspondences TASK 1: Part Segmentation ... ... sampled points input image segmented parts rendered images for the specific part Figure 2: We annotate dense correspondence between images and a 3D surface model by asking the annotators to segment the image into semantic regions and to then localize the corresponding surface point for each of the sampled points on any of the rendered part images. The red cross indicates the currently annotated point. The surface coordinates of the rendered views localize the collected 2D points on the 3D model. the Skinned Multi-Person Linear (SMPL) model of [2], or the more recent Adam model of [14] obtained through carefully controlled 3D surface acquisition. Turning to the task of image-to-surface mapping, in [2], the authors propose a two-stage method of ﬁrst detecting human landmarks through a CNN and then ﬁtting a parametric deformable surface model to the image through iterative minimization. In parallel to our work, [20] develop the method of [2] to operate in an end-to-end fashion, incorporating the iterative reprojection error minimization as a module of a deep network that recovers 3D camera pose and the lowdimensional body parametrization. Our methodology differs from all these works in that we ta',\n",
       " '1611.05923': 'Sample inﬂuence scores have been largely neglected in modern large-scale data analysis, perhaps considered a mere anachronism in the historical context of science experiments which explored model behavior with and without a handful of aberrant cases. However, sample inﬂuence scores can help solve the “needle in the haystack\" problem in modern data analysis: where in a corpus of many millions of samples should one devote one’s attention? Modern datasets can be of such enormous sizes that human experts may have had a smallto-nonexistent role in their creation. However, human experts may be available to provide a deeper analysis of some but not all samples. A scalable measure of sample inﬂuence could 1This work is copyrighted by the IEEE. Personal use of this material is permitted. However, permission to reprint/republish this material for advertising or promotional purposes or for creating new collective works for resale or redistribution to servers or lists, or to reuse any copyrighted component of this work in other works must be obtained from the IEEE. solve this queueing problem, prioritizing samples which have the largest model impact. Consider, for example, two special cases. First, modern large-scale datasets are often labeled by a heuristic or algorithm, introducing the problem of label noise [5]. For example, in the ﬁeld of cybersecurity, there are not enough professional reverse engineers to analyze every new piece of software that encounters the world’s computers; thus, the security of software is traditionally determined based on whether “signatures\" of maliciousness have been satisﬁed. Similarly, in the ﬁeld of natural language processing, inexpensive labeling from non-experts can be often obtained for huge datasets through Mechanical Turk2; however, this labeling can be substantially less reliable than labeling by experts [5]. A scalable measure of sample inﬂuence could point towards potentially mislabeled samples, particularly those with pernicious model impact. Second, even high-performing models can harbor vulnerabilities, as in the now well-known example of the model that learned to discriminate between wolves and huskies through background “snow features\" [13]. Because the model’s decision making was based not on physical features, but on background snow, the model was vulnerable to attack. A scalable measure of sample inﬂuence could point towards important vulnerabilities in the model, therefore subserving a primary goal of adversarial learning. In this paper, we present an attempt to revive, modernize, and scale up a technique from classical statistics of the late 1970s: a measure of sample inﬂuence known as Cook’s Distance [2]. In particular, we focus on Generalized Cook’s Distance [12], which can identify inﬂuential samples with respect to any regression model (linear, logistic, Poisson, beta, etc.) in the family of Generalized Linear Models. Cook’s Distance deems a sample inﬂuential when its inclusion causes “strange\" (or unexpected) perturbations in the regression weights. As we will see, these inﬂuential samples can have a strong impact on a model’s predictions about future samples. High inﬂuence scores are',\n",
       " '1612.04065': 'Cloud radio access network (CRAN) provides a costeffective way to achieve network densiﬁcation and hence meet the exponential growth in wireless network trafﬁc, by replacing the conventional base stations (BSs) with low-power distributed remote radio heads (RRHs) that are coordinated by a central processor (CP) [1]. In addition, CRAN offers both improved spectral efﬁciency and energy efﬁciency compared to conventional cellular networks, due to the centralized resource allocation and joint signal processing over the RRHs at the CP [2]–[7]. However, along with the growth in the amount of wireless data trafﬁc, the type of services required by users R. G. Stephen is with the NUS Graduate School for Integrative Sciences and Engineering (NGS), National University of Singapore (e-mail: reubenstephen@u.nus.edu). He is also with the Department of Electrical and Computer Engineering, National University of Singapore. R. Zhang is with the Department of Electrical and Computer Engineering, National University of Singapore (e-mail: elezhang@nus.edu.sg). He is also with the Institute for Infocomm Research, A*STAR, Singapore. c⃝2016 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works. is also making a transition from the traditional connectioncentric communications such as voice calls and web surﬁng, to the so-called content-centric communications such as video streaming, mobile application downloads, etc. [1], [8]. An important characteristic of such content-centric communication is that the same contents are requested by multiple users at similar time. In order to address this paradigm shift in the nature of wireless trafﬁc, it has been proposed to employ cache-enabled RRHs in a CRAN [1], [8], where the RRHs can store popular contents beforehand, and hence, transmit the data requested by the users directly, without the need of fetching it from the CP over the fronthaul. Such a network architecture is also referred to as Fog Radio Access Network (FRAN) [9]. Moreover, if the popular contents are cached at many RRHs in a CRAN, all of them can cooperatively transmit the data to many users at the same time, offering additional beamforming gains [8]–[11], and hence reducing the total transmit power required to satisfy the users’ content requests. For a single-channel wireless system, the joint caching and transmit beamforming design was considered in [10], [11]. When the caching placement is known, a joint optimization of the BS clustering and transmit beamforming was studied in [8], while [9] considered the joint optimization of transmit precoding and quantization noise covariances. In contrast to the above work, we consider the orthogonal frequency division multiple access (OFDMA)-based CRAN with multiple subchannels (SCs), where the RRHs are enabled with caches of ﬁxed size. Since the caching',\n",
       " '1311.3534': '1 1.1 Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 1.2 Thesis Context . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 1.3 Thesis Contributions . . . . . . . . . . . . . . . . . . . . . . . . . 3 1.4 Thesis Structure . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 1.5 The EARTH Project . . . . . . . . . . . . . . . . . . . . . . . . . 4 2 Motivation and Background 7 2.1 Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7 2.2 Energy Eﬃcient Base Stations . . . . . . . . . . . . . . . . . . . . 7 2.3 Quantifying Energy Eﬃciency . . . . . . . . . . . . . . . . . . . . 10 2.4 Green Radio in Literature . . . . . . . . . . . . . . . . . . . . . . 11 2.5 Technical Background . . . . . . . . . . . . . . . . . . . . . . . . 14 2.5.1 LTE . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14 2.5.2 Multi-carrier Technology . . . . . . . . . . . . . . . . . . . 15 2.5.3 Multiple Antenna Technology . . . . . . . . . . . . . . . . 19 2.5.4 Convex Optimization . . . . . . . . . . . . . . . . . . . . . 21 2.5.5 Network Simulation . . . . . . . . . . . . . . . . . . . . . . 22 2.6 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26 xi  xii CONTENTS 3 Power Saving on the Device Level 27 3.1 Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27 3.2 Challenges in Power Modeling . . . . . . . . . . . . . . . . . . . . 28 3.3 Existing Power Models . . . . . . . . . . . . . . . . . . . . . . . . 28 3.4 The Component Power Model . . . . . . . . . . . . . . . . . . . . 29 3.4.1 Remarks . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29 3.4.2 The Components of a BS . . . . . . . . . . . . . . . . . . . 30 3.4.3 BS Power Consumption . . . . . . . . . . . . . . . . . . . 40 3.5 The Parameterized Power Model . . . . . . . . . . . . . . . . . . 43 3.6 The Aﬃne Power Model . . . . . . . . . . . . . . . . . . . . . . . 46 3.7 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48 4 Power Saving on the Cell Level (Single-cell) 51 4.1 Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51 4.2 Power-saving RRM in Literature . . . . . . . . . . . . . . . . . . 52 4.3 PC and TDMA . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53 4.4 Power and Resource Allocation Including Sleep (PRAIS) . . . . . 58 4.5 Resource allocation using Antenna adaptation, Power control and Sleep modes (RAPS) . . . . . . . . . . . . . . . . . . . . . . . . . 63 4.5.1 Problem Formulation . . . . . . . . . . . . . . . . . . . . . 65 4.5.2 Step 1: Antenna Adaptation (AA), DTX and Resource Allocation . . . . . . . . . . . . . . . . . . . . . . . . . . . 67 4.5.3 Step 2: Subcarrier and Power Allocation . . . . . . . . . . 69 4.5.4 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72 4.6 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 79 5 Power Saving on the Network Level (Multi-cell) 81 5.1 Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 81 5.2 Channel Allocation in Literature . . . . . . . . . . . . . . . . . . 81 5.3 System Model and Problem Formulation . . . . . . . . . . . . . . 83 5.4 DTX Alignment Strategies . . . . . . . . . . . . . . . . . . . . . . 84 5.4.1 Sequential Alignment . . . . . . . . . . . . . . . . . . . . . 84 5.4.2 Random Alignment . . . . . . . . . . . . . . . . . . . . . . 85 5.4.3 P-persistent Ranking . . . . . . . . . . . . . . . . . . . . . 85 5.4.4 Distributed DTX Alignment with Memory . . . . . . . . . 86 5.5 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87 5.6 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 92 6 Conclusions, Limitations and Future Work 95 6.1 Summary and Conclusions . . . . . . . . . . . . . . . . . . . . . . 95 6.2 Limitations and Future Work . . . . . . . . . . . . . . . . . . . . 97 Appendices 99  CONTENTS xiii A Appendix 99 A.1 Proof of Convexity for Problem (4.12) . . . . . . . . . . . . . . . . 99 A.2 Proof of Convexity for Problem (4.15) . . . . . . . . . . . . . . . . 99 A.3 Margin-adaptive Resource Allocation . . . . . . . . . . . . . . . . 100 B List of Publications 103 B.1 Published . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103 B.2 Accepted . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104 B.3 Submitted . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104 B.4 Project Reports . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104 B.5 Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104 C Attached Publications 105 Literature References 107  xiv CONTENTS  List of Tables 3.1 Model parameters assumed for ﬁgures of Chapter 3 . . . . . . . . 30 3.2 Reference power consumption values of RF transceiver blocks . . 34 3.3 Complexity of BB operations . . . . . . . . . . . . . . . . . . . . 35 3.4 Parameter breakdown . . . . . . . . . . . . . . . . . . . . . . . . . 46 3.5 Summary of aﬃne power model parameters . . . . . . . . . . . . . 48 3.6 Comparison of required input parameters for diﬀerent power models 49 4.1 Simulation parameters . . . . . . . . . . . . . . . . . . . . . . . . 57 4.2 Power model parameters used in Section 4.4 . . . . . . . . . . . . 62 4.3 System parameters . . . . . . . . . . . . . . . . . . . . . . . . . . 74 5.1 Simulation parameters',\n",
       " '1703.01256': 'Low-rank matrices arise in a wide variety of applications throughout science and engineering, ranging from quantum tomography [1], signal processing [2], machine learning [3], [4], and so on; see [5] for a comprehensive review. In all of these settings, we often encounter the following rankconstrained optimization problem: minimize X∈Rn×m f(X), subject to rank(X) ≤r, (1) where the objective function f : Rn×m →R is smooth. Whether the objective function f is convex or nonconvex, the rank constraint renders low-rank matrix optimizations of the form (1) highly nonconvex and computationally NPhard in general [6]. Signiﬁcant efforts have been devoted to The ﬁrst two authors contribute equally. This work was supported by NSF grant CCF-1409261, NSF grant CCF-1464205, NSF grant 2008460, NSF CAREER grant CCF-1149225, and Award N660011824020 from the DARPA Lagrange Program. ZZ is with the Department of Electrical and Computer Engineering, University of Denver, QL is with the Department of Mathematics, University of California, Los Angeles, and GT and MW are with the Department of Electrical Engineering, Colorado School of Mines. Email: zhihui.zhu@du.edu, qiuweili@math.ucla.edu, {gtang, mwakin}@mines.edu. transforming (1) into a convex problem by replacing the rank constraint with one involving the nuclear norm. This strategy has been widely utilized in matrix inverse problems [7] arising in signal processing [5], machine learning [8], and control [6]. With convex analysis techniques, nuclear norm minimization has been proved to provide optimal performance in recovering low-rank matrices [9]. However, in spite of the optimal performance, solving nuclear norm minimization is very computationally expensive even with specialized ﬁrstorder algorithms. For example, the singular value thresholding algorithm [10] requires performing an expensive singular value decomposition (SVD) in each iteration, making it computationally prohibitive in large-scale settings. This prevents nuclear norm minimization from scaling to practical problems. To relieve the computational bottleneck, recent studies propose to factorize the variable into X = UV T, and optimize over the n × r and m × r matrices U and V rather than the n × m matrix X. The rank constraint in (1) then is automatically satisﬁed through the factorization. This strategy is usually referred to as the Burer-Monteiro type decomposition after the authors in [11], [12]. Plugging this parameterization of X in (1), we can recast the program into the following one: minimize U∈Rn×r,V ∈Rm×r h(U, V ) := f(UV T). (2) The bilinear nature of the parameterization renders the objective function of (2) nonconvex. Hence, it can potentially have spurious local minima (i.e., local minimizers that are not global minimizers) or even saddle points. With technical innovations in analyzing the landscape of nonconvex functions, however, several recent works have shown that the factored objective function h(U, V ) in certain matrix inverse problems has no spurious local minima [13]–[15]. A. Summary of results and outline In this paper, we provide a comprehensive geometric analysis for solving',\n",
       " '1807.09358': 'Combinatorial optimization problems ﬁnd a variety of applications in robotics. Typical examples include: • Sensor placement: Where to place sensors to maximally cover the environment [1] or reduce the uncertainty in the environment [2]? • Task allocation: How to allocate tasks to robots to maximize the overall utility gained by the robots [3]? • Combinatorial auction: How to choose a combination of items for each player to maximize the total rewards [4]? Algorithms for solving such problems ﬁnd use in sensor placement for environment monitoring [1,2], robot-target assignment and tracking [5,6,7], and informative path planning [8]. The underlying optimization problem in most cases can be written as: max S∈I,S∈Xf(S), (1) arXiv:1807.09358v2  [cs.AI]  26 Oct 2018  2 L. Zhou & P. Tokekar where X denotes a ground set from which a subset of elements S must be chosen. f is a monotone submodular utility function [9,10]. Submodularity is the property of diminishing returns. Many information theoretic measures, such as mutual information [2], and geometric measures such as the visible area [11], are known to be submodular. I denotes a matroidal constraint [9,10]. Matroids are a powerful combinatorial tool that can represent constraints on the solution set, e.g., cardinality constraints (“place no more than k sensors”) and connectivity constraints (“the communication graph of the robots must be connected”) [12]. The objective of this problem is to ﬁnd a set S satisfying a matroidal constraint I and maximizing the utility f(S). The general form of this problem is NPcomplete. However, a greedy algorithm yields a constant factor approximation guarantee [9,10]. In practice, sensors can fail or get compromised [13] or robots may not know the exact positions of the targets [14]. Hence, the utility f(S) is not necessarily deterministic but can have uncertainty. Our main contribution is to extend the traditional formulation given in Eq. 1 to also account for the uncertainty in the actual cost function. We model the uncertainty by assuming that the utility function is of the form f(S, y) where S ∈X is the decision variable and y ∈Y represents a random variable which is independent of S. We focus on the case where f(S, y) is monotone submodular in S ∈X and integrable in y. The traditional way of stochastic optimization is to use the expected utility as the objective function: maxS∈I,S∈X Ey[f(S, y)]. Since the sum of the monotone submodular functions is monotone submodular, Ey[f(S, y)] is still monotone submodular in S. Thus, the greedy algorithm still retains its constant-factor performance guarantee [9,10]. Examples of this approach include inﬂuence maximization [15], moving target detection and tracking [14], and robot assignment with travel-time uncertainty [16]. Fig. 1. Mobility on demand with travel time uncertainty of self-driving vehicles. While optimizing the expected utility has its uses, it also has its pitfalls. Consider the example of mobility-on',\n",
       " '1711.06606': 'Deep Learning offers great promise for the reconstruction and interpretation of medical images [27, 6]. Countless applications in clinical diagnostics, disease screening, interventional planning, and therapeutic surveillance rely on the subjective interpretation of medical images from healthcare providers. This approach is costly, time-intensive, and has well-known accuracy and precision limitations—all of Figure 1. Unsupervised reverse domain adaption for endoscopy images. We use an accurate forward model of an endoscope and an anatomically correct colon model to generate synthetic endoscopy images with ground truth depth. This large synthetic dataset can be used to train a deep network for depth estimation. An adversarial network transforms input endoscopy images to a syntheticlike representation while preserving clinically relevant features via self-regularization. These synthetic-like images can be directly used for depth estimation from the network trained on synthetic images. which could be mitigated by objective, automatic image analysis. For conventional images, deep learning has achieved remarkable performance for a variety of computer vision tasks, typically by utilizing large sets of real-world im1 arXiv:1711.06606v2  [cs.CV]  29 Nov 2017  ages for training, such as ImageNet [12], COCO [13] and Pascal VOC [4]. Unfortunately, the potential beneﬁts of deep learning have yet to transfer to the most critical needs in medical imaging because there are no large, annotated dataset of medical images available. Despite the compelling need for such a dataset, there are practical concerns that impede its development, including the cost, time, expertise, privacy, and regulatory issues associated with medical data collection, annotation, and dissemination. The obstacles associated with developing a large dataset of real images can be circumvented by generating synthetic images [22, 26, 24]. Considerable effort has been devoted to adapting models generated with synthetic data as the source domain to real data as the target domain [2]. Advances in adversarial training have sparked interest in making synthetic data look more realistic via unsupervised adversarial learning (SimGAN) [28]. In the medical imaging domain, there has been recent success in generating realistic synthetic data for the relatively constrained problem of 2D retinal imaging using standard GANs [7]. In more complex applications, it is challenging to generate an appropriate span of synthetic medical images for training, because few models exist that accurately simulate the anatomical complexity and diversity found in healthy to pathologic tissues. Moreover, the forward models for medical imaging devices are more complex than those used in many conventional vision applications. Consequently, models trained on synthetic medical data may fail to generalize to real medical images, where accurate interpretation may be critically important. Cross-patient network usage is a well-known challenge to learning-based medical imaging methods. Often a network trained on data from one patient fails to generalize to other patients. This is commonly observed for optical imaging methods, such as endoscopy, which capture both lowand high-level texture details of the patient. Low-level texture details',\n",
       " '1304.5850': 'Wireless networks are becoming more and more pervasive, with users relying on them to transmit sensitive data. Due to the broadcast nature of the physical medium, every node in the network is a potential eavesdropper, and securing the transmitted information is critical. Security of wireless communications has traditionally been ensured by network layer key-based cryptography. However, these schemes may not be suitable in the case of large dynamic wireless networks, since they raise issues like key distribution and management (for symmetric cryptosystems) and high computational complexity (for asymmetric cryptosystems). Moreover, these schemes are potentially vulnerable, because they rely on the unproven assumption that certain mathematical functions are hard to invert [1]. To provide an additional level of protection and to achieve perfect secrecy, methods exploiting the randomness inherent in noisy channels, known as physical layer security, have been proposed [2], [3]. Physical layer security has recently become an active area of research [4], [5]. The maximum rate at which a message can be reliably transmitted to an intended user while the rate of information leakage at an eavesdropper vanishes asymptotically with the code length, denoted as the secrecy capacity, has been studied for several network topologies. These include multi-antenna wiretap channels [6] and multi-receiver wiretap channels [7]. Techniques like artiﬁcial noise and adaptive encoding have been proposed for the case when the eavesdropper’s channel is not known by the transmitter [8]–[11]. The secrecy capacity of a two-user broadcast channel with conﬁdential messages (BCC) has also been studied in [12], where the intended users can act maliciously as eavesdroppers. For a larger BCC with any number of malicious users, practical linear precoding schemes have been proposed [13]. Although suboptimal, linear precoding can control the amount of interference and information leakage between the users of a BCC, thus achieving secrecy with low-complexity implementation [14], [15]. In this paper, we propose a linear precoder based on regularized channel inversion (RCI) for the multiple-input single-output (MISO) BCC. In the MISO BCC, a base station (BS) equipped with M antennas simultaneously transmits K independent conﬁdential messages to K spatially dispersed single-antenna users that potentially eavesdrop on each other. Under this system setup, we carry out a large-system analysis assuming that both M and K grow large, while their ratio β = K/M is ﬁxed. This paper directly extends some of the analysis in [16], [17] by requiring the transmitted messages to be kept conﬁdential. Furthermore, this paper generalizes the results provided in [14], where the  2 special case of β = 1 with perfect channel state information (CSI) was considered. Our main contributions can be summarized as follows. • We obtain a deterministic equivalent for the large-system secrecy sum-rate achievable by the RCI precoder in a MISO BCC. We then derive the optimal regularization parameter ξ that maximizes the secrecy sum-rate. Numerical results conﬁrm that our analysis is accurate even for ﬁnite M. • We derive a closed-form approximation for the optimal',\n",
       " '1811.01249': 'F EATURE selection methods have been largely studied in the literature. Usually, the main goal of feature selection is deﬁned as selecting a subset of available features to increase the prediction performance and to reduce over-ﬁtting. In real world scenarios, however, the cost of extracting or acquiring each feature is different from other features. The cost difference can be due to various factors such as differences in computational load in the extraction of features [1], [2], user disruptions in computer and user interactions [3], patient pain in medical procedures and tests [4], and so forth [5]. In these scenarios, selecting a feature that may only marginally contribute to an increase in the prediction accuracy which entails high costs would be unacceptable. In other words, there exists a trade-off between the feature cost and prediction performance that should be considered in the algorithm design. To overcome this issue, there are methods suggested in the literature trying to adapt feature selection algorithms to consider the cost of each feature [6], [7], [8], [9]. However, another point of concern that requires attention is that selecting a ﬁxed set of features to be used during the training phase and using them at test-time would not be an optimal solution; as it neglects the potential interdependence between features. Authors are with the UCLA Department of Computer Science. Address: UCLA Computer Science Dept., #391 Eng. VI, 404 Westwood Plaza, CA 90095, USA (Email: mkachuee@cs.ucla.edu). In many scenarios, there are features that are either freely available or easy to acquire at test-time. An optimal decision about other features to include in the analysis can be highly dependent on them. For instance, a doctor decides whether to prescribe an MRI scan based on the patient’s current available information such as age, gender, symptoms and so on. In this example, having a ﬁxed list of required tests and asking patients to provide the results of these tests for a clinical visit, would result in the high cost of MRI for all patients. In other words, the decision to include each feature should be based on the learned system dynamics as well as the available information at test-time. In this paper, we suggest a novel approach for feature acquisition considering costs at test-time (FACT). The proposed solution is capable of incrementally asking for features to be included in the prediction based on the current available context and user-deﬁned feature costs. The rest of the paper is organized as follows. Section II brieﬂy reviews the current relevant literature. Section III introduces the suggested approach including theoretical and implementation details. Section IV presents the results of using the suggested method and compares them with the state-of-the-art approaches in the literature. Finally, Section VI concludes the paper. II. RELATED WORK One of the approaches to incorporate feature acquisition costs or feature costs in general is considering the feature costs during the training phase and trading off',\n",
       " '1810.09660': 'Recent rapid advances in camera technology, computing power and application areas in robotics and autonomous vehicles have resulted in a surge in Visual Place Recognition research [2], [3], [4], a key enabling component of many localization and SLAM systems. Much recent research has focused on the key challenges of deploying these techniques reliably on mobile robots, drones and autonomous vehicles, including being robust to varying environmental conditions and camera viewpoints. Much of the current research has focused primarily on improving standard metrics such as precision and recall on benchmark datasets, while storage and computational requirements, especially with respect to their scalability, have not been as thoroughly investigated. As the size of the deployment area for a drone, autonomous vehicle or mobile robot increases, so too does the storage and compute size if performance is to be maintained: this increase is typically at least linear with the size of The authors are with the School of Electrical Engineering and Computer Science, Queensland University of Technology, Brisbane, Australia. MM is also with the Australian Centre for Robotic Vision. This work was supported by an Asian Ofﬁce of Aerospace Research and Development Grant FA238616-1-4027 and an ARC Future Fellowship FT140101229 to MM. Email: {huu.le, michael.milford}@qut.edu.au ... ... ... ... Fig. 1. Overview of our sub-linear encoding system. Left: Each frame in the sequence is represented by a feature vector. The pattern learning mechanism in our system automatically learns the most relevant information that represents the multiple periodic patterns detected in the data, which are then used to train the encoding system. Right: Our new system (blue) achieves signiﬁcant improvements in both sub-linear storage scaling and absolute storage requirements over the previous state-of-the-art method proposed in [1] (red) while maintaining recognition performance and improving robustness to changing conditions and customizability to user requirements. the environment in current approaches. While the absolute capability of compute and storage technology continues to improve, efﬁcient algorithmic implementations are always desirable [5], as they provide the option to encode more or richer data, perform more extensive computation and deploy on cheaper, more compact and lower power consumption computational hardware. One unorthodox but promising area of inspiration for efﬁcient visual place recognition algorithms is biology. In 2004 neuroscientists discovered a new type of spatial mapping cell called a grid cell [6], which appeared to defy robotic mapping convention. Each grid cell ﬁred when the rat was at any one of a near unlimited number of physical locations at the vertices of a regular tesselating triangular grid over the environment. Multiple map scales were encoded in parallel, leading neuroscientists and mathematicians to posit a range of theories [7], [8] around their function including noise rejection and efﬁcient computation. One of the ﬁrst studies [1] to develop a robot-deployable version of these theories proposed a novel encoding scheme that mimicked the deliberate aliasing of place to map associations, demonstrating for the ﬁrst time sub-linear map storage growth with environment size',\n",
       " '1407.2921': 'Polar codes provably achieve the symmetric channel capacity as the code length N increases, when they are decoded with the low-complexity successive-cancellation (SC) decoding algorithm [1]. However, the error-correction performance of SC decoding of polar codes at moderate lengths is mediocre. List [2] and stack decoding [3] have been proposed to improve the error-correction performance without increasing code length. To further improve the error-correction capability of polar codes, various concatenation schemes have been proposed [4]– [6]. The most successful one is a serial concatenation of a polar code (PC) with a cyclic redundancy check (CRC) code, where the latter is used as an outer code [4]. For a given length N, the resulting code is shown to match or exceed the error-correction performance of turbo [5] as well as low-density parity-check (LDPC) codes [4]. The throughput of SC decoders is low due to the serial nature of the algorithm. This issue was resolved by the simpliﬁed successive cancellation (SSC) [7] and the FastSSC [8] decoding algorithms. The latter of which has fast hardware [8] and software decoders [9]. Since list decoders are dependent on SC decoders as their major components, their throughput is also very low and they would beneﬁt from improvements to the SC decoders. However, the SSC-based algorithms are not directly applicable to list, and list-CRC, decoding because they present a single estimate of codewords; whereas list decoders require multiple candidates with softvalued reliabilities. G. Sarkis, P. Giard, and W. J. Gross are with the Department of Electrical and Computer Engineering, McGill University, Montr´eal, Qu´ebec, Canada (email: {gabi.sarkis, pascal.giard}@mail.mcgill.ca, warren.gross@mcgill.ca). A. Vardy is with the Department of Electrical Engineering, University of California San Diego, La Jolla, CA. USA (e-mail: avardy@ucsd.edu). C. Thibeault is with the Department of Electrical Engineering, ´Ecole de technologie sup´erieure, Montr´eal, Qu´ebec, Canada (e-mail: claude.thibeault@etsmtl.ca). u0 + x0 W y0 u1 x1 W y1 (a) N = 2 u0 + v0 + x0 W y0 u1 v1 + x1 W y1 u2 + v2 x2 W y2 u3 v3 x3 W y3 (b) N = 4 Fig. 1: Construction of polar codes of lengths 2 and 4 In this work, we modify the SSC algorithm to present multiple candidate codewords using a Chase-decoding-like process and we present SSC-based list decoders that oﬀer higher throughput (average decoding speed) and lower latency (worst case decoding time) than their SC-based counterpart. It was shown in [9] that, for software implementations, polar decoders were faster than LDPC decoders with equivalent error-correction performance despite the longer lengths required for polar codes. In this work we show that software list polar decoders are faster than equivalent-performance LDPC decoders at the same code lengths. We start with a review of polar codes, list and list-CRC decoding, and SSC decoding in Section II. We present our',\n",
       " '1810.13098': 'Deep convolutional neural networks (CNNs) have advanced to show the state-of-the-art performance in image processing and computer vision applications [1, 2, 3]. However, the huge storage cost of the trainable parameters severely limits its deployment in practice, especially on resource-limited platforms such as smart-phones and wearable devices. For example, the AlexNet Caffemodel is over 200MB and the VGG16 Caffemodel is over 500MB [4]. Thence, how to efﬁciently compress the parameters of CNNs has become an urgent task and challenging problem. To address this problem, many methods have been proposed, including encoding, quantization and pruning [4]. In Corresponding Email: {chao.li, qibin.zhao}@riken.jp recent studies, the deep neural networks are also compressed by the tensor decomposition (TD) model, that embeds a multi-way array into a lower dimensional space [5]. TD itself shows promising results with high compression ratio with less degraded performance [6, 7, 8, 9, 10, 11]. Besides, a combination of TD and aforementioned methods, e.g., encoding and pruning, can further improve the compactness of the CNNs [12]. In early studies, TD was directly employed on the learned kernels. For example, Lebedev et al. exploited CANDECOMP/PARAFAC decomposition to compress the convolutional layers in AlexNet [6]. Similarly, Kim et al. used Tucker decomposition to speed up various CNNs [11]. More recently, more sophisticated TD models such as tensor train and tensor ring were also employed on compression, in which the kernels are tensorized into a higher-order tensors for higher compression level [13, 14]. It is worthwhile to mention that, these conventional TDbased compression methods depend on the occurrence of spatial or channel-wised linear dependence within the kernel, thus the kernel can be naturally embedded into a low-rank subspace with lower dimension. Meanwhile, such linear dependence is considered to be occasioned by the spatial similarity of the training data [15]. Such insight give rise to the following questions: Is the spatial similarity the essential cause of the low-rank structure of the kernels? In addition, how does the spatial similarity of the training data inﬂuence the low-rank structure the kernels? To attempt to answer the questions above, we remove the inﬂuence of the spatial similarity by leveraging random shufﬂing the parameters in the kernels of convolutional layer before using TD (see Section 3 for more details). The experimental results reveal an interesting phenomenon that the TD methods are able to compress CNNs effectively regardless of the random shufﬂing (see Figure 1 for example), which implies the fact that the spatial similarity of the training data is not the key factor for embedding the kernels into a low-rank subspace. Below, we ﬁrst introduce an uniﬁed model for tensor decomposition by using the framework of tensor network. Using this model, we then propose the randomly-shufﬂed tensor decomposition (RsTD) based convolutional layer, which is used for CNN compression in Section 2. After that',\n",
       " '1709.01472': 'Plant phenotyping is a growing ﬁeld that biologists have identiﬁed as a key sector for increasing plant productivity and resistance, necessary to keep up with the expanding global demand for food. Computer vision and machine learning are important tools to help loosen the bottleneck in phenotyping formed by the proliferation of data generating systems without all the necessary image analysis tools [22]. The number of leaves of a plant is considered one of the key phenotypic metrics related to its development and growth stages [28, 30], ﬂowering time [18] and yield potential. Automated leaf counting based on imaging is a difﬁcult task. Leaves vary in shape and scale, they can be difﬁcult to distinguish and are often occluded. Moreover, a plant is a dynamic object with leaves shifting, rotating and growing between frames which can be challenging to computer vision counting approaches [22]. From a machine learning perspective, counting the number of leaves can be addressed in two different ways: (i) obtaining a per-leaf segmentation, which automatically leads to the number of leaves in a rosette [24, 26, 27]; or (ii) learning a direct image-to-count regressor model [11, 23]. Deep learning approaches in this ﬁeld show impressive results in obtaining leaf count as a result of per-leaf segmentation, but they require individual leaf annotations as training data, which are difﬁcult and laborious to produce. In fact, regression approaches leverage this issue by using the total leaf count in plants as its only supervision information [24, 26]. There are few annotated datasets for rosette plants [3, 5, 21] which is a limitation when trying to implement deep learning approaches for plant phenotyping problems [29] or for ﬁeld of phenotyping in general [20]. In this paper, we propose a deep learning model for leaf counting in rosette plants on top-down view images. The backbone of the model is a modiﬁed Resnet50 deep residual network [14] pre-trained on the ImageNet dataset (c.f. Figure 1). The network is ﬁne-tuned on one or more datasets and provides as output a leaf count. To boost deep learning performance to learn despite being provided with small datasets, we found that pooling data from different sources and even different species (and cultivars) for the purposes of training improves leaf prediction accuracy. Our method treats leaf counting as a direct regression problem, therefore it only requires the total leaf count of each image as annotation. We evaluate our approach on datasets provided in the Leaf Counting Challenge (LCC) held as part of the Computer Vision Problems in Plant Phenotyping (CVPPP 2017) workshop. The datasets consist of top-down images of single plants of Arabidopsis (A1, A2, A4) and tobacco (A3) plants collected from a variety of imaging setups and labs. In this challenge, there was also a “wild” test dataset (A5) which combines test images from all the other datasets in order to assess the generalization capabilities of machine 4321',\n",
       " '1703.08524': 'E VENT sequences are becoming increasingly available in a variety of applications. Such event sequences, which are asynchronously generated with random timestamps, are ubiquitous in areas such as e-commerce, social networks, electronic health data, and equipment failures. The event data can carry rich information not only about the event attribute (e.g., type, participator) but also the timestamp {zi, ti}N i=1 indicating when the event takes place. A major line of research [1] has been devoted to studying event sequence, especially exploring the timestamp information to model the underlying dynamics of the system, whereby point process has been a powerful and elegant framework in this direction. Being treated as a random variable when the event is stochastically generated in an asynchronous manner, the timestamp makes the event sequence of point processes fundamentally different from the time series [2] evenlysampled from continuous signals because the asynchronous timestamps reﬂect the network dynamic while the time for time-series is deterministic.. • S. Xiao and X. Yang are with the Department of Electrical Engineering, Shanghai Jiao Tong University, China. E-mail: benjaminforever@sjtu.edu.cn, xkyang@sjtu.edu.cn • J. Yan (correspondence author) is with the Department of Electrical Engineering, Shanghai Jiao Tong University, China. He is also secondarily afﬁliated with IBM Research - China. E-mail: yanesta13@163.com • M. Farajtabar, H. Zha and L. Song are with School of Computational Science and Engineering, College of Computing, Georgia Institute of Technology, Atlanta, Georgia, 30332, USA. E-mail: mehrdad@gatech.edu,{zha,lsong}@cc.gatech.edu However these time series data, when available, provide timely updates of background environment where events occur in the temporal point process, such as temperature for computing servers or blood pressure for patients. Many complex systems posses such time series data regularly recorded along with the point processes data. While there have been many recent works on modeling continuous-time point processes [3], [4], [5], [6], [7] and time series [8], [9], [10], most of them treat these two processes independently and separately, ignoring the inﬂuence one may have on the other over time. To better understand the dynamics of point processes, there is an urgent need for joint models of the two processes, which are largely inexistent to date. There are related efforts in linking the time series and event sequence to each other. In fact, one popular way to convert a time series to an event sequence is by detecting multiple events (e.g., based on thresholding the stock price series [11]) from the series data. On the other hand, statistical aggregation (e.g., total number of counts) is often performed on each time interval with equal length to extract aligned time series data from the event sequences. However such a coarse treatment can lead to the key information loss about the actual behavior of the process, or at least in a too early stage. Recent progresses on modeling point process includes mathematical reformulations and optimization techniques [5], [12], [13], [14',\n",
       " '1503.08155': 'The explosive growth in the number of web pages has drawn much attention to the study of information extraction [Sarawagi, 2008] in recent decades. The aim of this is to distill unstructured online texts, so that we can store and exploit the distilled information as structured knowledge. Thanks to the long-term efforts made by experts, crowdsouring and even machine learning techniques, several web-scale knowledge repositories have been built, such as Wordnet1, Freebase2 and NELL3, and most of them contain tens of millions of extracted beliefs which are commonly represented by triplets, i.e. ⟨head entity, relation, tail entity⟩. Although we have gathered colossal quantities of beliefs, state of the art work in the literature [West et al., 2014] reported that in this ﬁeld, our knowledge bases 1http://wordnet.princeton.edu/ 2https://www.freebase.com/ 3http://rtw.ml.cmu.edu/rtw/ are far from complete. For instance, nearly 97% persons in Freebase have unknown parents. To populate incomplete knowledge repositories, a large proportion of researchers follow the classical approach by extracting knowledge from texts [Zhou et al., 2005; Bach and Badaskar, 2007; Mintz et al., 2009]. For example, they explore ideal approaches that can automatically generate a precise belief like ⟨Madrid, capital city of, Spain⟩from the sentence “Madrid is the capital and largest city of Spain.”4 on the web. However, even cutting-edge research [Fan et al., 2014] could not satisfy the demand of web-scale deployment, due to the diversiﬁcation of natural language expression. Moreover, many implicit relations between two entities which are not recorded by web texts still need to be mined. Therefore, some recent studies focus on inferring undiscovered beliefs based on the knowledge base itself without using extra web texts. One representative idea is to consider the whole repository as a graph where entities are nodes and relations are edges. The canonical approaches [Quinlan and Cameron-Jones, 1993; Lao and Cohen, 2010; Lao et al., 2011; Gardner et al., 2013] generally conduct relationspeciﬁc random walk inference based on the local connectivity patterns learnt from the imperfect knowledge graph. An alternative paradigm aims to perform open-relation inference via embedding all the elements, including entities and relations, into low-dimensional vector spaces. The proposed methods [Sutskever et al., 2009; Jenatton et al., 2012; Bordes et al., 2011; Bordes et al., 2013; Socher et al., 2013; Wang et al., 2014] show promising performance, however, by means of learning from ground-truth training knowledge. This paper thus contributes a probabilistic knowledge embedding model called IIKE5 to measure the probability of each triplet, i.e. ⟨h, r, t⟩, and our objective is to learn a better low-dimensional vector representation for each entity (h and t) and relation (r) in the process of minimizing the loss of ﬁtting the corresponding conﬁdence given by machine learning (NELL) or crowdsouring (Freebase). To the best of our knowledge, IIKE is the ﬁrst approach',\n",
       " '1612.00410': 'We adopt an information theoretic view of deep networks. We regard the internal representation of some intermediate layer as a stochastic encoding Z of the input source X, deﬁned by a parametric encoder p(z|x; θ).1 Our goal is to learn an encoding that is maximally informative about our target Y , measured by the mutual information between our encoding and the target I(Z, Y ; θ), where I(Z, Y ; θ) = Z dx dy p(z, y|θ) log p(z, y|θ) p(z|θ)p(y|θ).2 (1) Given the data processing inequality, and the invariance of the mutual information to reparameterizations, if this was our only objective we could always ensure a maximally informative representation by taking the identity encoding of our data (Z = X), but this is not a useful representation of our data. Instead we would like to ﬁnd the best representation we can obtain subject to a constraint on its complexity. A natural and useful constraint to apply is on the mutual information between our encoding and the original data, I(X, Z) ≤Ic, where Ic is the information constraint. This suggests the objective: max θ I(Z, Y ; θ) s.t. I(X, Z; θ) ≤Ic . (2) Equivalently, with the introduction of a Lagrange multiplier β, we can maximize the objective function RIB(θ) = I(Z, Y ; θ) −βI(Z, X; θ). (3) Here our goal is to learn an encoding Z that is maximally expressive about Y while being maximally compressive about X, where β ≥0 controls the tradeoff.3 This approach is known as the information bottleneck (IB), and was ﬁrst proposed in Tishby et al. (1999). Intuitively, the ﬁrst term in RIB encourages Z to be predictive of Y ; the second term encourages Z to “forget” X. Essentially it forces Z to act like a minimal sufﬁcient statistic of X for predicting Y . The IB principle is appealing, since it deﬁnes what we mean by a good representation, in terms of the fundamental tradeoff between having a concise representation and one with good predictive power (Tishby & Zaslavsky, 2015a). The main drawback of the IB principle is that computing mutual information is, in general, computationally challenging. There are two notable exceptions: the ﬁrst 1 In this work, X, Y, Z are random variables, x, y, z and x, y, z are instances of random variables, and F(·; θ) and f(·; θ) are functionals or functions parameterized by θ. 2 Note that in the present discussion, Y is the ground truth label which is independent of our parameters so p(y|θ) = p(y). 3 Note that, in our notation, large β results in a highly compressed representation. In some works, the IB principle is formulated as the minimization of I(Z, X) −βI(Z, Y ), in which case large β corresponds to high mutual information between Z and Y , and hence low compression. 1 arXiv:1612.00410v7  [cs.LG]  23 Oct 2019  Published a',\n",
       " '1105.5853': 'Suppose x ∈Rn is a sparse vector, meaning its number of nonzero entries k is smaller than n. The support of x is the locations of the nonzero entries and is sometimes called its sparsity pattern. A common sparse estimation problem is to infer the sparsity pattern of x from linear measurements of the form y = Ax + w, (1) where A ∈Rm×n is a known measurement matrix, y ∈Rm represents a vector of measurements and w ∈Rm is a vector of measurement errors (noise). Sparsity pattern detection and related sparse estimation problems are classical problems in nonlinear signal processing and arise in a variety of applications including wavelet-based image processing [1] and statistical model selection in linear regression [2]. There has also been considerable recent interest in sparsity pattern detection in the context of compressed sensing, which focuses on large random measurement matrices A [3]–[5]. It is this scenario with random measurements that will be analyzed here. Optimal subset recovery is NP-hard [6] and usually involves searches over all the \\x00n k \\x01 possible support sets of x. Thus, most This work was supported in part by a University of California President’s Postdoctoral Fellowship. The material in this paper was presented in part at the Conference on Neural Information Processing Systems, Vancouver, BC, Canada, December 2009. A. K. Fletcher (email: alyson@eecs.berkeley.edu) is with the Department of Electrical Engineering and Computer Sciences, University of California, Berkeley. S. Rangan (email: srangan@poly.edu) is with the Polytechnic Institute of New York University, Brooklyn, NY. attention has focused on approximate methods. One simple and popular approximate algorithm is orthogonal matching pursuit (OMP) [7]–[9]. OMP is a greedy method that identiﬁes the location of one nonzero entry of x at a time. A version of the algorithm will be described in detail below in Section II. The best known analysis of the detection performance of OMP for large random matrices is due to Tropp and Gilbert [10], [11]. Among other results, Tropp and Gilbert show that when A has i.i.d. Gaussian entries, the measurements are noise-free (w = 0), and the number of measurements scales as m ≥(1 + δ)4k log(n) (2) for some δ > 0, the OMP method will recover the correct sparse pattern of x with a probability that approaches one as n and k →∞. The analysis uses a deterministic sufﬁcient condition for success on the matrix A based on a greedy selection ratio introduced in [12]. A similar deterministic condition on A was presented in [13], and a condition using the restricted isometry property was given in [14]. Numerical experiments reported in [10] suggest that a smaller number of measurements than (2) may be sufﬁcient for asymptotic recovery with OMP. Speciﬁcally, the experiments suggest that the constant 4 can be reduced to 2. Our main result, Theorem 1 below, does a bit better than proving this conjecture. We show that the scaling in measurements m ≥(1 + δ)2k log',\n",
       " '1507.07267': 'Federal Communications Commission (FCC) and the National Telecommunications and Information Administration (NTIA) studies show very low utilization of huge chunks of spectrum held by the federal agencies, especially in urban areas. Meanwhile, there is a very heavy utilization of spectrum held by commercial operators, e.g. cellular operators, in these urban areas. President’s Council of Advisors on Science and Technology (PCAST) recommendations in order to efﬁciently utilize federal spectrum are to share federal spectrum with commercial operators [1]. The sharing will result in enormous economic and social advances for the nation. Meanwhile, this sharing should not endanger the main mission of federal incumbents, e.g. sharing radar spectrum should not affect its target tracking capabilities. Therefore, new approaches should be developed with these considerations in mind. A recent report by NTIA [2] concluded that sharing radar spectrum with WiMAX requires huge exclusion zones up to tens of kilometers to protect the WiMAX receivers from harmful interference signal transmitted by radar. This is due to WiMAX receivers are designed to handle low power levels in the range of Watts while the power transmitted by radar is in the range of Kilo and Mega Watts. This includes shipborne radars that are deployed on military ships on the east and west coasts of the United States. Which in turn results in depriving these areas, i.e. where the majority of the US population live, from the beneﬁts of sharing radar spectrum. On the other hand, within the cellular system, interference is a major obstacle against achieving the spectral efﬁciency expected from developed multiple-antenna techniques [3]. It is shown in [4], [5] that multiple-input multiple-output (MIMO) capacity gains are deteriorated due to inter-cellular interference. In a radar/cellular coexistence scenario, radar receivers have highly sensitive receivers for detecting reﬂected signals from far targets. Therefore, it is highly susceptible to interference from commercial wireless system operating on radar bands. In the past, radar has been guaranteed exclusive rights to radio spectrum allocation to avoid its operation from being affected by commercial wireless systems interference [2], [6]. Therefore, a radar/cellular network-level interference management is of fundamental importance to sustain the radar/cellular coexistence along with limiting inter-cellular interference and harnessing the advantages of cellular MIMO technology. To address the aforementioned challenges, we propose a novel coexistence scenario and model between radar and cellular system. In this model, the radar signal is steered to null-space plus small singular values space of the interference channel between the radar and cellular system. The approach beneﬁts both radar and cellular systems. On the radar side, it will increase the projection space dimensions and therefore radar performance metrics are improved compared to projection with smaller dimensions, e.g. null space projection [7], see [8] for more details. On the cellular side, this approach suppresses the high power of radar in the direction of cellular network so it does not burn out the cellular receivers. In addition, the transmitted radar signal',\n",
       " '1710.05941': 'At the heart of every deep network lies a linear transformation followed by an activation function f(·). The activation function plays a major role in the success of training deep neural networks. Currently, the most successful and widely-used activation function is the Rectiﬁed Linear Unit (ReLU) (Hahnloser et al., 2000; Jarrett et al., 2009; Nair & Hinton, 2010), deﬁned as f(x) = max(x, 0). The use of ReLUs was a breakthrough that enabled the fully supervised training of state-of-the-art deep networks (Krizhevsky et al., 2012). Deep networks with ReLUs are more easily optimized than networks with sigmoid or tanh units, because gradients are able to ﬂow when the input to the ReLU function is positive. Thanks to its simplicity and effectiveness, ReLU has become the default activation function used across the deep learning community. While numerous activation functions have been proposed to replace ReLU (Maas et al., 2013; He et al., 2015; Clevert et al., 2015; Klambauer et al., 2017), none have managed to gain the widespread adoption that ReLU enjoys. Many practitioners have favored the simplicity and reliability of ReLU because the performance improvements of the other activation functions tend to be inconsistent across different models and datasets. The activation functions proposed to replace ReLU were hand-designed to ﬁt properties deemed to be important. However, the use of search techniques to automate the discovery of traditionally human-designed components has recently shown to be extremely effective (Zoph & Le, 2016; Bello et al., 2017; Zoph et al., 2017). For example, Zoph et al. (2017) used reinforcement learningbased search to ﬁnd a replicable convolutional cell that outperforms human-designed architectures on ImageNet. In this work, we use automated search techniques to discover novel activation functions. We focus on ﬁnding new scalar activation functions, which take in as input a scalar and output a scalar, because scalar activation functions can be used to replace the ReLU function without changing the network architecture. Using a combination of exhaustive and reinforcement learning-based search, we ﬁnd a number of novel activation functions that show promising performance. To further validate the ∗Work done as a member of the Google Brain Residency program (g.co/brainresidency). 1 arXiv:1710.05941v2  [cs.NE]  27 Oct 2017  effectiveness of using searches to discover scalar activation functions, we empirically evaluate the best discovered activation function. The best discovered activation function, which we call Swish, is f(x) = x · sigmoid(βx), where β is a constant or trainable parameter. Our extensive experiments show that Swish consistently matches or outperforms ReLU on deep networks applied to a variety of challenging domains such as image classiﬁcation and machine translation. On ImageNet, replacing ReLUs with Swish units improves top-1 classiﬁcation accuracy by 0.9% on Mobile NASNet-A (Zoph et al., 2017) and 0.6% on Inception-ResNet-v2 (Szegedy et al., 2017). These accuracy gains are signiﬁcant given that one year of architectural tuning and enlarging yielded 1.3% accuracy improvement going from Inception V3 (Szegedy et al',\n",
       " '1112.5309': '3 1.1 Basic Ideas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 1.2 Outline of Remainder . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 2 Notation & Algorithmic Framework POWERPLAY (Variant I) 5 3 TASK INVENTION, SOLVER MODIFICATION, CORRECTNESS DEMO 5 3.1 Implementing TASK INVENTION . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 3.1.1 Example: Pattern Recognition Tasks . . . . . . . . . . . . . . . . . . . . . . . . . 6 3.1.2 Example: General Decision Making Tasks in Dynamic Environments . . . . . . . 6 3.2 Implementing SOLVER MODIFICATION . . . . . . . . . . . . . . . . . . . . . . . . . . . 7 3.3 Implementing CORRECTNESS DEMONSTRATION . . . . . . . . . . . . . . . . . . . . . . 7 3.3.1 Most General: Proof Search . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8 3.3.2 Keeping Track Which Components of the Solver Affect Which Tasks . . . . . . . 8 3.3.3 Advantages of Preﬁx Code-Based Problem Solvers . . . . . . . . . . . . . . . . . 8 4 Implementations of POWERPLAY 9 4.1 Implementation Based on Optimal Ordered Problem Solver OOPS . . . . . . . . . . . . . 9 4.1.1 Building on Existing OOPS Source Code . . . . . . . . . . . . . . . . . . . . . . 10 4.1.2 Alternative Problem Solvers Based on Recurrent Neural Networks . . . . . . . . . 10 4.2 Adapting the Probability Distribution on Programs . . . . . . . . . . . . . . . . . . . . . 11 4.3 Implementation Based on Stochastic or Evolutionary Search . . . . . . . . . . . . . . . . 11 5 Outgrowing Trivial Tasks - Compressing Previous Solutions 11 6 Adding External Tasks 12 6.1 Self-Reference Through Novel Task Search as an External Task . . . . . . . . . . . . . . 12 7 Softening Task Acceptance Criteria of POWERPLAY 12 7.1 POWERPLAY Variant II: Explicitly Penalizing Time and Space Complexity . . . . . . . . 13 7.2 Probabilistic POWERPLAY Variants . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14 8 First Illustrative Experiments 14 9 Previous Relevant Work 14 9.1 Existing Theoretically Optimal Universal Problem Solvers . . . . . . . . . . . . . . . . . 14 9.2 Connection to Traditional Active Learning . . . . . . . . . . . . . . . . . . . . . . . . . . 15 9.3 Greedy Implementation of Aspects of the Formal Theory of Creativity . . . . . . . . . . . 15 9.4 Beyond Algorithmic Zero-Sum Games [37, 38] (1997-2002) . . . . . . . . . . . . . . . . 16 9.5 Opposing Forces: Improving Generalization Through Compression, Breaking Generalization Through Novelty . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17 9.6 Relation to G¨odel’s Sequence of Increasingly Powerful Axiomatic Systems . . . . . . . . 17 10 Words of Caution 17 11 Acknowledgments 18 2  1 Introduction Given a realistic piece of computational hardware with speciﬁc resource limitations, how can one devise software for it that will solve all, or at least many, of the a priori unknown tasks that are in principle easily solvable on this architecture? In other words, how to build a practical general problem solver, given the computational restrictions? It does not need to be universal and asymptotically optimal [17, 13, 41, 44] like the recent (not necessarily practically feasible) general problem solvers discussed in Section 9.1; instead it should take into account all constant architecture-speciﬁc slowdowns ignored in the asymptotic optimality notation of theoretical computer science, and be generally useful for real-world applications. Let us draw inspiration from biology. How do initially helpless human babies become rather general problem solvers over time? Apparently by playing. For example, even in the absence of external reward or hunger they are curious about what happens if they move their eyes or ﬁngers in particular ways, creating little experiments which lead to initially novel and surprising but eventually predictable sensory inputs, while also learning motor skills to reproduce these outcomes. (See [31, 30, 37, 42, 45, 62] and Section 9.3 for previous artiﬁcial',\n",
       " '1709.07417': 'The choice of the right optimization method plays a major role in the success of training deep learning models. Although Stochastic Gradient Descent (SGD) often works well out of the box, more advanced optimization methods such as Adam (Kingma & Ba, 2015) or Adagrad (Duchi et al., 2011) can be faster, especially for training very deep networks. Designing optimization methods for deep learning, however, is very challenging due to the non-convex nature of the optimization problems. In this paper, we consider an approach to automate the process of designing update rules for optimization methods, especially for deep learning architectures. The key insight *Equal contribution 1Google Brain. Correspondence to: Irwan Bello <ibello@google.com>, Barret Zoph <barretzoph@google.com>, Vijay Vasudevan <vrv@google.com>, Quoc V. Le <qvl@google.com>. Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017 by the author(s). Figure 1. An overview of Neural Optimizer Search. is to use a controller in the form of a recurrent network to generate an update equation for the optimizer. The recurrent network controller is trained with reinforcement learning to maximize the accuracy of a particular model architecture, being trained for a ﬁxed number of epochs with the update rule, on a held-out validation set. This process is shown in Figure 1. On CIFAR-10, our approach discovers several update rules that are better than many commonly used optimizers such as Adam, RMSProp, or SGD with and without Momentum on a small ConvNet model. Many of the generated update equations can be easily transferred to new architectures and datasets. For instance, update rules found on a small ConvNet architecture improve training of the Wide ResNet architecture (Zagoruyko & Komodakis, 2016) when compared to Adam, RMSProp, Momentum, and SGD. On ImageNet, our update rules improve top-1 and top-5 accuracy of a state-of-the-art mobile sized model (Zoph et al., 2017) by up to 0.4%. The same update rules also work well on Google’s Neural Machine Translation system (Wu et al., 2016), giving an improvement of up to 0.7 BLEU on the WMT 2014 English to German task. 2. Related Work Neural networks are difﬁcult and slow to train, and many methods have been designed to reduce this difﬁculty (e.g., Riedmiller & Braun (1992); LeCun et al. (1998); Schraudolph (2002); Martens (2010); Le et al. (2011); Duchi et al. (2011); Zeiler (2012); Martens & Sutskever (2012); Schaul et al. (2013); Pascanu & Bengio (2013); Pascanu et al. (2013); Kingma & Ba (2015); Ba et al. arXiv:1709.07417v2  [cs.AI]  22 Sep 2017  Neural Optimizer Search with Reinforcement Learning (2017)). More recent optimization methods combine insights from both stochastic and batch methods in that they use a small minibatch, similar to SGD, but implement many heuristics to estimate diagonal second-order information, similar to Hessian-free or L-BFGS (Liu & Nocedal, 1989). This combination often yields faster convergence for',\n",
       " '1802.09431': 'The spatial resolution of magnetic resonance (MR) images (MRI) is chosen based on imaging time, desired signal to noise ratio, and other factors. Ultimately, the spatial resolution is limited by the amount of k-space acquired in the Fourier domain. To facilitate faster, and therefore cheaper, MRI acquisitions, it is common for MR images to have worse through-plane resolution (slice thickness) than in-plane resolution. This means that the in-plane data has a relatively complete sampling of k-space along an appropriate axis, whereas data in the through-plane direction is bandlimited within the corresponding k-space. One common way to address the resolution mismatch between the in-plane and through-plane directions is to upsample the data to an isotropic resolution. This, however, results in images with partial volume artifacts that lead to degraded image analysis in subsequent processing. More appropriate approaches for estimating the high frequency information are known as super-resolution (SR) methods, as they are meant to enhance the spatial resolution. SR has been a well-explored technique in computer vision. Popular methods include neighbor embedding regression [1,2], random forest approaches [3,4], and state-of-the-art CNN methods such as those reported for the NTIRE 2017 Challenge [5], most of which were based on VDSR [6] or SRResNet [7] as a baseline model. EDSR [8] which was modiﬁed from SRResNet [7] had the best performance in the NTIRE 2017 Challenge. Unfortunately, all the NTIRE 2017 Challenge methods require external paired atlas images to learn the transformation from low (LR) to high resolution (HR). This is not a desirable situation for MR imaging, as training data is not generally available because: 1) scanner gain means that even data acquired on the same scanner will have a different dynamic range; 2) acquiring HR MR data is difﬁcult due to scan times, patient motion and safety; and 3) it is difﬁcult to match atlas and subject image resolutions perfectly. In contrast, exsiting single image self super-resolution (SSR) methods [9–11] downsample the LR image to create a lower resolution (LR2) image and learn the mapping from LR2 to LR; and subsequently apply the mapping to LR with the goal of approximating HR. In this paper, we build upon the work of Jog et al. [11] which had an alternative approach to SSR. Jog et al. used the fact that MR images are inherently anisotropic to learn a regression between LR and HR images. The approach generated new additional images, each of which is LR along a certain direction, but is HR in the plane normal to it. Thus, each new image contributed information to a new region of Fourier space. Then the collection of images is combined using Fourier Burst Accumulation [12]. We modify the deep network framework of EDSR [8], while incorporating the ideas of Jog et al. to provide the training data. Thus, we present a single image arXiv:1802.09431v1  [eess',\n",
       " '1301.2030': 'Multiple Input Multiple Output (MIMO) communication opens new directions and possibilities for Cognitive Radio (CR) networks [1–7]. In particular, in underlay CR networks, MIMO technology enables the SU to transmit a signiﬁcant amount of power simultaneously in the same band as the Primary User This work is supported by the ONR under grant N000140910072P00006, the AFOSR under grant FA9550-08-1-0480, and the DTRA under grant HDTRA1-08-1-0010. Yair Noam is with the Faculty of Engineering, Bar-Ilan University, Ramat-Gan, 52900, Israel. Andrea J. Goldsmith is with the Dept. of Electrical Engineering, Stanford University, Stanford CA, 940305. DRAFT  2 (PU) without interfering with it, if the SU utilizes separate spatial dimensions than the PU. This spatial separation requires that the interference channel from the SU to the PU be known to the SU. Thus, acquiring this knowledge, or operating without it, is a major topic of active research in CR [6, 8–15] and in other ﬁelds [16]. We consider MIMO primary and secondary systems deﬁned as follows: we assume a ﬂat-fading MIMO channel with one PU and one SU, as depicted in Fig. 1. Let Hps be the channel matrix between the SU’s transmitter and the PU’s receiver, hereafter referred to as the SU-Tx and PURx, respectively. In the underlay CR paradigm, SUs are constrained not to inﬂict “harmful” interference on the PU-Rx. This can be achieved if the SU restricts its signal to lie within the null space of Hps; however, this is only possible if the SU knows Hsp. The optimal power allocation in the case where the SU knows the matrix Hps in addition to its own Channel State Information (CSI) was derived by Zhang and Liang [1]. For the case of multiple SUs, Scutari at al. [3] formulated a competitive game between the secondary users. Assuming that the interference matrix to the PU is known by each SU, they derived conditions for the existence and uniqueness of a Nash Equilibrium point to the game. Zhang et al. [9] were the ﬁrst to take into consideration the fact that the interference matrix Hps may not be perfectly known (but is partially known) to the SU. They proposed robust beamforming to assure compliance with the interference constraint of the PU while maximizing the SU’s throughput. Another work on the case of an unknown interference channel with known probability distribution is due to Zhang and So [11], who optimized the SU’s throughput under a constraint on the maximum probability that the interference to the PU is above a threshold. The underlay concept of CR in general, and MIMO CR in particular, is that the SU must be able to mitigate the interference to the PU blindly without any cooperation. Zhang [6] was the ﬁrst to propose a blind solution where the MIMO SU mitigates interference to the PU by null space learning. This work was followed by Yi [13], Chen et al. [12], and Gao',\n",
       " '1601.07576': 'H UMAN has a remarkable ability to categorize complex scenes very accurately and rapidly. This ability is imThis work is partly supported by National High-Tech Research and Development Program of China (2016YFC1400704), National Natural Science Foundation of China (61503367), Guangdong Research Program (2014B050505017,2015B010129013,2015A030310289), External Cooperation Program of BIC Chinese Academy of Sciences (172644KYSB20150019), and Shenzhen Research Program (JSGG20150925164740726, JCYJ20150925 163005055, CXZZ20150930104115529). S. Guo is with Shenzhen College of Advanced Technology, University of Chinese Academy of Sciences, and is with Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China (email:guosheng1001@gmail.com) W. Huang is with Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China, (e-mail: wl.huang@siat.ac.cn) L. Wang was with Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China, and is with Computer Vision Laboratory, ETH Zurich, Switzerland, (e-mail: 07wanglimin@gmail.com) Y. Qiao is with Shenzhen Key Lab of Computer Vision and Pattern Recognition, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China, and is with Department of Information Engineering, The Chinese University of Hong Kong (e-mail: yu.qiao@siat.ac.cn) category (left) category (right) FC-Fea. Conv.-Fea. Both auditorium movietheater 38.9 22.2 11.1 bookstore library 25.0 10.0 5.0 elevator corridor 9.5 4.8 4.8 livingroom bedroom 15.0 10.0 0.0 gym dentaloffice 11.1 5.6 0.0 jewelleryshop shoeshop 9.1 4.6 0.0 Fig. 1. Top Figure: category pairs with similar global layouts, which are difﬁcult to be discriminated by purely using high-level fully-connected features (FC-features). The category names are listed in the bottom table. Bottom Table: classiﬁcation errors (%) between paired categories by using the convolutional features, FC-features, or both of them. portant for human to infer the current situations and navigate the environments [1]. Computer scene recognition and understanding aims at imitating this human ability by using algorithms to analyze input images. This is a fundamental problem in computer vision, and plays a crucial role on the success of numerous application areas like image retrieval, human machine interaction, autonomous driving, etc. The difﬁculties of scene recognition come from several aspects. Firstly, scene categories are deﬁned not only by various image contents they contain, such as local objects and background environments, but also by global arrangements, interactions or actions between them, such as eating in restaurants, reading in library, watching in cinema. These cause a large diversity of the scene contents which imposes a huge number of scene categories and large within-class variations. These make it much more challenging than the task of object classiﬁcation. Furthermore, scene images often include numerous ﬁne-grained categories which exhibit very similar contents and structures, as shown in Fig. 1. These ﬁnearXiv:1601.07576v2  [cs.CV]  15 Dec 2016  2 grained categories are hard to be discriminated by purely using the high',\n",
       " '1802.08760': 'The empirical success of deep learning has thus far eluded interpretation through existing lenses of computational complexity (Blum & Rivest, 1988), numerical optimization (Choromanska et al., 2015; Goodfellow & Vinyals, 2014; Dauphin et al., 2014) and classical statistical learning theory (Zhang et al., 2016): neural networks are highly non-convex models with extreme capacity that train fast and generalize well. In fact, not only do large networks demonstrate good test performance, but larger networks often generalize better, counter to what would be expected from classical measures, such as VC dimension. This phenomenon has been observed in targeted experiments (Neyshabur et al., 2015), historical trends of Deep Learning competitions (Canziani et al., 2016), and in the course of this work (Figure 1). This observation is at odds with Occam’s razor, the principle of parsimony, as applied to the intuitive notion of function complexity (see §A.2 for extended discussion). One resolution of the apparent contradiction is to examine complexity of functions in conjunction with the input domain. f(x) = x3 sin(x) may seem decisively more complex than g(x) = x. But restrained to a narrow input domain of [−0.01, 0.01] they appear differently: g remains a linear function of the input, while f(x) = O \\x00x4\\x01 resembles a constant 0. In this work we ﬁnd that such intuition applies to neural networks, that behave very differently close to the data manifold than away from it (§4.1). We therefore analyze the complexity of models through their capacity to distinguish different inputs in the neighborhood of datapoints, or, in other words, their sensitivity. We study two simple metrics presented in §3 and ﬁnd that one of them, the norm of the input-output Jacobian, correlates with generalization in a very wide variety of scenarios. ∗Work done as a member of the Google Brain Residency program (g.co/brainresidency) 1 arXiv:1802.08760v3  [stat.ML]  18 Jun 2018  Published as a conference paper at ICLR 2018 100k 1M 10M 100M 1B 0.4 0.6 0.8 Number of weights Generalization gap 1p 1n 1μ 0.001 0.4 0.6 0.8 Train loss Figure 1: 2160 networks trained to 100% training accuracy on CIFAR10 (see §A.5.5 for experimental details). Left: while increasing capacity of the model allows for overﬁtting (top), very few models do, and a model with the maximum parameter count yields the best generalization (bottom right). Right: train loss does not correlate well with generalization, and the best model (minimum along the y-axis) has training loss many orders of magnitude higher than models that generalize worse (left). This observation rules out underﬁtting as the reason for poor generalization in low-capacity models. See (Neyshabur et al., 2015) for similar ﬁndings in the case of achievable 0 training loss. This work considers sensitivity only in the context of image classiﬁcation tasks. We interpret the observed correlation with generalization as an expression of a universal prior on (natural) image classiﬁcation functions that favor robustness (see',\n",
       " '1808.06560': 'To model and understand complex systems, we must consider how different entities within a system relate to one another. Many such relational data sets provide multiple views of the same underlying set of entities. For example, a group of people can be characterized by their interactions with one another on a social networking platform. As a ﬁrst approximation, we can consider only whether a relationship exists between two people on this platform. However, we can also study their interactions across other platforms, or across the different modes of communications provided by the platform [1], which provide us multiple views of the relationships between the same group of people. Other examples of multi-view data sets include multi-omics measurements in single cell RNA sequencing data [2] and 2D projections of a single 3D object captured from multiple angles for 3D reconstruction [3]. Graphs are used extensively to model this type of relational data for machine learning tasks, where the nodes or vertices of the graph represent the entities studied in the data set and edges represent their relationships. By learning a vector for This work was supported by the US National Science Foundation (NSF) grants CCF-1319653 and CCF-1553075. each node in the graph, we can create a graph embedding, which gives the entities in the data set a representation in Euclidean space. These embeddings can be used for various applications such as data visualization, clustering, and link prediction. There are several well-known algorithms for creating graph embeddings from a single-view graph. The extension to multi-view or multi-layer graphs, however, has not been well studied up to this point. Providing more views leads to improved accuracy in clustering and embedding. This has increased recent interest in developing efﬁcient multiview graph embedding methods. In a multi-view graph embedding, each node is assigned a vector that incorporates data from all views of the graph. Simple methods to create multi-view embeddings include combining multiple views of the graph into one graph using an AND/OR aggregation of the edge sets and embedding the resulting single graph, or embedding each view independently and concatenating the different embeddings obtained for each node [4]. More sophisticated algorithms have been developed based on matrix factorization [5], [6], tensor factorization [7], [8], and spectral embedding [9]–[11]. Many of these algorithms focus on clustering multi-view graphs, a speciﬁc application thereof. High clustering accuracy indicates a good embedding since relative similarity between nodes should be correctly reﬂected in the embedding. The similarity between nodes of a graph can be quantiﬁed by a distance measure, such as the shortest path or geodesic distance (number of edges in the shortest path connecting two nodes) or the commute time distance (expected number of edges in a random walk from one node to the other and back). If two nodes are similar, then they are likely to have a shorter distance between them. Ideally, graph embeddings should preserve the distances between',\n",
       " '1612.00628': 'Exploiting the spatial dimension of the wireless channel through multiuser-multiantenna techniques has become an inevitable necessity to meet the requirements of future wireless networks. It is well established that achieving such spatialmultiplexing gains is highly dependent on the availability of accurate Channel State Information at the Transmitter (CSIT) [1], [2]. Since highly accurate CSIT is not always guaranteed, initial studies and deployments strived to apply multiantenna schemes that assume perfect CSIT to scenarios with partial CSIT [3]. However, recent breakthroughs in the study of Degrees of Freedom (DoF) unveiled that such approach is fundamentally ﬂawed as it fails to achieve the informationtheoretic limits of the channels [4], [5]. On the other hand, insights drawn from such fundamental works have proved very promising for the design of future wireless networks [6]. The ability to simultaneously support a tremendous number of devices with heterogeneous demands and capabilities is amongst the various features envisioned for future wireless networks [7]. Hence, it is expected that many networks will operate in overloaded regimes, roughly described as scenarios where the number of messages exceeds the number of transmitting antennas. One fundamental example is captured by the Single-Input-Single-Output (SISO) Broadcast Channel (BC), widely studied in literature. However, insights drawn from such studies are deemed insufﬁcient when considering multiple antennas, as the SISO BC is robust against CSIT inaccuracies due to its degraded nature. On the other hand, the study of overloaded multiantenna channels is uncommon, e.g. works on the Multiple-Input-Single-Output (MISO) BC 1This work has been partially supported by the EPSRC of UK, under grant EP/N015312/1. with imperfect CSIT consider a number of users less or equal to the number of transmitting antennas [1], [2], [4], [5]. A. An overloaded MISO BC with heterogeneous partial CSIT In this work, we make progress towards understanding the fundamental limits of overloaded multiantenna networks with heterogeneous partial CSIT. We consider a MISO BC comprising a transmitter equipped with M antennas, and K > M single-antenna receivers (or users) indexed by K = {1, . . ., K}. As in [4], [5], partial instantaneous CSIT is captured by allowing the k-th user’s CSIT error variance to decay with the Signal to Noise Ratio (SNR) P as O(P −αk) for some exponent αk ∈[0, 1] that represents the CSIT quality. It is well understood that αk = 0 and αk = 1 correspond to no-CSIT and perfect CSIT in a DoF sense, respectively. While a general heterogeneous setup assumes arbitrary CSIT qualities, we restrict the analysis to the case where partial CSIT for M of the K users is available (αk > 0), while noCSIT is available for the remaining K −M users (αk = 0)2. We further simplify the analysis by considering a symmetric scenario where all users with partial CSIT have the same quality α. Such setup is sufﬁcient to gain some insight into the structure of the DoF-optimum transmission scheme and the inﬂuence of heterogeneous partial CSIT',\n",
       " '1807.10584': 'Colon cancer prevention is currently primarily done with the help of regular colonoscopy screenings. However, depending on the size and type, roughly 8 −37% of polyps are missed during the process [1]. Missed polyps can have fatal consequences, as they are potential precursors to colon cancer, which causes the third most cancer deaths globally [2]. Hence, increasing the detection rate of polyps is an important topic of research. Towards this end, automated detection procedures have been proposed [3, 4], which have the advantage of not being inﬂuenced by factors such as the fatigue of medical personnel towards the end of long operations. However, they present additional novel challenges. For instance, This work is partially funded by the Norwegian Research Council FRIPRO grant no. 239844 on developing the Next Generation Learning Machines. *Corresponding author: kwi030@uit.no to enable effective use of such methods, medical staff should be able to understand why the model believes that a speciﬁc region contains a polyp (interpretability) and there should be some notion of uncertainty in predictions. The last couple of years have seen several works on automatic procedures based on Deep Convolutional Neural Networks (CNN) for health domain tasks such as interstitial lung disease classiﬁcation [5], cell detection [6], estimation of cardiothoracic ratio [7], and polyp detection [8]. CNNs have improved the state of the art in a number of computer vision tasks such as image classiﬁcation [9], object detection [10] and semantic segmentation [11, 12]. Recently, CNNs have shown promising performance for the task of polyp segmentation [2]. However, despite the promising results obtained on polyp segmentation, model interpretability and uncertainty quantiﬁcation have been lacking, and recent advances in deep learning have not been incorporated [2]. In this paper, we enhance and evaluate two recent CNN architectures for pixel-to-pixel based segmentation of colorectal polyps, referred to as Fully Convolutional Networks (FCNs). Furthermore, we incorporate and develop recent advances in the ﬁeld of deep learning for semantic segmentation of colorectal polyps in order to model uncertainty and increase model interpretability leading to novel uncertainty maps [13, 14] in a polyp segmentation context as well as the visualization of descriptive regions in the input image using Guided Backpropagation [15]. To the author’s knowledge, these techniques have not been previously explored in the ﬁeld of semantic segmentation of colorectal polyps. 2. ENHANCED FULLY CONVOLUTIONAL NETWORKS FOR POLYP SEGMENTATION We choose two architectures for the task of polyp segmentation, namely the Fully Convolutional Network 8 (FCN-8) [11] and the more recent SegNet [16]. Previous use of FCNs for polyp segmentation have shown promising results, and we hypothesized that the inclusion of recent advances in deep learning would improve these results further. SegNet has been shown to achieve comparative results to FCNs in some appliarXiv:1807.10584v1  [cs.CV]  16 Jul 2018  cation domains but is a less memory intensive approach with fewer parameters to optimize. The FCN is a',\n",
       " '1807.06962': 'Segmentation has several medical applications, such as patient-speciﬁc surgical planning. Due to limited resources of expert physicians, detailed manual annotations are often not possible, even when desired anatomy may be visible with suﬃcient contrast using non-invasive imaging modalities such as MRI and ultrasound. Deep learning has shown encouraging performance for segmentation [1,2], but often only when suﬃcient amount of labeled data for a target anatomy is available. Medical image data across diﬀerent medical centers is often not uniform, for instance with respect to machine manufacturer, imaging settings, and cohort demographics. Thus, studies and corresponding annotations are only carried out in isolated datasets, with diﬃculties in merging information with data sharing, patient rights, and conﬁdentiality concerns. Hence, a suﬃciently large dataset for a given task needs to be labeled. Active learning aims at maximizing the prediction performance through an intelligent sample querying system so arXiv:1807.06962v1  [cs.CV]  18 Jul 2018  that the limited expert annotation resources can be properly managed as opposed to training on a randomly selected next batch of samples which would contain a lot of redundancy. In a clinical environment, one can imagine that expert(s) will allocate a ﬁxed amount of annotation time per time interval (i.e., week), hence the correct use of this time (i.e., on most valuable samples) is essential. Therefore, the segmentation framework would be initially provided a very limited labeled dataset, which will be extended with a certain batch size of samples intelligently selected at each iteration of the active learning. Intuitively, the prediction conﬁdence of a learned model can be used as a surrogate metric for its potential accuracy, in order to propose the most uncertain predictions for future manual annotation. In [3], MC dropout is proposed to sample from the approximate trained model posterior, which can be used to quantify an uncertainty metric through variations in the model predictions for a given input. Based on this, several approaches of querying the next batch of data are studied and compared with uniform random sampling in [4]. Unfortunately, it is intractable to assess conditional uncertainty of multiple samples; e.g. would ith sample be still as uncertain as before once jth sample is queried and trained for. Thus, it is intuitive to select a representative subset of these uncertain samples to reduce redundancy. Using a simpliﬁed version of DCAN [2] architecture (which has won the ﬁrst place in the 2015 MICCAI Gland Segmentation Challenge [5]) for the purpose of faster training, a state-of-the-art method was proposed in [6] to select optimal sample images to annotate. First, a batch of uncertain samples is chosen based on the mean variance of multiple network predictions, followed by picking a subset of these using maximum set coverage [7] over the image descriptors of these samples. Recently in [8], a content distance [9] concept was proposed to quantify the similarity between two images, for selecting representative samples in class',\n",
       " '1302.2855': 'Polar codes [1] are known as a low-complexity binary coding scheme that provably approaches the capacity of arbitrary symmetric binary-input discrete memoryless channels (B-DMCs). The generalization to M-ary channels (M > 2) has been the subject of various works, cf., e.g. [2], [3], [4]. However, the topic of polar-coded modulation, i.e., the combination of M = 2m-ary digital modulation, especially digital PAM (i.e., ASK, PSK, QAM), and binary polar codes for increased spectral efﬁciency, has hardly been addressed so far. In [5], a transmission scheme for polar codes with bit-interleaved coded modulation (BICM) [6], [7] has been proposed, focussing on the interleaver design. In this paper, we discuss both the multilevel coding (MLC) construction [8], [9] and BICM. We restrict our considerations to memoryless channels like the AWGN channel (no fading). In case of BICM, we follow an alternative approach that differs from [5]. It has been observed (cf., e.g., [10]) that the MLC approach is closely related to that of polar coding on a conceptual level. Based on these similarities, we propose a framework that allows us to completely describe both polar coding and 2m-ary PAM modulation in a uniﬁed context. To this end, we introduce so-called channel partitions. These transformations split an arbitrary memoryless 2m-ary channel (e.g., the equivalentbaseband PAM channel in case of PAM modulation) into m binary-input memoryless channels (so-called bit channels). We distinguish two classes of such binary partitions, sequential and parallel binary partitions. For the latter, the resulting bit channels are independent. It is thus applicable, e.g., to describe BICM. For sequential binary partitions, the bit channels depend on each other in a well-deﬁned order – this class can be used for representing MLC. We show that both binary polar coding as well as polar-coded modulation may be described by the concatenation of binary partitions. All authors are with the Institute of Information Transmission, FriedrichAlexander-Universit¨at Erlangen-N¨urnberg, 91058 Erlangen, Germany. E-mail: {seidl,schenk,clemens,jbhuber}@LNT.de. Parts of this paper have been submitted for presentation at IEEE ISIT ’13. Considering the trade-off between power efﬁciency and spectral efﬁciency, this uniﬁed description makes it possible to design optimized constellation-dependent coding schemes both for MLC and BICM. Additionally, we provide an efﬁcient method for a numerical evaluation of the performance of polar-coded modulation and present extensive numerical results for various settings. Using this method, we present a comprehensive comparison of polarcoded modulation based on MLC as well as on BICM, and we show results of a comparison to LDPC-coded modulation (for the latter only the common BICM approach is considered). The paper is organized as follows: In Sec. II, the framework for a joint description of polar coding and 2m-ary PAM modulation is developed. This framework is then used for describing the polar coding construction in Sec. III, leading to a novel interpretation',\n",
       " '1511.07236': 'P OLAR codes proposed by Arıkan [1] have been proved to achieve the capacity of any symmetric binary input symmetric discrete memoryless channels (B-DMCs) under a successive cancellation (SC) decoder as the code length goes to inﬁnity. Recently, polar codes have been identiﬁed as one of the channel coding schemes in the 5G wireless communication system due to its excellent performance [2]. To construct polar codes, the channel reliabilities are calculated efﬁciently using the symmetric capacities of subchannels or the Bhattacharyya parameters for the binary-input erasure channels (BECs). As a heuristic method, Arıkan has suggested to use the recursion which is optimal only for BECs also for other B-DMCs [3]. Mori et al. regarded the construction problem as an instance of density evolution (DE) [4], which theoretically has the highest This work is supported by the National Natural Science Foundation of China (No. 61671080 & No. 61171099), BUPT-SICE Excellent Graduate Students Innovation Fund and Huawei HIRP project. The material in this paper was presented in part at the Recent Results Session of IEEE International Symposium on Information Theory (ISIT), Hong Kong, June 2015. The authors are with the Key Laboratory of Universal Wireless Communications, Ministry of Education, Beijing University of Posts and Telecommunications, Beijing 100876, China (email: {daijincheng, niukai, sizhongwei, dongchao, jrlin}@bupt.edu.cn). accuracy. Considering its high computational complexity, Tal and Vardy devised two approximation methods to simplify the calculation of DE, by which one can get the upper and lower bounds on the error probability of each subchannel. Tal and Vardy’s method has almost no performance loss compared with DE [5]–[8]. Afterwards, Gaussian approximation (GA) was proposed to further reduce the computational complexity of DE [9] without much sacriﬁce in accuracy, which became popular in the construction of polar codes thanks to its good tradeoff between the complexity and performance. In the GA construction of polar codes, the bit log-likelihood ratio (LLR) of each subchannel is assumed to obey a constraint Gaussian distribution in which the mean is half of the variance. Hence, the iterative evaluation of each subchannel reliability is only involved with the mean update of LLRs. However, the LLR mean updates in check nodes still depend on complex integration. Consequently, for construction of polar codes, the computational complexity of exact GA (denoted by EGA) grows exponentially with the polarization levels. This makes EGA too complicated to be practically employed. Therefore, in practical implementation, like GA utilized in LDPC codes, the well-known approximate version of GA (denoted by AGA) given by Chung et al. based on a two-segment approximation function is used to speed up the calculations [10]–[12]. Initially, the approximation function in conventional AGA chosen by Chung is suitable for LDPC codes. However, in principle, we don’t know whether this approximation method can be also good for the polar codes. In fact, the calculation error of AGA versus EGA will be accumulated and ampliﬁed in the recursion process of polar codes construction',\n",
       " '1810.01398': 'Recent advances in natural language processing and speech recognition hinge on the development of expressive neural network architectures for sequence to sequence (seq2seq) learning (Sutskever et al., 2014; Bahdanau et al., 2015). Such encoder-decoder architectures are adopted in both machine translation (Bahdanau et al., 2015; Wu et al., 2016; Hassan et al., 2018) and speech recognition systems (Chan et al., 2016; Bahdanau et al., 2016a; Chiu et al., 2017) achieving impressive performance above traditional multi-stage pipelines (Koehn et al., 2007; Povey et al., 2011). Improving the building blocks of seq2seq models can fundamentally advance machine translation and speech recognition, and positively impact other domains such as image captioning (Xu et al., 2015), parsing (Vinyals et al., 2015), summarization (Rush et al., 2015), and program synthesis (Zhong et al., 2017). To improve the key components of seq2seq models, one can either design better architectures, or develop better learning algorithms. Recent architectures using convolution (Gehring et al., 2017) and self attention (Vaswani et al., 2017) have proved to be useful, especially to facilitate efﬁcient training. On the other hand, despite many attempts to mitigate the limitations of Maximum Likelihood Estimation (MLE) (Ranzato et al., 2016; Wiseman and Rush, 2016; Norouzi et al., 2016; Bahdanau et al., 2017; Leblond et al., 2018), MLE is still considered the dominant approach for training seq2seq models. Current alternative approaches require pre-training or joint optimization with conditional log-likelihood. They are difﬁcult to implement and require careful tuning of new hyper-parameters (e.g. mixing ratios). In addition, alternative approaches typically do not offer a substantial performance improvement over a well tuned MLE baseline, especially when label smoothing (Pereyra et al., 2017; Edunov et al., 2018) and scheduled sampling (Bengio et al., 2015) are used. In this paper, we borrow ideas from search-based structured prediction (Daumé et al., 2009; Ross et al., 2011) and policy distillation (Rusu et al., 2016) and develop an efﬁcient algorithm for optimizing seq2seq models based on edit distance1. Our key observation is that given an arbitrary preﬁx (e.g. a partial sequence generated by sampling from the model), we can exactly and efﬁciently identify all of the sufﬁxes that result in a minimum total edit distance (v.s. the ground truth target). Our training procedure, called Optimal Completion Distillation (OCD), is summarized as follows: 1. We always train on preﬁxes generated by sampling from the model that is being optimized. 2. For each generated preﬁx, we identify all of the optimal sufﬁxes that result in a minimum total edit distance v.s. the ground truth target using an efﬁcient dynamic programming algorithm. 3. We teach the model to optimally extend each generated preﬁx by maximizing the average log probability of the ﬁrst token of each optimal sufﬁx identiﬁed in step 2. 1Edit distance between two sequences u and v is the minimum number of insertion, deletion, and substitution edits required to convert u to v and vice versa. 1 arXiv:1810.01398v2  [cs.LG]  14 Jan 2019  Published as a conference paper at ICLR 2019',\n",
       " '1901.10124': 'In recent years, there has been a significant increase in smart city initiatives [9, 30, 31]. As a result, government authorities are emphasizing the use of technology and increased citizen participation for better maintenance of urban areas. Various web platforms – SeeClickFix [27], FixMyStreet [1], ichangemycity [16] – have been Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for third-party components of this work must be honored. For all other uses, contact the owner/author(s). Conference’17, July 2017, Washington, DC, USA © 2019 Copyright held by the owner/author(s). ACM ISBN 123-4567-24-567/08/06. https://doi.org/10.475/123_4 Figure 1: Comparison between Civic Issue Graph and Scene Graph for the same image. The scene graph provides a complete representation of all objects and relationships in the image, while the Civic Issue Graph only consists of relations representative of the civic issue. introduced across the world, which enable the citizens to report civic issues such as poor road condition, garbage dumps, missing traffic signs, etc., and track the status of their complaints. Such initiatives have resulted in exponential increase in the number of civic issues being reported [2]. Even social media sites (Twitter, Facebook) have been increasingly utilized to report civic issues. Studies have found the importance of civic issue reporting platforms and social media sites in enhancing civic awareness among citizens [36]. These platforms help the concerned authorities to not only identify the problems, but also access the severity of the problems. Civic issues are reported online through various mediums – textual descriptions, images, videos, or a combination of them. Previous work [10] highlights the importance of mediums in citizen participation. Yet, no prior work has tried to understand the role of these mediums in reporting of civic issues. In this work, we first identify the most preferred medium for reporting civic issues, by conducting a user study with 13 citizens and 3 government authorities. Using the 84 civic issues reported by the citizens using our mobile app, and follow-up semi-structured interviews, we found that images are the most usable medium for the citizens. In contrast, authorities found text as the most preferred medium, as images are hard to analyze at scale. To fill this gap, several works have proposed methods to automatically identify a specific category of civic issues from images, such as garbage dumps [28] and road damage [24]. However, their methods are limited to the specific categories that they address. arXiv:1901.10124v1  [cs.AI]  29 Jan 2019  Conference’17, July 2017, Washington, DC, USA Shanu Kumar and Shubham Atreja, Anjali Singh, Mohit Jain Furthermore, existing holistic approaches of analyzing civic issues are limited to text [4]. To this end, we',\n",
       " '1709.01434': 'We study nonconvex ﬁnite-sum problems of the form min x∈Rd f(x) := 1 n n X i=1 fi(x), (1) where neither f : Rd →R nor the individual functions fi : Rd →R (i ∈[n]) are necessarily convex. We operate in a general nonconvex setting except for few smoothness assumptions like Lipschitz continuity of the gradient and Hessian. Optimization problems of this form arise naturally in machine learning and statistics as empirical risk minimization (ERM) and M-estimation respectively. In the large-scale settings, algorithms based on ﬁrst-order information of functions fi are typically favored as they are relatively inexpensive and scale seamlessly. An algorithm widely used in practice is stochastic gradient descent (SGD), which has the iterative update: xt+1 = xt −ηt∇fit(xt), (2) *Equal Contribution †Also at Amazon Web Services Deep Learning, Palo Alto CA 94301 arXiv:1709.01434v1  [cs.LG]  5 Sep 2017  Figure 1: First order methods like GD can potentially get stuck at saddle points. Second-order methods can escape it in very few iterations (as observed in the left plot) but at the cost of expensive Hessian based iterations (see time plot to the right). The proposed framework, which is a novel mix of the two strategies, can escape saddle points faster in time by carefully trading off computation and iteration complexity. where it ∈[n] is a randomly chosen index and ηt is a learning rate. Under suitable selection of the learning rate, we can show that SGD converges to a point x that, in expectation, satisﬁes the stationarity condition ∥∇f(x)∥≤ϵ in O(1/ϵ4) iterations [14]. This result has two critical weaknesses: (i) It does not ensure convergence to local optima or second-order critical points; (ii) The rate of convergence of the SGD algorithm is slow. For general nonconvex problems, one has to settle for a more modest goal than sub-optimality, as ﬁnding the global minimizer of ﬁnite-sum nonconvex problem will be in general intractably hard. Unfortunately, SGD does not even ensure second-order critical conditions such as local optimality since it can get stuck at saddle points. This issue has recently received considerable attention in the ML community, especially in the context of deep learning [8–10]. These works argue that saddle points are highly prevalent in most optimization paths, and are the primary obstacle for training large deep networks. To tackle this issue and achieve a second-order critical point for which ∥∇f∥≤ϵ and ∇2f ⪰−√ϵI, we need algorithms that either use the Hessian explicitly or exploit its structure. A key work that explicitly uses Hessians to obtain faster convergence rates is the cubic regularization (CR) method [28]. In particular, Nesterov and Polyak [28] showed that CR requires O(1/ϵ3/2) iterations to achieve the second-order critical conditions. However, each iteration of CR is expensive as it requires computing the Hessian and solving multiple linear systems, each of which has complexity O(dω) (ω is the matrix',\n",
       " '1511.06457': 'Humans are able to recover the occlusion relationships of objects from single images. This has long been recognized as an important ability for scene understanding and perception [15,4]. As shown on the left of Fig. 1, we can use occlusion relationships to deduce that the person is holding a dog, because the person’s hand occludes the dog and the dog occludes the person’s body. Electrophysiological [18] and fMRI [13] studies suggest that occlusion relationships are detected as early as visual area V2. Biological studies [9] also suggest that occlusion detection can require feedback from higher level cortical regions, indicating that long-range context and semantic-level knowledge may be needed. Psychophysical studies show that there are many cues for occlusion including edge convexity [23], edge-junctions, intensity gradients, and texture [35]. Computer vision researchers have also used similar cues for estimating occlusion relations. A standard strategy is to apply machine learning techniques to combine cues like convexity, triple-points, geometric context, image features like HOG, and spectral features, e.g. [37,20,5,46]. These methods, however, mostly arXiv:1511.06457v4  [cs.CV]  24 Jul 2016  2 Peng Wang1 Alan Yuille1,2 Foreground Background Fig. 1. Left: Occlusion boundaries represented by orientation θ (the red arrows), which indicates occlusion relationship using the “left” rule where the left side of the arrows is foreground. Right: More examples from our Pascal instance occlusion dataset (PIOD). rely on hand-crafted features and have only been trained on the small occlusion datasets currently available. But in recent years, fully convolutional deep convolutional neural networks (FCN) [29] that exploit local and non-local cues, and trained on large datasets, have been very successful for related visual tasks such as edge detection [50] and semantic segmentation [6]. In addition, visualization of deep networks [52,30] show that they can also capture and exploit the types of visual cues needed to estimate occlusion relations. This motivates us to apply deep networks to estimate occlusion relationships, which requires constructing a large annotated occlusion dataset. This also requires making design choices such as how to represent occlusion relations and what type of deep network architecture is best able to capture the local and non-local cues required. We represent occlusion relations by a per-pixel representation with two variables: (i) a binary edge variable to indicate if a pixel in on a boundary, and (ii) a continuous-valued occlusion orientation variable (at each edge pixel) in the tangent direction of the edge whose direction indicates the occlusion relationship using the left rule (i.e. the region to the left of the edge is in front of the region to the right). Our DOC network architecture is based on recent fully convolutional networks [29] and is multi-scale so that it can take into account local and non-local image cues. More speciﬁcally, we design two versions of DOC based on [50] and [6] respectively. To construct our dataset, we',\n",
       " '1003.1354': 'In the supervised learning setting, one is given a training set of labeled data points and the aim is to learn a function which predicts labels on unseen data points. Sometimes the label space has a rich internal structure which characterizes the combinatorial or recursive inter-dependencies of the application domain. It is widely believed that capturing these dependencies is critical for effectively learning with structured output. Examples of such problems include sequence labeling, context free grammar parsing, and word alignment. However, parameter estimation is generally hard even for simple linear models, because the size of the label space is potentially exponentially large (see e.g. [3]). Therefore it is crucial to exploit the underlying conditional independence assumptions for the sake of computational tractability. This is often done by deﬁning a graphical model on the output space, and exploiting the underlying graphical model factorization to perform computations. Research in structured prediction can broadly be categorized into two tracks: Using a maximum a posterior estimate from the exponential family results in conditional random ﬁelds [CRFs, 10], and a maximum margin approach leads to max-margin Markov networks [M3Ns, 18]. Unsurprisingly, these two approaches share many commonalities: First, they both minimize a regularized risk with a square norm regularizer. Second, they assume that there is a joint feature map φ which maps (x, y) to a feature vector in Rp.1 Third, they assume a label loss ℓ(y, yi; xi) which quantiﬁes the loss of predicting label y when the correct label of input xi is yi. Finally, they assume that the space of labels Y is endowed with a graphical model structure and that φ(x, y) and ℓ(y, yi; xi) factorize according to the cliques of this graphical model. The main difference is in the loss function employed. CRFs minimize the L2-regularized logistic loss: J(w) = λ 2 ∥w∥2 + 1 n n X i=1 log X y∈Y exp \\x00ℓ(y, yi; xi) −  w, φ(xi, yi) −φ(xi, y) \\x0b\\x01 , (1) while the M3Ns minimize the L2-regularized hinge loss J(w) = λ 2 ∥w∥2 + 1 n n X i=1 max y∈Y \\x08 ℓ(y, yi; xi) −  w, φ(xi, yi) −φ(xi, y) \\x0b\\t . (2) 1We discuss kernels and associated feature maps into a Reproducing Kernel Hilbert Space (RKHS) in the appendix. arXiv:1003.1354v1  [cs.LG]  6 Mar 2010  dual gap  duality gap  primal gap  𝐽(𝐰)  𝐷(𝛂)  (Taskar et al, 2006) (Ours)  (Collins et al, 2008)  (Taskar 2004, Ch 6)  𝐰𝑘  𝛂𝑘  min 𝐰 𝐽(𝐰)  max 𝛂  𝐷(𝛂)  =  (a) Primal gap, dual gap, and duality gap primal gap  (Teo et al, 2010) 𝐰𝑘  𝐽(𝐰)  min 𝐰 𝐽(𝐰)  (b) BMRM gap (and similarly for SVM-Struct) Figure 1: Illustration of stopping criterion monitored by various algorithms; convergence rates are stated with respect to these stopping criterion. D(α) is the Lagrange dual of J(w), and minw J(w) = maxα D(α). Neither',\n",
       " '0803.1733': 'Multiple-input-multiple-output (MIMO) systems have been proven to be very powerful in point-to-point communication. Following their success in the point-to-point case, MIMO techniques have been widely applied to various multiuser communication scenarios. Since the capacity region for most network communication scenarios has been an open question for many years, capacity approximations are needed to provide an evaluation of the system performance. The number of degrees of freedom (DOF), which is also known as capacity pre-log or multiplexing gain [1], provides a capacity approximation CΣ(ρΣ) = η log(ρΣ) + o(log(ρΣ)) where η is the number of degrees of freedom, CΣ(ρΣ) is the sum rate capacity, and ρΣ is the signal-to-noise ratio (the total transmit power of all nodes divided by the local noise power). The approximation error is within o(log(ρΣ)) for any ρΣ and the accuracy of the approximation approaches 100% as ρΣ increases. The DOF of various multiuser MIMO systems have been found. The two-user multiple access channel (MAC) with M1, M2 antennas at the transmitters and N antenna at the receiver has the DOF of min(M1 + M2, N) [2]. The two-user broadcast channel (BC) with M antennas at the transmitter and N1, N2 antennas at the receivers has the DOF of min(M, N1 + N2) [3]– [5]. The DOF of the two-user MIMO interference channel with M1, M2 antennas at the transmitter and N1, N2 antennas at the receivers, which will be referred to (M1, M2, N1, N2) interference channel later in this paper, is min{M1 + M2, N1 + N2, max(M1, N2), max(M2, N1)} [6]. Note that in the MIMO MAC and BC, the distributed processing at either the transmitter side or the receiver side does not cause any loss in the DOF. But in the MIMO interference channel, there may be a signiﬁcant loss in the DOF due to the distributed processing at both transmitter and receive sides. For example, while a (1, n, n, 1) interference channel has only one degrees of freedom, the pointto-point MIMO system with 1 + n antennas at both transmitter and receiver has 1 + n degrees of freedom. Many techniques are possible candidates to compensate the loss in DOF caused by the distributed processing nature of the MIMO interference channel. In this paper, we consider two of them: user cooperation and cognitive message sharing. We will explore the beneﬁts, in the sense of DOF, of these two techniques for a two-user MIMO Gaussian interference channel. A. Cooperation The basic idea for cooperation is that several nodes cooperate with each other and act as a large virtual antenna array. Nodes can cooperate to form a transmit antenna array or receive antenna array. Cooperation is made possible by allowing noisy links between distributed transmitters or distributed receivers. A two-user interference channel with single antenna at all nodes is considered by Host-Madsen and Nosratinia in [7], [8]. They show that',\n",
       " '1803.06417': 'M ODERN magnetic recording (MR) systems require error correcting codes (ECCs) with outstanding error ﬂoor performance. Low-density parity-check (LDPC) codes are a primary choice for MR systems because of their error correcting capabilities [1]–[3]. In a magnetic-recording device, some sections can be more error prone than other sections because of the read/write mechanism and physical properties of the device [4]. A realistic channel model for magnetic recording systems must consider the variation of signal to noise ratio (SNR) among consecutive sections of a hard disk drive. In this paper, we develop ECCs that address the SNR variation for data storage systems. For channels with uniform SNR, i.e., channels with a single SNR, the goal is to ﬁnd a code that achieves a certain level of bit error rate (BER) for that SNR. For channels with SNR variation, conventional ECCs are designed to achieve the target BER for the section with the lowest SNR. For the sections with higher SNRs, this approach results in an additional redundancy which is not required to achieve the target BER. One solution for handling the non-uniformity of SNR is using interleaving. In this approach, we assume that the channel consists of N sections of equal sizes, and the length of each codeword is also equal to the length of a section. Each codeword is divided into N chunks. Then, different chunks from all codewords are interleaved such that one chunk from each codeword is passed through one section of the channel. As a result, the average SNR that all codewords are affected by is the same and equal to the average SNR of the channel, and one just needs to consider the average SNR rather than the worst SNR in the code design process [4]. One disadvantage of this approach is that the length of each codeword is equal Fig. 1: The parity-check matrix of an SC code with memory m and coupling length L. to the length of one section of the channel which might be relatively short. The authors in [5] have recently presented a concatenated code design scheme for magnetic recording systems that considers the SNR variation. Their approach consists of a number of inner codes and one outer code. While the inner codes span one section each, the outer code spans many sections, possibly an entire track. Spatially-coupled (SC) codes are a family of graph-based codes that have attracted signiﬁcant attention because of their capacity approaching performance and low decoding latency [6], [7]. SC codes are constructed by partitioning a paritycheck matrix H of the underlying block code into component matrices {H0, H1, · · · , Hm}, H = Pm y=0 Hy, and coupling L replicas of the component matrices together to obtain the parity-check matrix HSC, see Fig. 1. The parameters m and L are known as the memory and coupling length, respectively. In [8]–[10], SC codes over non-uniform channels are studied. In these papers, the asymptotic performance of',\n",
       " '1810.06999': 'In recent years, there has been increased interest in coordinate descent (CD) methods due to their simplicity, low cost per iteration, and eﬃciency (Wright, 2015). Algorithms based on coordinate descent are the state of the art for many optimization problems (Nesterov, 2012; Shalev-Shwartz and Zhang, 2013b; Lin et al., 2014; Shalev-Shwartz and Zhang, 2013a, 2016; Richtarik and Takac, 2016; Fercoq and Richtárik, 2015; Nesterov and Stich, 2017). Most of the CD methods draw their coordinates from a ﬁxed distribution—for instance from the uniform distribution as in uniform coordinate descent (UCD). However, it is clear that signiﬁcant improvements can be achieved by choosing more important coordinates more frequently (Nesterov, 2012; Nesterov and Stich, 2017; Stich et al., 2017a,b; Perekrestenko et al., 2017). In particular, we could greedily choose the ‘best’ coordinate at each iteration i.e. the steepest coordinate descent (SCD). ∗Equal contribution. 1 arXiv:1810.06999v1  [math.OC]  16 Oct 2018  SCD for composite problems. Consider the smooth quadtratic function f(α) def= 1 2 ∥Aα −b∥2 2. There are three natural notions of the ‘best’ coordinate.1 One could choose (i) GS-s: the steepest coordinate direction based on (sub)-gradients, (ii) GS-r: the coordinate which allows us to take the largest step, and (iii) GS-q: the coordinate that allows us to minimize the function value the most. For our example (and in general for smooth functions), the three rules are equivalent. When we add an additional non-smooth function to f, such as g(α) = λ ∥α∥1, however, the three notions are no more equivalent. The performance of greedy coordinate descent in this composite setting is not well understood, and is the focus of this work. Iteration complexity of SCD. If the objective f decomposes into n identical separable problems, then clearly SCD is identical to UCD. In all but such extreme cases, Nutini et al. (2015) give a reﬁned analysis of SCD for smooth functions and show that it outperforms UCD. This lead to a renewed interest in greedy methods (e.g. (Karimi et al., 2016; You et al., 2016; Dünner et al., 2017; Song et al., 2017; Nutini et al., 2017; Stich et al., 2017a; Locatello et al., 2018; Lu et al., 2018)). However, for the composite case the analysis in (Nutini et al., 2015) of SCD methods for any of the three rules mentioned earlier falls back to that of UCD. Thus they fail to demonstrate the advantage of greedy methods for the composite case. In fact it is claimed that the rate of the GS-s greedy rule may even be worse than that of UCD. In this work we provide a reﬁned analysis of SCD for a certain class of composite problems, and show that all three strategies (GS-s, GS-r, and GS-q) converge on composite problems at a rate similar to SCD in the smooth case. Thus for these problems too, greedy coordinate algorithms are provably faster than UCD other than in',\n",
       " '1701.06532': 'FAILED',\n",
       " '0704.0304': 'Throughout history we have used concepts from our current technology as metaphors to describe our world. Examples of this are the description of the body as a factory during the Industrial Age, and the description of the brain as a computer during the Information Age. These metaphors are useful because they extend the knowledge acquired by the scientiﬁc and technological developments to other areas, illuminating them from a novel perspective. For example, it is common to extend the particle metaphor used in physics to other domains, such as crowd dynamics [27]. Even when people are not particles and have very complicated behaviour, for the purposes of crowd dynamics they can be eﬀectively described as particles, with the beneﬁt that there is an established mathematical framework suitable for this description. Another example can be seen with cybernetics [4, 28], where the system metaphor is used: everything is seen as a system with inputs, outputs, and a control that regulates the internal variables of the system under the inﬂuence of perturbations from its environment. Yet another example can be seen with the computational metaphor [60], where the universe can be modelled with simple discrete computational machines, such as cellular automata or Turing machines. Having in mind that we are using metaphors, this paper proposes to extend the concept of information to describe the world: from elementary particles to galaxies, with everything in between, particularly life and cognition. There is no suggestion on the nature of reality as information [58]. This work only explores the advantages of describing the world as information. In other words, there are no ontological claims, only epistemological. In the next section, the motivation of the paper is presented, followed by a section describing the notion of information to be used throughout the paper. In Section 4, eight tentative laws of information are put forward. These are applied to the notions of life (Section 5) and cognition (Section 6). The paper closes presenting future work and conclusions. 2 Why Information? There is a great interest in the relationship between energy, matter, and information [32, 54, 43]. One of the main reasons for this arises because this relationship plays a central role in the deﬁnition of life: Hopﬁeld [30] suggests that the diﬀerence between biological and physical systems is given by the meaningful information content of the former ones. Not that information is not present in physical systems, but—as Roederer puts it—information is passive in physics and active in biology [49]. However, it becomes complicated to describe how this information came to be in terms of the physical laws of matter and energy. In this paper the inverse approach is proposed: let us describe matter and energy in terms of information. If atoms, molecules and cells are described as information, there is no need of a qualitative shift (from non-living to living matter) while describing the origin and evolution of life: this is translated into a quantitative  shift (from less complex to',\n",
       " '1807.05195': 'Text classiﬁcation is the generic term to describe the process of assigning a document x to a class y (Aggarwal & Zhai, 2012). Depending on the semantics of the class label y, text classiﬁcation can be used for a variety of tasks, including ∗Corresponding author Email addresses: griesshaber@hdm-stuttgart.de (Daniel Grießhaber), thangvu@ims.uni-stuttgart.de (Ngoc Thang Vu), maucher@hdm-stuttgart.de (Johannes Maucher) Preprint submitted to Computer Speech & Language April 23, 2020 arXiv:1807.05195v2  [cs.CL]  22 Apr 2020  sentiment analysis (Liu & Zhang, 2012), spam ﬁltering (Sahami et al., 1998) or topic labeling (Wang & Manning, 2012). Traditional approaches use sparse, symbolic representations of words and documents, such as the bag-of-words model (Collobert et al., 2011). Then, linear models or kernel methods are used for the classiﬁcation (Wang & Manning, 2012). This approach has obvious disadvantages. While the symbolic representation of words can not model similarities and relations between words (Bengio et al., 2003), the bag-of-words approach removes any order and thus relation between words which is particularly important for sentiment detection in longer documents (Pang et al., 2002). Current state-of-the-art natural language processing (NLP) models often use distributed representations of words (Mikolov et al., 2013; Pennington et al., 2014) which are then fed into complex neural network models such as convolutional neural networks (CNNs) (Kim, 2014) or recurrent neural networks (RNNs) (Tai et al., 2015). While these approaches proved to be successful for many NLP tasks (Collobert et al., 2011; Bahdanau et al., 2014), they often require large amounts of labeled data. However, there is often only little training data or even no data available when a NLP application is needed for new domains (Glorot et al., 2011) or new languages (Agi´c et al., 2016; Fang & Cohn, 2017; Hao et al., 2018; Wan, 2008; Salameh et al., 2015). Moreover, in the case of adaptation to new languages, multilingual word vectors are considered to be required. They are, however, not trivial to obtain due to the lack of parallel data (Faruqui & Dyer, 2014) or multilingual dictionaries (Ammar et al., 2016). Therefore, the ability to use these state-of-the-art architectures in such low-resource scenarios is investigated in this work. In this work we therefore, concentrate on the low-resource setting, where only little data is available to train such a potentially complex network. For this, we explore domain adversarial training and its interpretation as a regularizer for the training of complex model architectures avoiding overﬁtting in low-resource and zero-resource settings. In the case of transfer learning from one language to another low-resource one, our experimental results reveal that 2  a projection of word vectors from diﬀerent languages into a common space can be automatically learnt during training, which suggests that the multilingual word vectors are no longer needed. We also extend the domain-adversarial neural network architecture to multiple source domains and show that this beneﬁts the',\n",
       " '1807.11637': 'Image denoising is the most fundamental image restoration problem, which has been studied for decades. In order to regularize its ill-posed nature, a large body of works adopt signal priors. By adopting a certain image model, one assumes that the original image should induce a small value for a given model-based signal prior. Representative priors in the literature include non-local self-similarity [5], total variation (TV) prior [37], sparsity prior [15], graph Laplacian regularizer [33], etc. However, these works place their emphases to the removal of additive white Gaussian noise (AWGN), which is unrealistic and limits their applications in practice. In the real world, image noise stems from multiple sources, e.g., thermal noise, shot noise, dark ∗Both authors contributed equally to this work. Jiahao Pang is the corresponding author. (a) Noise Clinic. (b) CDnCNN. (c) DeepGLR. Figure 1. Results of real image denoising. (a) Noise Clinic (modelbased); (b) CDnCNN (data-driven); (c) DeepGLR (proposed). Our method and CDnCNN are trained for Gaussian denoising. current noise, making it much more sophisticated than the ideal AWGN. Recent developments in deep learning have revolutionized the aforementioned model-based paradigm in image restoration. Thanks to the strong learning capacity of convolutional neural networks (CNN) to capture image characteristics, CNN-based approaches have achieved the state-of-the-art performance in Gaussian denoising, e.g., [48, 43, 40]. However, the application of deep learning models on real noise removal remains quite challenging. Unlike model-based approaches, CNN-based approaches are data-driven. To learn a CNN for real image noise removal, thousands of real noisy images and their noise-free versions are necessary to characterize the correspondence between the corrupted images and the ground-truths [50]. Unfortunately, acquiring the noise-free images is non-trivial [46, 7], leading to limited amount of training data. In this case, a purely data-driven approach is prone to overﬁt to the particular characteristics of the training data. It fails on test images with statistics different from the training images [29], e.g., Figure 1b showcases the result of a pure datadriven approach trained for a different domain. Differently, model-based denoising approaches rely on basic assumptions about the original images, which “encode” assumed image characteristics. Without the notion of training, the performance of model-based denoising is generally more robust than data-driven approaches when facing the heterogeneity of natural images [13]. However, the assumed characteristics may not perfectly hold in the real arXiv:1807.11637v3  [cs.CV]  3 May 2019  world, hindering their performance and ﬂexibility in practice [30], e.g., the denoising result of Figure 1a. To achieve robust denoising of real images, in this paper we combine the robustness merit of model-based approaches and the powerful learning capacity of data-driven approaches. We achieve this goal by incorporating the graph Laplacian regularizer—a simple yet effective image prior for image restoration tasks—into a deep',\n",
       " '1703.02930': 'Deep neural networks underlie many of the recent breakthroughs in applied machine learning, particularly in image and speech recognition. These successes motivate a renewed study of these networks’ theoretical properties. Classiﬁcation is one of the learning tasks in which deep neural networks have been particularly successful, e.g., for image recognition. A natural foundational question that arises is: what are the generalization guarantees of these networks in a statistical learning framework? An established way to address this question is by considering VC-dimension, which characterizes uniform convergence of misclassiﬁcation frequencies to probabilities (see Vapnik and Chervonenkis, 1971), and asymptotically determines the sample complexity of PAC learning with such classiﬁers (see Blumer, Ehrenfeucht, Haussler, and Warmuth, 1989). Deﬁnition 1 (growth function, VC-dimension, shattering) Let H denote a class of functions from X to {0, 1} (the hypotheses, or the classiﬁcation rules). For any non-negative integer m, we deﬁne the growth function of H as ΠH(m) := max x1,...,xm∈X |{(h(x1), . . . , h(xm)) : h ∈H}| . If |{(h(x1), . . . , h(xm)) : h ∈H}| = 2m, we say H shatters the set {x1, . . . , xm}. The Vapnik-Chervonenkis dimension of H, denoted VCdim(H), is the size of the largest shattered set, i.e. the largest m such that ΠH(m) = 2m. If there is no largest m, we deﬁne VCdim(H) = ∞. For a class of real-valued functions, such as those generated by neural networks, a natural measure of complexity that implies similar uniform convergence properties is the pseudodimension (see Pollard, 1990). Deﬁnition 2 (pseudodimension) Let F be a class of functions from X to ℜ. The pseudodimension of F, written Pdim(F), is the largest integer m for which there exists (x1, . . . , xm, y1, . . . , ym) ∈X m × ℜm such that for any (b1, . . . , bm) ∈{0, 1}m there exists f ∈F such that ∀i : f(xi) > yi ⇐⇒bi = 1 For a class F of real-valued functions, we may deﬁne VCdim(F) := VCdim(sgn(F)), where sgn(F) := {sgn(f) : f ∈F} and sgn(x) = 1[x > 0]. For any class F, clearly VCdim(F) ≤Pdim(F). If F is the class of functions generated by a neural network with a ﬁxed architecture and ﬁxed activation functions (see Section 1.3 for deﬁnitions), then it is not hard to see that indeed Pdim(F) ≤VCdim(F) (see (Anthony and Bartlett, 1999, Theorem 14.1) for a proof), and hence Pdim(F) = VCdim(F). Therefore, all the results of this paper automatically apply to the pseudodimensions of neural networks as well. The main contribution of this paper is to prove nearly-tight bounds on the VC-dimension of deep neural networks in which the non-linear activation function is a piecewise linear function with a constant number of pieces. For simplicity we will henceforth refer to such 2  Nearly-tight VC-dimension bounds for piecewise linear neural networks networks as “piecewise linear networks”. The activation function that is the most commonly used in practice is the rectiﬁed linear',\n",
       " '1311.6091': 'Considerable impact in speech recognition has been created in recent years using fully-connected deep neural networks (DNN) that drastically cut errors in large vocabulary speech recognition (Yu et al., 2010; Dahl et al., 2011; Seide et al., 2011; Dahl et al., 2012; Kingsbury et al., 2012; Hinton et al., 2012; Deng et al., 2013b,c; Yu et al., 2013; Dahl et al., 2013; Sainath et al., 2013). However, the well-known problem of the previous state-of-the-art approach based on Gaussian Mixture Model (GMM)-HMMs has not been addressed by the DNNs in a principled way: missing temporal correlation structure that is prevalent in the speech sequence data. Recurrent neural networks (RNN) have shown their potential to address this problem (Robinson, 1994; Graves et al., 2013), but the difﬁculty of learning RNNs due to vanishing or exploding gradients (Pascanu et al., 2013) or the complexity of the LSTM (long short-term memory) structure in RNNs (Graves et al., 2013) have so far slowed down the research progress in using RNNs to improve speech recognition and other sequence processing tasks. In this paper, we propose an architecture of RNNs for supervised learning, where the input sequence to the RNN is computed by an independent feature extractor using a fully-connected DNN receiving its input from raw data sequences. We have formulated both autoregressive (AR) and autoregressive and moving-average (ARMA) versions of this RNN. A new learning method is developed in this work, which is successfully applied to both AR and ARMA versions of the RNN. The new method frames the RNN learning problem as a constrained optimization one, where cross entropy is maximized subject to having the inﬁnity norm of the recurrent matrix of the RNN to be less than 1 arXiv:1311.6091v3  [cs.LG]  6 Mar 2014  a ﬁxed value that provides a sufﬁcient condition for the stability of RNN dynamics. A primal-dual technique is devised to solve the resulting constrained optimization problem in a principled way. Experimental results on phone recognition demonstrate: 1) the primal-dual technique is effective in learning RNNs, with satisfactory performance on the TIMIT benchmark; 2) The ARMA version of the RNN produces higher recognition accuracy than the traditional AR version; 3) The use of a DNN to compute high-level features of speech data to feed into the RNN gives much higher accuracy than without using the DNN; and 4) The accuracy drops progressively as the DNN features are extracted from higher to lower hidden layers of the DNN. 2 Related Work The use of recurrent or temporally predictive forms of neural networks for speech recognition dated back to early 1990’s (Robinson, 1994; Deng et al., 1994), with relatively low accuracy. Since deep learning became popular in recent years, much more research has been devoted to the RNN (Graves et al., 2006; Graves, 2012; Maas et al., 2012; Mikolov, 2012; Vinyals et al., 2012; Graves et al., 2013). Most work on RNNs made use of',\n",
       " '1212.0248': 'FAILED',\n",
       " '1608.08306': 'The demand for data trafﬁc over cellular networks continues to increase with emphasis on low latency and high reliability. Heterogeneous networks are an important solution to the problem of increase in capacity demand. In heterogeneous networks, pico base stations are deployed with the existing macro base stations. The downlink coordinated multi-point (DL CoMP) operation was ﬁrst introduced in 3gpp Rel 11 for long term evolution advanced (LTE-A) networks. It was a feature that improved data rates coverages and cellular capacity at cell edge using a ﬁber backhaul [1], [2]. DL CoMP was further enhanced in 3gpp Rel 13 (eCoMP) with fast channel state information (CSI) acquisition messages being sent between the base stations involved. DL CoMP will play an important role in the ﬁfth generation of wireless communications (5G) air interface which is also known as New Radio (NR) [3]. CoMP was studied extensively in several papers [4]–[6] with solutions offered through convex optimization, Markov chain based models, and queuing theory. Different from these papers, we employ machine learning on the joint transmission scheme where the UE is likely to receive data from multiple streams. In this paper, we focus on the joint processing scheme of CoMP in the downlink direction, where the receiver is the user equipment (UE). Spatially multiplexed data streams transmitted by the base station (BS) are available at more than one transmission point. These points (or base stations) form the CoMP cooperating set. This effectively forms a distributed multiple input multiple output (MIMO) channel with streams from each BS in the CoMP cooperating set. Our objective is to improve the CoMP joint processing distributed MIMO performance. To achieve this objective, we propose an online supervised machine learning based algorithm which acquires physical layer data from the connected Macro BS Pico BS User Equipment Area with poor SINR Fiber backhaul b b Data acquisition interface SVM Fig. 1. Joint processing and support vector machine (SVM) in a coordinated multipoint heterogeneous network. UEs within the channel coherence time in a radio frame. This algorithm can reside in a centralized location as part of a selforganizing network (SON) or in an edge compute node at the BS. We use a minimalistic set of learning features to keep the time and space complexity in polynomial order. The overall view is in Fig. 1. Our main contributions are as follows: 1) Demonstrate that a machine learning model can improve the performance of joint processing CoMP triggering in a realistic environment. 2) Increase the user throughput in a heterogeneous network as a result of learning improved triggering conditions of CoMP compared to the industry-compliant baseline. II. SYSTEM MODEL The system is composed of two modules: • An inter-site CoMP operation in a heterogeneous network composed of macro and pico base stations connected with optical ﬁber. • A machine learning algorithm using a support vector machine (SVM) classiﬁer to derive improved triggering point for CoMP to operate if applicable. A. Radio Environment Our setup for the macro base',\n",
       " '1606.02348': 'I N Massive Multiple-Input Multiple-Output (MIMO), the base station (BS) is equipped with a large antenna array (with hundreds of antennas) that simultaneously serves many (tens or more of) users. It is a key, scalable technology for next generations of wireless networks, due to its promised huge energy efﬁciency and spectral efﬁciency [2]–[7]. In Massive MIMO, time-division duplex (TDD) operation is preferable, because the amount of pilot resources required does not depend on the number of BS antennas. With TDD, the BS obtains the channel state information (CSI) through uplink training. This CSI is used to detect the signals transmitted from users in the uplink. On downlink, owing to the reciprocity of propagation, CSI acquired at the BS is used for precoding. Each user receives an effective (scalar) channel gain multiplied by the desired symbol, plus interference and noise. To coherently detect the desired symbol, each user should know its effective channel gain. Manuscript received May 09, 2016; revised September 07, 2016 and October 28, 2016; accepted November 08, 2016. The associate editor coordinating the review of this paper and approving it for publication was Dr. Jun Zhang. This work was supported in part by the Swedish Research Council (VR), the Swedish Foundation for Strategic Research (SSF), and ELLIIT. Part of this work was presented at the 2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) [1]. H. Q. Ngo and E. G. Larsson are with the Department of Electrical Engineering (ISY), Linköping University, 581 83 Linköping, Sweden (Email: hien.ngo@liu.se; egl@isy.liu.se). H. Q. Ngo is also with the School of Electronics, Electrical Engineering and Computer Science, Queen’s University Belfast, Belfast BT3 9DT, U.K. Digital Object Identiﬁer xxx/xxx Conventionally, each user is assumed to approximate its instantaneous channel gain by its mean [8]–[10]. This is known to work well in Rayleigh fading. Since Rayleigh fading channels harden when the number of BS antennas is large (the effective channel gains become nearly deterministic), the effective channel gain is close to its mean. Thus, using the mean of this gain for signal detection works very well. This way, downlink pilots are avoided and users only need to know the channel statistics. However, for small or moderate numbers of antennas, the gain may still deviate signiﬁcantly from its mean. Also, in propagation environments where the channel does not harden, using the mean of the effective gain as substitute for its true value may result in poor performance even with large numbers of antennas. The users may estimate their effective channel gain by using downlink pilots, see [2] for single-cell systems and [11] for multi-cell systems. Effectively, these downlink pilots are orthogonal between the users and beamformed along with the downlink data. The users may use, for example, linear minimum mean-square error (MMSE) techniques for the estimation of this gain. The downlink rates of multicell systems for maximum-ratio (MR) and zero-forcing',\n",
       " '1505.06807': 'Modern datasets are rapidly growing in size and complexity, and there is a pressing need to develop solutions to harness this wealth of data using statistical methods. Several ‘next generation’ data ﬂow engines that generalize MapReduce (Dean and Ghemawat, 2004) have been developed for large-scale data processing, and building machine learning functionality on these engines is a problem of great interest. In particular, Apache Spark (Zaharia et al., 2012) has emerged as a widely used open-source engine. Spark is a fault-tolerant and general-purpose cluster computing system providing APIs in Java, Scala, Python, and R, along with an optimized engine that supports general execution graphs. Moreover, Spark is eﬃcient at iterative computations and is thus well-suited for the development of large-scale machine learning applications. In this work we present MLlib, Spark’s distributed machine learning library, and the largest such library. The library targets large-scale learning settings that beneﬁt from dataparallelism or model-parallelism to store and operate on data or models. MLlib consists of fast and scalable implementations of standard learning algorithms for common learning settings including classiﬁcation, regression, collaborative ﬁltering, clustering, and dimensionality reduction. It also provides a variety of underlying statistics, linear algebra, and optimization primitives. Written in Scala and using native (C++ based) linear algebra libraries on each node, MLlib includes Java, Scala, and Python APIs, and is released as part of the Spark project under the Apache 2.0 license. MLlib’s tight integration with Spark results in several beneﬁts. First, since Spark is designed with iterative computation in mind, it enables the development of eﬃcient implementations of large-scale machine learning algorithms since they are typically iterative in nature. Improvements in low-level components of Spark often translate into performance gains in MLlib, without any direct changes to the library itself. Second, Spark’s vibrant open-source community has led to rapid growth and adoption of MLlib, including contributions from over 140 people. Third, MLlib is one of several high-level libraries built on top of Spark, as shown in Figure 1(a). As part of Spark’s rich ecosystem, and in part due to MLlib’s spark.ml API for pipeline development, MLlib provides developers with a wide range of tools to simplify the development of machine learning pipelines in practice. 2  MLlib: Machine Learning in Apache Spark 0\" 20\" 40\" 60\" 80\" 100\" 120\" 140\" 160\" v0.8\" v0.9\" v1.0\" v1.1\" v1.2\" v1.3\" v1.4\" #\"of\"Contributors\" MLlib\"version\" (a) (b) Figure 1: (a) Apache Spark ecosytem. (b). Growth in MLlib contributors. 2. History and Growth Spark was started in the UC Berkeley AMPLab and open-sourced in 2010. Spark is designed for eﬃcient iterative computation and starting with early releases has been packaged with example machine learning algorithms. However, it lacked a suite of robust and scalable learning algorithms until the creation of MLlib. Development of MLlib began in 2012 as part of the MLbase',\n",
       " '1702.00932': 'FAILED',\n",
       " '1803.07544': 'FAILED',\n",
       " '1208.0645': 'AUC (Area Under ROC Curve) is an important evaluation criterion, which has been adopted in diverse learning tasks such as cost-sensitive learning, class-imbalance learning, learning to rank, information retrieval, etc. (Elkan, 2001; Freund et al., 2003; Cortes and Mohri, 2004; Balcan et al., 2007; Ailon and Mohri, 2008; Cl´emen¸con and Vayatis, 2009; Cl´emen¸con et al., 2009; Kotlowski et al., 2011; Flach et al., 2011), where traditional criteria such as accuracy, precision, recall, etc. are inadequate (Provost et al., 1998; Provost and Fawcett, 2001) since AUC is irrelevant to class distribution. Owing to the non-convexity and discontinuousness, it is not easy, or even infeasible, to optimize AUC directly since such optimization often yields NPhard problems. To make a compromise for avoiding computational diﬃculties, pairwise surrogate losses that can be optimized more eﬃciently are usually adopted in practical algorithms, e.g., exponential loss (Freund et al., 2003; Rudin and Schapire, 2009), hinge loss (Brefeld and Scheﬀer, 2005; Joachims, 2005; Zhao et al., 2011), least square loss (Gao et al., 2013), etc. An important theoretic problem is how well does minimizing such convex surrogate losses lead to improving the actually AUC; in other words, does the expected risk of learning with surrogate losses converge to the Bayes risk of AUC? Consistency (also called Bayes consistency) guarantees that optimizing a surrogate loss will yield an optimal function with Bayes risk in the limit of inﬁnite sample. Thus, the above problem, in a formal expression, is whether the optimization of surrogate losses is consistent with AUC. 1.1. Our Contribution We ﬁrst introduce the generalized calibration for AUC optimization based on minimizing the pairwise surrogate losses, and ﬁnd that the generalized calibration is necessary yet insuﬃcient for AUC consistency. For example, hinge loss and absolute loss are calibrated but inconsistent with AUC. The deep reason is that, for pairwise surrogate losses, minimizing the expected risk over the whole distribution is not equivalent to minimizing the conditional risk on each pair of instances. We then provide a new suﬃcient condition for the AUC consistency of learning approaches based on minimizing pairwise surrogate losses. From this ﬁnding, we prove that exponential loss, logistic loss and distance-weighted loss are consistent with AUC. In addition, we derive the q-norm hinge loss and general hinge loss that are consistent with AUC. We also derive the 2  regret bounds for exponential loss and logistic loss, and present the regret bounds for more general surrogate losses in the realizable setting. Finally, we provide regret bounds that disclose the equivalence between the pairwise exponential surrogate loss of AUC and the exponential surrogate loss of accuracy; in other words, the exponential surrogate loss of accuracy is consistent AUC, while the pairwise surrogate loss of AUC is consistent with accuracy by selecting a proper threshold. One direct consequence of such ﬁnding is the equivalence between AdaBoost and RankBoost in the limit of inﬁnite sample. 1.2. Related Work The studies on AUC',\n",
       " '1608.03902': 'Time-critical analysis of social media data streams is important for many application areas [1], [2], [3]. During the onset of a crisis situation, people use social media platforms to post situational updates, look for useful information, and ask for help [4], [5]. Rapid analysis of messages posted on microblogging platforms such as Twitter can help humanitarian organizations like the United Nations gain situational awareness, learn about urgent needs of affected people, critical infrastructure damage, medical emergencies, etc. at different locations, and decide on response actions accordingly [6], [7]. Artiﬁcial Intelligence for Disaster Response1 (AIDR) is an online platform to support disaster response utilizing big crisis data from social networks [8]. During a disaster, any person or organization can provide keywords to collect tweets of interest. Filtering using keywords helps cut down the volume of the data to some extent. But, identifying different kinds of useful tweets that responders can act upon cannot be achieved using only keywords because a large number of tweets may contain the keywords but are of limited utility for the responders. The best-known solution to address this problem is to use supervised classiﬁers that 1http://aidr.qcri.org/ would separate useful tweets from the rest and classify them accordingly into informative classes. Automatic classiﬁcation of tweets to identify useful tweets is a challenging task because: (i) tweets are short – only 140 characters – and therefore, hard to understand without enough context; (ii) they often contain abbreviations, informal language, spelling variations and are ambiguous; and, (iii) judging a tweet’s utility is a subjective exercise. Individuals differ on their judgment about whether a tweet is useful or not. Classifying tweets into different topical classes posits further difﬁculties because: (i) tweets may actually contain information that belongs to multiple classes; choosing the dominant topical class is hard; and, (ii) the semantic ambiguity in the language used sometimes makes it hard to interpret the tweets. Given these inherent difﬁculties, a computer cannot generally agree with annotators at a rate that is higher than the rate at which the annotators agree with each other. Despite advances in natural language processing (NLP), interpreting the semantics of the short informal texts automatically remains a hard problem. To classify crisis-related data, traditional classiﬁcation approaches use batch learning with discrete representation of words. This approach has three major limitations. First, in the beginning of a disaster situation, there is no event labeled data available for training. Later, the labeled data arrives in small batches depending on the availability of geographically dispersed volunteers (e.g. in case of AIDR). These learning algorithms are dependent on the labeled data of the event for training. Due to the discrete word representations and the variety across events from which the big crisis data is collected, they perform poorly when trained on the data from previous events (out-of-event data). Second, training a classiﬁer from scratch every time a new batch of labeled data arrives is infeasible due to the velocity of the big crisis',\n",
       " '1505.05899': 'Ever since [1] demonstrated the large accuracy gains from using deep neural network acoustic models versus Gaussian mixture models, the Switchboard corpus has become the de facto standard experimental testbed for reporting believable and, more importantly, reproducible results for LVCSR. We surmise that this is because it is the largest publicly available dataset (up to 2300 hours of training data) composed of truly conversational speech and because, in general, techniques which result in improvements on Switchboard tend to work well on both small and large vocabulary tasks. One can think of LDA/STC, VTLN, FMLLR and lattice-based model and feature-space discriminative training which were developed ﬁrst on Switchboard and then became ubiquitous as prime examples of such techniques. Since Switchboard is such a well-studied corpus, we thought we would take a step back and reﬂect on how far we have come in terms of speech recognition technology. To set the baseline, the human word error rate on this task is estimated to be around 4% [2]. Quoting [2] again, in 1995, “a high-performance HMM recognizer” achieved a 43% WER on Switchboard [3]. In 2000, Cambridge University achieved an at the time impressive error rate of 19.3% during the Hub5e DARPA evaluation [4] which they attributed to “careful engineering”. At the height of technological development for GMM-based systems, the winning IBM submission scored 15.2% WER during the 2004 DARPA EARS Rich Transcription evaluation [5] largely due to the Attila ASR toolkit [6] and fMPE [7]. Nowadays, deep neural networks have levelled the playing ﬁeld and multiple sites can easily reach 12-14% WER using much simpler systems [8, 9, 10, 11, 12] as shown in Table 6. To achieve an error rate of 8.0% on this task is not trivial. In our opinion, a successful recipe has to contain several ingredients. The ﬁrst and most obvious one is to train larger acoustic and language models on more data. The second (a little less obvious) is to train neural nets that have diverse architectures and operate on different input representations so that we get accuracy gains from both feature and model combination. Third, extra “spice” such as networks with maxout nonlinearities and exponential and NN language models were also found to signiﬁcantly lower the error rate of our system. Last but not least, it is our experience that having a strong GMM-HMM baseline system [6, 13] which provides high-quality alignments used for the various speaker adaptation techniques and for DNN crossentropy training helps. The paper is organized as follows: in section 2 we describe the processing steps that are common across all models, in section 3 we present a set of system improvements, and in section 4 we summarize our ﬁndings and ponder future opportunities for improvement. 2. General processing Here we describe the common processing steps for all the models detailed in this paper. In particular, we discuss frontend processing, speaker adaptation and neural network training',\n",
       " '1406.5311': 'Assume that we have a d × n matrix A representing n points a1, ..., an in Rd. In this paper, we will be concerned with linear feasibility problems that ask if there exists a vector w ∈Rd that makes positive dot-product with every ai, i.e. ?∃w : ATw > 0, (P) where boldfaced 0 is a vector of zeros. The corresponding algorithmic question is “if (P) is feasible, how quickly can we ﬁnd a w that demonstrates (P)’s feasibility?”. Such problems abound in optimization as well as machine learning. For example, consider binary linear classiﬁcation - given n points xi ∈Rd with labels yi ∈{+1, −1}, a classiﬁer w is said to separate the given points if wTxi has the same sign as yi or succinctly yi(wTxi) > 0 for all i. Representing ai = yixi shows that this problem is a speciﬁc instance of (P). 1 arXiv:1406.5311v2  [math.OC]  29 Jan 2016  We call (P) the primal problem, and (we will later see why) we deﬁne the dual problem (D) as: ?∃p ≥0 : Ap = 0, p ̸= 0, (D) and the corresponding algorithmic question is “if (D) is feasible, how quickly can we ﬁnd a certiﬁcate p that demonstrates feasibility of (D)?”. Our aim is to deepen the geometric, algebraic and algorithmic understanding of the problems (P) and (D), tied together by a concept called margin. Geometrically, we provide intuition about ways to interpret margin in the primal and dual settings relating to various balls, cones and hulls. Analytically, we prove new margin-based versions of classical results in convex analysis like Gordan’s and Hoﬀman’s theorems. Algorithmically, we give new insights into the classical Perceptron algorithm. We begin with a gentle introduction to some of these concepts, before getting into the details. Notation When we write v ≥w for vectors v, w, we mean vi ≥wi for all their indices i (similarly v ≤w, v = w). To distinguish surfaces and interiors of balls more obviously to the eye in mathematical equations, we choose to denote Euclidean balls in Rd by # := {w ∈Rd : ∥w∥= 1},  := {w ∈Rd : ∥w∥≤1} and the probability simplex Rn by △:= {p ∈Rn : p ≥0, ∥p∥1 = 1}. We denote the linear subspace spanned by A as lin(A), and convex hull of A by conv(A). Lastly, deﬁne  A :=  ∩lin(A) and r is the ball of radius r (#A, r# are similarly deﬁned). 1.1 Margin ρ The margin of the problem instance A is classically deﬁned as ρ := sup w∈# inf p∈△wTAp (1) = sup w∈# inf i wTai. If there is a w such that ATw > 0, then ρ > 0. If for all w, there is a point at an obtuse angle to it, then ρ < 0. At the boundary ρ can be zero. The w ∈# in the deﬁnition is important – if it were w ∈ , then ρ would be non-negative, since w = 0 would be allowed. This deﬁnition of margin was introduced by Goﬃn [13] who gave several geometric interpretations. It has since been extensively studied (for example, [20, 21] and [4]) as a notion',\n",
       " '1109.4994': 'We live in a world that, like a digital photograph, has only ﬁnite resolution. This was ﬁrst recognized in statistical mechanics, when Planck introduced a ﬁnite grain-size h to get a realistic counting of distinct states [1, 2]. Once it was understood that h relates all energy and momentum to waves [3, 4], ﬁnite resolution was explained as a property of waves: a tradeoﬀbetween range of frequencies superposed and maximum localization [5–19]. There is also a tradeoﬀ, in superpositions of waves, between frequency range and average localization. This is known in communications theory as the Nyquist bound: a ﬁnite bandwidth signal can carry only a ﬁnite number of distinct values per unit length. This holds because a ﬁnite number of Fourier components can add up to chosen values at only a ﬁnite number of places [20]. In this paper, we combine and generalize these tradeoﬀs. We count how many quantum states can be distinguished from each other with certainty, in a ﬁnite time or distance, given average constraints on wavefunction bandwidth. These certainty bounds redeﬁne energy and momentum as maximum counts, and challenge the distinction between continuous and discrete in physics. To illustrate the connection between bandwidth and distinct quantum states, consider a free particle moving in one dimension, in a periodic space of length L. Momentum eigenstates must have a whole number of oscillations in period L, so allowed spatial frequencies pn/h are 1/L apart. A wavefunction using N diﬀerent spatial frequencies must have at least N−1 times this minimal separation, between minimum and maximum frequencies: pmax −pmin h ≥N −1 L . (1) This is a bandwidth bound for a superposition of N distinct energy-momentum eigenstates. It also bounds the total number of distinct states that can occur as the particle moves a distance L: N distinct eigenstates can add up to at most N distinct sums. Similar arguments apply to energy and time, for an evolution periodic in time [26]. More generally, any absolute moment of energy or momentum is an average measure of the frequency-width of the wavefunction, and can play the role that momentumbandwidth does in (1), determining a maximum count of distinct states for any portion of any evolution with that moment. For N = 2 these tradeoﬀs become minimum uncertainty relations. To achieve the maximum count, the wavefunction must use a ﬁnite range of frequencies. Then the exact evolution can be interpolated from the state on a discrete set of points in space and time [21–35]. Perhaps the most interesting moment is average energy above the minimum possible [13]. What we call energy classically, counts how many distinct states can occur in a unit of time. How much change. How many distinct computational steps. We can also count just the distinct states due to overall motion, by comparing energy counts in rest and non-rest frames. Surprisingly, motional change is bounded not by the',\n",
       " '1505.02186': 'In [22] Koetter and Kschischang developed an approach to random network coding where the encoded information is represented as subspaces of a given ambient space. This accounts for the unknown network topology by assuming that any linear combination of packets may occur at the nodes of the network. This approach has led to the area of subspace codes and speciﬁcally to intensive research eﬀorts on constructions of subspace codes with large subspace distance [23, 21, 25, 10, 14, 9, 16, 12, 15, 11, 24, 29, 17]. Most of the research focuses on constant-dimension codes (CDC’s), that is, codes where all subspaces have the same dimension. One direction for constructing CDC’s is based on so-called cyclic orbit codes [23, 9, 24, 29, 17], which are orbits of a subspace in the Fq-vector space Fqn under the natural action of F∗ q. While the resulting codes have very beneﬁcial algebraic structure, they do not have large cardinality in general. Taking unions of such codes leads to cyclic subspace codes which still have nice structure, but it remains an open problem how to take unions of cyclic orbit codes without decreasing the distance. A second major research direction is based on rank-metric codes as introduced and studied earlier by Delsarte [6] and Gabidulin [13]. Lifting rank-metric codes [26] is a very simple construction which results in subspace codes where the reduced row echelon form of each subspace has its identity matrix in the leftmost position. While these codes are asymptotically good [21], they can still be improved upon. Through a careful study of general reduced row echelon forms, ∗HGL was partially supported by the National Science Foundation Grant DMS-1210061. HGL and CT are with the Department of Mathematics, University of Kentucky, Lexington KY 40506-0027, USA; {heide.gl, carolyn.troha}@uky.edu. 1  Etzion and Silberstein [10] could enlarge lifted rank-metric codes. This is known as the echelonFerrers construction (or multilevel construction) and has led to the best codes known at that time. In the same paper it is also demonstrated how to decode these codes. In [11] the same authors could enlarge their codes even further by making use of the pending dot construction initiated by Trautmann/Rosenthal [30]. A diﬀerent way of enlarging lifted rank-metric codes has been presented by Skachek in [27], where for a speciﬁc case of the resulting codes also a decoding algorithm is developed. A slightly diﬀerent approach is taken in [12, Sec. III] by Etzion/Vardy and [19] by Gorla/Ravagnani. Therein, the authors focus on CDC’s with the best theoretical distance. This distance is achieved when any two distinct subspaces of the code intersect trivially. In [12, 19] the authors present constructions of such codes with large cardinality (in fact, the same cardinality). In ﬁnite projective geometry, collections of pairwise trivially intersecting subspaces are known as partial spreads, or as spreads if the subspace',\n",
       " '1505.02417': 'The majority of problems in statistical estimation can be cast as ﬁnding the parameter value θ⋆∈Θ such that θ⋆= arg min θ∈Θ E (L(θ, ξ)) , (1) where the expectation is with respect to the random variable ξ ∈Ξ ⊆Rd that represents the data, Θ ⊆Rp is the parameter space, and L : Θ×Ξ →R is a loss function. A popular procedure for solving Eq.(12) is stochastic gradient descent (sgd) (Zhang, 2004; Bottou, 2004), where a sequence θn approximates θ⋆, and is updated iteratively, one data point at a time, through the iteration θn = θn−1 −γn∇L(θn−1, ξn), (2) Appearing in Proceedings of the 19th International Conference on Artiﬁcial Intelligence and Statistics (AISTATS) 2016, Cadiz, Spain. JMLR: W&CP volume 41. Copyright 2016 by the authors. where {ξ1, ξ2, . . .} is a stream of i.i.d. realizations of ξ, and {γn} is a non-increasing sequence of positive real numbers, known as the learning rate. The nth iterate θn in sgd (2) can be viewed as an estimator of θ⋆. To evaluate such iterative estimators it is typical to consider three properties: convergence rate and numerical stability, by studying the mean-squared errors E \\x00||θn −θ⋆||2\\x01 ; and statistical eﬃciency, by studying the limit nVar (θn), as n →∞. While computationally eﬃcient, the sgd procedure (2) suffers from numerical instability and statistical ineﬃciency. Regarding stability, sgd is sensitive to speciﬁcation of the learning rate γn, since the mean-squared errors can diverge arbitrarily when γn is misspeciﬁed with the respect to problem parameters, e.g., the convexity and Lipschitz parameters of the loss function (Benveniste et al., 1990; Moulines and Bach, 2011). Regarding statistical eﬃciency, sgd loses statistical information. In fact, the amount of information loss depends on the misspeciﬁcation of γn with respect to the spectral gap of the matrix E \\x00∇2L(θ⋆, ξ) \\x01 (Toulis et al., 2014), also known as the Fisher information matrix. Several solutions have been proposed to resolve these two issues, e.g., using projections and gradient clipping. However, they are usually heuristic and hard to generalize. In this paper, we aim for the ideal combination of computational eﬃciency, numerical stability, and statistical eﬃciency using the following procedure: ai-sgd θn = θn−1 −γn∇L(θn, ξn), (3) ¯θn = (1/n) n X i=1 θi. (4) Our proposed procedure, termed averaged implicit sgd (ai-sgd), is comprised of two inner procedures. The ﬁrst procedure employs updates given in Eq.(3), which are implicit because the iterate θn appears on both sides of the equation. Procedure (3), also known as implicit SGD (Toulis et al., 2014), aims to stabilize the updates of the classic sgd procedure (2). In fact, implicit sgd can be motivated as the limit of a sequence of improved classic sgd procedures. To see this, ﬁrst ﬁx the sample history Fn−1 = {θs 0, ξ1, ξ2, . . . , ξn−1}, where we use the superscript “s” in the classic sgd procedure',\n",
       " '1309.0790': 'In modern astronomy, one is increasingly faced with the problem of analysing large, complicated and multidimensional data sets. Such analyses typically include tasks such as: data description and interpretation, inference, pattern recognition, prediction, classiﬁcation, compression, and many more. One way of performing such tasks is through the use of machine learning methods. For accessible accounts of machine learning and its use in astronomy, see, for example, MacKay (2003), Ball & Brunner (2010) and Way et al. (2012). Moreover, machine learning software easily used for astronomy, such as the Python-based ASTROML package1, or C-based Fast Artiﬁcial Neural Network Library (FANN2) have recently started to become available. Two major categories of machine learning are: supervised ⋆Email: philip.b.graff@gmail.com † Email: f.feroz@mrao.cam.ac.uk 1 http://astroml.github.com/ 2 http://leenissen.dk/fann/wp/ learning and unsupervised learning. In supervised learning, the goal is to infer a function from labeled training data, which consist of a set of training examples. Each example has both ‘properties’ and ‘labels’. The properties are known ‘input’ quantities whose values are to be used to predict the values of the labels, which may be considered as ‘output’ quantities. Thus, the function to be inferred is the mapping from properties to labels. Once learned, this mapping can be applied to datasets for which the values of the labels are not known. Supervised learning is usually further subdivided into classiﬁcation and regression. In classiﬁcation, the labels take discrete values, whereas in regression the labels are continuous. In astronomy, for example, using multifrequency observations of a supernova lightcurve (its properties) to determine its type (e.g. Ia, Ib, II, etc.) is a classiﬁcation problem since the label (supernova type) is discrete (see, e.g., Karpenka, Feroz & Hobson 2013), whereas using the observations to determine (say) the energy output of the supernova explosion is a regression problem, since the label (energy output) is continuous. Classiﬁcation can also be used to obtain a distribution for an output value that would normally be treated as a regression problem. This is demonstrated by Bonnett c⃝2013 RAS arXiv:1309.0790v2  [astro-ph.IM]  27 Jan 2014  2 P. Graff et al. (2013) for measuring redshifts in CFHTLenS. A particularly important recent application of regression supervised learning in astrophysics and cosmology (and beyond) is the acceleration of the statistical analysis of large data sets in the context of complicated models. In such analyses, one typically performs many (∼104−6) evaluations of the likelihood function describing the probability of obtaining the data for different sets of values of the model parameters. For some problems, in particular in cosmology, each such function evaluation can take up to tens of seconds, making the analysis very computationally expensive. By performing regression supervised learning to infer and then replace the mapping between model parameters and likelihood value, once can reduce the computation required for each likelihood evaluation by several orders of magnitude, thereby vastly accelerating the analysis (see, e.g., Fendt',\n",
       " '1611.05162': 'In the context of universal approximation, neural networks can represent functions of arbitrary complexity when the network is equipped with suﬃciently large number of layers and neurons [17]. Such model ﬂexibility has made the artiﬁcial deep neural network a pioneer machine ∗A. Aghasi was previously with the Department of Mathematical Sciences, IBM T.J. Watson Research Center and is currently with the Georgia State School of Business. N. Nguyen is with the IBM T.J. Watson Research Center. A. Abdi and J. Romberg are with the Department of Electrical and Computer Engineering, Georgia Institute of Technology. Contact: aaghasi@gsu.edu 1 arXiv:1611.05162v4  [cs.LG]  23 Nov 2017  learning tool over the past decades (see [20] for a comprehensive review of deep networks). Basically, given unlimited training data and computational resources, deep neural networks are able to learn arbitrarily complex data models. In practice, the capability of collecting huge amount of data is often restricted. Thus, learning complicated networks with millions of parameters from limited training data can easily lead to the overﬁtting problem. Over the past years, various methods have been proposed to reduce overﬁtting via regularizing techniques and pruning strategies [19, 14, 21, 24]. However, the complex and non-convex behavior of the underlying model barricades the use of theoretical tools to analyze the performance of such techniques. In this paper, we present an optimization framework, namely Net-Trim, which is a layerwise convex scheme to sparsify deep neural networks. The proposed framework can be viewed from both theoretical and computational standpoints. Technically speaking, each layer of a neural network consists of an aﬃne transformation (to be learned by the data) followed by a nonlinear unit. The nested composition of such mappings forms a highly nonlinear model, learning which requires optimizing a complex and non-convex objective. Net-Trim applies to a network which is already trained. The basic idea is to reduce the network complexity layer by layer, assuring that each layer response stays close to the initial trained network. More speciﬁcally, the training data is transmitted through the learned network layer by layer. Within each layer we propose an optimization scheme which promotes weight sparsity, while enforcing a consistency between the resulting response and the trained network response. In a sense, if we consider each layer response to the transmitted data as a checkpoint, Net-Trim assures the checkpoints remain roughly the same, while a simpler path between the checkpoints is discovered. A favorable leverage of Net-Trim is the possibility of convex formulation, when the ReLU is employed as the nonlinear unit across the network. Figure 1 demonstrates the pruning capability of Net-Trim for a sample network. The neural network used for this example classiﬁes 200 points positioned on the 2D plane into two separate classes based on their label. The points within each class lie on nested spirals to classify which we use a neural network with two hidden layers of each 200 neurons (the reader is referred to the',\n",
       " '0911.5703': 'A category is a kind of thing (object, event, action, trait or state). To categorize is to do the right thing (eat, ﬁght, ﬂee, mate, etc.) with the right kind of thing. All species can acquire categories through trial and error sensorimotor induction. We are the only species that can also acquire and transmit categories through verbal instruction, by naming and deﬁning them. The words in our dictionaries are almost all the names of categories, followed by their deﬁnitions. In principle, all 1  categories can be acquired through verbal deﬁnition, but we cannot acquire all of them that way: we have to know the meanings of some of the deﬁning words already, by some other means. This is the “symbol grounding problem” [4] and presumably that other means of acquiring categories is sensorimotor induction. But how many words – and which ones – need to be grounded directly through sensorimotor induction in order to allow all the rest to be acquired through verbal deﬁnition? We have been analyzing dictionaries in order to answer this question. By eliminating all the words that can be reached from other words through deﬁnition alone, we have been able to reduce the dictionary to its “grounding kernel” (GK) – a set of words (about 10%) – out of which all the rest of the words can be reached through deﬁnition alone [1]. The GK has some striking properties: The words in it are learned at a signiﬁcantly younger age than the rest of the dictionary and are also more concrete [2], but if the variance correlated with age is removed, the residual GK words are more abstract than the rest of the dictionary. What is the cause of this polarity shift? The GK is unique, and sufﬁcient to ground all the rest of the dictionary, but it is not minimal – it is not the smallest set of words from which all the rest can be reached via deﬁnition alone. That would be a “minimum grounding set” (MGS), which is not in general unique; we have not yet been able to compute a MGS, because this problem (equivalent to ﬁnding a “minimum cardinality feedback vertex set” for a general graph) is NP-complete (i.e. too hard to compute in general). We hope to be able to compute MGSs for our special cases, but meanwhile the GKs of our dictionaries – Cambridge International Dictionary of English (CIDE) [8] and Longman Dictionary of Contemporary English (LDOCE) [7] – already turn out to have more differentiated internal substructure which we begin analyzing further in this article. In particular two substructures play important roles: the GK itself and a strongly connected subset of the GK that we call the “Kernel Core” (KC). The GK words that are acquired earlier, and are more concrete than the rest of the dictionary, tend to be in the KC, whereas the GK words uncorrelated with age of acquisition tend to be in the outer layer surrounding the KC and are more abstract. These correlations between the KC and',\n",
       " '1804.08597': 'The combination of classical Reinforcement Learning (RL) with deep neural networks has achieved human-level competence at solving some difﬁcult problems, especially with the use of Deep QNetworks (DQN) at solving games[15, 17, 20]. There is no doubt that Deep Reinforcement Learning (DRL) has offered new perspectives to the areas of automation and Artiﬁcial Intelligence (AI), but despite their success, DRL seems unable to tackle a number of problems that are considered relatively simple for humans to solve. DRL requires large training data sets, thus learning slowly. A trained deep network performing very well in one task will often perform poorly in another, analogous (sometimes very similar) task. Finally, DRL lacks interpretability, being criticized frequently for being a “black-box” model. Some authors have tried to address the above shortcomings by adding prior knowledge to neural networks in general, and more recently to RL [4, 8, 11, 24]. In [5], it is argued that combining aspects of symbolic AI with neural networks and Reinforcement Learning could solve at once all of the above shortcomings. Such ideas are then instantiated in a computational system called Deep Symbolic Reinforcement Learning (DSRL). DSRL uses convolutional neural networks which, applied to navigation tasks typically consisting of negotiating obstacles (objects) and ﬁnding optimal paths or collecting other objects, can learn relevant object types from images, thus building a more abstract symbolic representation of the state-space, which is followed by a Q-learning algorithm for learning a policy on this state-space. Despite the fact that DSRL does not learn as effectively as DQN in arXiv:1804.08597v1  [cs.LG]  23 Apr 2018  a deterministic environment, DSRL was shown to outperform DQN when the policy learned in a deterministic environment is transferred to a random environment, thus indicating the value of using a more abstract, symbolic representation. In this paper, we seek to reproduce the DSRL system with some simpliﬁcations. We have implemented this simpliﬁed, but also more generic system, which we refer to as Symbolic Reinforcement Learning (SRL). For the sake of analysis, it is desirable to separate within SRL, learning and decision-making from the object recognition part of the system, this latter part carried out in DSRL by convolutional neural networks. Such a separation allows us to focus the analysis of performance on the learning and decision making by providing the symbols and positions of the objects directly to the SRL system. Aspects of type transition and symbol interaction dealt with by DSRL are not analyzed in this paper. We also propose an extension of SRL called Symbolic Reinforcement Learning with Common Sense (SRL+CS). SRL+CS makes one modiﬁcation to the learning of SRL and one modiﬁcation to the decision-making. This is then shown empirically to be sufﬁcient for producing a considerable improvement in performance by comparison with various other algorithms. Differently from SRL, in SRL+CS only the states containing objects with which an agent interacts have their Q-values updated when rewards are non-zero (let',\n",
       " '1701.07717': 'Unsupervised learning can serve as an important auxiliary task to supervised tasks [14, 29, 11, 28]. In this work, we propose a semi-supervised pipeline that works on the original training set without an additional data collection process. First, the training set is expanded with unlabeled data using a GAN. Then our model minimizes the sum of the supervised and the unsupervised losses through a new ∗To whom all correspondence should be addressed. Figure 1. The pipeline of the proposed method. There are two components: a generative adversarial model [27] for unsupervised learning and a convolutional neural network for semi-supervised learning. “Real Data” represents the labeled data in the given training set; “Training data” includes both the “Real Data” and the generated unlabeled data. We aim to learn more discriminative embeddings with the “Training data”. regularization method. This method is evaluated with person re-ID, which aims to spot the target person in different cameras. This has been recently viewed as an image retrieval problem [50]. This paper addresses three challenges. First, current research in GANs typically considers the quality of the sample generation with and without semi-supervised learning in vivo [24, 32, 27, 7, 26, 41]. Yet a scientiﬁc problem remains unknown: moving the generated samples out of the box and using them in currently available learning frameworks. To this end, this work uses unlabeled data produced by the DCGAN model [27] in conjunction with the labeled training data. As shown in Fig. 1, our pipeline feeds the newly generated samples into another learning machine (i.e. a CNN). Therefore, we use the term “in vitro” to differentiate our method from [24, 32, 27, 7]; these methods perform semi-supervised learning in the discriminator of the GANs (in vivo). Second, the challenge of performing semi-supervised learning using labeled and unlabeled data in CNN-based methods remains. Usually, the unsupervised data is used as a pre-training step before supervised learning [28, 11, 14]. Our method uses all the data simultaneously. In [25, 18, 24, 32], the unlabeled/weak-labeled real data are assigned  labels according to pre-deﬁned training classes, but our method assumes that the GAN generated data does not belong to any of the existing classes. The proposed LSRO method neither includes unsupervised pre-training nor label assignments for the known classes. We address semisupervised learning from a new perspective. Since the unlabeled samples do not belong to any of the existing classes, they are assigned a uniform label distribution over the training classes. The network is trained not to predict a particular class for the generated data with high conﬁdence. Third, in person re-ID, data annotation is expensive, because one has to draw a pedestrian bounding box and assign an ID label to it. Recent progress in this ﬁeld can be attributed to two factors: 1) the availability of large-scale reID datasets [49, 51, 44',\n",
       " '1704.05753': 'Paraphrases are useful for a range of tasks, including machine translation evaluation (Kauchak and Barzilay, 2006), semantic parsing (Wang et al., 2015), and question answering (Fader et al., 2013). Crowdsourcing has been widely used as a scalable and cost-effective means of generating paraphrases (Negri et al., 2012; Wang et al., 2012; Tschirsich and Hintz, 2013), but there has been limited analysis of the factors inﬂuencing diversity and correctness of the paraphrases workers write. In this paper, we perform a systematic investigation of design decisions for crowdsourcing paraphrases, including the ﬁrst exploration of worker incentives for paraphrasing. For worker incentives, we either provide a bonus payment when a paraphrase is novel (encouraging diversity) or when it matches a paraphrase from another worker (encouraging agreement/correctness). We also varied the type of example paraphrases shown to workers, the number of paraphrases requested from each worker per sentence, the subject domain of the data, whether to show answers to questions, and whether the prompt sentence is the same for multiple workers or varies, with alternative prompts drawn from the output of other workers. Effective paraphrasing has two desired properties: correctness and diversity. To measure correctness, we hand-labeled all paraphrases with semantic equivalence and grammaticality scores. For diversity, we measure the fraction of paraphrases that are distinct, as well as Paraphrase In N-gram Changes (PINC), a measure of n-gram variation. We have released all 2,600 paraphrases along with accuracy annotations. Our analysis shows that the most important factor is how workers are primed for a task, with the choice of examples and the prompt sentence affecting diversity and correctness signiﬁcantly. 2 Related Work Previous work on crowdsourced paraphrase generation ﬁts into two categories: work on modifying the creation process or workﬂow, and studying the effect of prompting or priming on crowd worker output. Beyond crowdsourced generation, other work has explored using experts or automated systems to generate paraphrases. 2.1 Workﬂows for Crowd-Paraphrasing The most common approach to crowdsourcing paraphrase generation is to provide a sentence as a prompt and request a single paraphrase from a worker. One frequent addition is to ask a different set of workers to evaluate whether a generated paraphrase is correct (Buzek et al., 2010; Burrows et al., 2013). Negri et al. (2012) also explored an alternate workﬂow in which each worker writes  two paraphrases, which are then given to other workers as the prompt sentence, forming a binary tree of paraphrases. They found that paraphrases deeper in the tree were more diverse, but understanding how correctness and grammaticality vary across such a tree still remains an open question. Near real-time crowdsourcing (Bigham et al., 2010) allowed Lasecki et al. (2013a) to elicit variations on entire conversations by providing a setting and goal to pairs of crowd workers. Continuous real-time crowdsourcing (Lasecki et al., 2011) al',\n",
       " '1708.04968': 'Mobile apps are typically available for download at digital distribution platforms like Google Play Store and Apple Store. Once a user has downloaded and used an app, these distribution platforms also allow the user to enter feedback about the app. Te feedback is received in the form of a review comment and an associated star rating. Te star rating ranges from one to ﬁve stars with one star denoting extreme dissatisfaction with an app and ﬁve stars denoting high satisfaction. Te review comments and star ratings are very important as studies and our survey show that users typically download an app based on these factors [9]. As ratings are an important factor in determining the download of an app, it is imperative that ratings be accurate i.e., a rating accurately reﬂects the experience of the user with the app. However, a study [3] and our investigations suggest that ofen the star rating given by a user is not consistent with the opinion expressed in the review comment. Consider the following review text for the Instagram app on Android. “Love instagram it’s the best in the world Love it it’s the best in the world” (sic) One would reasonably expect that due to the highly positive sentiment expressed in the review, the associated star rating would be ﬁve stars, but the actual star rating is one star! Such mismatches bring down the average rating of an app, which can adversely aﬀect future downloads of the app (especially for small and upcoming apps without many downloads). Review rating mismatches can occur due to a variety of reasons; one reason could be that novice end users may simply be confused about the diﬀerence between one and ﬁve stars [3]. On the other end, a negative opinion accompanied by ﬁve stars could happen due to the following reason: A user may initially provide a rating of ﬁve stars to an app due to a positive experience. Review systems allow users to simply rate without an explicit review comment. Later on, the user may have a negative experience with the app, (usually afer an update). He may then write about his problems with the app, but may forget to update the rating to accurately reﬂect his current review text. Tus, a review with a largely negative opinion can have a high rating of ﬁve stars. Tis hypothesis is in fact conﬁrmed by our survey responses in Section 2 In this paper, we perform a study of this review rating mismatch problem. We ﬁrst establish by means of a user survey and manual study that the review rating mismatch problem is prevalent across arXiv:1708.04968v2  [cs.LG]  11 Aug 2018  CoDS-COMAD, Jan 11-13, 2018, Goa, India Rahul Aralikate, Giriprasad Sridhara, Neelamadhav Gantayat, and Senthil Mani popular apps on Android. We also establish the need for a system which can automatically detect inconsistencies between reviews and ratings. We then show that the development of such an automated system is',\n",
       " '1709.02082': 'FAILED',\n",
       " '1812.10617': 'Magnetic-resonance imaging (MRI), a non-invasive, nonionizing and high-ﬁdelity visualization technology, has found widespread applications in cardiac-cine, dynamic contrastenhanced and neuro-imaging, playing a key role in medical research and diagnosis [1]. MRI’s inherent limitations and various physiological constraints often incur slow data acquisition, while long scanning times make MRI an expensive process, may cause patient discomfort, and hinder thus its usefulness. Raw MRI data are observed in the k-space domain; the image (visual) data are computed by the inverse Fourier transform of the k-space ones [1]. A prominent way to speed up data acquisition is to sample the k-space or frequency domain densely enough to ensure reconstruction of a high-ﬁdelity and artifact-free image via Fourier-transform arguments [2]. In the case of dynamic (d)MRI, where an extra-temporal dimension is added to the spatial domain, sampling is also performed along the time axis. Due to MRI’s slow scanning times, it becomes difﬁcult for the data acquisition process to keep up with the motion of the organs or the ﬂuid ﬂow in the ﬁeld of view (FOV) [1]. It is a usual case to not be able to reach the necessary sampling density, not only in the temporal direction but also in the k-space domain, to guarantee artifact-free reconstructed images. This “under-sampling” inﬂicts signal aliasing and distortion [3]. Naturally, a lot of the MRI-research effort has been focusing on developing reconstruction algorithms that improve the spatio-temporal resolution of MR images given the highly under-sampled k-space data. To this end, artiﬁcial-intelligence (AI) approaches have been very recently placed at the focal point of MRI research; examples are convolutional neural networks (CNNs) [4]–[9], deep variational networks(VNs) [10], and generative adversarial neural networks (GANs) [11], [12]. AI methods learn non-linear mappings via extensive ofﬂine training on large-scale datasets, different from or in addition to the acquired data, and use those learned non-linear mappings to map the observed low-resolution, or, undersampled data to their high-ﬁdelity counterparts. In contrast to the data-driven AI methods, the present work, as well as the following priorart schemes, assume no ofﬂine training on large-scale datasets and resort solely to the observed data. A popular approach to exploit the underlying spatiotemporal patterns within dMRI data is compressed sensing (CS) [13]–[16]. Low-rank structures [17], [18] and totalvariation-based schemes [19]–[21] have also been explored at length and found to produce promising results for slow varying dynamic data. For instance, [18] proposes the estimation, ﬁrst, of a temporal basis of image time series via singular-value decomposition, prior to formulating a sparsity inducing convexrecovery task. Nevertheless, these schemes seem to be less effective when it comes to dMRI with extensive inter-frame motion or with a low number of temporal frames, as mentioned in [22], [23]. Acceleration capabilities of CS combined',\n",
       " '1806.09792': 'China is known as “the kingdom of poetry”. This is not only because of the long history of Chinese poetry, but also the number of poets and works, which has a special and signiﬁcant place in Chinese social life and cultural development. Poetry is the carrier of language, the most original and the most authentic art. It is engraved with human reason and emotion, wise and thought, imagination and shouting, rough and smooth. There are several writing formats for Chinese Tang poetry, among which quatrain is perhaps the best-known one which requires strict rules including words, rhyming, tone and antithesis, we illustrate an example of famous quatrains in Figure 1. 1) Words. The quatrain consists of 4 lines of sentences, and the length of each line is ﬁxed to 5 or 7 characters. 2) Rhyming. The syllables of Chinese characters are composed of initials and ﬁnals. Rhyming words must have same ﬁnals. Poetry pays attention to the beauty of melody and rhythm. Therefore, the Chinese poetry must rhyme. Rhyme means to put the same rhyme in the same place, usually at the end of a sentence (the underlined characters in Figure 1). 3) Tone. This is the character of Chinese. The height, the rise and fall and the length of speech form the tones of Chinese. The four ancient sounds were:level tone, rising tone, fallingtone, and entering tone. The relationship between the four tones and the rhyme is very close. The words in different tones usually can’t rhyme. Poets divided the four voices into two broad categories: Ping (level tone) or Ze (down-ward Fig. 1. An example of 5-character quatrains. The poet wrote the poem moved by the sight on the left of the ﬁgure. The rhyming characters are shown in underline. The tone of each character is shown at the end of each line (within parentheses); P and Z are short-hands for Ping and Ze tones respectively; * indicates that the tone is not ﬁxed and can be either. tone). The Ping and Ze alternates in the verses according to certain rules, so that the tone is diversiﬁed rather than monotonous. Writing a good poem is difﬁcult and poets need to master profound literary skills. It is hard to master such skills for ordinary people. In recent years, automatic Chinese poetry generation has made great progress. There are several different kinds of approaches to generate poems. One of the most promising approaches is taking the generation of Chinese poem lines as a sequence-to-sequence learning problem [1], [2]. The RNN Encoder-Decoder model with attention mechanism [3], [4] is employed to generate Chinese poems. It has been shown that this sequence-to-sequence (seq2seq) neural model can successfully generate Chinese poems [5], [6]. However, there are still some defects in these existing approaches: (i) These methods can only generate a poem with a given ﬁrst line or the user’s intention, and often generate non-thematic poetry or the theme of',\n",
       " '1707.03377': '3 2 Deﬁnition of Deep Symbolic Networks 4 2.1 Recursive hierarchical model . . . . . . . . . . . . . . . . . . . . . 4 2.2 Identifying operators of symbols . . . . . . . . . . . . . . . . . . 4 3 Structure and properties of Deep Symbolic Networks 5 3.1 Links between the symbols . . . . . . . . . . . . . . . . . . . . . 5 3.1.1 Links by the composition relationship . . . . . . . . . . . 6 3.1.2 Links by the inheritance relationship . . . . . . . . . . . . 6 3.1.3 Links by dependence . . . . . . . . . . . . . . . . . . . . . 6 3.1.4 Links by causality . . . . . . . . . . . . . . . . . . . . . . 8 3.1.5 Links by abstraction . . . . . . . . . . . . . . . . . . . . . 8 3.1.6 Higher order links . . . . . . . . . . . . . . . . . . . . . . 8 3.1.7 Links can also be represented by symbols . . . . . . . . . 8 3.2 Dynamics, interactions and processes . . . . . . . . . . . . . . . . 9 3.2.1 Dynamics . . . . . . . . . . . . . . . . . . . . . . . . . . . 9 3.2.2 Interactions . . . . . . . . . . . . . . . . . . . . . . . . . . 9 3.2.3 Processes . . . . . . . . . . . . . . . . . . . . . . . . . . . 9 3.3 Storing the Deep Symbolic Networks (DSN) to storage media . . 11 3.4 Use of the Deep Symbolic Networks (DSN) . . . . . . . . . . . . 11 3.4.1 General principles of statistical inference and object generating . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11 3.4.2 Deep Symbolic Networks (DSN) for survival . . . . . . . . 12 3.4.3 Automatic coding . . . . . . . . . . . . . . . . . . . . . . 13 4 Learning of the Deep Symbolic Networks (DSN) model from data 14 4.1 Identifying operators . . . . . . . . . . . . . . . . . . . . . . . . . 14 4.2 Unsupervised learning . . . . . . . . . . . . . . . . . . . . . . . . 16 4.3 Supervised learning . . . . . . . . . . . . . . . . . . . . . . . . . . 17 5 Experiment 18 6 Conclusion 19 2  1 Introduction Deep learning[5] has achieved great success in many machine learning or artiﬁcial intelligence (AI) areas, and it is attracting the attention of the entire scientiﬁc community[2]. In this paper, we study the general AI problem from a statistical physics point of view, and introduce a Deep Symbolic Networks (DSN) model to generalize the Deep Neural Networks (DNN) model in Deep learning. The Deep Symbolic Networks (DSN) model aims at solving the drawback of Deep learning that the obtained models remain black-boxes[3]. In other words, DSN aims at becoming a white-box version of DNN. We study the problem from a diﬀerent angle than DNN, by naturally combining the DNN’s structure with the methodologies (i) of Statistical Physics dealing with the micro-macro problem and (ii) of complex system theory dealing with emergence and hierarchies [9]. In a nutshell, these theories describe the world in a deep, hierarchical structure. Indeed, physical matter constituting the Universe, i.e. anything occupying some space and having some mass, is made of elements. All these matter pieces are organised in many composition layers, from the microscopic level to the macroscopic level. From the micro to the macro levels, atoms make molecules, molecules make cells, cells make organs and body parts, organs and body parts make plants, animals (and human beings). Animals form communities, people form societies, states, nations, unions... Soil particles makes lands, water drops make rivers and oceans. Lands and rivers make continents, continents and oceans make our Earth. The Sun, our Earth and other planets make our solar system, billions of solar systems make our galaxy, and billions of galaxies make the known universe. Similarly, from the macro to the micro levels, atoms have their own hierarchical structures, formed of a nucleus',\n",
       " '1710.07990': 'Markov Decision Processes (MDP) is the standard framework for optimal sequential decision making under uncertainty [1]. However, this framework assumes that the decision maker, customary referred to as the “agent,” is perfectly rational [2]. That ∗D. Larsson is a PhD student with the D. Guggenheim School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, GA, 30332-0150, USA. Email: daniel.larsson@gatech.edu †D. Braun is a Professor with the Institute of Neural Information Processing, Ulm University, D-89081 Ulm, Germany. Email: daniel.braun@uni-ulm.de ‡P. Tsiotras is a Professor with the D. Guggenheim School of Aerospace Engineering and the Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, 30332-0150, USA. Email: tsiotras@gatech.edu The work of DL and PT has been supported by ONR award N00014-13-1-0563 and of DB by project ERC STG BRISC 678082. arXiv:1710.07990v1  [cs.AI]  22 Oct 2017  is, the agent is assumed to have unlimited computational and/or time resources to process all information and compute the optimal solution unhindered. In many practical applications this is a strong and often unrealistic assumption. For example, biological systems are adaptive in nature and excel at ﬁnding solutions to complex problems that may not be globally optimal but are “good enough” given the constraints and/or available sensory information [2,3]. Over the past several years considerable eﬀort has been devoted to developing a framework that accounts for the available computational constraints. The idea is to account for the cost of computation not after the fact, as is traditionally the case, but from the beginning, as part of the problem formulation. This steam of research has led to the development of information-constrained MDPs [3–5] that utilize concepts from information theory in order to model the computational limitation(s) of the agent [6, 7]. The approach also has strong connections with the thermodynamic point of view of the theory of computation [8–10]. The introduction of the added constraints (computational and otherwise) to the decision process is meant to model an agent that does not have access to unlimited resources, and hence will select actions that are not optimal in the traditional sense of maximizing value or utility, but rather in the sense of maximizing (expected) value or utility for a given processing cost [2,4,7]. Such a decision maker, who alters its behavior based on its resources, is said to be a bounded rational agent [2,11–13]. In this work, we apply this framework to develop decision-making algorithms for path-planning problems while also accounting for the information processing costs of computing the optimal actions. The information-limited MDP problem is formally posed as a constrained optimization problem, where the objective is to maximize the value function subject to a constraint that penalizes the diﬀerence between the resulting policy and a known prior (computationally cheap) policy. This constraint is often represented using the Kullback-Leibler (KL) divergence [3,4',\n",
       " '1709.06662': 'Deep neural networks have become ubiquitous in machine learning with applications ranging from computer vision to speech recognition and natural language processing. Neural networks demonstrate excellent performance in many practical problems, often beating specialized algorithms for these problems, which led to their rapid adoption in industrial applications. With such a wide adoption, important questions arise regarding our understanding of these neural networks: How robust are these networks to perturbations of inputs? How critical is the choice of one architecture over the other? Does certain ordering of transformations matter? Recently, a new line of research on understanding neural networks has emerged that look into a wide range of such questions, from interpretability of neural networks to verifying their properties (Bau et al. 2017; Szegedy et al. 2014; Bastani et al. 2016; Huang et al. 2017; Katz et al. 2017). In this work we focus on an important class of neural networks: Binarized Neural Networks (BNNs) (Hubara et Copyright c⃝2018, Association for the Advancement of Artiﬁcial Intelligence (www.aaai.org). All rights reserved. al. 2016). These networks have a number of important features that are useful in resource constrained environments, like embedded devices or mobile phones. Firstly, these networks are memory efﬁcient, as their parameters are primarily binary. Secondly, they are computationally efﬁcient as all activations are binary, which enables the use of specialized algorithms for fast binary matrix multiplication. These networks have been shown to achieve performance comparable to traditional deep networks that use ﬂoating point precision on several standard datasets (Hubara et al. 2016). Recently, BNNs have been deployed for various embedded applications ranging from image classiﬁcation (McDanel, Teerapittayanon, and Kung 2017) to object detection (Kung et al. 2017). The goal of this work is to analyze properties of binarized neural networks through the lens of Boolean satisﬁability (SAT). Our main contribution is a procedure for constructing a SAT encoding of a binarized neural network. An important feature of our encoding is that it is exact and does not rely on any approximations to the network structure. This means that this encoding allows us to investigate properties of BNNs by studying similar properties in the SAT domain, and the mapping of these properties back from the SAT to the neural network domain is exact. To the best of our knowledge, this is the ﬁrst work on verifying properties of deep neural networks using an exact Boolean encoding of a network. In our construction, we exploit attributes of BNN’s, both functional, e.g., most parameters of these networks are binary, and structural, e.g., the modular structure of these networks. While these encodings could be directly handled by modern SAT solvers, we show that one can exploit the structure of these encodings to solve the resulting SAT formulas more efﬁciently based on the idea of counterexample-guided search (Clarke et al. 2000; McMillan 2005; McMillan 2003). While our',\n",
       " '1803.02999': 'While machine learning systems have surpassed humans at many tasks, they generally need far more data to reach the same level of performance. For example, Schmidt et al. [17, 15] showed that human subjects can recognize new object categories based on a few example images. Lake et al. [12] noted that on the Atari game of Frostbite, human novices were able to make signiﬁcant progress on the game after 15 minutes, but double-dueling-DQN [19] required more than 1000 times more experience to attain the same score. It is not completely fair to compare humans to algorithms learning from scratch, since humans enter the task with a large amount of prior knowledge, encoded in their brains and DNA. Rather than learning from scratch, they are ﬁne-tuning and recombining a set of pre-existing skills. The work cited above, by Tenenbaum and collaborators, argues that humans’ fast-learning abilities can be explained as Bayesian inference, and that the key to developing algorithms with human-level learning speed is to make our algorithms more Bayesian. However, in practice, it is challenging to develop (from ﬁrst principles) Bayesian machine learning algorithms that make use of deep neural networks and are computationally feasible. Meta-learning has emerged recently as an approach for learning from small amounts of data. Rather than trying to emulate Bayesian inference (which may be computationally intractable), meta-learning seeks to directly optimize a fast-learning algorithm, using a dataset of tasks. Speciﬁcally, we assume access to a distribution over tasks, where each task is, for example, a classiﬁcation problem. From this distribution, we sample a training set and a test set of tasks. Our algorithm is fed the training set, and it must produce an agent that has good average performance on the test set. Since each task corresponds to a learning problem, performing well on a task corresponds to learning quickly. 1 arXiv:1803.02999v3  [cs.LG]  22 Oct 2018  A variety of diﬀerent approaches to meta-learning have been proposed, each with its own pros and cons. In one approach, the learning algorithm is encoded in the weights of a recurrent network, but gradient descent is not performed at test time. This approach was proposed by Hochreiter et al. [8] who used LSTMs for next-step prediction and has been followed up by a burst of recent work, for example, Santoro et al. [16] on few-shot classiﬁcation, and Duan et al. [3] for the POMDP setting. A second approach is to learn the initialization of a network, which is then ﬁne-tuned at test time on the new task. A classic example of this approach is pretraining using a large dataset (such as ImageNet [2]) and ﬁne-tuning on a smaller dataset (such as a dataset of diﬀerent species of bird [20]). However, this classic pre-training approach has no guarantee of learning an initialization that is good for ﬁne-tuning, and ad-hoc tricks are required for good performance. More recently, Finn et',\n",
       " '1703.09470': 'Single-image super-resolution is a challenging computer vision problem with many interesting applications, e.g. in the ﬁelds of astronomy, medical imaging and law enforcement. The goal is to infer, from a single low-resolution image, the missing high frequency content that would be visible in a corresponding high resolution image. The problem itself is inherently ill-posed, extremely so for large upscaling factors. Still, several successful schemes have been designed [10]. The key is to exploit the high degree of struc400nm 700nm wavelength Figure 1. Spectral super-resolution: our method is able to predict ﬁne-grained hyperspectral images, using only a single RGB image as input (number of output channels reduced for visualisation, actual output has 31 bands of width 10 nm). ture in the visual world and design or learn a prior that constrains the solution accordingly. Indeed there is a large body of literature on single-image super-resolution, which is however largely limited to the spatial domain. Very few authors address the complementary problem, to increase the spectral resolution of the input image beyond the coarse RGB channels. The topic of this paper is single-image spectral super-resolution. We pose the obvious question whether we can also learn the spectral structure of the visual world, and use it as a prior to predict hyper-spectral images with ﬁner spectral resolution from a standard RGB image.1 Note the trade-off between spatial 1Or from some other image with similarly broad channels, e.g., a color infrared image. arXiv:1703.09470v1  [cs.CV]  28 Mar 2017  and spectral information, even at the sensor level: to obtain a reasonable signal-to-noise ratio, cameras can have small pixels and integrate over large spectral bands; or they can have ﬁne spectral resolution, but integrate over large pixels. Depending on the available images and the application, it may be useful to increase the resolution in space or to obtain a ﬁner quantisation of the visible spectrum. While in the spatial domain the restoration of missing high-frequency information reveals smaller objects and more accurate boundaries, high-frequency spectral information makes it easier to separate the spectral signatures of different objects and materials that have similar RGB color. The extra information included in the recovered hyper-spectral (HS) image bands enables applications like tracking [37], segmentation [35], face recognition [30], document analysis [22, 29], analysis of paintings [12], food inspection [39] and image classiﬁcation [6]. A related, but simpler problem has been studied by several authors, namely hyper-spectral super-resolution [2, 18, 24, 33]. There, one assumes that both a HS image of low spatial resolution and an RGB image with ﬁner resolution are available, and the two are fused to get the best of both worlds. The desired output is thus the same as in our problem — but requires an additional input. Our work can be seen as an attempt to do away with',\n",
       " '1809.00357': 'Neural machine translation (NMT) has made a big leap in performance and became the unquestionable winning approach in the past few years (Bahdanau et al., 2014; Sutskever et al., 2014; Sennrich et al., 2017; Vaswani et al., 2017). The main reason behind the success of NMT in realistic conditions was the ability to handle large vocabulary (Sennrich et al., 2016b) and to utilize large monolingual data (Sennrich et al., 2016a). However, NMT still struggles if the parallel data is insufﬁcient (e.g. fewer than 1M parallel sentences), producing ﬂuent output unrelated to the source and performing much worse than phrasebased machine translation (Koehn and Knowles, 2017). Many strategies have been used in MT in the past for employing resources from additional languages, see e.g. Wu and Wang (2007), Nakov and Ng (2012), El Kholy et al. (2013), or Hoang and Bojar (2016). For NMT, a particularly promising approach is transfer learning or “domain adaptation” where the “domains” are the different languages. For example, Zoph et al. (2016) train a “parent” model in a high-resource language pair, then use some of the trained weights as the initialization for a “child” model and further train it on the low-resource language pair. In Zoph et al. (2016), the parent and child pairs shared the target language (English) and a number of modiﬁcations of the training process were needed to achieve an improvement in translation from Hansa, Turkish, and Uzbek into English with the help of FrenchEnglish data. Nguyen and Chiang (2017) explore a related scenario where the parent language pair is also low-resource but it is related to the child language pair. They improved the previous approach by using a shared vocabulary of subword units (BPE, Sennrich et al., 2016b). Additionally, they used transliteration to improve their results. In this paper, we contribute empirical evidence that transfer learning for NMT can be simpliﬁed even further. We leave out the restriction on relatedness of the languages and extend the experiments to parent–child pairs where the target language changes. Moreover, we do not utilize any special modiﬁcations to the training regime or data pre-preprocessing. In contrast to previous work, we test the method with the Transformer model (Vaswani et al., 2017), instead of the recurrent approaches (Bahdanau et al., 2014). As documented in e.g. Popel and Bojar (2018) and anticipated in WMT18,1 the Transformer model seems superior to other NMT approaches. 1http://www.statmt.org/wmt18/translation-task.html  2 Method Description The proposed method is extremely simple: We train the parent language pair for a number of iterations and switch the training corpus to the child language pair for the rest of the training, without resetting any of the training (hyper)parameters. As such, this method is similar to the transfer learning proposed by Zoph et al. (2016) but uses the shared vocabulary as in Nguyen and Chiang (2017). The',\n",
       " '1809.03368': 'Deep Neural Networks are notorious for having vast memory and computation requirements, both during training and test/prediction time. As such, Deep Neural Networks may be unfeasible in various environments such as on-body devices (such as hearing aids) due to heat dissipation, battery driven devices due to power requirements, embedded systems because of memory requirements, or real-time system in which constraints are imposed by a limited economical budget. Hence, there is a clear need for Neural Networks that can operate in resource limited environments. One method for reducing the memory and computational requirements for Neural Networks is to reduce the bit-width of the parameters and activations of the Neural Network. This can be achieved either during training (e.g., Ullrich et al. (2017); Achterhold et al. (2018)) or using post-training mechanisms (e.g., Louizos et al. (2017), Han et al. (2015)). By taking the reduction of the bit-width for weights and activations to the extreme, i.e., a single bit, one obtains a Binary Neural Network. Binary Neural Networks have several advantageous properties, i.e., a 32× reduction in memory requirements and the forward pass can be implemented using XNOR operations and bit-counting, which results in a 58× speedup (Rastegari et al., 2016). Moreover, Binary Neural Networks are more robust to adversarial examples (Galloway et al., 2018). Shayer et al. (2018) introduced a probabilistic training method for Neural Networks with binary weights, but allow for full precision activations. In this paper, we propose a probabilistic training method for Neural Networks with both binary weights and binary activations, which are even more memory and computation efﬁcient. In short, we train a stochastic Binary Neural Network by leveraging both the local reparametrization trick (Kingma et al., 2015) and the Concrete distribution (Maddison et al., 2016; Jang et al., 2016). At test time, we obtain a single deterministic Binary Neural Network or an ensemble of Binary Neural Networks by sampling from the parameter distribution. An advantage of our method is that we can take samples from the parameter distribution indeﬁnitely—without retraining. Hence, this method allows for anytime ensemble predictions and uncertainty estimates. The stochastic network has a clear Bayesian interpretation: the parameter Preprint. Work in progress. arXiv:1809.03368v1  [cs.LG]  10 Sep 2018  distribution p(W) of the stochastic network is a variational approximation to the true posterior p(W|X, Y), where (X, Y) denote the data, assuming a uniform prior on the weights. This interpretation may be used for further pruning of the network or allows for the introduction of more sophisticated priors. Note that while in this work we only consider the binary case, our method supports any discrete distribution over weights and activations. In the proposed method, binary activations are sampled as the very last operation in each layer. As such, any other operation that is normally applied to the pre-activation must be applied to random variables. One of the contributions of this paper is the deﬁnition',\n",
       " '1208.4423': 'A. Background Wireless sensor networks (WSNs) have been widely studied for detection and estimation problems. Recently, considerable research has focused on the fusion of analog rather than encoded digital data in a distributed sensor network to improve estimation performance. The advantages of analog WSNs have been established in [1]–[3], where it was shown that when using distortion between the source and recovered signal as the performance metric, digital transmission (separate source and channel coding) achieves an exponentially worse performance than analog signaling. A number of studies have focused on algorithm development and analysis for analog WSNs with a single-antenna fusion center (FC). In [4], the sensors amplify and forward their observations of a scalar source to the FC via fading channels, and algorithms are developed to either minimize estimation error subject to transmit power constraints or minimize power subject to estimation error constraints. The scalar source model for this problem was generalized to correlated vector sources in [5]. An opportunistic power allocation approach was proposed in [6], and the scaling law with respect to the number of sensors was shown to be the same as the optimal power allocation proposed in [4]. In [7], the asymptotic variance of the best linear unbiased estimator of an analog WSN is derived, together with an analysis of the effect of different assumptions regarding channel knowledge at the sensors. Scaling laws with respect to the number of sensors have been studied in [8] for a diversity-based method (where only the sensor with the best channel transmits), as well as for the coherent multiple access channel (MAC) and orthogonal channel cases, assuming a Gaussian source. In [9], a power optimization problem was formulated to minimize the outage probability of the MSE for the coherent MAC channel. More complicated settings involving analog WSNs with nonlinear measurement models [10] or relays [11], [12] have also been studied. The results described above all assume that the FC is equipped with only one antenna. Just as multi-antenna receivers can provide signiﬁcant capacity or diversity gains in communication systems, the estimation performance of a WSN should also beneﬁt from the use of a multiantenna FC, though prior work on this scenario is limited. A general scenario is investigated in [13], involving vector observations of a vector-valued random process at the sensors, and linearly precoded vector transmissions from the sensors to a multi-antenna FC. Optimal solutions for the precoders that minimize the mean-squared error (MSE) at the FC are derived for a coherent MAC August 21, 2018 DRAFT  3 under power and bandwidth constraints. In [14], single-antenna sensors amplify and forward their observations to a multi-antenna FC, but it is shown that for Rayleigh fading channels, the improvement in estimate variance is upper bounded by only a factor of two compared to the case of a single-antenna FC. The performance of two heuristic algorithms for choosing the gain and phase of the sensor transmissions is also studied. Subsequent results by',\n",
       " '1502.07523': 'Signals with sparse representations can be recovered from much less number of measurements than the number of samples given by the Nyquist rate using compressed sensing (CS) methods M. Shaghaghi is with the Department of Electrical and Computer Engineering, University of Alberta, Edmonton, AB, T6G 2V4 Canada (e-mail: mahdi.shaghaghi@ualberta.ca). S. A. Vorobyov is with Aalto University, Department of Signal Processing and Acoustics, Finland. April 15, 2018 DRAFT  2 [1]–[3]. Such measurements can be obtained by correlating the signal with a number of sensing waveforms [4]–[9]. The algorithms used for recovering the signals from such measurements exploit the sparsity of the signals in a proper basis (see [3], [10]–[17] to mention just a few existing algorithms). There are signals which inherently possess a sparse structure meaning that they can be deﬁned by a small number of parameters. However, such signals may not necessarily be represented as sparse signals using a proper ﬁnite basis, i.e., there may not exist or be known a ﬁnite basis such that the transformation of the signal to that basis results in a small number of non-zero coefﬁcients. For example, consider a signal composed of a linear combination of sinusoids. Such a signal generates sparse coefﬁcients by the discrete-time Fourier transform (DTFT), but its representation in the Fourier basis obtained by the discrete Fourier transform (DFT) exhibits frequency leakage [18]. Although the DTFT is a proper transformation, as it results in a small number of non-zero coefﬁcients for the considered signal, it is not a ﬁnite basis and cannot be used in conventional CS recovery methods which rely on a ﬁnite sparsity basis. Such methods have poor performance for the considered signals if the DFT basis is used [19]. In this , we consider a general class of sparse signals which are represented by a small number of parameters in a low-rank signal model. Our goal is to study the performance bounds for the estimation of unknown parameters and also the reconstruction of this class of signals from compressed measurements. The Cram´er-Rao bound (CRB) [20] for estimating a sparse parameter vector from compressed measurements has been studied in [21]. However, the signal model in [21] considers signals which can be represented by a ﬁnite sparsity basis. Then, the CRB is computed using approaches from the theory of constrained CRB in [22] and [23]. The constrained CRB for estimating a lowrank matrix from compressed measurements has been studied in [24]. In this , we consider a different signal model which does not involve the constraint on the rank of a matrix. The CRB for parameter estimation in compressed sensing has been also studied in [25]–[27]. In [25], the signal of interest is assumed to be a function of real-valued parameters, and it is not assumed to be necessarily sparse in a ﬁnite basis. The CRB is computed and bounded for different realizations of the measurement matrix. The signal model considered in [26] and',\n",
       " '1712.02466': 'Private information retrieval (PIR) is a canonical problem in the study of privacy issues that arise from the retrieval of information from public databases. Speciﬁcally, PIR involves a database that contains M records and a users with query interest θ ∈{1, ..., M}. The goal is to make the user get retrieves the θth record without revealing the index θ. In the information theoretic sense, the PIR problem can only be solved trivially solved by downloading all M records if the database is stored in one server. Therefore, in FOCS’95 Chor et al. [4,5] developed the distributed formulation for of PIR, where the database is stored across N servers and the user can communicate with all N servers. The privacy requirement is to ensure the secrecy of θ against any individual server. Since then, PIR has become a central research topic in the computer science literature, see [10] for a survey on PIR. A central issue in PIR is minimizing the communication cost, which is usually measured by the total number of bits transferred from the user to the servers (i.e. the upload size) and from the servers to the user (i.e. the download size). In the initial setting of PIR where each record is set to one bit, the * Corresponding author (email: zfz@amss.ac.cn)  Xu J K, et al. Sci China Inf Sci 2 minimum communication cost achieved is M O( 1 log log M ) [8, 9]. However, in real-world applications, it is common for the size of each record to be arbitrarily large. Therefore, the upload size is usually negligible compared to the download size. Consequently, the communication cost can be measured by considering only the download size. Speciﬁcally, deﬁne the rate of a PIR scheme as the ratio between the size of the retrieved record and the download size, and deﬁne the capacity as the supremum of the rate over all PIR schemes. In addition, the reciprocal of the capacity describes the minimum possible download size per unit of retrieved records. Recently, much work has been done on determining the capacity of PIR in various cases: Replication-based PIR: In this case, each of the N servers stores a replication of the database. In [14], Sun and Jafar proved that the capacity in the non-colluding case is (1 + 1 N + · · · + 1 NM−1 )−1. In [15], they derived the capacity for the colluding case (i.e. ensuring the secrecy of the retrieval index θ against any subset containing at most T colluding servers for 1 ⩽T < N) and the robust case (i.e. some servers may fail to respond). They also determined the capacity of PIR with symmetric privacy in [16], where symmetric privacy means that the user is required to get no information about the record other than the θth record. Banawan and Ulukus [2] recently derived the capacity of a multi-message PIR with replicated non-colluding servers for the case of retrieving more than half records. In',\n",
       " '1810.06208': 'To better understand the visual content, we should not only know what is the object, i.e, the so-called classiﬁcation task, but also know where is the very object, i.e., the so-called location task. The object detection task is to simultaneously provide these two information for a given image. Depending on the pipeline, most of the object detection techniques could be divided into two categories, i.e., onestage method [16, 14, 17] and two-stage method [5, 7, 4, 18, 6, 2, 11, 12, 15, 1, 9, 8]. Generally speaking, the one-stage methods focus on the detection speed while the dominant merit of the two-stage methods is the detection precision. In this challenge, we concentrate on the two-stage methods considering the advantages in detection precision. Speciﬁcally, in the modern convolutional neural network (CNN) context, the regions with CNN features (R-CNN) [5] method should be the earliest two-stage detector. Just as its name implies, the R-CNN methods ﬁrst output multiple region proposals using the selective-search algorithm, then regress the bounding-box (bbox) coordinates and classify each proposal into a speciﬁed class based on the extracted CNN features using the matured support vector machine (SVM) algorithm. To accelerate the pipeline, the SPPNet [7] is proposed by claiming that the feature maps could be shared by different proposals, and hence reducing the computation burden of the feature extraction process. Similar idea is used by the well-known Fast R-CNN [4] method. In this method, the features of the proposed regions are extracted by a newly-designed region-of-interest pooling (ROI-pooing) layer, and a multitask loss which combines the regression loss and the classiﬁcation loss is considered for optimized training process. It should be noted that for all the above mentioned methods, the regions are proposed in an ofﬂine method such that they could not be end-to-end optimized in one network. To solve this problem and therefore enable an end-to-end training style, a region proposal network (RPN) is incorporated into the overall pipeline, shaping the well-known Faster R-CNN method [18]. It should be noted that the RPN is nearly cost-free considering the backbone-sharing property. Aforementioned improvements of two-stage detection algorithms mainly focus on speeding up the whole pipeline. Another track of improving focuses on boosting precision of detectors [11, 12, 15, 1, 9, 8]. As we know, the series of R-CNN based methods uses the same feature maps to handle both the large and small objects, and consequently cannot adapt the object scales. To alleviate this drawback, one can either use the image-level or the feature-level solutions. As for the image-level solution, an intuitive method is to use the multiscale training/testing (MST) strategy. However, as pointed out by Bharat Singh et.al., the MST strategy are trying to memorize the features of objects with different scales based on the capacity of the network, resulting',\n",
       " '1801.04063': 'The actual system of big data needs to process lots of data within a limited time generally, so many researches are on sample data to improve their efﬁciency [1]. Distribution goodness-of-ﬁt plays a fundamental role in signal processing and information theory, which focuses on the error magnitude between the distribution of a set of sample values and the real distribution. This paper desires to solve this problem based on information theory. Shannon entropy [2] is possibly the most important quantity in information theory, which describes the fundamental laws of data compression and communication [3]. Due to its success, numerous entropies have been provided in order to extend information theory. Among them, the most successful expansion is Rényi entropy [4]. There are many applications based on Rényi entropy, such as hypothesis testing [5]. Actually, entropy is a quantity with respect to probability distribution, which satisﬁes the intuitive notion of what a measure of information should be [6]. Therefore, in this paper, we propose differential message importance measure (DMIM) as a measure of information for continuous random variable to characterize the process of information collection. DMIM is expanded from discrete message importance measure (MIM) [7] which is such an information quantity which agrees with the intuitive notion of information importance for small probability event. Recent studies show that MIM has many applications in big data, such as information divergence measures [8] and compressed data storage [9]. Much of the research in the goodness of ﬁt in the past several decades focused on the Kolmogorov-Smirnov test [10], [11]. Based on it, [12] gave an error estimation of empirical distribution. This result can describe the goodness of ﬁt very well and guide us to choose the sampling numbers. However, it can not visually display the process of information collection because the previous results can not describe the message carried by each sample and the information changes with the increase of the sampling size. The problem of testing goodness-of-ﬁt in a discrete setting was discussed in [13]. Fortunately, DMIM is the proper measure to help us consider the problem of goodness of ﬁt in the view of the information collection of continuous random variables. Moreover, Compared with Kolmogorov-Smirnov statistic, DMIM also shows the relationship between the variance of a random variable and the error estimation of empirical distribution. The rest of this paper is organized as follows. Section II introduces the deﬁnition and basic properties of DMIM. Then, the DMIM of some basic continuous distribution is discussed in Section III, in which we give the asymptotic analysis of Gaussian distribution. In Section IV, the goodness of ﬁt with DMIM is discussed to analyze the process of information collection. The validity of proposed theoretical results is veriﬁed by the simulation results in Section V. Finally, we ﬁnish the paper with conclusions in Section VI. II. THE DEFINITION AND PROPERTIES OF DMIM A. Differential Message Important Measure In this part, a new measure of information for continuous random variable',\n",
       " '1803.05428': 'Generative modeling describes the framework of estimating the underlying probability distribution p(x) used to generate data x. This can facilitate a wide range of applications, from sampling novel datapoints to unsupervised representation learning to estimating the probability of an existing datapoint under the learned distribution. Much recent progress in generative modeling has been expedited by the use of deep neural networks, producing “deep generative models,” which leverage the expressive power of deep networks to model complex and high-dimensional distributions. Practical achievements include generating realistic images with 1Google Brain, Mountain View, CA, USA. Correspondence to: Adam Roberts <adarob@google.com>. Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018 by the author(s). 2https://goo.gl/magenta/musicvae-code 3https://goo.gl/magenta/musicvae-examples A3 A4 A5 A6 A3 A4 A5 A6 Note 0 2 4 6 8 10 12 14 16 Time (bars) A3 A4 A5 A6 Figure 1. Demonstration of latent-space averaging using MusicVAE. The latent codes for the top and bottom sequences are averaged and decoded by our model to produce the middle sequence. The latent-space mean involves a similar repeating pattern to the top sequence, but in a higher register and with intermittent pauses like the bottom sequence. Audio for this example is available in the online supplement.3 See Figs. 12 and 13 in Appendix E for a baseline comparison. millions of pixels (Karras et al., 2017), generating synthetic audio with hundreds of thousands of timesteps (van den Oord et al., 2016a), and achieving state-of-the-art performance on semi-supervised learning tasks (Wei et al., 2018). A wide variety of methods have been used in deep generative modeling, including implicit models such as Generative Adversarial Networks (GANs) (Goodfellow et al., 2014) and explicit deep autoregressive models such as PixelCNN (van den Oord et al., 2016b) and WaveNet (van den Oord et al., 2016a). In this work, we focus on deep latent variable models such as the Variational Autoencoder (VAE) (Kingma & Welling, 2014; Rezende et al., 2014). The advantage of these models is that they explicitly model both p(z|x) and p(z), where z is a latent vector that can either be inferred from existing data or sampled from a distribution over the arXiv:1803.05428v5  [cs.LG]  11 Nov 2019  A Hierarchical Latent Vector Model for Learning Long-Term Structure in Music latent space. Ideally, the latent vector captures the pertinent characteristics of a given datapoint and disentangles factors of variation in a dataset. These autoencoders also model the likelihood p(x|z), which provides an efﬁcient way of mapping the latent vector back to the data space. Our interest in deep latent variable models primarily comes from their increasing use in creative applications of machine learning (Carter & Nielsen, 2017; Ha & Eck, 2018; Engel et al., 2017a). This arises from surprising and convenient characteristics of the latent spaces typically learned by these models. For',\n",
       " '1412.0035': 'Most image understanding and computer vision methods build on image representations such as textons [15], histogram of oriented gradients (SIFT [18] and HOG [4]), bag of visual words [3][25], sparse [35] and local coding [32], super vector coding [37], VLAD [9], Fisher Vectors [21], and, lately, deep neural networks, particularly of the convolutional variety [13, 23, 36]. However, despite the progress in the development of visual representations, their design is still driven empirically and a good understanding of their properties is lacking. While this is true of shallower handcrafted features, it is even more so for the latest generation of deep representations, where millions of parameters are learned from data. In this paper we conduct a direct analysis of representations by characterising the image information that they retain (Fig. 1). We do so by modeling a representation as a function Φ(x) of the image x and then computing an approximated inverse φ−1, reconstructing x from the code Φ(x). A common hypothesis is that representations collapse irrelevant differences in images (e.g. illumination or Figure 1. What is encoded by a CNN? The ﬁgure shows ﬁve possible reconstructions of the reference image obtained from the 1,000-dimensional code extracted at the penultimate layer of a reference CNN[13] (before the softmax is applied) trained on the ImageNet data. From the viewpoint of the model, all these images are practically equivalent. This image is best viewed in color/screen. viewpoint), so that Φ should not be uniquely invertible. Hence, we pose this as a reconstruction problem and ﬁnd a number of possible reconstructions rather than a single one. By doing so, we obtain insights into the invariances captured by the representation. Our contributions are as follows. First, we propose a general method to invert representations, including SIFT, HOG, and CNNs (Sect. 2). Crucially, this method uses only information from the image representation and a generic natural image prior, starting from random noise as initial solution, and hence captures only the information contained in the representation itself. We discuss and evaluate different regularization penalties as natural image priors. Second, we show that, despite its simplicity and generality, this method recovers signiﬁcantly better reconstructions from DSIFT and HOG compared to recent alternatives [31]. As we do so, we emphasise a number of subtle differences between these representations and their effect on invertibility. Third, we apply the inversion technique to the analysis of recent deep CNNs, exploring their invariance by sampling possible approximate reconstructions. We relate this to the depth of the representation, showing that the CNN gradually builds an increasing amount of invariance, layer after layer. Fourth, we study the locality of the information stored in 1 arXiv:1412.0035v1  [cs.CV]  26 Nov 2014  the representations by reconstructing images from selected groups of neurons, either spatially or by channel. The rest of the paper is organised as follows. Sect. 2 introduces the inversion method, posing',\n",
       " '1708.06297': 'In the recent past, collaborative and crowdsourcing platforms (Estell´es-Arolas and Gonz´alez-Ladr´on-DeGuevara, 2012) have been investigated for their ability to obtain large amounts of user interactions for the annotation of image databases. Particularly, the capacity to outsource simple human intelligence tasks to a crowd population and simultaneously draw from client computing resources for interfacing, are being increasingly appreciated in the imaging community (McKenna et al., 2012; Maier-Hein et al., 2014; Mavandadi et al., 2012). First studies employing collaborative (Haehn et al., 2014; Rajchl et al., 2016b) or crowd sourcing platforms (Maier-Hein et al., 2014; Albarqouni et al., 2016) via web interfaces have been proposed for biomedical image segmentation. Since such interfaces often have limited capacity to interact with image data, weak forms of annotations (e.g. bounding boxes, user scribbles, ∗Corresponding author. Email address: m.rajchl@imperial.ac.uk (Martin Rajchl) image-level tags, etc.) have been investigated to reduce the required annotation eﬀort. Recent studies have shown that placing bounding box annotations is approximately 15 times faster than creating pixel-wise manual segmentations (Lin et al., 2014; Papandreou et al., 2015). However, in contrast to annotating natural images (Lin et al., 2014; Russell et al., 2008) or recognising instruments in a surgical video sequence (Maier-Hein et al., 2014), the correct interpretation of medical images requires specialised training and experience (Nodine and Mello-Thoms, 2000; Gurari et al., 2015), and therefore might pose a challenge for non-expert annotators, leading to incorrectly annotated data (Cheplygina et al., 2016). Nonetheless, considering the limited resources of available clinical experts and the rapid increase in information of medical imaging data (e.g. through highresolution, whole-body imaging, etc.) alternative approaches are sought. Particular challenges arise, when trying to develop machine learning based approaches that can be scaled to very large datasets (i.e. population studies). Many of the currently available approaches rePreprint submitted to arXiv.org August 22, 2017 arXiv:1708.06297v1  [cs.CV]  21 Aug 2017  quire large amounts of labelled training data to deal with the variability of anatomy and potential pathologies. 1.1. Related Work To reduce the annotation eﬀort, many well-known studies propose segmentation methods employing simple forms of user annotations to obtain voxel-wise segmentations (Boykov and Jolly, 2000; Rother et al., 2004; Rajchl et al., 2017; Koch et al., 2017). While adjusting hyperparameters can be considered an interaction, in this study we concentrate on simpliﬁed forms of pictorial input (Olabarriaga and Smeulders, 2001), called weak annotations (WA). Such annotations have been extensively used in the literature, particularly in the context of medical object segmentation problems. Boykov and Jolly (2000) used user-provided scribbles (SC) or brush strokes as input and hard constraints to an interactive graphical segmentation problem. Similarly, Baxter et al. (2015), Baxter et al. (2017) and Rajchl et al. (2012) expressed this problem',\n",
       " '1802.09030': 'Combinatorial optimization is one of the foundational problems of computer science. Though in general such problems are NP-hard (Papadimitriou 2003), it is often the case that locally optimal solutions can be useful in practice. In clustering for example, a common objective is to divide a given set of examples into a ﬁxed number of groups so as to minimize the distances between group members. Since enumerating all the possible groupings is usually intractable, local search methods such as k-means (MacQueen and others 1967) are frequently used to approach such problems. In many problems however, methods that transform one solution to another can be highly sensitive to their initialization. In some cases this is a result of applying a local search to a problem which has multiple local optima. In others, the search space is simply disconnected, and transforming one valid solution to another is only possible within a small sub-space. In such cases, the quality of the ﬁnal solution is determined by how the search is initialized. One common heuristic around this is to sample few initial solutions, and to apply the search multiple times. However, the success of this heuristic mostly depends on the sampling distribution that produces these initial solutions. Thus, if we can have an algorithm that adapts a sampling distribution towards solutions that are associated with good objective values, then we might be able to use it to ﬁnd good local optima. Such a method could potentially sample locally optimal solutions on its own, or be used as an algorithm that learns how to initialize a particular local search. One type of algorithms which seem suitable for the task, and which have drawn considerable interest in the last few years are policy gradient methods (Sutton and Barto 2017). Such methods construct a parametric sampling distribution over the search space, and optimize the expected value of some objective function by applying gradient updates in the parameters’ space. On the surface, when provided with the right sampling distribution, such methods can access any valid solution, and can therefore provide a strategy that is suitable to our setting. Nonetheless, a closer inspection reveals these methods are highly sensitive to perturbations of the objective function. In particular, the objective values directly affect the sign and the magnitude of the gradient, making these methods notoriously hard to tune. Since the objective in this construction is essentially a random variable whose distribution changes from problem to problem, ﬁnding a general rule for tuning them seems impractical. Following this understanding, we propose to circumvent this sensitivity by utilizing a generic surrogate objective function that has the following two properties. First, the surrogate should preserve the set of locally optimal solutions. Second, the surrogate should have a predetermined distribution for every possible objective. Once in this form, such constructions can provide us with a generic adaptive sampler. With this idea in mind, we show how the empirical cumulative distribution',\n",
       " '1607.03474': 'Network depth is of central importance in the resurgence of neural networks as a powerful machine learning paradigm (Schmidhuber, 2015). Theoretical evidence indicates that deeper networks can be exponentially more efﬁcient at representing certain function classes (see e.g. Bengio & LeCun (2007); Bianchini & Scarselli (2014) and references therein). Due to their sequential nature, Recurrent Neural Networks (RNNs; Robinson & Fallside, 1987; Werbos, 1988; Williams, 1989) have long credit assignment paths and so are deep in time. However, certain internal function mappings in modern RNNs composed of units grouped in *Equal contribution 1ETH Zürich, Switzerland 2The Swiss AI Lab IDSIA (USI-SUPSI) & NNAISENSE, Switzerland. Correspondence to: Julian Zilly <jzilly@ethz.ch>, Rupesh Srivastava <rupesh@idsia.ch>. layers usually do not take advantage of depth (Pascanu et al., 2013). For example, the state update from one time step to the next is typically modeled using a single trainable linear transformation followed by a non-linearity. Unfortunately, increased depth represents a challenge when neural network parameters are optimized by means of error backpropagation (Linnainmaa, 1970; 1976; Werbos, 1982). Deep networks suffer from what are commonly referred to as the vanishing and exploding gradient problems (Hochreiter, 1991; Bengio et al., 1994; Hochreiter et al., 2001), since the magnitude of the gradients may shrink or explode exponentially during backpropagation. These training difﬁculties were ﬁrst studied in the context of standard RNNs where the depth through time is proportional to the length of input sequence, which may have arbitrary size. The widely used Long Short-Term Memory (LSTM; Hochreiter & Schmidhuber, 1997; Gers et al., 2000) architecture was introduced to speciﬁcally address the problem of vanishing/exploding gradients for recurrent networks. The vanishing gradient problem also becomes a limitation when training very deep feedforward networks. Highway Layers (Srivastava et al., 2015b) based on the LSTM cell addressed this limitation enabling the training of networks even with hundreds of stacked layers. Used as feedforward connections, these layers were used to improve performance in many domains such as speech recognition (Zhang et al., 2016) and language modeling (Kim et al., 2015; Jozefowicz et al., 2016), and their variants called Residual networks have been widely useful for many computer vision problems (He et al., 2015). In this paper we ﬁrst provide a new mathematical analysis of RNNs which offers a deeper understanding of the strengths of the LSTM cell. Based on these insights, we introduce LSTM networks that have long credit assignment paths not just in time but also in space (per time step), called Recurrent Highway Networks or RHNs. Unlike previous work on deep RNNs, this model incorporates Highway layers inside the recurrent transition, which we argue is a superior method of increasing depth. This enables the use of substantially more powerful and trainable sequential models efﬁciently, signiﬁcantly outperforming existing architectures on widely used benchmarks. arXiv:1607.03474v5  [cs.LG]  4 Jul 2017  Recurrent Highway Networks 2. Related Work on Deep Recurrent Transitions In recent years, a common method of utilizing the computational advantages of depth in recurrent networks is stacking',\n",
       " '1608.06111': 'Semantic parsing aims to solve the problem of canonicalizing language and representing its meaning: given an input sentence, it aims to extract a semantic representation of that sentence. Abstract meaning representation (Banarescu et al., 2013), or AMR for short, allows us to do that with the inclusion of most of the shallow-semantic natural language processing (NLP) tasks that are usually addressed separately, such as named entity recognition, semantic role labeling and coreference resolution. AMR is partially motivated by the need to provide the NLP community with a single dataset that includes basic disambiguation information, instead of having to rely on different datasets for each disambiguation problem. The annotation process is straightforward, enabling the development of large datasets. Several parsers for AMR have been recently developed (Flanigan et al., 2014; Wang et al., 2015a; Peng et al., 2015; Pust et al., 2015; Goodman et al., 2016; Rao et al., 2015; Vanderwende et al., 2015; Artzi et al., 2015; Barzdins and Gosko, 2016; Zhou et al., 2016). This line of research is new and current results suggest a large room for improvement. Greedy transition-based methods (Nivre, 2008) are one of the most popular choices for dependency parsing, because of their good balance between efﬁciency and accuracy. These methods seem promising also for AMR, due to the similarity between dependency trees and AMR structures, i.e., both representations use graphs with nodes that have lexical content and edges that represent linguistic relations. A transition system is an abstract machine characterized by a set of conﬁgurations and transitions between them. The basic components of a conﬁguration are a stack of partially processed words and a buffer of unseen input words. Starting from an initial conﬁguration, the system applies transitions until a terminal conﬁguration is reached. The sentence is scanned left to right, with linear time complexity for dependency parsing. This is made possible by the use of a greedy classiﬁer that chooses the transition to be applied at each step. In this paper we introduce a parser for AMR that is inspired by the ARCEAGER dependency transition system of Nivre (2004). The main difference between our system and ARCEAGER is that we need to account for the mapping from word tokens to AMR nodes, non-projectivity of AMR structures and reentrant nodes (multiple incoming edges). Our AMR parser brings closer dependency parsing and AMR parsing by showing that dependency parsing algorithms, with some modiﬁcations, can be used for AMR. Key properties  such as working left-to-right, incrementality1 and linear complexity further strengthen its relevance. The AMR parser of Wang et al. (2015a), called CAMR, also deﬁnes a transition system. It differs from ours because we process the sentence left-toright while they ﬁrst acquire the entire dependency tree and then process it bottom-up. More recently Zhou et al. (2016) presented a non-greedy transition system for AMR parsing, based on ARCSTANDARD (Nivre, 2004). Our transition sys',\n",
       " '1111.4580': 'Existing approaches to decentralized estimation or social learning are restricted to either (i) static (a ﬁxed number) parameter estimation [1], [2], [3], [4], [5]; or, (ii) when the parameter ∗A. Jadbabaie and U. Khan’s research was supported by the following grants: ONR MURI N000140810747, NSF Career, AFOSR’s Complex Networks Program and AFOSR MURI CHASE. †Department of Electrical and Computer Engineering, Tufts University, khan@ece.tufts.edu. §Department of Electrical and Systems Engineering, University of Pennsylvania, jadbabai@seas.upenn.edu. arXiv:1111.4580v1  [cs.IT]  19 Nov 2011  2 of interest is dynamic, the estimation demands a large number of agent communications within each dynamical system evolution step1 [9], [10], [11], [12]. In this paper, we consider networked estimation of (vector) dynamical systems in the context of single time-scale estimation, i.e., when each agent can communication only once with its neighbors per dynamical system evolution step [13]. Interested readers may also see [14], where identity system and observation matrices are considered. We consider social learning and networked estimation where the state of the world follows a potentially unstable discrete-time linear dynamical system. The dynamical system is monitored by a network of agents that have linear noisy observations and the agents are able to communicate over a sparse topology. Estimation within such settings heavily relies on the communication timescale among the agents [13]. To motivate this, we refer to Fig. 1, where Fig. 1(a) shows the traditional networked estimation approach, e.g., the Kalman-consensus ﬁlter [9], where a largenumber of consensus iterations are required between each k and k + 1; k being the time-index of the discrete-time dynamical system. On the other hand, our approach implements the agent communication and sensing at the same time-index, k, of the dynamical system; we show this in Fig. 1(b). We assume that the agents are collectively-observable, i.e., the collection of all of the agent observations guarantees observability of the underlying state. It turns out that the collectiveobservability, although necessary, is not sufﬁcient when we restrict to single time-scale estimation. This is due to the fact that the dynamics can be faster than the rate of observation fusion supported by a sparse network. The network connectivity and observation structure should be therefore related to the system instability. In this context, we address the networked estimation problem from two sides. Firstly, we formulate the estimation problem as a spectral radius (largest eigenvalue) optimization of concerned matrices. Borrowing results from Lyapunov theory and Linear Matrix Inequalities (LMIs), we show that in the networked setting, the LMI formulation reduces to a bi-(multi-)linear optimization and may not have a solution. In cases when the LMIs do have a solution, we provide an iterative optimization procedure based on a cone complementarity linearization algorithm [15]. 1With the exception of [6], [7], [8], in which the parameter is a scalar and each agent is assumed to observe this scalar state. Clearly, the scalar',\n",
       " '1806.10714': 'Regularization plays a crucial role in supervised learning. A successfully regularized model strikes a balance between a perfect description of the training data and the ability to generalize to unseen data. A common intuition for the design of regularzers is the Occam’s razor principle, where a regularizer enforces certain simplicity of the model in order to avoid overﬁtting. Classic regularization techniques include functional norms such as L1 (Krishnapuram et al., 2005), L2 (Tikhonov) (Ng, 2004) and RKHS norms (Schölkopf and Smola, 2002). Such norms produce a model with relatively less ﬂexibility and thus is less likely to overﬁt. A particularly interesting category of methods is inspired by the geometry. These methods design new penalty terms to enforce a geometric simplicity of the classiﬁer. Some methods stipulate that similar data should have similar score according to the classiﬁer, and enforce the smoothness of the classiﬁer function (Belkin et al., 2006; Zhou and Schölkopf, 2005; Bai et al., 2016). Others directly pursue a simple geometry of the classiﬁer boundary, i.e., the submanifold separating diﬀerent classes (Cai and Sowmya, 2007; Varshney and Willsky, 2010; Lin et al., 2012, 2015). These geometry-based regularizers are intuitive and have been shown to be useful in many supervised and semi-supervised learning settings. However, regularizing total smoothness of the classiﬁer (or that of the classiﬁcation boundary) is not always ﬂexible enough to balance the tug of war between overﬁtting and overall accuracy. The key issue is that these measurement are usually structure agnostic. For example, in Figure 1, a classiﬁer may either overﬁt (as in (b)), or becomes too smooth and lose overall accuracy (as in (c)). In this paper, we propose a new direction to regularize the “simplicity” of a classiﬁer – Instead of using geometry such as total curvature / smoothness, we directly enforce the “simplicity” of the classiﬁcation boundary, by regularizing over its topological complexity. (Here, we take a similar functional view as Bai et al. (2016) and consider the classiﬁer boundary as the 0-valued level set of the classiﬁer function f(x); see Figure 2 for an example.) Furthermore, our measurement of topological complexity incorporates the importance of topological structures, e.g., connected components, handles, in a meaningful manner, and provides a direct control over spurious topological structures. This new structural simplicity can be combined with other regularizing terms (say geometry-based ones or functional norms) to train a better classiﬁer. See Figure 1 (a) for an example, where the classiﬁer computed with topological regularization achieves a better balance between overﬁtting and classiﬁcation accuracy. To design a good topological regularizer, there are two arXiv:1806.10714v3  [cs.LG]  16 Oct 2018  Manuscript under review (a) (b) (c) (d) Figure 1: Comparison of classiﬁers with diﬀerent regularizers. For ease of exposition, we only draw training data (blue and orange markers) and the classiﬁcation boundary (red). (a): our method achieves structural simplicity without ove',\n",
       " '1605.06523': 'Large knowledge bases (KBs) have proven useful in many tasks, but it is unclear how to integrate this sort of knowledge into “deep” gradient-based learning systems. Motivated by this, we describe a probabilistic deductive database (PrDDB) system in which reasoning is performed by a differentiable process. In addition to enabling novel gradient-based learning algorithms for PrDDBs, this approach could potentially enable tight integration of logical reasoning into deep learners (or conversely, of deep learning into reasoning systems. In a traditional deductive database (DDB), a database DB with a theory T together deﬁne a set of facts f1, . . . , fn which can be derived by accessing the database and reasoning using T . As an example, Figure 1 contains a small theory and an associated database. End users can test to see if a fact f is derivable, or retrieve all derivable facts that match some query: e.g., one could test if f = uncle(joe,bob) is derivable in the sample database, or ﬁnd all values of Y such that uncle(joe,Y) holds. A probabilistic DDB is a “soft” extension of a DDB, where derived facts f have a numeric conﬁdence, typically based on augmenting DB with a set of parameters Θ. In many existing PrDDB models computation of conﬁdences is computationally expensive, and often not be conducive to learning the parametersb Θ. Here we describe a probabilistic deductive database called TensorLog in which reasoning uses a differentiable process. In TensorLog, each clause in a logical theory is ﬁrst converted into certain type of factor graph, in which each logical variable appearing in the clause is associated with a random variable in the factor graph, and each literal is associated with a factor (as shown in Figure 2). Then, for each type of query to the factor graph, the message-passing steps required to perform BP are “unrolled” into a function, which is differentiable. Each function will answer queries for a particular combination of evidence variables and query variables in the factor graph, which in turn corresponds to logical queries in a particular syntactic form. We also show how these functions can be composed 29th Conference on Neural Information Processing Systems (NIPS 2016), Barcelona, Spain. arXiv:1605.06523v2  [cs.AI]  19 Jul 2016  1. uncle(X,Y):-child(X,W),brother(W,Y). 2. uncle(X,Y):-aunt(X,W),husband(W,Y). 3. status(X,tired):-child(W,X),infant(W). child(liam,eve),0.99 infant(liam),0.7 child(dave,eve),0.99 infant(dave),0.1 child(liam,bob),0.75 aunt(joe,eve),0.9 husband(eve,bob),0.9 brother(eve,chip),0.9 Figure 1: An example database and theory. Uppercase symbols are universally quantiﬁed variables, and so clause 3 should be read as a logical implication: for all database constants cX and cW , if child(cX,cW ) and infant(cW ) can be proved, then status(cX,tired) can also be proved. recursively to perform inference in non-trivial logical theories containing',\n",
       " '0903.0666': 'Multiple-input multiple-output (MIMO) antenna wireless communication systems have received enormous attention in recent years due to their ability for providing linear capacity growth without the need for increased power and bandwidth [1, 2]. Since the important discoveries in [1, 2], a major focus has been directed at investigating the MIMO channel capacity under a wide range of propagation scenarios. For example, the impact of physical phenomena such as spatial correlation, line-of-sight, antenna mutual coupling, frequency-selectivity, and co-channel interference, have now been well-studied, especially for single-user MIMO systems [3–18]. Many key results have also been derived in the multi-user context, and this is still an important topic of on-going research (see, eg. [19–23], and references therein). Despite the abundance of literature on MIMO channel capacity, the vast majority of existing work in this area has focused primarily on systems employing optimal nonlinear receiver structures. It is very wellknown, however, that such receivers can have prohibitive complexity requirements for practical systems and that low complexity receivers, such as linear minimum mean-squared error (MMSE) receivers, are more appealing for many applications. However, despite their practical importance, there are currently few closed-form analytical results on the achievable rates of MIMO MMSE receivers. In fact, most prior related work has focused on studying the asymptotic achievable rates of linear MMSE receivers, and has been derived in the context of code-division multiple access (CDMA) systems employing random spreading. It is well-known that such systems, under certain conditions, are isomorphic to single-user MIMO MMSE systems. In this context, the primary approach has been to study the asymptotic spectral efﬁciency and signal to interference plus noise ratio (SINR) as the system dimensions grow large with ﬁxed ratio, using advanced tools from large-dimensional random matrix theory [24–29]. Those results, which are extremely accurate for the high system dimensions encountered in CDMA applications (determined by the spreading factor and the number of users), may become less accurate for the much smaller system dimensions indicative of current MIMO systems (determined by the numbers of transmit and receive antennas). Moreover, in many cases, the existing CDMA results restrict the equivalent channel gains to be independent random variables with zero mean; thereby precluding many MIMO statistical channel models of practical interest (eg. correlated Rayleigh and Rician fading). An exception is the very recent work [30], which investigated the asymptotic (large antenna) mutual information distribution of MIMO MMSE receivers in the presence of spatial correlation.  3 For ﬁnite-dimensional systems with arbitrary numbers of transmit and receive antennas, there are remarkably few analytic results dealing with the achievable rates of MIMO MMSE receivers. The only directly related results, of which we are aware, were derived very recently in [23, 31, 32]. Speciﬁcally, [31] investigated the achievable rates of MIMO MMSE receivers by characterizing the asymptotic diversitymultiplexing trade-off. In [32], expressions for the exact achievable sum rates were derived for MIMO MMSE',\n",
       " 'cs/0407060': 'Codes based on random graphs are of huge practical and theoretical relevance. The analysis of such communication schemes is currently in a mixed status. From a practical point of view, the most relevant issue is the analysis of linear-time decoding algorithms. As far as message-passing algorithms are concerned, our understanding is rather satisfactory. Density evolution [1–4] allows to compute exact thresholds for vanishing bit error probability, at least in the large blocklength limit. These results have been successfully employed for designing capacity-approaching code ensembles [5,6]. A more classical problem is the evaluation of decoding schemes which are optimal with respect to some ﬁdelity criterion, such as word MAP (minimizing the block error probability) or symbol MAP decoding (minimizing the bit error probability). Presently, this issue has smaller practical relevance than the previous one, and nonetheless its theoretical interest is great. Any progress in this direction would improve our understanding of the eﬀectiveness of belief propagation (and similar message-passing algorithms) in general inference problems. Unhappily, the status of this research area [7,10] is not as advanced as the analysis of iterative techniques. In most cases one is able to provide only upper and lower bounds on the thresholds for vanishing bit error probability in the large blocklength limit. Moreover, the existing techniques seems completely unrelated from the ones employed in the analysis of iterative decoding. This is puzzling. We know that, at least for some code constructions and some channel models, belief propagation has performances which are close to optimal. The same has been observed empirically in inference problems. Such a convergence in behavior hints at a desirable convergence in the analysis techniques. This paper aims at bridging this gap. We introduce a new technique which allows to derive lower bounds on the entropy of the transmitted message conditional to the received one. We conjecture that the lower bound provided by this approach is indeed tight. Interestingly enough, the basic objects involved in the new bounds are probability densities over R, as in the density evolution analysis of iterative decoding. These densities are required moreover to satisfy the same ‘symmetry’ condition (see Sec. 4 for a deﬁnition) as the messages distributions in density evolution. The bound can be optimized with respect to the densities. A necessary condition for the densities to be optimal is that they correspond to a ﬁxed point of density evolution for belief propagation decoding. The method presented in this paper is based on recent developments in the rigorous theory of mean ﬁeld spin glasses. Mean ﬁeld spin glasses are theoretical models for disordered magnetic alloys, displaying an extremely rich probabilistic structure [12,13]. As shown by Nicolas Sourlas [14–16], there exists a precise mathematical correspondence between such models and error correcting codes. Exploiting this correspondence, a number of heuristic techniques from statistical mechanics have been applied to the analysis of coding systems, including LDPC codes [17–20] and turbo codes [21,22]. Unhappily, the results',\n",
       " '1803.00057': 'Sequence alignment (see Figure 1) is a prevalent problem that ﬁnds diverse applications in molecular biology [27], natural language processing [3], historic linguistics [33], and computer vision [7]. In this paper, we focus on aligning heterogeneous sequences with complex correspondences. Heterogeneity refers to the lack of an obvious surface matching (a literal similarity metric between elements of the sequences). A prime example is the alignment between visual and textual content. Such alignment requires sophisticated extraction of comparable feature representations in each modality, often performed by a deep neural network. A common solution to the alignment problem consists of two stages that are performed separately: (1) the learning of a similarity metric between elements in the sequences and (2) ﬁnding the optimal alignment between the ∗The technique was conceived when all authors worked for Disney Research. (a) 1 2 3 4 1 3 2 4 (c) 4 1 1 1 2 2 3 5 (b) 1 1 1 2 3 3 1 3 2 4 5 1 3 2 4 5 5 6 6 Figure 1: Types of sequence correspondence. Matching blocks in two sequences have identical colors and numbers. (a) A one-to-one matching where the white blocks do not match anything. (b) A one-to-many matching where one block on the bottom sequence matches multiple blocks on the top. (c) A non-monotonic situation where the matching does not always proceed strictly from left to right due to the red-1 block after the yellow-2 on top. sequences. Alignment techniques based on dynamic programming, such as Dynamic Time Warping (DTW) [4] and Canonical Time Warping (CTW) [59], are widely popular. In a simple form, DTW can be understood as ﬁnding the shortest path where the edge costs are computed with the similarity metric, so the decision is Markov. Variations of DTW [43, 60] accommodate some degrees of nonmonotonicity (see Figure 1 (c)). In all cases, these approaches are disadvantaged by the separation of the two stages. Conceptually, learning a metric that directly helps to optimize alignment should be beneﬁcial. Further, methods with ﬁrst-order Markov assumptions take only limited local context into account, but contextual information conducive to alignment may be scattered over the entire sequence. For example, knowledge of the narrative structure of a movie may help to align shots to their sentence descriptions. To address these limitations, we propose an end-toend differentiable neural architecture for heterogeneous sequence alignment, which we call NeuMATCH. The NeuMATCH architecture represents the current state of the workspace using four Long Short-term Memory (LSTM) chains: two for the partially aligned sequences, one for the matched content, and one for historical alignment decisions. arXiv:1803.00057v2  [cs.CV]  9 Apr 2018  Elrond addresses the council. Frodo steps forward and moves towards a stone plinth. He places the ring on the plinth and returns to his seat. Boromir turns sharply. Frodo looks at someone questioningly. null',\n",
       " '1711.02637': 'Modern machine learning applications operate on massive datasets. The algorithms that are used for data analysis face the difﬁcult challenge to cope with the enormous amount of data or the vast dimensionality of the problems. A simple and well established strategy to reduce the computational costs is to split the data and to operate only on a small part of it, as for instance in coordinate descent (CD) methods and stochastic gradient (SGD) methods. These kind of methods are state of the art for a wide selection of machine learning, deep leaning and signal processing applications [9, 11, 35, 27]. The application of these schemes is not only motivated by their practical preformance, but also well justiﬁed by theory [18, 19, 2]. Deterministic strategies are seldom used for the data selection—examples are steepest coordinate descent [4, 34, 20] or screening algorithms [14, 15]. Instead, randomized selection has become ubiquitous, most prominently uniform sampling [27, 29, 7, 8, 28] but also non-uniform sampling based on a ﬁxed distribution, commonly referred to as importance sampling [18, 19, 2, 33, 16, 6, 25, 24]. While these sampling strategies typically depend on the input data, they do not adapt to the information of the current parameters during optimization. In contrast, adaptive importance sampling strategies constantly re-evaluate the relative importance of each data point during training and thereby often surpass the performance of static algorithms [22, 5, 26, 10, 21, 23]. Common strategies are gradientbased sampling [22, 36, 37] (mostly for SGD) and duality gap-based sampling for CD [5, 23]. The drawbacks of adaptive strategies are twofold: often the provable theoretical guarantees can be worse than the complexity estimates for uniform sampling [23, 3] and often it is computationally inadmissible to compute the optimal adaptive sampling distribution. For instance gradient based sampling requires the computation of the full gradient in each iteration [22, 36, 37]. Therefore one has to rely on approximations based on upper bounds [36, 37], or stale values [22, 1]. But in general these approximations can again be worse than uniform sampling. ∗EPFL, Machine Learning and Optimization Laboratory, sebastian.stich@epfl.ch †Max Planck Institute for Intelligent Systems, anant.raj@tuebingen.mpg.de ‡EPFL, Machine Learning and Optimization Laboratory, martin.jaggi@epfl.ch §First version May 19, 2017. To appear at NIPS 2017. 1 arXiv:1711.02637v1  [cs.LG]  7 Nov 2017  This makes it necessary to develop adaptive strategies that can efﬁciently be computed in every iteration and that come with theoretical guarantees that show their advantage over ﬁxed sampling. Our contributions. In this paper we propose an efﬁcient approximation of the gradient-based sampling in the sense that (i) it can efﬁciently be computed in every iteration, (ii) is provably better than uniform or ﬁxed importance sampling and (iii) recovers the gradient-based sampling in the fullinformation setting. The scheme is completely generic and can easily be added as an improvement to both CD and SGD type methods. As our key contributions, we (1',\n",
       " '1702.03040': 'Learning theory traditionally has been studied in a statistical framework, discussed at length, for example, by Shalev-Shwartz and Ben-David (2014). The issue with this approach is that the analysis of the performance of learning methods seems to critically depend on whether the data generating mechanism satisﬁes some probabilistic assumptions. Realizing that these assumptions are not necessarily critical, much work has been devoted recently to studying learning algorithms in the so-called online learning framework (Cesa-Bianchi and Lugosi, 2006). The online learning framework makes minimal assumptions about the data generating mechanism, while allowing one to replicate results of the statistical framework through online-to-batch conversions (Cesa-Bianchi et al., 2004). By following a minimax approach, however, results proven in the online learning setting, at least initially, led to rather conservative results and algorithm designs, failing to capture how more regular, “easier” data, may give rise to faster learning speed. This is problematic as it may suggest overly conservative learning strategies, missing opportunities to extract more information when the data is nicer. Also, it is hard to argue that data resulting from passive data collection, such as weather data, would ever be adversarially generated (though it is equally hard to defend that such data satisﬁes precise stochastic assumptions). Realizing this issue, during recent years much work has been devoted to understanding what regularities and how can lead to faster learning speed. For example, much work has been devoted to showing that faster learning speed (smaller “regret”) can be achieved in the online convex optimization setting when the loss functions are “curved”, such as when the loss functions are strongly convex or exp-concave, or when the losses show small variations, or the best prediction in hindsight has a small total loss, and that these properties can be exploited in an adaptive manner (e.g., Merhav and Feder 1992, Freund and Schapire 1997, Gaivoronski and Stella 2000, Cesa-Bianchi and Lugosi 2006, Hazan et al. 2007, Bartlett ∗R. Huang and Cs. Szepesvári are with the Department of Computing Science, University of Alberta, AB, Canada, email: ruitong@ualberta.ca, szepesva@ualberta.ca. T. Lattimore was with the School of Informatics and Computing, Indiana University, IN, USA, email: tor.lattimore@gmail.com. A. György is with the Department of Electrical and Electronic Engineering, Imperial College London, UK, email: a.gyorgy@imperial.ac.uk. 1 arXiv:1702.03040v1  [cs.LG]  10 Feb 2017  et al. 2007, Kakade and Shalev-Shwartz 2009, Orabona et al. 2012, Rakhlin and Sridharan 2013, van Erven et al. 2015, Foster et al. 2015). In this paper we contribute to this growing literature by studying online linear prediction and the follow the leader (FTL) algorithm. Online linear prediction is arguably the simplest yet fundamental of all the learning settings, and lies at the heart of online convex optimization, while it also serves as an abstraction of core learning problems such as prediction with expert advice. FTL, the online analogue of empirical risk minimization of statistical learning, is the',\n",
       " '1809.10374': 'Many deep learning practitioners closely monitor both training and test errors, hoping to achieve both a small training error and a small generalization error, or gap between testing and training errors. Training is usually stopped early, before overﬁtting sets in and increases the test error. This procedure often results in large networks that generalize well on structured tasks, raising an important generalization puzzle (Zhang et al., 2016): many existing theories that upper bound generalization error (Bartlett & Mendelson, 2002; Neyshabur et al., 2015; Dziugaite & Roy, 2017; Golowich et al., 2017; Neyshabur et al., 2017; Bartlett et al., 2017; Arora et al., 2018, e.g) in terms of various measures of network complexity yield very loose bounds. Therefore they cannot explain the impressive generalization capabilities of deep nets. In the absence of any such tight and computable theory of deep network generalization error, we develop an analytic theory of generalization error for deep linear networks. Such networks exhibit highly nonlinear learning dynamics (Saxe et al., 2013a;b) including many prominent phenomena like learning plateaus, saddle points, and sudden drops in training error. Moreover, theory developed for the learning dynamics of deep linear networks directly inspired better initialization schemes for nonlinear networks (Schoenholz et al., 2016; Pennington et al., 2017; 2018). Here we show that deep linear networks also provide a good theoretical model for generalization dynamics. In particular we develop an analytic theory for both the training and test error of a deep linear network as a function of training time, number of training examples, network architecture, initialization, and task structure and SNR. Our theory matches simulations and reveals that deep networks with small 1 arXiv:1809.10374v2  [stat.ML]  4 Jan 2019  Published as a conference paper at ICLR 2019 weight initialization learn the most important aspects of a task ﬁrst. Thus the optimal test error at the early stopping time depends largely on task structure and SNR, and not on network architecture, as long as the architecture is expressive enough to attain small training error. Thus our exact analysis of generalization dynamics reveals the important lesson that any theory that seeks to upper bound generalization error based only on network architecture, and not on task structure, is likely to yield exceedingly loose upper bounds. Intriguingly our theory also reveals a non-gradient-descent learning algorithm that proveably out-performs neural network training through gradient descent. We also apply our theory to multi-task learning, which enables knowledge transfer from one task to another, thereby further lowering generalization error (Dong et al., 2015; Rusu et al., 2015; Luong et al., 2016, e.g.). Moreover, knowledge transfer across tasks may be key to human generalization capabilities (Hansen et al., 2017; Lampinen et al., 2017). We provide an analytic theory for how much knowledge is transferred between pairs of tasks, and we ﬁnd that it displays a sensitive but computable dependence on the relationship between pairs of tasks, in particular, their SNRs and feature space alignments. We note that a related prior work',\n",
       " '1304.1018': 'Hidden Markov model (HMM) based automatic speech recognition (ASR) system, similar to conventional pattern recognition system, breaks the problem into several sub-tasks: feature extraction, modeling and decision making, and optimizes them in independent manner. For instance, acoustic features such as, mel frequency cepstral coefﬁcients (MFCC), perceptual linear prediction (PLP) cepstral coefﬁcients, linear prediction cepstral coefﬁcients are extracted based on prior knowledge about speech perception and/or speech production. These features are then usually modeled by either Gaussian mixture models (GMM) or artiﬁcial neural networks (ANNs) to estimate state emission distribution. This step is often referred to as acoustic modeling. The decision making, i.e. recognition, This work was partly supported by the HASLER foundation through the grant “Universal Spoken Term Detection with Deep Learning” (DeepSTD) and by the Swiss NSF through the Swiss National Center of Competence in Research (NCCR) on Interactive Multimodal Information Management (www.im2.ch). step integrates the acoustic model, lexical knowledge and language model/syntactical constraints (again estimated independently on text data) to decode the test utterance. In recent years, in the ﬁeld of computer vision [1] and text processing [2] studies on sequence recognition problems similar to ASR have shown that such divide and conquer strategy may not be necessary. More precisely, these studies have shown that it is possible to build end-to-end systems (fed with raw input data) by using architectures composed of many layers, where each layer learns features (i.e. abstract representations), that are relevant to the problem of interest. Inspired from these studies, the present paper, as a ﬁrst modest step, investigates estimation of phoneme class conditional probabilities from raw speech signal using convolutional neural networks1 (CNN) [4] for phoneme sequence recognition. In the framework of hybrid HMM/ANN system, we compare the proposed approach with the conventional approach of extracting spectral-based acoustic feature extraction and then modeling them by ANN. In addition, we also propose a discriminative decoding algorithm based on a simple conditional random ﬁeld (CRF). Experimental studies conducted on TIMIT corpus show that (a) the proposed approach can yield a phoneme recognition system that is similar to or better than the system based on conventional approach and (b) CRF-based decoding yields better performance than conventional joint likelihood based decoding. The remainder of the paper is organized as follows. Section 2 presents a brief survey of related literature. Section 3 presents the architecture of the proposed system. Section 4 presents the experimental setup and Section 5 presents the results. Section 6 presents an analysis, Section 7 provides a discussion and Section 8 concludes the paper. 2. Related Work Despite the success of spectral-based acoustic features, there has been interest in modeling raw speech signal for speech recognition. In one of the earliest work, Poritz proposed an approach where the speech signal is modeled by a linear prediction HMM [5]. This work was',\n",
       " '1711.02348': 'Tracking has a signiﬁcant role in understanding human mobility patterns, wild-life monitoring, and mobile asset tracking [1], [2]. These applications involve long-term tracking of mobile agents where there are restrictions on weight and size of the tracking devices in order to minimize any disruption to the natural movement of the tracked device/individual. These restrictions limit the computational power and energy resources available to the tracking devices. The conﬂicting nature of long-term tracking and resource limitations highlights the need for energy-efﬁcient tracking algorithms. The global positioning system (GPS) has revolutionized the outdoor tracking. However, it suffers from high energy consumption and poor performance in urban areas and dense forests [3]. There are signiﬁcant efforts by the research community to alleviate the dominance of energy consumption by the GPS in tracking. Some propose to use inertial sensors to augment the GPS in between GPS sampling intervals. These appraoches are generally based on techniques such as extended Kalman ﬁlter, particle ﬁlter, and look-ahead ﬁlters [4], [5]. In tracking using inertial-sensors, the accuracy is a function of the inertial sensor’s sampling frequency [6]. Tracking based on inertial sensors generally requires an occasional reliable position estimate from an independent positioning system to curb the accumulation of errors over time. Another approach is to use cooperation among co-located devices to share the tracking load [6]–[8]. The core idea of this approach is to reduce the energy usage of a group of nodes by limiting the use of each node’s GPS. The mobile nodes exploit an opportunistic grouping behavior and request for position estimates from their neighbours. A node activates its own GPS only in case position updates from its neighbouring nodes are unavailable. Multilateration-based localization techniques are popular for their energy efﬁciency and simplicity. However, they may suffer from inaccuracy when there are perturbations in the position information of the anchor nodes (the nodes that have estimates of their current locations, e.g., using GPS) or in the distance estimates, e.g., using RSSI measurements between the anchor nodes and the blind node (the node interested in estimating its own position). In [9], the authors propose a localization algorithm based on weighted leastsquares (WLS), referred to as “WLSR” hereafter, that accounts for perturbations in the RSSI measurements only. Our algorithm proposed in [10], referred to as “WLSRP” hereafter, improves the WLSR algorithm by accounting for perturbation in the anchor position information as well. In contrast to the iterative and computationally complex solutions such as those based on second-order cone programming (SOCP) or semideﬁnite programming (SDP) [11]–[13], WLSR and WLSRP are closed-form and easy to implement making them suitable for localization in resource-constrained applications. In static or slow-varying sensor networks, tracking based on multilateration is relatively straightforward. However, it is not directly applicable to long-term tracking of dynamic groups of resource-constrained mobile nodes such as humans, animals, and vehicles. The dynamic group',\n",
       " '1302.4405': 'A. Motivation Compressed sensing (CS) is an emerging area of signal processing that allows to reconstruct sparse signals from a reduced number of measurements [1–3]. Because real world applications involve noisy measurements, CS with noise has drawn a lot of attention [4–7]. In recent work, Wu and Verd´u [8] deﬁned the noise sensitivity as the ratio of the reconstruction error to the noise variance. The reconstruction is called robust if the noise sensitivity is ﬁnite. Wu and Verd´u proved that the reconstruction is robust only when the measurement rate R, which is the ratio of the number of measurements to the signal length, exceeds a certain threshold. Wu and Verd´u’s threshold deals with the case where the noise is low. Unfortunately, the measurement noise in realworld applications might be greater than that required by Wu and Verd´u. Thus, it is of interest to investigate the behavior of the CS reconstruction error in regions where there is more noise. B. Contribution Tanaka’s ﬁxed point equation provides the fundamental information theoretical limit on the reconstruction performance, which is quantiﬁed as the minimum mean square error (MMSE) of signal reconstruction in the presence of measurement noise [9–13]. In this paper, we use Tanaka’s equation to evaluate the reconstruction performance for sparse Gaussian signals. That is, each element follows a Gaussian distribution with probability p, while it is zero with probability 1 −p. We call p the sparsity rate of the signal. It might seem that lower noise always results in better reconstruction performance. However, the main result of this paper is to show that the behavior of the reconstruction performance is more nuanced in CS. There are several different performance Fig. 1. Different regions and thresholds in CS reconstruction. regions and thresholds that separate these regions, as illustrated in Figure 1. (See Section III for a detailed discussion. Note that the γ in Figure 1 stands for the inverse noise level; larger γ means less noise.) • Low measurement region: The measurement rate R is too small. Robust reconstruction is impossible. • High measurement region: R is sufﬁciently large. This region consists of Region 1, and parts of Regions 4 and 5. Increasing the inverse noise level γ leads to an immediate improvement in performance. • Medium measurement region: R is modest. This region consists of Regions 2 and 3, and parts of Regions 4 and 5. In the following we add further detail about the medium measurement region. 1) Region 4: (Including the portion of Region 4 in the high measurement region.) The noise is high in this region, and thus, the reconstruction quality is poor. 2) Regions 2 and 3: The noise is modest in these regions. For ﬁxed R, when the noise decreases (γ increases) we leave Region 4 and enter Region 2. The performance hits a barrier and stays roughly constant. This barrier is broken through when we further increase γ and enter Region 3, and the performance',\n",
       " '1412.0823': 'The advancing interference management techniques have sharpened our understanding in the fundamental limits (e.g., channel capacity) of wireless networks with interference. The degrees of freedom (DoF) characterization serves as the ﬁrst-order capacity approximation for wireless networks, by which the obtained insights can be transferred to practical scenarios. The DoF indicates the system throughput scaling with the signal-to-noise ratio (SNR) in the high SNR regime. Although the DoF as a ﬁgure of merit has limitations [2], it has proved useful in understanding the fundamental limits of several cooperative communication protocols, such as interference alignment (IA) [3] and network MIMO [4] among many others. A common feature behind much of the analysis of cooperation beneﬁts in either interference channels (IC) or broadcast channels (BC) has been the availability of instantaneous channel state information at the transmitters (CSIT), with exceptions dealing with so-called limited feedback schemes. Nevertheless, most efforts on limited [5]–[7], imperfect [7], [8], or delayed feedback settings [9]–[14], among others [15]–[18], rely on the assumption that the transmitters are endowed with an instantaneous form of channel information whose coherence time is similar to that of the actual fading channels, so that a good fraction or the totality of the DoF The present work was carried out within the framework of Celtic-Plus SHARING project. X. Yi and D. Gesbert are with the Mobile Communications Dept., EURECOM, 06560 Sophia Antipolis, France (email: {xinping.yi, david.gesbert}@eurecom.fr). This work was presented in part at ISIT 2014, Honolulu, HI, USA [1]. arXiv:1412.0823v1  [cs.IT]  2 Dec 2014  2 achieved with perfect CSIT can be obtained. Such an assumption is hard to realize in many practical scenarios, such as cellular networks [19]. Conversely, it has been reported in [20]–[23] that a substantial DoF gain cannot be realized in IC or BC scenario without CSIT. A closer examination of these pessimistic results however reveals that many of the considered networks are fully connected, in that any transmitter interferes with any non-intended receiver in the network. Owing to the nodes’ random placement, the fact that power decays fast with distance, the existence of obstacles, and local shadowing effects, we may argue that certain interference links are unavoidably much weaker than others, suggesting the use of a partially-connected graph to model, at least approximately, the network topology. An interesting question then arises as to whether the partial connectivity could be leveraged to allow the use of some relaxed form of CSIT while still achieving a substantial DoF performance. In particular the exploitation of topological information, simply indicating which of the interfering links are weak enough to be approximated by zero interference and which links are too strong to do so, is of great practical interest. The evidence that the topological information is beneﬁcial can be traced back to [24], where some local topological information was exploited to improve network performance by some coloring schemes such as “coded set scheduling”. Most recently, this question',\n",
       " '1703.04977': 'Understanding what a model does not know is a critical part of many machine learning systems. Today, deep learning algorithms are able to learn powerful representations which can map high dimensional data to an array of outputs. However these mappings are often taken blindly and assumed to be accurate, which is not always the case. In two recent examples this has had disastrous consequences. In May 2016 there was the ﬁrst fatality from an assisted driving system, caused by the perception system confusing the white side of a trailer for bright sky [1]. In a second recent example, an image classiﬁcation system erroneously identiﬁed two African Americans as gorillas [2], raising concerns of racial discrimination. If both these algorithms were able to assign a high level of uncertainty to their erroneous predictions, then the system may have been able to make better decisions and likely avoid disaster. Quantifying uncertainty in computer vision applications can be largely divided into regression settings such as depth regression, and classiﬁcation settings such as semantic segmentation. Existing approaches to model uncertainty in such settings in computer vision include particle ﬁltering and conditional random ﬁelds [3, 4]. However many modern applications mandate the use of deep learning to achieve state-of-the-art performance [5], with most deep learning models not able to represent uncertainty. Deep learning does not allow for uncertainty representation in regression settings for example, and deep learning classiﬁcation models often give normalised score vectors, which do not necessarily capture model uncertainty. For both settings uncertainty can be captured with Bayesian deep learning approaches – which offer a practical framework for understanding uncertainty with deep learning models [6]. In Bayesian modeling, there are two main types of uncertainty one can model [7]. Aleatoric uncertainty captures noise inherent in the observations. This could be for example sensor noise or motion noise, resulting in uncertainty which cannot be reduced even if more data were to be collected. On the other hand, epistemic uncertainty accounts for uncertainty in the model parameters – uncertainty 31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA. arXiv:1703.04977v2  [cs.CV]  5 Oct 2017  (a) Input Image (b) Ground Truth (c) Semantic Segmentation (d) Aleatoric Uncertainty (e) Epistemic Uncertainty Figure 1: Illustrating the difference between aleatoric and epistemic uncertainty for semantic segmentation on the CamVid dataset [8]. Aleatoric uncertainty captures noise inherent in the observations. In (d) our model exhibits increased aleatoric uncertainty on object boundaries and for objects far from the camera. Epistemic uncertainty accounts for our ignorance about which model generated our collected data. This is a notably different measure of uncertainty and in (e) our model exhibits increased epistemic uncertainty for semantically and visually challenging pixels. The bottom row shows a failure case of the segmentation model when the model fails to segment the footpath due to increased epistemic uncertainty, but not aleatoric uncertainty. which captures our ignorance about which model generated our collected data. This uncertainty can be',\n",
       " '1608.00778': 'Word embeddings are a powerful approach for analyzing language (Bengio et al., 2006; Mikolov et al., 2013a,b; Pennington et al., 2014). A word embedding method discovers distributed representations of words; these representations capture the semantic similarity between the words and reﬂect a variety of other linguistic regularities (Rumelhart et al., 1986; Bengio et al., 2006; Mikolov et al., 2013c). Fitted word embeddings can help us understand the structure of language and are useful for downstream tasks based on text. There are many variants, adaptations, and extensions of word embeddings (Mikolov et al., 2013a,b; Mnih and Kavukcuoglu, 2013; Levy and Goldberg, 2014; Pennington et al., 2014; Vilnis and McCallum, 2015), but each reﬂects the same main ideas. Each term in a vocabulary is associated with two latent vectors, an embedding and a context vector. These two types of vectors govern conditional probabilities that relate each word to its surrounding context. Speciﬁcally, the conditional probability of a word combines its embedding and the context vectors of its surrounding words. (Different methods combine them differently.) Given a corpus, we ﬁt the embeddings by maximizing the conditional probabilities of the observed text. In this paper we develop the exponential family embedding (ef-emb), a class of models that generalizes the spirit of word embeddings to other types of high-dimensional data. Our motivation is that other types of data can beneﬁt from the same assumptions that underlie word embeddings, namely that a data point is governed by the other data in its context. In language, this is the foundational idea that words with similar meanings will appear in similar contexts (Harris, 1954). We use the tools of exponential families (Brown, 1986) and generalized linear models (glms) (McCullagh and Nelder, 1989) to adapt this idea beyond language. 30th Conference on Neural Information Processing Systems (NIPS 2016), Barcelona, Spain. arXiv:1608.00778v2  [stat.ML]  21 Nov 2016  As one example beyond language, we will study computational neuroscience. Neuroscientists measure sequential neural activity across many neurons in the brain. Their goal is to discover patterns in these data with the hope of better understanding the dynamics and connections among neurons. In this example, a context can be deﬁned as the neural activities of other nearby neurons, or as neural activity in the past. Thus, it is plausible that the activity of each neuron depends on its context. We will use this idea to ﬁt latent embeddings of neurons, representations of neurons that uncover hidden features which help suggest their roles in the brain. Another example we study involves shoppers at the grocery store. Economists collect shopping data (called “market basket data”) and are interested in building models of purchase behavior for downstream econometric analysis, e.g., to predict demand and market changes. To build such models, they seek features of items that are predictive of when they are purchased and in what quantity. Similar to language, purchasing an item depends on its context, i.e., the other items in the shopping cart. In market',\n",
       " '1410.6264': 'A popular way to deal with diversity of imaging conditions as well as geometric variation in objects or entire scenes is to simply represent images or image regions as disordered “bags” of image features [1]–[3]. These models are particularly, attractive due to the computational efﬁciency and simplicity achieved by ignoring spatial relationships of the image patches or object parts. The bag of features can arise in a variety of ways. For example, after extracting local low-level features from images, these are often clustered and a discrete “codeword” is assigned to each feature descriptor. An image is then described by a histogram over the codebook entries. Ideally, these features should be highly discriminative so that most categories of images of interest are uniquely identiﬁable by the presence of a handful of features. In practice, however, individual features are not sufﬁciently discriminative, and modeling joint variation in feature counts becomes an interesting machine learning problem. It is tempting to use here the existing discrete models, such as histograms [4], multinomial mixtures [5,6] or topic models [7,8], already extensively validated on text data, where each document is also simply represented as a count distribution over the entire vocabulary. However, the bags of features extracted from natural images have an imprint of the images’ spatial structure, which is evident when the bags from related images are considered together. Thus ignoring these natural constraints on the feature counts may have negative consequences in classiﬁcation tasks. For an illustration, Fig. 2 provides a synthetic example starting with several images of a train station, taken as windows into the larger scene - ii). Just for illustrative purposes, we hand-labeled the scene with feature labels as shown in - iii). In a realistic application, where we may want to train a model that assigns high likelihood to images of train stations, it is likely that most available images would be taken with a narrower ﬁeld of view, as simulated here. Feature extractors would presumably generalize much less effectively than our ideal features, but still enough to permit comparisons of images of different train stations, too. Then the question is if a learning model that captures feature count co-variation uses the training data efﬁciently. Assuming that a few images are taken at random from the scene, we wonder if the feature counts in these images are sufﬁcient to predict the possible feature counts in other images of the scene. In particular, we consider images taken from the regions close to A, B, and C and ask the question if the image D would ﬁt the so deﬁned train station class. The literature uses two sets of approaches to this problem. Kernel or nearest-neighbor techniques start with the comparisons of the feature counts in the test image and each of the previously studied exemplars [9]–[13]. Although this comparison can be done in many different ways, we note here that these approaches would be complicated by the fact that none of',\n",
       " '1702.02779': 'Camera pose estimation is an important problem in computer vision, with applications in simultaneous localisation and mapping (SLAM) [29, 28, 19], virtual and augmented reality [1, 4, 14, 30, 31, 38] and navigation [21]. In SLAM, the camera pose is commonly initialised upon starting reconstruction and then tracked from one frame to the next, but tracking can easily be lost due to e.g. rapid movement or textureless regions in the scene; when this happens, it is important to be able to relocalise the camera with respect to the scene, rather than forcing the user to start the reconstruction again from scratch. Camera relocalisation is also crucial for loop closure when trying to build globally consistent maps ∗S. Golodetz and N. Lord assert joint second authorship. [7, 18, 40]. Traditional approaches to camera relocalisation have been based around one of two main paradigms: (i) Image matching methods match the current image from the camera against keyframes stored in an image database (potentially with some interpolation between keyframes where necessary). For example, Galvez-Lopez et al. [10] describe an approach that computes a bag of binary words based on BRIEF descriptors for the current image and compares it with bags of binary words for keyframes in the database using an L1 score. Gee et al. [12] estimate camera pose from a set of synthetic (i.e. rendered) views of the scene. Their approach is interesting because unlike many image matching methods, they are to some extent able to relocalise from novel poses; however, the complexity increases linearly with the number of synthetic views needed, which poses signiﬁcant limits to practical use. Glocker et al. [13] encode frames using Randomised Ferns, which when evaluated on images yield binary codes that can be matched quickly by their Hamming distance: as noted in [23], this makes their approach much faster than [12] in practice. (ii) Keypoint-based methods ﬁnd 2D-to-3D correspondences between keypoints in the current image and 3D scene points, so as to deploy e.g. a Perspective-n-Point (PnP) algorithm [16] (on RGB data) or the Kabsch algorithm [17] (on RGB-D data) to generate a number of camera pose hypotheses that can be pruned to a single hypothesis using RANSAC [8]. For example, Williams et al. [41] recognise/match keypoints using an ensemble of randomised lists, and exclude unreliable or ambiguous matches when generating hypotheses. Their approach is fast, but needs signiﬁcant memory to store the lists. Li et al. [23] use graph matching to help distinguish between visuallysimilar keypoints. Their method uses BRISK descriptors for the keypoints, and runs at around 12 FPS. Sattler et al. [32] describe a large-scale localisation approach that ﬁnds 1 arXiv:1702.02779v2  [cs.CV]  26 Jun 2017  Camera Pose Estimation Pre-Training Online Adaptation Pose Hypothesis N Pose Hypothesis 1 Depth RGB Pre-emptive  RANSAC ... ... ... Output Pose  Hypothesis RGB Depth Reconstructed Scene RGB Depth Reconstructed Scene Figure 1',\n",
       " '1602.00223': 'We consider the following convex optimization problem min x∈Rd P(x) def = F(x) + R(x), (1) where F is the average of a set of smooth convex functions fi(x), namely F(x) = 1 n n X i=1 fi(x), and R(x) is convex and can be non-smooth. The formulation (1) includes many applications in machine learning, such as regularized empirical risk minimization. For example, given a training set {(a1, b1), (a2, b2), . . . , (am, bm)}, where ai ∈Rd is the 1  feature of the ith sample and bi ∈R is the response. If we take fi(x) = 1 2(aT i x−bi)2, and R(x) = λ1||x||1, then we can obtain lasso regression. If we take fi(x) = log(1 + exp(−bixT ai)) + λ1||x||2 (bi ∈{1, −1}), R(x) = λ2||x||1, then the model becomes logistic regression with elastic net penalty. One typical approach for solving the formulation (1) is ﬁrst order methods that use proximal mappings to handle the non-smooth part, such as ISTA Daubechies et al. (2003), SpaRSA Wright et al. (2009) and TRIP Kim et al. (2010). The ﬁrst order method can be improved by Nesterov’s acceleration strategy Nesterov (1983). One seminal work is the FISTA Beck & Teboulle (2009), and related package TFOCS Becker et al. (2011) has been widely used. Another class of methods to handle Problem (1) is proximal Newton-type algorithms Fukushima & Mine (1981); Becker & Fadili (2012); Oztoprak et al. (2012); Lee et al. (2014). Proximal Newton-type methods approximate the smooth part with a local quadratic model and successively minimize the surrogate functions. Compared with the ﬁrst-order methods, the Newton-type methods obtain rapid convergence rate because they incorporate additional curvature information. Both conventional ﬁrst order and Newton-type methods require the computation of full gradient in each iteration, which is very expensive when the number of the component n is very large. In this case, ones usually exploit the stochastic optimization algorithms, which only process single or mini-batch components of the objective at each step. The stochastic gradient descent (SGD) Bottou (2010) has been widely used in many machine learning problems. However, SGD usually suffers from large variance of random sampling, leading to a slower convergence rate. There are some methods to improve SGD in the case that the objective is smooth (a special case of Problem (1) in which R(x) ≡0). They include the ﬁrst order methods such as SAG Roux et al. (2012) and SVRG Johnson & Zhang (2013), and the Newton-type methods such as stochastic quasi-newton method Byrd et al. (2014), uniﬁed quasi-Newton method Sohl-Dickstein et al. (2014) and linearly-convergent stochastic L-BFGS Moritz et al. (2015). There are also some extensions to solve the formulation (1) which includes the non-smooth case, e.g., the ﬁrst order method Prox-SVRG Xiao & Zhang (2014), accelerated Prox-SVRG Nitanda (2014) and proximal stochastic Newton-type gradient descent Shi',\n",
       " '1810.11027': 'The standard ΛCDM cosmological model – based on a cosmological constant as the source of the observed accelerated cosmic expansion (Riess et al. 1998; Perlmutter et al. 1999; Schmidt et al. 1998) and on cold dark matter particles as the bulk of the clustering mass in the universe (White & Rees 1978; White 1993, 1996; Springel et al. 2005) – has survived the past two decades of cosmological observations targeted to a wide range of independent probes. This includes the statistical properties of Cosmic Microwave Background (CMB) ⋆E-mail: julian.merten@inaf.it anisotropies (Bennett et al. 2013; Planck Collaboration et al. 2018), the large-scale distribution and dynamics of visible galaxies (Parkinson et al. 2012; Alam et al. 2017; Pezzotta et al. 2017), weak gravitational lensing signals (Fu et al. 2008; Joudaki et al. 2017; Hildebrandt et al. 2017; Troxel et al. 2018; Hikage et al. 2018), the abundance of galaxy clusters, as well as its time evolution (Vikhlinin et al. 2009; Planck Collaboration et al. 2016b). Despite this astonishing success, the fundamental nature of the two main ingredients of the ΛCDM model – summing up to about 95% of the total energy density of the universe – remains unknown. On one side, the energy scale associated with the cosmological constant does not © 2019 The Authors arXiv:1810.11027v2  [astro-ph.CO]  27 Mar 2019  2 J. Merten et al. ﬁnd any reasonable explanation in the context of fundamental physics, with predictions based on the standard model of particle physics failing by tens of orders of magnitude. On the other hand, no clear detection – direct or indirect – of any new fundamental particle that may be associated with cold dark matter has been made despite a longstanding chase through astrophysical observations (Aartsen et al. 2013; Ackermann et al. 2017; Albert et al. 2017) and laboratory experiments (see e.g. Bernabei et al. 2018; ATLAS Collaboration 2013; CMS Collaboration 2016). This leaves the next generation of cosmological observations with the arduous challenge of clarifying the fundamental nature of the dark sector by systematically scrutinising the huge wealth of high-quality data that will be made available in the near future by several wide-ﬁeld surveys (such as Laureijs et al. 2011; Ivezic et al. 2008; Spergel et al. 2015; Benitez et al. 2014). As a matter of fact, any possible insights from future datasets must come in the form of very small deviations from the expectations of the ΛCDM model, otherwise past observations would have already detected them. This suggests that either the fundamental physics behind dark energy and dark matter is indeed extremely close to that of General Relativity (GR) with a cosmological constant and heavy fundamental particles with negligible thermal velocities, respectively, or that a more radical shift from this standard paradigm is hidden and masked by other effects such as an observational degeneracy with some not yet fully constrained cosmological parameter. The latter scenario may result in a severe',\n",
       " '1612.04799': 'In recent years, deep learning has radically transformed a majority of approaches to computer vision, reinforcement learning, and generative models [Schmidhuber (2015)]. Theoretically, we still lack a uniﬁed description of what computational mechanisms have made these deeper models more successful than their wider counterparts. Substantial analysis by Shalev-Shwartz et al. (2011), Raghu et al. (2016), Poole et al. (2016) and many others gives insight into how the properties of neural architectures, like depth and weight sharing, determine the expressivity of those architectures. However, less studied is the how the properties of data, such as sample statistics or geometric structure, determine the architectures which are most expressive on that data. Surprisingly, the latter perspective leads to simple questions without answers rooted in theory. For example, what topological properties of images allow convolutional layers such expressivity and generalizeability thereon? Intuitively, spatial locality and translation invariance are sufﬁcient justiﬁcations in practice, but is there a more general theory which suggests the optimality of convolutions? Furthermore, do there exist weight sharing schemes beyond convolutions and fully connected layers that give rise to provably more expressive models in practice? In this paper, we will more concretely study the data-architecture relationship and develop a theoretical framework for creating layers and architectures with provable properties subject to topological and geometric constraints imposed on the data. The Problem with Resolution. To motivate a use for such a framework, we consider the problem of learning on high resolution data. Computationally, machine learning deals with discrete signals, but frequently those signals are sampled in time from a continuous function. For example, audio is inherently a continuous function f : [0, tend] →R, but is sampled as a vector v ∈R44,100×t. Even in vision, images are generally piecewise smooth functions f : R2 →R3 mapping pixel position to color intensity, but are sampled as tensors v ∈Rx×y×c. Performing tractible machine learning as the resolution of images or audio increases almost always requires some lossy preprocessing like PCA or Discrete Fourier Analysis [Burch (2001)]. Convolutional neural networks avoid dealing therein by intutively assuming a spacial locality on these vectors. However, one wonders what is lost through the use of various dimensionality reduction and weight sharing schemes1. 1Note we do not claim that deep learning on high resolution data is currently intractible or ineffective. The problem of resolution is presented as an example in which topological constaints can be imposed on a type of data to yield new architecutres with desired, provable properties. 1 arXiv:1612.04799v2  [stat.ML]  6 Nov 2017  Figure 1: Left: A discrete vector v ∈Rl×w representation of an image. Right: The true continuous function f : R2 →R from which it was sampled. A key observation in discussing a large class of smooth functions is their simplicity. Although from a set theoretic perspective, the graph of a function consists of inﬁniteley many points, relatively complex algebras of functions can be described with symbolic simplicity. A great example are polynomials: the space of all',\n",
       " '1607.06641': 'Evolutionary Algorithms (EA) have been widely used in both continuous and discrete domains [1], [2], [3]. Resampling1 has proved to be a powerful tool in improving the local performance of EAs in noisy optimisation [3], [4], [5], and different resampling rules have been applied to a variety of EAs in continuous noisy optimisation, as studied in [6], [7]. Akimoto et al. [8] concluded that the running time for an adapted algorithm using resampling to solve a problem with additive Gaussian noise is similar to the runtime in the noise-free case when multiplying by a factor log n, where n is the problem dimension. Previous work on solving the OneMax problem [9] has concentrated on using a (1+1)-Evolution Algorithm (EA) [10], [11]. The OneMax problem with One-bit noise (exactly one uniformly selected bit changes with probability p ∈(0, 1) due to the noise) has been studied previously by Droste [10]. Qian et al. [11] claimed that resampling wasn’t beneﬁcial in optimising OneMax with additive Gaussian noise using (1+1)- EA. Recently, Liu et al. [12], [13] applied a bandit-based RMHC to the noisy OneMax problem, and showed that it was important to choose an optimal resampling number, so as to compromise the reduction in sampling noise against the cost of doing so. The main contribution of this work is the analysis of the optimal resampling number in the OneMax problem, in the presence of additive Gaussian noise. We show that the optimal resampling number increases with the problem dimension. 1In this paper, “resampling” refers to the multiple re-evalutions of a solution. The paper is structured as follows. Section II provides a brief review of the related work and describes our noisy OneMax problem. Section III explains the modiﬁed Random Mutation Hill-Climbing algorithm used in the noisy context. Section IV analyses the optimal resampling number in the deﬁned noisy OneMax problem. Experimental results are presented and discussed in Section V. Finally, Section VI concludes the work. II. BACKGROUND This section is organised as follows. Section II-A presents the original Random Mutation Hill-Climbing algorithm and its relation to (1+1)-EA. Section II-B recalls the OneMax problem, then a noisy variant of OneMax problem is deﬁned in Section II-C. More related literatures in solving different noisy variants of OneMax problems are discussed in Section II-D A. Random Mutation Hill-Climbing The Random Mutation Hill-Climbing (RMHC), also called Stochastic Hill Climbing, is a derivative-free optimisation method mostly used in discrete domains [14], [15]. RMHC can also be seen as an evolutionary algorithm in which there is a population of just one individual, and at each generation a child genome is formed from the current (best-sofar) individual by mutating exactly one gene, chosen uniformly at random. After mutation, the mutated child genome replaces its parent if its ﬁtness value is improved or equivalent. In other words, RMHC randomly selects a neighbour candidate in the search space (where neighbour',\n",
       " '1603.04042': 'Interactive object selection (also known as interactive segmentation) has become a very popular research area over the past years. It enables users to select objects of interest accurately by interactively providing inputs such as strokes and bounding boxes. The selected results are useful for various applications such as localized editing and image/video composition. There are many algorithms proposed to solve this problem. One of the most famous algorithms is proposed by Boykov and Jolly [2] where they formulate interactive segmentation as the graph cut optimization and solve it via max-ﬂow/min-cut energy minimization. Rother et al. [19] extend graph cut by using a more powerful, iterative version of optimization. Bai and Sapiro [1] present a new algorithm that computes weighted geodesic distances to the userprovided scribbles. Grady [8] uses the graph theory to estimate the probabilities of random walks from unlabeled pixels to labeled pixels. In order to get accurate segmentation, all these algorithms require substantial user interactions to have a good estimation of the foreground/background distributions. In contrast, our approach simpliﬁes user interactions to a few clicks, with one or two clicks usually giving reasonably good results. The advantage of our approach over the others is the capability to understand objectness and semantics by leveraging deep learning techniques. To our best knowledge, this is the ﬁrst work that solves interactive segmentation in the framework of deep learning. Our approach is inspired by recent successes of deep fully convolutional neural networks (FCNs) on the semantic segmentation problem [15, 26, 3, 14, 12]. Long et al. [15] adapt popular deep classiﬁcation networks into FCNs for semantic segmentation and improve the architecture with multi-resolution layer combinations. Built upon this, Chen et al. [3] combine the outputs of FCNs with Conditional Random Field (CRF) while Zheng et al. [26] formulate mean-ﬁeld approximate inference as Recurrent Neural Network (RNN) and plug it on top of FCNs to get ﬁner results. A seemingly plausible transformation of those approaches to interactive segmentation is that we ﬁrst perform semantic segmentation on the whole image and then select the connected components which contain user-provided selections. However, there exists at least three problems with this approach. First, it is not always clear how to response to use inputs. For example, if the user places a foreground click and background click inside the same class label, this approach cannot response to that. Second, current semantic segmentation methods do not support instance-level seg1 arXiv:1603.04042v1  [cs.CV]  13 Mar 2016  mentation while that is often the user’s desire. Last but not the least, current semantic segmentation approaches do not generalize to unseen objects. This means that we have to train a model for every possible object in the world, which is obviously impractical. In this paper, we present a novel algorithm for interactive object selection (Fig. 1). To select an object in an image, users provide',\n",
       " '1804.09398': 'Context features play a crucial role in many vision classiﬁcation problems, such as semantic segmentation [1,2,3,4,5,6], object detection [7,8] and pose estimation [9,10]. As illustrated by the toy example in Fig. 1, when performing classiﬁcation on the blurry white objects with similar appearance, if the semantic histogram from the whole image has a higher bin on the class “sea”, then the object is more likely to be classiﬁed as a “boat”; if the histogram has a higher bin on the class “sky”, then it is more likely to be classiﬁed as a “bird”. The semantic context thus acts as an important indicator for this classiﬁcation task. Context features could be mainly categorized into statistical and non-statistical ones depending on whether they abandon the spatial orders of the context information. On the one hand, for most deep learning methods that gain increasing attention in recent years, non-statistical context features dominate. Some examples include [11] for object detection and [12] for semantic segmentation. On the other hand, statistical context features were mostly used in conventional classiﬁcation methods with hand-crafted features. Commonly used statistical features include histogram, Bag-of-Words (BoW) [13], Fisher vector [14], ⋆Corresponding authors arXiv:1804.09398v3  [cs.CV]  15 Oct 2018  2 Zhe Wang, Hongsheng Li, Wanli Ouyang, Xiaogang Wang boat bird sky sea Global context (histogram) Appearance  feature boat bird sky sea Global context  (histogram) Appearance  feature More likely to be  “bird” More likely to be  “boat” Fig. 1. A toy example showing that the global context (histogram) of a whole image is helpful for classifying image patches. The image patch is more likely to be a “bird” if the histogram has higher bin counts on the class “sky”, or a “boat” if the histogram has higher bin counts on the class “sea”. Second-order pooling [15], etc. Such global context features performed successfully with hand-crafted low-level features at their times. However, they were much less studied since the popularity of deep learning. There are a limited number of deep learning methods that tried to incorporate statistical features into deep neural networks. Such examples include the deep Fisher network [16] that incorporate Fisher vector and orderless pooling [17] that combines with Vector of Locally Aggregated Descriptors (VLAD). Both methods aim to improve the image classiﬁcation performance. However, when calculating the statistical features, both methods ﬁx the network parameters and simply treat features by deep networks as oﬀ-the-shelf features. In such a way, the deep networks and the statistical operations are not jointly optimized, which is one of the key factors for the success of deep networks. In this work, we introduce a learnable histogram layer for deep neural networks. Unlike existing deep learning methods that treat statistical operations as a separate module, our proposed histogram layer is able to back-propagate (BP) errors and learn optimal bin centers and bin width during training. Such properties make it',\n",
       " '1805.10796': 'N ATURAL Language processing (NLP) is considered one of three main pillars of Deep Learning along with image and video processing. Mobile devices are becoming increasingly dominant both in terms of their number as well as a computing load and network trafﬁc. They also become more interactive in terms of NLP algorithms implemented for applications such as translation or voice-typing. Consequently, there is a signiﬁcant beneﬁt from reducing memory footprint and computational burden for deployment of NLP modules on embedded devices. It is worth noting that despite an abundance of research efforts in Deep Learning architectures compression for image processing [4], [5], [11], there are just a few projects aiming at NLP neural architectures compression [1], [2], [3], [12]. This paper shows a case study of employing common compression techniques for compressing NLP architectures. A series of quantization and pruning techniques were implemented and deployed in FPGA platform. The main goal of the paper was to examine feasibility and efﬁciency of using FPGAs in a domain of embedded neural computations. A set of common datasets were used to conduct reliable experiments. The experiments reviled a strong relationship between a size and the structure of datasets and performance of quantization and pruning methods used. All the layers of the neural architecture [6] were analyzed separately with respect to their ability to be quantized and pruned. The structure of the paper is structured as follows. Section II provides an overview of CNN architectures, quantization and pruning processes. Section III covers the dataset used for the experiments. Section IV describes neural model used for the experiments as well as FPGA implementation details of the architecture. Finally, section VI contains the results of the experiments. Section VII summarizes contribution of this work. II. CONVOLUTIONAL NEURAL NETWORK CNNs are composed of neurons that have learnable weights and biases. Each neuron receives inputs structured as multidimensional vectors (tensor), perform a convolution operation on this input it with multi-dimensional ﬁlters and then optionally follows outputs with pooling and non-linearity functions. Typically, the layers of a CNN have neurons that generate outputs feature maps yi, i = 1...N as follows yi = bi + M X j=1 Fij ∗xj (1) where Fij are two-dimensional (2D) convolutional kernels of dimensions H × W, ∗represents the convolution operation and bi are the bias terms. The number of multiply-accumulate (MAC) operations and cycles spent on the execution of in a practical implementation is often used as the metric for a complexity of a CNN. Assuming each output feature map yi has P elements (where P is equal to height multiplied by width of given feature map) the total number of MAC calculations for a convolutional ﬁltering operation is MACs = PHWMN. Our role in quantization is to reduce the complexity of each one of these operations and in network compression through pruning the goal is to reduce the total number of operations. A. Quantization process Quantization is the procedure of constraining values from a continuous set',\n",
       " '1809.09910': 'Reproducing kernel Hilbert spaces (RKHS) (Aronszajn, 1950; Saitoh and Sawano, 2016) provide the ability to approximate functions by nonparametric functional representations, and thus have developed into an important tool in many areas, especially kernel methods in machine learning (Suykens et al., 2002; Sch¨olkopf and Smola, 2018). For any two data points x, x′ ∈X, kernel *. Fanghui Liu and Lei Shi contributed equally to this work. Corresponding authors: Fanghui Liu and Jie Yang. ©2021 Fanghui Liu, Lei Shi, Xiaolin Huang, Jie Yang, and Johan A.K. Suykens. License: CC-BY 4.0, see https://creativecommons.org/licenses/by/4.0/. Attribution requirements are provided at http://jmlr.org/papers/v22/19-482.html. arXiv:1809.09910v4  [cs.LG]  19 Oct 2022  LIU, SHI, HUANG, YANG AND SUYKENS methods work under the setting: the original data are mapped to high or inﬁnite dimensional RKHS such that k(x, x′) = ⟨ϕ(x), ϕ(x′)⟩H with an implicit feature mapping ϕ : X →H. Here the kernel is required to be symmetric and positive deﬁnite (PD) 1, and corresponds a unique RKHS. The “reproducing” terminology indicates the reproducing property of RKHS f(x) = ⟨f, k(x, ·)⟩H, for all f ∈H and x ∈X . Accordingly, for each x ∈X, the point evaluation function f →f(x) is continuous, showing that strong convergence in RKHS implies point-wise convergence. This property makes RKHS an appealing choice in machine learning problems with nice theoretical guarantees in an approximation theory view (Caponnetto and De Vito, 2007; Cucker and Zhou, 2007). The structure of RKHS is determined by the choice of the kernel k, but selecting appropriate kernels is not a trivial task. In fact, RKHS is not large enough (Bach, 2017; Steinwart, 2020) and thus would lead to a lack of adaptivity in many learning problems. In this paper, we consider to learn the kernel from a hyper-reproducing kernel Hilbert space (hyper-RKHS) (Ong et al., 2005) associated with the reproducing hyper-kernel (Kondor and Jebara, 2007). Different from RKHS, every element in hyper-RKHS is a kernel function, which allows for signiﬁcant model ﬂexibility from a broad class. Speciﬁcally, the learned kernel endowed by hyper-RKHS has the property of translation and rotation invariant simultaneously (Motai, 2015), and thus is extensively applied to feature representations (Raj et al., 2017) and other applications such as classiﬁcation (Tsang and Kwok, 2006), density estimation (Ganti et al., 2008), and out-of-sample extensions (Pan et al., 2017). Learning in hyper-RKHS H is general to cover various settings or applications, e.g., kernel learning, out-of-sample extensions, and indeﬁnite kernels (real, symmetric but not positive deﬁnite). First, in kernel learning aspect, let X be a compact metric space, eY ⊆R be the output space2, D = {(xi, ˜yi)}m i=1 be the training set with xi ∈X and the response ˜yi ∈eY . Let k(·, ·) : X×X →R be a positive deﬁnite kernel function that we need to learn. Figure 1 shows the kernel learning framework in',\n",
       " '1812.02900': 'Batch reinforcement learning, the task of learning from a ﬁxed dataset without further interactions with the environment, is a crucial requirement for scaling reinforcement learning to tasks where the data collection procedure is costly, risky, or time-consuming. Off-policy batch reinforcement learning has important implications for many practical applications. It is often preferable for data collection to be performed by some secondary controlled process, such as a human operator or a carefully monitored program. If assumptions on the quality of the behavioral policy can be made, imitation learning can be used to produce strong policies. However, most imitation learning algorithms are known to fail when exposed to suboptimal trajectories, or 1Department of Computer Science, McGill University, Montreal, Canada 2Mila Qu´ebec AI Institute. Correspondence to: Scott Fujimoto <scott.fujimoto@mail.mcgill.ca>. Proceedings of the 36 th International Conference on Machine Learning, Long Beach, California, PMLR 97, 2019. Copyright 2019 by the author(s). require further interactions with the environment to compensate (Hester et al., 2017; Sun et al., 2018; Cheng et al., 2018). On the other hand, batch reinforcement learning offers a mechanism for learning from a ﬁxed dataset without restrictions on the quality of the data. Most modern off-policy deep reinforcement learning algorithms fall into the category of growing batch learning (Lange et al., 2012), in which data is collected and stored into an experience replay dataset (Lin, 1992), which is used to train the agent before further data collection occurs. However, we ﬁnd that these “off-policy” algorithms can fail in the batch setting, becoming unsuccessful if the dataset is uncorrelated to the true distribution under the current policy. Our most surprising result shows that off-policy agents perform dramatically worse than the behavioral agent when trained with the same algorithm on the same dataset. This inability to learn truly off-policy is due to a fundamental problem with off-policy reinforcement learning we denote extrapolation error, a phenomenon in which unseen state-action pairs are erroneously estimated to have unrealistic values. Extrapolation error can be attributed to a mismatch in the distribution of data induced by the policy and the distribution of data contained in the batch. As a result, it may be impossible to learn a value function for a policy which selects actions not contained in the batch. To overcome extrapolation error in off-policy learning, we introduce batch-constrained reinforcement learning, where agents are trained to maximize reward while minimizing the mismatch between the state-action visitation of the policy and the state-action pairs contained in the batch. Our deep reinforcement learning algorithm, Batch-Constrained deep Q-learning (BCQ), uses a state-conditioned generative model to produce only previously seen actions. This generative model is combined with a Q-network, to select the highest valued action which is similar to the data in the batch. Under mild assumptions, we prove this batch-constrained paradigm is necessary for',\n",
       " '1308.3513': 'Many control applications involve repeated encounters with domains that have similar, but not identical, dynamics. An agent swinging a bat may encounter several bats with different weights or lengths, while an agent manipulating a cup may encounter cup with different amounts of liquid. An agent driving a car may encounter many different cars, each with unique handling characteristics. In all of these scenarios, it makes little sense of the agent to start afresh when it encounters a new bat, a new cup, or a new car. Exposure to a variety of related domains should correspond to faster and more reliable adaptation to a new instance of the same type of domain. If an agent has already swung several bats, for example, we would hope that it could easily learn to swing a new bat. Why? Like many domains, the bat-swinging domain has a low-dimensional representation that affects the system’s dynamics in structured ways. The agent’s prior experience should allow it to both learn how to model related instances of a domain—such as the bat’s length, a latent parameter that smoothly changes in the bat’s dynamics—and what speciﬁc model parameters (e.g., lengths) are likely. Domains with closely-related dynamics are an interesting regime for transfer learning. We introduce the Hidden Parameter Markov Decision Process (HiP-MDP) as a formalization of these types of domains, with two important features. First, we posit that there exist a bounded number of latent parameters that, if known, would fully specify the dynamics. Second, we assume the parameter values remain ﬁxed for a task’s duration (e.g. the bat’s length will not change during a swing), and the agent will know when a change has occurred (getting a new bat). The HiP-MDP parameters encode the minimum amount of learning required for the agent to adapt to a new domain instance. Given a generative model of how the latent parameters affect domain dynamics, an agent could rapidly identify the dynamics of a particular domain instance by maintaining and updating its distribution (or belief) over the latent parameters. Instead of learning a new policy for each domain instance, it could synthesize a parametrized control policy [1, 2] based on a point estimate of the parameter values, or plan in the belief space over its parameters [3, 4, 5, 6, 7]. We present a method for learning the structure of a HiP-MDP from data. Our generative model uses Indian Buffet Processes [8] to model what latent parameters are relevant for a particular set of dynamics and Gaussian processes [9] to model the dynamics functions. We do not require knowledge of a system’s kinematics equations, nor must ∗Both authors are primary authors on this occasion. 1 arXiv:1308.3513v1  [cs.LG]  15 Aug 2013  we specify the number of latent parameters in advance. Our HiP-MDP model efﬁciently performs control in the challenging acrobot domain [10] by rapidly identifying the dynamics of new instances. 2 Background Bayesian Reinforcement Learning',\n",
       " '1708.02550': 'The last years the re-appearance of Convolutional Neural Networks (CNNs), whose origin traces back to the 1970s and 1980s, has led to signiﬁcant advances in many computer vision tasks, such as image classiﬁcation [14], object detection [8], semantic scene segmentation [16], instance segmentation [9], and monocular depth estimation [6] to name a few. The majority of these works rely on ﬁnetuning or slightly altering a CNN architecture, typically the VGG network [19], resulting in task-speciﬁc CNNs with long inference times that each require a single GPU to run. Admittedly, this is not enough for autonomous driving applications where many of the aforementioned tasks should run in parallel, in real-time, and on a limited number of GPU devices. Furthermore, as shown in recent works [13], [20], [22] there is merit in combining multiple tasks in a single integrated architecture, as one task might beneﬁt from another leaving smaller space for ’blindspots’, which is crucial for self-driving vehicles. Motivated by these observations, in this paper we focus on street scene understanding and present an efﬁcient implementation that combines the tasks of semantic scene segmentation, instance segmentation, and monocular depth estimation. Unlike state-of-the-art methods, that use networks with huge number of parameters and long inference times (e.g. VGG [19], SegNet [2], FCN [16]), we build upon a real-time architecture, in particular ENet [18] that has proven to offer image processing rates higher than 10 fps on a single GPU device. Speciﬁcally, we use a common ENet encoding step for all tasks, but introduce a branched ENet architecture for the decoding step (i.e. one branch for each of the three different tasks). Fig. 1 gives an overview of our approach. Fig. 1. Overview of our method. From left to right: the input image is passed though the encoding step of an ENet-inspired architecture to create feature maps, which in turn are forwarded to different branches that perform decoding to arrive at the three outputs, i.e. semantic labels, instance labels and depth. A video is available at https://youtu.be/55ElRh-g_7o. Although we do not introduce a new architecture, in this paper we show how to efﬁciently combine existing components to build a solid architecture for real-time scene understanding. In Sec. II we describe related work on integrated architectures that tackle multiple tasks. Next, we present the implementation details of our method in Sec. III. Finally, in Sec. IV and V we report results for each of the tasks and provide some insights into the strengths and limitations of the presented approach. II. RELATED WORK The amount of research performed in literature on the three main tasks studied in this paper, i.e. semantic scene segmentation, instance segmentation, and monocular depth estimation, is vast. In what follows, we solely focus on related works that have combined one or more of these tasks in a single integrated architecture. Eigen and Fergus [5] addressed the tasks of depth',\n",
       " '1811.04064': 'Markov random ﬁelds (MRFs) and conditional random ﬁelds (CRFs) are powerful classes of models for learning and inference of factored probability distributions (Koller and Friedman 2009; Wainwright and Jordan 2008). They have been widely used in tasks such as structured prediction (Taskar, Guestrin, and Koller 2004) and computer vision (Nowozin and Lampert 2011). Traditional training methods for MRFs learn by maximizing an approximate maximum likelihood. Many such methods use variational inference to approximate the crucial partition function. With MRFs, the gradient of the log likelihood with respect to model parameters is the marginal vector. With CRFs, it is the expected feature vector. These identities suggest that each iteration of optimization must involve computation of the full marginal vector, containing the estimated marginal probabilities of all variables and all dependent groups of variables. In some applications, the number of variables can be massive, making traditional, full-inference learning too expensive in practice. This problem limits the application of MRFs in modern data science tasks. In this paper, we propose block belief propagation learning (BBPL), which alleviates the cost of learning by computing approximate gradients with inference over only a small block of variables at a time. BBPL ﬁrst separates the Markov Copyright c⃝2019, Association for the Advancement of Artiﬁcial Intelligence (www.aaai.org). All rights reserved. network into several small blocks. At each iteration of learning, it selects a block and computes its marginals. It approximates the gradient with a mix of the updated and the previous marginals, and it updates the parameters of interest with this gradient. Related Work Many methods have been developed to learn MRFs. In this section, we cover only the BP-based methods. Mean-ﬁeld variational inference and belief propagation (BP) approximate the partition function with non-convex entropies, which break the convexity of the original partition function. In contrast, convex BP (Globerson and Jaakkola 2007; Heskes 2006; Schwing et al. 2011; Wainwright, Jaakkola, and Willsky 2005; Wainwright 2006) provides a strongly convex upper bound for the partition function. This strong convexity has also been theoretically shown to be beneﬁcial for learning (London, Huang, and Getoor 2015). Thus, our BBPL method uses convex BP to approximate the partition function. Regarding inference, some methods are developed to accelerate computations of the beliefs and messages. Stochastic BP (Noorshams and Wainwright 2013) updates only one dimension of the messages at each inference iteration, so its iteration complexity is much lower than traditional BP. Distributed BP (Schwing et al. 2011; Yin and Gao 2014) distributes and parallelizes the computation of beliefs and messages on a cluster of machines to reduce inference time. Sparse-matrix BP (Bixler and Huang 2018) uses sparsematrix products to represent the message-passing indexing, so that it can be implemented on modern hardware. However, to learn MRF parameters, we need to run these inference algorithms for many iterations on the whole network until convergence at each parameter update',\n",
       " '1509.00825': 'Multiple Classiﬁer Systems (MCS) aim to combine classiﬁers in order to increase the recognition accuracy in pattern recognition systems [1, 2]. MCS are composed of three phases [3]: (1) Generation, (2) Selection, and (3) Integration. In the ﬁrst phase, a pool of classiﬁers is generated. In the second phase, a single classiﬁer or a subset having the best classiﬁers of the pool is(are) selected. We refer to the subset of classiﬁers as the Ensemble of Classiﬁers (EoC). In the last phase, integration, the predictions of the selected classiﬁers are combined to obtain the ﬁnal decision [1]. Recent works in MCS have shown that dynamic ensemble selection (DES) techniques achieve higher classiﬁcation accuracy when compared to static ones [3, 4, 5]. This is specially true for ill-deﬁned problems, i.e., for problems where the size of the training data is small, and there are not enough data available to train the classiﬁers [6, 7]. The key issue in DES is to deﬁne a criterion to measure the level of competence of a base classiﬁer. Most DES techniques [5, 8, 9, 10] estimate the classiﬁers’ local accuracy in small regions of the feature space surrounding the query instance, called the region of competence, as a search criterion for estimating the competence level of the base classiﬁer. However, in our previous work [10], we demonstrated that the use of local accuracy estimates alone is insufﬁcient to provide higher classiﬁcation performance. In addition, a dissimilarity analysis among eight dynamic selection techniques, performed in [11], indicates that techniques based on different criteria for estimating the competence level of base classiﬁers yields different results. To tackle this issue, in [4] we proposed a novel DES framework, called META-DES, in which multiple criteria regarding the behavior of a base classiﬁer are used to compute its level of competence. The framework is based on two environments: the classiﬁcation environment, in which the input features are mapped into a set of class labels, and the meta-classiﬁcation environment, where several properties from the classiﬁcation environment, such as the classiﬁer accuracy in a local region of the feature space, are extracted from the training data and encoded as meta-features. Given a test data, the meta-features are extracted using the test data as reference, and used as input to the meta-classiﬁer. The meta-classiﬁer decides whether the base classiﬁer is competent enough to classify the test sample. One interesting properties of the META-DES framework is that it obtains higher classiﬁcation accuracy using only linear classiﬁers. In this work, we perform a deep analysis of the training and classiﬁcation steps of the META-DES framework. We perform step-by-step examples in order to show the inﬂuence of different sets of meta-features used to better estimate the competence of the base classiﬁer. The analysis is conducted using the P2 problem [12, 13] which is a two-class non-linear problem with a complex decision boundary. Furthe',\n",
       " '1705.00652': 'Applications of natural language understanding (NLU) are becoming increasingly interesting with scalable machine learning, web-scale training datasets, and applications that enable fast and nuanced quality evaluations with large numbers of user interactions. Early NLU systems parsed natural language with hand-crafted rules to explicit semantic representations, and used manually written state machines to generate speciﬁc responses from the output of parsing [18]. Such systems are generally limited to the situations imagined by the designer, and much of the development work involves writing more rules to improve the robustness of semantic parsing and the coverage of the state machines. These systems are brittle, and progress is slow [31]. Eventually adding more parsing rules and response strategies becomes too complicated for a single designer to manage, and dependencies between the rules become challenging to coordinate across larger teams. Often the best solution is to keep the domains decidedly narrow. Statistical systems can offer a more forgiving path by learning implicit trade-offs, generalizations, and robust behaviors from data. For example, neural network models have been used to learn more robust parsers [14, 24, 29]. In recent work, the components of task-oriented dialog systems have been implemented as neural networks, enabling joint learning of robust models [7, 26, 27]. However these methods all rely on either an explicit semantic representation or an explicit representation of the task, always hand-crafted. End-to-end systems avoid using hand-crafted explicit representations, by learning to map to and from natural language via implicit internal vector representations [19, 25]. Such systems avoid the unnecessary contraints and bottlenecks inevitably imposed by the system designer. In that context, natural language understanding might be evaluated less in terms of an explicit semantic representation, and more by the utility of the system itself. The system shows evidence of understanding when it offers useful responses. Such end-to-end tasks are difﬁcult: systems not only need to learn language but also must learn to do something useful with it. This paper addresses the task of suggesting responses in human-tohuman conversations. There are further challenges that arise when building an end-to-end dialog Corresponding authors: {matthen, rmyeid, bps}@google.com. © 2017 Copyright held by the owner/author(s). Publication rights licensed to ACM. arXiv:1705.00652v1  [cs.CL]  1 May 2017  Efﬁcient Natural Language Response Suggestion for Smart Reply Henderson et al. system, i.e. a computer agent that interacts directly with a human user. Dialog systems must learn effective and robust interaction strategies, and goal-oriented systems may need to interact with discrete external databases. Dialog systems must also learn to be consistent throughout the course of a dialog, maintaining some kind of memory from turn to turn. Machine learning requires huge amounts of data, and lots of helpful users to guide development through live interactions, but we also need to make some architectural decisions, in particular how to represent natural language text. Neural natural language understanding models typically represent words, and possibly phrases, sentences',\n",
       " '1704.06369': 'In recent years, Convolutional neural networks (CNNs) achieve state-of-the-art performance for various computer vision tasks, such as object recognition [12, 29, 32], detection [5], segmentation ∗Alan L. Yuille’s visiting student. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and the full citation on the ﬁrst page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission and/or a fee. Request permissions from permissions@acm.org. MM ’17, October 23–27, 2017, Mountain View, CA, USA. © 2017 ACM. ISBN 978-1-4503-4906-2/17/10...$15.00 DOI: https://doi.org/10.1145/3123266.3123359 [19] and so on. In the ﬁeld of face veriﬁcation, CNNs have already surpassed humans’ abilities on several benchmarks[20, 33]. The most common pipeline for a face veriﬁcation application involves face detection, facial landmark detection, face alignment, feature extraction, and ﬁnally feature comparison. In the feature comparison step, the cosine similarity or equivalently L2 normalized Euclidean distance is used to measure the similarities between features. The cosine similarity ⟨·, ·⟩ ∥·∥∥·∥is a similarity measure which is independent of magnitude. It can be seen as the normalized version of inner-product of two vectors. But in practice the inner product without normalization is the most widely-used similarity measure when training a CNN classiﬁcation models [12, 29, 32]. In other words, the similarity or distance metric used during training is diﬀerent from that used in the testing phase. To our knowledge, no researcher in the face veriﬁcation community has clearly explained why the features should be normalized to calculate the similarity in the testing phase. Feature normalization is treated only as a trick to promote the performance during testing. To illustrate this, we performed an experiment which compared the face features without normalization, i.e. using the unnormalized inner-product or Euclidean distance as the similarity measurement. The features were extracted from an online available model [36]1. We followed the standard protocol of unrestricted with labeled outside data[9] and test the model on the Labeled Faces in the Wild (LFW) dataset[10]. The results are listed in Table 1. Table 1: Eﬀect of Feature Normalization Similarity Before Normalization After Normalization Inner-Product 98.27% 98.98% Euclidean 98.35% 98.95% As shown in the table, feature normalization promoted the performance by about 0.6% ∼0.7%, which is a signiﬁcant improvement since the accuracies are already above 98%. Feature normalization seems to be a crucial step to get good performance during testing. Noting that the normalization operation is diﬀerentiable, there is no reason that stops us importing this operation into the CNN model to perform end',\n",
       " '1708.03816': 'The advent of deep learning has reduced the amount of hand-engineered processing required for computer vision by integrating many operations such as pooling, normalization, and resampling within Convolutional Neural Networks (CNN). The succession of such operations gradually discards the effects of irrelevant signal transformations, allowing the higher layers of CNNs to exhibit increased robustness to small input perturbations. While this invariance is desirable for high-level vision tasks, it can harm tasks such as pose estimation where one aims at precise spatial localization, rather than abstraction. It is therefore common to apply some form of computer vision-based post-processing on top of CNN-based scores to obtain sharp, localized geometric features. One of the ﬁrst steps in this direction has been the use of structured prediction on top of semantic segmentation, e.g. by combining image-based DenseCRF [22] inference with CNNs for semantic segmentation [11], training both systems jointly [41], or more recently learning CNN-based pairwise terms in structured prediction modules [10, 25]. All of these works involve coupling decisions so as to reach some consistency in the labeling of global structures, typically coming in the form of smoothness constraints. While this is meaningful for tasks where information is spread out, such as semantic segmentation, we are interested in more general transformations, some of which are illustrated in Fig. 1. For instance, we consider tasks that require outputs in the forms of 1-D or 0-D outputs (boundary and keypoint detection, respectively), effectively collapsing the spatially extended output of a CNN into lowerdimensional structures. Even though in principle this could be cast in structured prediction terms, the resulting optimization problem amounts to maximizing a submodular function [6] and can only be approximately optimized. We therefore turn to geometry-based, rather than optimization-based methods, and pursue their incorporation in the context of deep learning. arXiv:1708.03816v1  [cs.CV]  12 Aug 2017  H0 H0 H0 vector displacement ﬁeld o(x) displaced outputs m(x) mass c(x) H0 H0 ox and oy components (a) (b) (c) (d) Figure 1: The low spatial resolution of CNNs results in overly smooth per-pixel conﬁdence scores (mass), as shown in the image on the left. Rather than stretch the CNN’s capabilities in order to obtain spatially sharp responses, we propose instead to append a dispacement ﬁeld as another CNN output that rearranges the classiﬁcation scores, lending more evidence to the ground truth positions. The ox and oy-components of different displacement ﬁelds o(x) are shown in the top row on the right (the middle row shows the same components presented as a vector ﬁeld and displayed in color, for illustrative purposes). These are combined by a Mass Displacement module into a sharp decision, shown in the bottom row. This can amount to making the classiﬁcation obtain a particular shape, e.g. through alignment with image boundaries (a), a 1D structure such as a line, or a curve (b), a point (c), or displacing to another',\n",
       " '1701.06181': 'FAILED',\n",
       " '1701.01212': 'With signiﬁcant advancements in the drone technology, like increased payload capacity, longer average ﬂight time, better power management techniques, and the capability to harvest solar energy, unmanned aerial vehicles (UAVs) can serve a multitude of purposes such as surveillance, localization and communication, making them a ﬂexible solution to augment and enhance the capabilities of the current cellular systems. They provide an especially attractive solution to provide connectivity in the wake of disasters and accidents, which may completely cripple the terrestrial networks due to damaged equipment and/or loss of power [2], [3]. In general, UAVs provide a realistic solution in scenarios where there is a temporary need for network resources. These could include ﬁrst responder situations, such as the one discussed above, or even usual civilian scenarios, such as football games or concerts. In order to provide short-term connectivity in such scenarios, temporary deployment of UAVs may be faster and more cost-effective compared to the temporary installation of conventional base stations. They are also currently being investigated as a possible candidate for providing ubiquitous connectivity in remote areas that lack traditional cellular infrastructure. While there is no doubt about the deployment ﬂexibility and general beneﬁts of UAVs, their performance in terms of the coverage and capacity provided to the terrestrial users is not quite well understood. This is especially true for a realistic use case of ﬁnite UAV networks, where we have a given number of UAVs serving users in a given region (such as a city). In this paper, we use tools from stochastic geometry to derive downlink signal-to-interference ratio distribution for this setup, which immediately provides useful insights into the coverage performance of the resulting three-dimensional network. Several intermediate results derived in this paper are also of general interest for the analysis of ﬁnite wireless networks. A. Motivation and Related Work The improvements in payload capacity and prolonged ﬂight times have enabled the commercial use of UAVs, especially for communication purposes. UAV networks differ signiﬁcantly from conventional wireless networks in terms of the mobility, energy constraints, as well as the propagation conditions. This has stimulated interest in the design of application-oriented protocols for the effective utilization of aerial networks [4]–[6]. For instance, a cluster-based protocol, which improves the resilience to frequent link failures resulting from the motion of UAVs, has been proposed in [5]. The ﬂexibility offered by the mobility of UAVs has motivated a lot of algorithmic research efforts towards ﬁnding efﬁcient trajectories and deployment strategies  3 aimed at optimizing different network resources [7]–[13]. For instance, an algorithm to optimize transmit power and frequency spectrum for autonomous self-deployment was proposed in [7]. An adaptive algorithm for adjusting the UAV heading was proposed in [8] to improve the uplink performance and minimize mutual interference. An approach to optimize the altitude of UAVs to maximize coverage on the ground was proposed in [9]. The performance of UAVs acting as relays between terrestrial users and base stations was',\n",
       " '1706.03692': 'Different from traditional classiﬁcation tasks, the goal of veriﬁcation tasks is to determine whether two samples belong to the same class or not, without predicting the class directly [Chopra et al., 2005]. Veriﬁcation tasks arise from applications where thousands or millions of classes are present with very few samples within each category (in some cases just one). For example, in face and signature veriﬁcation, faces and signatures of a person are considered to belong to a class. While there can be millions of persons in the database, very few examples for each person are available. In such applications, it is also necessary to handle new classes without the need to train the model from the scratch. It is not trivial to address such challenges with traditional classiﬁcation techniques. Motivated by the impressive performance brought by deep networks to many machine learning tasks [LeCun et al., 2015; Bahaadini et al., 2017; Zheng et al., 2017], we pursue a deep learning model to improve existing veriﬁcation models. However, deep networks require a large amount of labeled data for each class, which are not readily available in veriﬁcation. There are semi-supervised training methods for deep network to tap on the large amount of unlabeled data. These semi-supervised methods usually have separate learning stages [Sun et al., 2017; Nair and Hinton, 2010]. They ﬁrst pre-train a model using unlabeled data and then ﬁne-tune the model with labeled data to ﬁt the target tasks. Such twophase methods are not suitable for veriﬁcation. First, the large number of classes and the lack of data (be it labeled or unlabeled) within each category prohibit us from any form of within class pre-training and ﬁne-tuning. Second, if we pool data from all categories for pre-training, the learned features are general but not speciﬁc towards each category, and the later ﬁne-tuning within each category may not be able to correct such bias due to the lack of labeled data. To address such challenges, we propose Deep SEmisupervised VEriﬁcation Networks (SEVEN) that consists of a generative and a discriminative component to learn general and category speciﬁc representations from both unlabeled and labeled data simultaneously. We cross the category barrier and pool unlabeled data from all categories to learn salient structures of the data manifold. The hope is that by tapping on the large amount of unlabeled data, the structures that are shared by all categories can be learned for veriﬁcation. SEVEN then adapts the general structures to each category by attaching the generative component to the discriminative component that uses the labeled data to learn categoryspeciﬁc features. In this sense, the generative component works as a regularizer for the discriminative component, and aids in exploiting the information hidden in the unlabeled data. On the other hand, as the discriminative component depends on the structures learned by the generative component, it is desirable to inform the generative',\n",
       " '1708.03447': 'Biomedical and clinical named entity recognition (NER) in text is one of the important step in several biomedical and clinical information extraction tasks [1, 2, 3]. State-of-art methods formulated NER task as a sequence labeling problem where each word is labeled with a tag and based on tag sequence entities of interest get identiﬁed. It has been observed that named entity recognition in biomedical and clinical domain is difﬁcult [4, 5] compared to the generic domain. There are several reasons behind this, including use of non standard abbreviations or acronyms, multiple variations of same entities etc. Further clinical notes are more noisy, grammatically error prone and contain less context due to shorter and incomplete sentences [3]. Most widely used models such as CRF, maximum entropy Markov model (MEMM) or support vector machine (SVM), use manually designed rules to obtain morphological, syntactic, semantic and contextual information of a word or of a piece of text surrounding a word, and use them as features for identifying correct label [6, 7, 8, 9, 10]. It has been observed that performance of such models are limited with the choice of explicitly designed features which are generally speciﬁc to task and its corresponding domain. For example, Chawdhury and Lavelli [7] explained several reasons why features designed for biological entities such as protein or gene are not equally important for disease name recognition. Deep learning based models have been used to reduce manual efforts for explicit feature design in [11]. Here distributional features were used in place of manually designed features and multilayer neural network were used in place of linear model to overcome the needs of task speciﬁc meticulous feature engineering. Although proposed methods outperformed several generic domain sequence tagging tasks but it fails to overcome state-of-art in biomedical domain [12]. There are two plausible reasons behind that, ﬁrst, it learned features only from a word level embedding and second, it took into account only a ﬁxed length context of the word. It has been observed that word level embeddings preserve syntactic and semantic properties of word, but may fail to preserve morphological information which can also play important role in biomedical entity recognition [13, 14, 7, 15]. For instance, drug names Cefaclor, Cefdinir, Ceﬁxime, Cefprozil, Cephalexin have common preﬁx and Doxycycline, Minocycline, 2  Tetracycline have common sufﬁx. Further, window based neural architecture can only consider contexts falling within the user decided window size and will fail to pick important clues lying outside the window. This work aims to overcome the above mentioned two issues. The ﬁrst one to obtain both morphologically as well as syntactic and semantically rich embedding, two BLSTMs are used in hierarchy. First BLSTM works on each character of words and obtain morphologically rich word embedding. Second BLSTM works at word level of a sentence to learn contextually reach feature vectors. The second one to make sure all context lying anywhere in the sentence should be utilized, we consider entire sentence',\n",
       " '1606.07548': 'The explosion of the Internet clearly warrants the development of techniques for organizing and presenting information to users in an effective way. Query-focused multi-document summarization (MDS) methods have been proposed as one such technique and have attracted signiﬁcant attention in recent years. The goal of query-focused MDS is to synthesize a brief (often ﬁxed-length) and well-organized summary from a set of topicrelated documents that answer a complex question or address a topic statement. The resulting summaries, in turn, can support a number of information analysis applications including openended question answering, recommender systems, and summarization of search engine results. As further evidence of its importance, the Document Understanding Conference (DUC) has used queryfocused MDS as its main task since 2004 to foster new research on automatic summarization in the context of users’ needs. To date, most top-performing systems for multi-document summarization—whether queryspeciﬁc or not—remain largely extractive: their summaries are comprised exclusively of sentences selected directly from the documents to be summarized (Erkan and Radev, 2004; Haghighi and Vanderwende, 2009; Celikyilmaz and Hakkani-T¨ur, 2011). Despite their simplicity, extractive approaches have some disadvantages. First, lengthy sentences that are partly relevant are either excluded from the summary or (if selected) can block the selection of other important sentences, due to summary length constraints. In addition, when people write summaries, they tend to abstract the content and seldom use entire sentences taken verbatim from the original documents. In news articles, for example, most sentences are lengthy and contain both potentially useful information for a summary as well as unnecessary details that are better omitted. Consider the following DUC query as input for a MDS system:1 “In what ways have stolen artworks been recovered? How often are suspects arrested or prosecuted for the thefts?” One manually generated summary includes the following sentence but removes the bracketed words in gray: A man suspected of stealing a million-dollar collection of [hundreds of ancient] Nepalese and Tibetan art objects in New York [11 years ago] was arrested [Thursday at his South Los Angeles home, where he had been hiding the antiquities, police said]. In this example, the compressed sentence is rela1From DUC 2005, query for topic d422g. arXiv:1606.07548v1  [cs.CL]  24 Jun 2016  tively more succinct and readable than the original (e.g. in terms of Flesch-Kincaid Reading Ease Score (Kincaid et al., 1975)). Likewise, removing information irrelevant to the query (e.g. “11 years ago”, “police said”) is crucial for query-focused MDS. Sentence compression techniques (Knight and Marcu, 2000; Clarke and Lapata, 2008) are the standard for producing a compact and grammatical version of a sentence while preserving relevance, and prior research (e.g. Lin (2003)) has demonstrated their potential usefulness for generic document summarization. Similarly, strides have been made to incorporate sentence compression into query-focused MDS systems (Zajic et al., 2006). Most attempts',\n",
       " '1810.03644': 'Consider a given pair of random variables (X,Y ) with joint probability distribution pXY . In this paper, all random variables are considered to be discrete, taking values x,y in ﬁnite alphabets X and Y, respectively. Tishby et al. [1] introduced the notion of the meaningful or relevant information that X provides about Y . They formalized this notion as a constrained optimization problem of ﬁnding the optimal compression of X (to a random variable W, say) which still retains maximum information about Y . The authors of [1] named this problem Information Bottleneck since W can be viewed as the result of squeezing the information that X provides about Y through a “bottleneck”. The information bottleneck can be regarded as a problem of lossy data compression for a source deﬁned by the random variable X, in presence of side information given by Y . The standard theory of lossy data compression introduced by Shannon [2] is rate distortion theory, which deals with the trade-off between the rate of lossy compression and the average distortion of the distorted signal (see also [3], [4]). The Information Bottleneck Method (IBM) can be considered as a generalization of this theory, in which the distortion measure between X and W is determined by the joint distribution pXY . This method has found numerous applications, e.g. in investigating deep neural networks [5], [6], video processing [7], clustering [8] and polar coding [9]. The constraint in the above-mentioned optimization problem, is given as a lower bound, say IY , on the mutual information, I(Y ;W) = H(Y ) + H(W) −H(Y W), since the latter is a measure of the information about Y contained in W. Here H(Y ) denotes the Shannon entropy of Y , i.e. if Y has a probability mass function {p(y)}y∈Y, where Y is a ﬁnite alphabet, then H(Y ) = −∑y∈Y p(y)log p(y). The rate function of the IBM, the so-called IB function, is a function of this bound and is given by R(IY ) = min p(w∣x) I(Y ;W )≥IY I(X′;W), for IY ≥0, (1) where X′ = X, and the minimization is over the set of conditional probabilities {p(w∣x)}, with w denoting values taken by the random variable W. A dual quantity, which gives an expression for the information IY as a function of the rate R, is given by IY (R) = max p(w∣x) I(X′;W )≤R I(Y ;W), for R ≥0. (2) It was shown in [10, Lemma 10] that the optimization problems in (1) and (2) are indeed dual to each other, meaning that R(IY ) and IY (R) are equivalent quantities, in the sense that they deﬁne the same curve with switched axes for 0 ≤IY ≤I(W;Y ) and 0 ≤R ≤R(I(W;Y )). In other words, R and IY are functions inverse to each other. As a matter of fact, in [11], the following closely related optimization',\n",
       " '1811.10984': 'A common concern in Multi Object Tracking (MOT) approaches is to prevent identity switching, the erroneous merging of trajectories corresponding to different targets into a single one. This is difﬁcult in crowded scenes, especially when the appearances of the individual target objects are not distinctive enough. Many recent approaches rely on tracklets—short trajectory segments—rather than individual detections, to keep track of the target objects. Tracklets can be merged into longer trajectories, which can be split again when an identity switch occurs. Most state-of-the-art approaches rely on deep networks, often in the form of RNN architectures that operate on such tracklets [34, 18, 25, 56, 27]. This requires training the sequence models and is subject to one or both of two wellknown problems, which our approach overcomes: • Loss-evaluation mismatch. It occurs when training by optimizing a metric poorly aligned with the actual desired performance during inference. In MOT, one example is the use of a classiﬁcation loss to create trajectories optimal for a tracking-speciﬁc metric, such as MOTA [6] or IDF [46]. To eliminate this mismatch, we introduce an original way to score tracklets that is an explicit proxy for the IDF metric and can be computed without the ground truth. We use it to identify how conﬁdently the person is tracked, predict tighter bounding box locations, and estimate whether the real trajectory extends beyond the observed tracklet. Figure 1. Keeping track in a difﬁcult situation. Top row: Because of the occlusion created by the passing car, a tracker can easily return a trajectory that includes several identity switches. The corresponding bounding boxes inside camera’s ﬁeld of view are shown on the right. Bottom row: Our algorithm not only eliminates identity switches but also regresses to a set of much tighter bounding boxes. In this example our algorithm did it solely on the basis of simple geometric features without requiring the use of appearance information. 1 arXiv:1811.10984v1  [cs.CV]  27 Nov 2018  • Exposure bias. It stems from the model not being exposed to its own errors during training and results in very different data distribution observed during training and inference/tracking. We remove this bias by introducing a much more exhaustive, yet computationally feasible, approach to exploiting the data while training the model. To this end, during training, we do not limit ourselves to only using tracklets made of detections of one or two people as in [40, 35, 48]. Instead, we consider any grouping of tracklets produced by the tracking algorithm to be a potential trajectory but prevent a combinatorial explosion by controlling the number of tracklets that share many common detections. This yields a much richer training dataset, solves the exposure bias problem, and enables our algorithm to handle confusing situations in which a tracking algorithm may easily switch from one person to the next or miss someone altogether. Fig. 1 depicts one such case. Note that this can be done',\n",
       " '1811.12704': 'The seminal work of Gatys et al. [5] opened up a new ﬁeld called Neural Style Transfer (NST). NST is the process of using Convolutional Neural Networks (CNN) to render an image in different styles. NST methods are capable of stylizing a content image by generalizing the abstractions of style, as they are expressed in a given style image, into the original content of the input image. NST is capable of producing spectacular stylized images according to vastly different styles and, as a result, it has become a trending topic that has attracted wide attention from both academia and industry. Early NST methods achieved quite impressive results, but, at the same time, required a slow iterative optimization step [4, 10, 12, 14, 17, 19]. Another category of NST approaches, the so-called feed-forward methods, were capable of accelerating NST, without requiring solving a new optimization problem for each input image. However, these methods are limited to transferring a speciﬁc style (or a small number of styles) for (a) Content image (b) Style image (c) Improved WCT [24] (d) Proposed (Semantic Sub-style Transfer) Figure 1: Usually multiple sub-styles exist in the same style image. Detecting and separately modeling each sub-style improves the quality of universal style transfer approaches. For example, note the uniform texture of the sea, when the substyles are independently modeled and matched to the appropriate regions of the content image (Fig. 1d) compared to a state-of-the-art universal style transfer method (Fig. 1c) that leaks the texture of the rocks into the sea, producing signiﬁcant artifacts and leading to less detailed texture. which they were pre-trained [3, 8, 11, 22, 23]. The aforementioned limitations were recently resolved by universal style transfer methods that employ one single trainable model to transfer arbitrary artistic styles via feature manipulations using a shared high-level feature space [6, 13, 20, 24]. Even though these universal style transfer approaches are capable of performing style transfer of arbitrary styles in a style-agnostic manner via feature transforms in (almost) realtime, they usually lead to less impressive results than the other algorithms [7]. Existing universal style transfer approaches assume that the content and style representations extracted by a pre-trained CNN can be described by a single multivariate Gaussian distribution and then perform style transfer by appropriately manipulating the feature statistics of the content image to match those of the target style style. Even though modeling the features using a single Gaussian distribution has been proven adequate to transfer a single style from relatively 1 arXiv:1811.12704v1  [cs.CV]  30 Nov 2018  Style Image(s)  Content Image  Encoder E(⋅) Encoder E(⋅) Style Decomposition Style 1 Style 2 Style 3 Content Decomposition Content 1 Content 2 Content 3 Option 1: Sub-style Mixture Transfer (SMT) Option 2: Semantic Sub-style Transfer (SST) Sub-style MIxture WCT Content to Style Matcthing Sub-style 1 WCT Sub-style 2 WCT Sub-style 3',\n",
       " '1604.04888': 'The recovery of a linear combination of exponentials from their few uniform samples is a classical problem in signal processing with extensive applications. Prony’s method, or one of its robust variants, attempts to recover the signal by estimating an annihilating polynomial whose zeros correspond to the frequency of the exponentials. The ﬁnite rate of innovation (FRI) framework [1] extended these methods to recover more general signals that reduce to a sparse linear combination of Dirac delta functions under an appropriate transformation (e.g. differential operators, convolution). Recently, several authors have further extended FRI methods to recover such signals from their non-uniform Fourier samples [2–6] by exploiting the low-rank structure of an enhanced matrix This work is supported by grants NSF CCF-1116067, ACS RSG-11-26701-CCE, and ONR-N000141310202. (e.g. Hankel matrix in 1-D). Performance guarantees do exist when the transform is an identity and when the Diracs are well-separated [2]. The above signal models have limited ﬂexibility in exploiting the extensive additional structure present in many multidimensional imaging problems. Speciﬁcally, the edges in multidimensional images are connected and can be modeled as smooth curves or surfaces. We have recently introduced a novel framework to recover piecewise polynomial images, whose edges are localized to smooth curves, from their uniform [7,8] and non-uniform [6] Fourier samples; this work generalizes a recent extension of the FRI framework to curves [9]. We model the piecewise smooth signal as having partial derivatives that vanish outside the zero level-set of a bandlimited function. This relation translates to an annihilation condition involving the uniform Fourier samples of the partial derivatives, which can be compactly represented as the multiplication of a speciﬁc structured matrix with the Fourier coefﬁcients of the bandlimited function. Our earlier work has shown that the structured matrix is low-rank, and we used this property to recover the signal from its non-uniform Fourier samples with good performance. Efﬁcient algorithms that work on the original signal samples rather than the structured high-dimensional matrix also were introduced [10]. We observe the signal models in [2,3,5] do not include the class of signals considered in this work. The main focus of this work is to introduce theoretical guarantees on the recovery of piecewise constant signals, whose discontinuities are localized to zero level-sets of bandlimited functions, from non-uniform Fourier samples. Since such signals cannot be expressed as a ﬁnite linear combination of isolated Diracs, the recovery guarantees in [2] cannot be directly extended to our setting. Speciﬁcally, the theory in [2] relies heavily on a explicit factorization of the enhanced matrix (e.g Vandermonde factorization of a Hankel matrix in the 1-D case), which is only available when the number of discontinuities are ﬁnite and well separated. Instead, we give a new description of the row and column subspace of the structured matrix, which allow',\n",
       " '1804.00891': 'First introduced by Kingma and Welling (2014a); Rezende et al. (2014), the Variational Auto-Encoder (VAE) is an unsupervised generative model that presents a principled fashion for performing variational inference using an auto-encoding architecture. Applying the noncentered parameterization of the variational posterior (Kingma and Welling, 2014b), further simpliﬁes sampling and allows to reduce bias in calculating gradients for training. Although the default choice of a Gaussian prior is mathematically convenient, we can show through a simple example that in some cases it breaks the assumption of an uninformative prior leading to unstable results. Imagine a dataset on the circle Z ⊂S1, that is subsequently embedded in RN using a transformation f ∗Equal contribution. . Correspondence to: Nicola De Cao <nicola.decao@gmail.com>. to obtain f : Z →X ⊂RN. Given two hidden units, an autoencoder quickly discovers the latent circle, while a normal VAE becomes highly unstable. This is to be expected as a Gaussian prior is concentrated around the origin, while the KL-divergence tries to reconcile the differences between S1 and R2. The fact that some data types like directional data are better explained through spherical representations is long known and well-documented (Mardia, 1975; Fisher et al., 1987), with examples spanning from protein structure, to observed wind directions. Moreover, for many modern problems such as text analysis or image classiﬁcation, data is often ﬁrst normalized in a preprocessing step to focus on the directional distribution. Yet, few machine learning methods explicitly account for the intrinsically spherical nature of some data in the modeling process. In this paper, we propose to use the von Mises-Fisher (vMF) distribution as an alternative to the Gaussian distribution. This replacement leads to a hyperspherical latent space as opposed to a hyperplanar one, where the Uniform distribution on the hypersphere is conveniently recovered as a special case of the vMF. Hence this approach allows for a truly uninformative prior, and has a clear advantage in the case of data with a hyperspherical interpretation. This was previously attempted by Hasnat et al. (2017), but crucially they do not learn the concentration parameter around the mean, κ. In order to enable training of the concentration parameter, we extend the reparameterization trick for rejection sampling as recently outlined in Naesseth et al. (2017) to allow for n additional transformations. We then combine this with the rejection sampling procedure proposed by Ulrich (1984) to efﬁciently reparameterize the VAE 1. We demonstrate the utility of replacing the normal distribution with the von Mises-Fisher distribution for generating latent representations by conducting a range of 1Code freely available on: https://github.com/ nicola-decao/s-vae arXiv:1804.00891v3  [stat.ML]  27 Sep 2022  experiments in three distinct settings. First, we show that our S-VAEs outperform VAEs with the Gaussian variational posterior (N-VAEs) in recovering a hyperspherical latent structure. Second, we conduct a thorough comparison with N-VAEs on the MNIST dataset through an unsupervised learning task',\n",
       " '1711.10317': 'Entity classiﬁcation aims to determine the type (e.g., person, location) of a certain entity. It is important for several natural language processing (NLP) tasks, such as question answering, textual entailment, machine reading, and text summarization. It is also a crucial resource to introduce the conceptlevel features to enhance the generalization power of machine learning systems (Paulheim and F¨umkranz, 2012). There are two main methods for entity classiﬁcation: named entity recognition and classiﬁcation (NERC) and entity hypernym extraction. The former assumes that the type of an entity can be determined from its context. The classiﬁcation tags utilized in NER systems are often coarse and do not involve all types of entities. Fine-grained NER faced with the difﬁculty of creating sufﬁcient training data. The latter method can obtain extremely ﬁne-grained categories of one entity, but it has to rely on an ontology to further obtain more general concepts. It also requires the cooccurrence of the entity and its hypernym in one sentence, which can make the recall lower. If there is no hypernym word in the context of the entity, and the context does not contain much information to determine the classiﬁcation, these two methods could not work well, and we have to rely on external knowledge sources. In this paper, we propose another method for entity classiﬁcation. Rather than inferring the type of an entity from the context, we classify it according to its descriptive sentences. A descriptive sentence is used to describe certain attributes of an entity, and is a natural source for humans to recognize the type of the unknown entity. For example, from the sentence “The logo of Baidu is a bear paw.”, we have no idea what Baidu is through the context information. But from a description of Baidu: Baidu, incorporated on 18 January 2000, is a Chinese web services company We can easily conclude that Baidu is a COMPANY. Motivated by this idea, we propose a classiﬁcation-based method for entity classiﬁcation. We ﬁrst pre-deﬁne a hierarchical concept taxonomy, and then try to classify an entity to a leaf of this taxonomy, based on its description and name information. Our contributions are three-fold: • We propose a simple classiﬁcation-based method for entity classiﬁcation, based on the description and name of the entity. • We introduce a clustering module to alleviate the data noise and imbalance problem during training, as well as to select the highly conﬁdent predicted entities from the prediction set to improve the precision. • We utilize this architecture on 2.1 million open-domain entities to verify its efﬁciency. Approximately 1.1 million entities are successfully identiﬁed, with a precision of 99.36%. 2 Methods This section presents the dataset and the method used for entity classiﬁcation. 2.1 Dataset and task The entities and their corresponding descriptions utilized are from Baidu Baike. It contains nearly 15 million Chinese pages until now, which is much',\n",
       " '1803.11303': 'D ETECTING unusual volume changes and monitoring abnormal growths in pancreas using medical images is a critical yet challenging diagnosis task. This would require to delineate pancreas from its surrounding tissues in radiology images, e.g., computed tomography (CT) and magnetic resonance imaging (MRI) scans. Having pancreas accurately segmented from 3D scans delivers more reliable and quantitative representations than simple cross-section diameter measurements, which may produce the precision segmentation based biomarkers, such as volumetric measurements and 3D shape/surface signatures. Moreover, automated rapid and accurate segmentation of pancreas on the scale of processing thousands of image scans can facilitates new protocols, J. Cai, F. Xing, and L. Yang are with the J. Crayton Pruitt Family Department of Biomedical Engineering, University of Florida, Gainesville, FL 32611 USA (e-mail: jimmycai@uﬂ.edu; shampool@uﬂ.edu; f.xing@uﬂ.edu; lin.yang@bme.uﬂ.edu). L. Lu is with Nvidia Corporation, 2788 San Tomas Expy, Santa Clara, CA 95051, USA (e-mail: lel@nvidia.com). CT\\\\MRI Images CNN Sub-Network RNN Sub-Network CNN output RNN output Ground Truth Fig. 1: Overview of the proposed model architecture. CT/MRI image sequence is processed by the CNN-RNN segmentation model. First, the CNN sub-network inferes probability maps of the 2D input slices. The RNN sub-network then reﬁnes the segmentations to improve the intra-slice shape continuity. We note that the CNN-RNN atacked model is trained end-to-end. ﬁndings, and insights for clinical trials. On the other hand, manual pancreas segmentation is very expensive and sometimes even intractable on the dataset at a very large scale. In this paper, to fulﬁll this practical and important demand, we improve the existing convolutional neural networks (CNN) based segmentation work with novel methodologies, i.e., new CNN module architecture, convolutional-recurrent neural contextual regularization and a new direct segmentation loss, to achieve signiﬁcantly boosted performances in both CT and MRI imaging modalities. One major group of related work on automatic pancreas segmentation in CT images is based on top-down multi-atlas registration and label fusion (MALF) [1]–[4]. Due to the high deformable shape and vague boundaries of the pancreas in CT scans from various patients, their reported segmentation accuracy results (measured in Dice Similarity Coefﬁcient or DSC) range from 69.6±16.7% [3] to 78.5±14.0% [1], [4] under leave-one-patient-out (LOO) evaluation protocol. On the other hand, bottom-up deep CNN based pancreas segmentation work [5]–[10] have revealed promising results and steady performance improvements, e.g., from 71.8±10.7% [7], 78.0±8.2% [8], to 81.3±6.3% [10] evaluated using the same NIH 82-patient CT dataset under 4 fold cross-validation (CV). In comparison, deep CNN approaches appear to demonstrate noticeably higher segmentation accuracies and numerically more stable results (signiﬁcantly lower in standard deviation, arXiv:1803.11303v1  [cs.CV]  30 Mar 2018  2 or std) than their MALF counterparts. [8], [10',\n",
       " '1410.5509': 'The use of the millimeter (mm) wave band for next generation (5G) mobile communication has gained considerable attention recently [1], [2]. Vast amounts of spectrum (both licensed and unlicensed) are available in the mmwave band (typically considered to be 30-300 GHz), A preliminary version [15] of this paper has been accepted for publication at IEEE Globecom, 2014 . DRAFT  making it attractive for high data rate communication. While propagation losses in the mmwave band are higher compared to those at lower microwave frequencies used currently for mobile communication, the smaller carrier wavelengths for mmwave frequencies also imply that more antennas can be packed in a relatively small area, making it feasible to design compact high-gain antenna arrays that can compensate for the increased propagation losses. In current systems employing multiple antennas (i.e., current MIMO systems, e.g., 3GPP LTE [3]), beamforming (or, precoding) is performed at baseband (BB), and the precoder outputs are fed into the different transmit antennas using a separate radio frequency (RF) chain (implied to include the upconversion components and the power ampliﬁer) for each antenna. For mmwave systems employing large antenna arrays, such an architecture is considered infeasible, given the prohibitive cost of the large number of RF chains and mixed signal components (D/A and A/D converters) [4]. Rather, beamforming may be performed at the RF level using a set of analog phase shifters, which limits the number of required RF chains to one. To obtain diversity/spatial multiplexing gains in such systems, a natural strategy is to consider the use of a transmitter (Tx) and/or receiver (Rx) antenna array consisting of multiple subarrays, where each of the subarrays is capable of independent electronic beam steering using RF phase shifters (concept ﬁrst introduced in [5], in context of line-of-sight mmwave MIMO systems), see Fig. 1. In essence, each subarray emulates a virtual antenna (that is capable of directional transmission) in the sense of current MIMO systems, and spatial multiplexing of L data streams can be supported, in principle, using at least L subarrays at both the Tx and the Rx. In addition to the RF beamforming at each subarray, a baseband precoder may also be employed at the Tx (as in current systems; with each subarray being analogous to one antenna in current systems) to process the data to be sent on different streams, providing an additional level of ﬂexibility on top of only the phase shift operations performed at RF. The overall precoding operation may then be referred to as hybrid (mix of analog and digital) precoding. We consider the preceding array-of-subarrays architecture, and study the corresponding hybrid precoder optimization problem, involving a joint optimization over the choice of the Tx BB precoder, and the Tx/Rx RF precoders (i.e., the Tx/Rx RF beamforming directions at the different subarrays). In this work, we consider codebook based precoding (wherein the different precoders are picked from a priori ﬁxed codebooks), a framework applicable, for example, to',\n",
       " '1801.00443': 'On November 8, 2017, “Drone Integration Pilot Program” [1] was launched under a presidential memorandum from the White House, which aimed at further exploring expanded use of unmanned aerial vehicles (UAVs) including beyond-visual-line-of-sight ﬂights, night-time operations, ﬂights over people, etc. [2]. In fact, the past several years have witnessed an unprecedented growth on the use of UAVs in a wide range of civilian and defense applications such as search and rescue, aerial ﬁlming and inspection, cargo/packet delivery, precise agriculture, etc. [3]. In particular, there has been a fast-growing interest in utilizing UAVs as aerial communication platforms to help enhance the performance and/or extend the coverage of existing wireless networks on the ground [4], [5]. For example, UAVs such as drones, helikites, and balloons, could be deployed as aerial base stations (BSs) and/or relays to enable/assist the terrestrial communications. UAV-enabled/aided wireless communications possess many appealing advantages such as swift and cost-effective deployment, line-of-sight (LoS) aerial-to-ground link, and controllable mobility in three-dimensional (3D) space, thus highly promising for numerous use cases in wireless communications including ground BS trafﬁc ofﬂoading, mobile relaying and edge computing, information/energy broadcasting and data collection for Internet-of-Things (IoT) devices, fast network recovery after natural disasters, etc. [6]–[12]. For example, Facebook has even ambitiously claimed that “Building drones is more feasible than covering the world with ground signal towers” [13]. By leveraging the aerial BSs along with terrestrial and satellite communications, Europe has established an industry-driven project called “ABSOLUTE” with the ultimate goal of enhancing the ground network capacity to many folds, especially for public safety in emergency situations [14]. At present, there are two major ways to practically implement aerial BSs/relays by using tethered and untethered UAVs, respectively, which are further explained as follows. A tethered UAV literally means that the UAV is connected by a cable/wire with a ground control platform (e.g., a custom-built trailer). Although it may sound ironic for a UAV to be on a tethering cable, this practice is very common due to many advantages including stable power supply and hence unlimited endurance, more affordable payload (e.g., more antennas), ultra-high speed backhaul with secured data transmission (e.g., real-time high-deﬁnition video), robustness to wind, etc. All these evident beneﬁts have triggered a great interest in testing tethered UAV BSs, such as Facebook’s “Tether-Tenna”, AT&T’s “ﬂying cell-on-wings (COWs)”, and EverythingEverywhere’s (UK’s largest mobile network operator, EE) “Air Masts”. However, such a tethering feature also limits the operations of UAVs to taking off, hovering, and landing only, thus rendering the wireless networks employing tethered UAV BSs like “hovering cells” over the air. As a  3 result, the research efforts in this paradigm mainly focus on the UAV deployment/placement optimization in a given target area to meet the ground data trafﬁc demand [10',\n",
       " '1508.00092': 'Thanks to the rapid progresses in remote sensing technology, and the reduction of acquisition costs, a large bulk of images of the Earth is readily available nowadays. They are taken from satellites or airplanes, with various imaging modalities, spatial and spectral resolutions, dynamic ranges. With no shortage of data, the focus shifts on the ability to automatically extract valuable information from them. In recent years, there have been great advances in remote sensing image processing, for both low-level tasks, such as denoising or segmentation, and high level ones, such as classiﬁcation. A plethora of land cover classiﬁcation algorithms have been developed, with solid theoretical foundations, based on spectral and spatial properties of the pixels. However, the task becomes incrementally more difﬁcult as the level of abstraction increases, going from pixels, to objects, and then scenes. Labeling an image according to a set of semantic categories is the goal of scene classiﬁcation. This is a very challenging problem, because land covers characterizing a given class may present a large variability and objects may appear at different scales and orientations. High intra-class variability then couples with low inter-class distance, a problem that grows ever more as ﬁner classiﬁcations are sought. The same land covers and even the same objects can be found in images belonging to different classes. An example is shown in Fig.1 where the difference is made only by the density of buildings. In this context, low-level features typical of pixel-based or object-based approaches [1], [2], [3], encoding spectral, textural, and geometrical properties, become mostly ineffective. More complex features and descriptors are necessary to capture the semantics of the scene. These have been the object The Authors are with the DIETI, Universit`a Federico II di Napoli, Naples, Italy. E-mail: mar.castelluccio@studenti.unina.it, {poggi, carlosan, verdoliv}@unina.it (a) (b) Fig. 1. Too close to call? Two similar images from the dense residential (a) and medium residential (b) classes of the UC-Merced dataset. Notice the different scales of observation. of intense research efforts in the last few years, leading to good results in many ﬁelds. Nonetheless, even these sophisticated and successful descriptors are rapidly giving way to deep neural networks. Artiﬁcial neural networks take inspiration from models of the biological brain, and try to reproduce some of its functions by using simple but massively interconnected processing units, the neurons. A typical neural network architecture comprises several layers of neurons feeding one another, by which the “deep” attribute. Deep learning has provided impressive results in object recognition [4]. Recently, it has been also applied to remote sensing tasks [5] [6] [7], including land use image classiﬁcation [8], showing always a great potential. Considering the subtle differences among categories in scene classiﬁcation, the superiority of deep learning with respect to “shallow” descriptors mentioned before can be easily claimed. While the latter aim at reproducing the behavior of the human interpreter, associating labels to images through a black',\n",
       " '1811.04437': 'In oncology CT and MR images are used in clinical care and clinical trials to assess the effect of treament on the size of lesions over time. In clinical trials of solid lesion indications, lesion size is assessed according to the Response Evaluation Criteria in Solid Tumors (RECIST) [1], with a single diameter measurement used to represent each target (quantiﬁed) lesion. For this purpose, and in clinical care settings, radiologists often manually delineate the boundary of a lesion on a single slice, where the lesion looks largest, so that the diameter measurements can be extracted from this region of interest (ROI). Nevertheless, deﬁnition of the whole lesion volume in three dimensions, a process called segmentation, is useful for a variety of applications, including lesion growth kinetic modeling and research into imaging features that may act as novel biomarkers. However, delineating lesions in 3D medical images is a laborand resource-intensive task, which prohibits the volumetric assessments from replacing the RECIST-based assessments. Although many works have been proposed to produce lesion segmentations in CT images using regionbased, graph-based, or deformable model-based approaches [2, 3, 4, 5], the performances of these conventional approaches are highly sensitive to the initial conditions and parameter settings of models. Therefore, it is highly desirable to develop an automatic 3D lesion segmentation algorithm that can provide accurate, robust, and consistent results. In this work, we aim to develop an automatic volumetric lesion segmentation algorithm by leveraging the 2D ROIs created by radiologists during RECIST evaluation of clinical CT images. First of all, we propose a progressive lesion segmentation (PLS) algorithm that iteratively generarXiv:1811.04437v1  [cs.CV]  11 Nov 2018  SiBA-Net  (RECIST) Train Final Model PTS Training ... RECIST Slices Edge Slices Progressively collect additional CT slices. SiBA-Net SiBA-Net Copy  Model Train ... ... Mask refinement  (CRF) Train Lesion  Volume  RECIST Mask refinement  (CRF) Supervised training on RECIST-slices Figure 1. : Overall pipeline of the proposed progressive lesion segmentation (PLS) approach using a scale-invariant and boundaryaware network (SiBA-Net). The initial SiBA-Net (orange block) is ﬁrst trained on RECIST-slices (orange boarder/line) with groundtruth 2D lesion delineations. Then after convergence an instance of the SiBA-Net (blue block) is copied for predicting the segmentation on the neighboring slices. The segmentations are reﬁnement by CRF (red boarder/line) and added to the training dataset with the corresponding images for the next iteration of training. The procedure repeats until no additional training samples are added, and the ﬁnal model is obtained upon convergence. ates 2D lesion segmentations from the RECIST slice to the neighboring slices, and eventually to the edge slices in a semi-supervised manner. Secondly, we introduce a scaleinvariant and boundary-aware network (SiBA-Net) that can effectively cope with the scale-variability of lesion when the PLS propagates from the RECIST slices to the edge slices or is applied',\n",
       " '1310.7001': 'The explosive growth of wireless data trafﬁc, spurred by powerful and data-hungry user devices such as smartphones and tablets, is putting existing wireless networks under stress and is calling for a technology paradigm shift. Two recent research trends in wireless networks have attracted signiﬁcant attention as potential solutions: massive MIMO and very dense spatial reuse. The former refers to serving multiple users on the same time-frequency channel resource by eliminating multiuser interference via spatial precoding, using a very large number of antennas at each base station site [1], [2]. The latter pertains to the use of small cells [3], such that multiple short-range low-power links can co-exist on the same time-frequency channel resource thanks to sufﬁcient spatial separation. Distributed Multiuser MIMO (MUMIMO) uniﬁes these two approaches, simultaneously obtaining both multiuser interference suppression through spatial precoding, and dense coverage by reducing the average distance between transmitters and receivers. This is achieved by coordinating a large number of Access Points (APs), distributed over a certain coverage region, through a wired backhaul network connected to a Central Server (CS), in order to form a distributed antenna system. While distributed MU-MIMO may be applied in a variety of different scenarios, in this work we focus primarily on cost-effective consumer grade equipment and focus particularly on the downlink (DL), which is both more demanding in terms of trafﬁc and more challenging in terms of implementation than the uplink (UL). We assume inexpensive APs connected to the CS via a conventional wired digital backbone (e.g., Ethernet), capable of transporting digital packetized data at sufﬁcient speed from/to the CS, but not able to distribute a common clock (i.e., timing and phase information) to the APs, beyond the limitations of standard network synchronization protocols such as IEEE 1588 [4]. In order to achieve large spectral efﬁciencies through MU-MIMO downlink spatial precoding, channel state information at the transmitter (CSIT) is needed. Following the massive MIMO approach [1], [2], CSIT can be obtained from the users’ uplink pilots by operating the system in Time-Division Duplexing (TDD) and exploiting the reciprocity of the radio channels. However, while the propagation channel from antenna to antenna is reciprocal,1 1This statement holds if the UL and DL transmissions take place within the coherence time and coherence bandwidth of the underlying doubly-selective channel. Using OFDM and TDD, the propagation channel is effectively reciprocal on each OFDM subcarrier over many consecutive OFDM symbols, since the coherence time for typical wireless local area networks with nomadic users may span ∼0.1s to 1s or more. In fact, 800 msec is commonly used as the simulation assumption for 801.11ac IEEE standard for WLAN [5]. In WARP software-radio based experiments, we observed the coherence time to be about 1 second. In contrast, Frequency Division Duplexing schemes have the UL and the DL separated by tens of MHz, well beyond the coherence bandwidth. Therefore, reciprocity for such systems typically does not hold.  3',\n",
       " '1610.09289': 'Common information, as an information measure on the common part between two random variables, was ﬁrst investigated by G´acs and K¨orner [1] in content of distributed common information extraction problem: extracting a same random variable from each of two sources individually. The common information of the sources is deﬁned by the maximum information of the random variable that can be extracted from them. For correlated memoryless sources X, Y (taken from ﬁnite alphabets), [1] shows that the G´acs-K¨orner common information between them is CGK(X; Y ) = sup f,g:f(X)=g(Y ) H(f (X)). (1) Lei Yu is with the Department of Electrical and Computer Engineering, National University of Singapore, Singapore (e-mail: leiyu@nus.edu.sg). This work was done when he was at University of Science and Technology of China. Houqiang Li is with the Department of Electronic Engineering and Information Science, University of Science and Technology of China, Hefei, China (e-mail: lihq@ustc.edu.cn). Chang Wen Chen is with Department of Computer Science and Engineering, State University of New York at Buffalo, Buffalo, NY, USA (e-mail: chencw@buffalo.edu). July 25, 2017 DRAFT arXiv:1610.09289v3  [cs.IT]  24 Jul 2017  It also can be expressed as CGK(X; Y ) = inf PU|XY :CGK(X;Y |U)=0 I(XY ; U), (2) (the proof of (2) is given in Appendix A), where CGK(X; Y |U) := sup f,g:f(X,U)=g(Y,U) H(f (X, U) |U) (3) denotes the conditional common information between X, Y given U. The constraint CGK(X; Y |U) = 0 in (2) implies all the common information between X, Y is contained in U. Wyner [3] studied distributed source synthesis (or distributed source simulation) problem, and deﬁned common information in a different way. Speciﬁcally, he deﬁned common information as the minimum information rate needed to generate sources in a distributed manner with asymptotically vanishing normalized relative entropy between the induced distribution and some target joint distribution. Given a target distribution PXY , this common information is proven to be CW (X; Y ) = inf PU|XY :X→U→Y I(XY ; U). (4) Furthermore, as a related problem, the problem of exactly generating target sources was studied by Kumar, Li, and Gamal recently [12]. The notion of exact common information (rate) (denoted as KKLG(X; Y )) is introduced, which is deﬁned to be the minimum code rate to ensure the induced distribution is exactly (instead approximately) same to some target joint distribution. By comparing these common informations, it is easy to show that CGK(X; Y ) ≤ I(X; Y ) ≤CW (X; Y ) ≤KKLG(X; Y ) ≤H(XY ). Observe that in the deﬁnitions of G´acs-K¨orner and Wyner common informations, different dependency constraints are used. G´acs-K¨orner common information requires the common variable U to be some function of each of the sources (or equivalently, there is no conditional common information given U); while Wyner common information requires',\n",
       " '1605.08283': 'Deep convolutional neural networks (DCNNs) have proven tremendously successful in a wide range of machine learning tasks (Bengio et al., 2013; LeCun et al., 2015). Such networks are composed of multiple layers, each of which computes convolutional transforms followed by the application of non-linearities and pooling operators. DCNNs are typically distinguished according to (i) whether the ﬁlters employed are learned (in a supervised (LeCun et al., 1998; Huang & LeCun, 2006; Jarrett et al., 2009) or unsupervised (Ranzato et al., 2006; 2007; JarProceedings of the 33 rd International Conference on Machine Learning, New York, NY, USA, 2016. JMLR: W&CP volume 48. Copyright 2016 by the author(s). rett et al., 2009) fashion) or pre-speciﬁed (and structured, such as, e.g., wavelets (Serre et al., 2005; Mutch & Lowe, 2006; Mallat, 2012), or unstructured, such as random ﬁlters (Ranzato et al., 2007; Jarrett et al., 2009)), (ii) the non-linearities used (e.g., logistic sigmoid, hyperbolic tangent, modulus, or rectiﬁed linear unit), and (iii) the pooling operator employed (e.g., sub-sampling, average pooling, or max-pooling). While a given choice of ﬁlters, nonlinearities, and pooling operators will lead to vastly different performance results across datasets, it is remarkable that the overall DCNN architecture allows for impressive classiﬁcation results across an extraordinarily broad range of applications. It is therefore of signiﬁcant interest to understand the mechanisms underlying this universality. First steps towards addressing this question and developing a mathematical theory of DCNNs for feature extraction were made—for the continuous-time case—in (Mallat, 2012; Wiatowski & B¨olcskei, 2015). Speciﬁcally, (Mallat, 2012) analyzed so-called scattering networks, where signals are propagated through layers that employ directional wavelet ﬁlters and modulus non-linearities but no intra-layer pooling. The resulting wavelet-modulus feature extractor is horizontally (i.e., in every network layer) translation-invariant (accomplished by letting the wavelet scale parameter go to inﬁnity) and deformationstable, both properties of signiﬁcance in practical feature extraction applications. Recently, (Wiatowski & B¨olcskei, 2015) considered Mallat-type networks with arbitrary ﬁlters (that may be learned or pre-speciﬁed), general Lipschitz-continuous non-linearities (e.g., rectiﬁed linear unit, shifted logistic sigmoid, hyperbolic tangent, and the modulus function), and a continuous-time pooling operator that amounts to a dilation. The essence of the results in (Wiatowski & B¨olcskei, 2015) is that vertical (i.e., asymptotically in the network depth) translation invariance and Lipschitz continuity of the feature extractor are induced by the network structure per se rather than the speciﬁc choice of ﬁlters and non-linearities. For band-limited arXiv:1605.08283v1  [cs.LG]  26 May 2016  Discrete Deep Feature Extraction: A Theory and New Architectures signals (Wiatowski & B¨olcskei, 2015), cartoon functions (Grohs et al., 2016), and Lipschitz-continuous functions (Grohs et al., 2016), Lipschitz continuity of the feature extractor automatically leads to bounds on deformation sensitivity. A discrete-time',\n",
       " '1607.00455': 'Alzheimer’s disease (AD) is a progressive brain disorder and the most common case of dementia in the late life. AD leads to the death of nerve cells and tissue loss throughout the brain, thus reducing the brain volume in size dramatically through time and affecting most of its functions [1]. The estimated number of affected people will double for the next two decades, so that one out of 85 persons will have the AD by 2050 [2]. Because the cost of caring the AD patients is expected to rise dramatically, the necessity of having a computer-aided system for early and accurate AD diagnosis becomes critical [3]. Several popular non-invasive neuroimaging tools, such as structural MRI (sMRI), functional MRI (fMRI), and positron emission tomography (PET), have been investigated for developing such a system [4,5]. The latter extracts features from the available images, and a classiﬁer is trained to distinguish between different groups of subjects, e.g., AD, mild cognitive impairment (MCI), and normal control (NC) groups [3, 6–8]. The sMRI has been recognized as a promising indicator of the AD progression [3,9]. Various machine learning techniques were employed to leverage multi-view MRI, PET, and CSM data to predict the AD. Liu et al. [10] extracted multi-view features using several selected templates in the subjects’ MRI dataset. Tissue density maps of each ∗Corresponding Author:— Tel: (502) 852 3165, Fax: (502) 852 3940, E-mail: ehsan.hosseiniasl@louisville.edu template were used then for clustering subjects within each class in order to extract an encoding feature of each subject. Finally, an ensemble of support vector machine (SVM) was used to classify the subject. Deep networks were also used for diagnozing the AD with different image modalities and clinical data. Suk et al. [11] used a stacked autoencoder to separately extract features from MRI, PET, and cerebrospinal ﬂuid (CSF) images; compared combinations of these features with due account of their clinical mini-mental state examination (MMSE) and AD assessment scale-cognitive (ADAScog) scores, and classiﬁed the AD on the basis of three selected MRI, PET, and CSF features with a multi-kernel SVM. Later on, a multimodal deep Boltzmann machine (BM) was used [12] to extract one feature from each selected patch of the MRI and PET scans and predict the AD with an ensemble of SVMs. Liu et al. [13] extracted 83 regions-of-interest (ROI) from the MRI and PET scans and used multimodal fusion to create a set of features to train stacked layers of denoising autoencoders. Li et al. [14] developed a multi-task deep learning for both AD classiﬁcation and MMSE and ADAScog scoring by multimodal fusion of MRI and PET features into a deep restricted BM, which was pre-trained by leveraging the available MMSE and ADAS-cog scores. Voxel-wise, cortical thickness, and hippocampus shape-volume features of the sMRI are used to diagnose the AD [3',\n",
       " '1704.07056': 'Image restoration (IR) aims to reconstruct a high quality image X from its degraded observation Y , which can be generally expressed as Y = H X + η (1) where H is a non-invertible linear degradation operator and η is the vector of some independent Gaussian white noise. With diﬀerent settings of matrix H , various IR problems can be derived from Eq. (1), such as image denoising [1, 2, 3, 4, 70] when H is an identity matrix, image deblurring [5, 6, 7, 8] when 5 H is a blur operator, image inpainting [9, 10, 11, 12] when H is a mask and image compressive sensing (CS) recovery when H is a random projection matrix [13, 14, 15, 16]. In this work, we focus on the latter three problems. IR is a typical ill-posed problem. To deal with this issue, image prior knowledge is usually exploited for regularizing the solution to the following minimization, ˆX = arg min X 1 2||Y −H X ||2 2 + λR(X ) (2) where the ﬁrst term above is the data ﬁdelity term and the second term depends on the employed image priors, and λ is the regularization parameter. Due to 10 the ill-posed nature of IR, the image prior knowledge plays a critical role in enhancing the performance of IR algorithms. In other words, how to design an eﬀective regularization model to represent the image priors is vital for IR tasks. The classical regularization models, such as Tikhonov regularization [17] and total variation (TV) regularization [18, 19], exploited the image local structure 15 and high eﬀectiveness to preserve image edges. Nonetheless, they tended to over-smooth the image and some image details are usually lost. As an emerging machine learning technique, sparse representation based modeling has been proved to be a promising model for image restoration [20, 21, 22, 23]. It assumes that image/image patch can be precisely represented as 20 a sparse linear combination of basic elements. These elements, called atoms, compose a dictionary [20, 21, 24, 25]. The dictionary is usually learned from a 2  natural image dataset [20, 21]. The well known dictionary learning (DL) based methods, such as KSVD [20, 21], ODL [24] and tasked driven DL [25], have been proposed and applied to image restoration and other image processing tasks. 25 Image patches that have similar pattern can be spatially far from each other and thus can be collected in the whole image. This so-called nonlocal selfsimilarity (NSS) prior is the most outstanding priors for image restoration. The seminal work of nonlocal means (NLM) [1] exploited the NSS prior to perform a series of the weighted ﬁltering for image denoising. Due to its eﬀectiveness, 30 a large amount of related developments have been proposed [3, 7, 16, 26, 27, 28, 29]. For instance, BM3D [28] exploited nonlocal similar 2D image patches and 3D transform domain collaborative ﬁltering. Marial et al. [3] considered the idea of NSS by simultaneous sparse coding (SSC). Dong et',\n",
       " '1812.03640': 'Massive MIMO refers to a wireless network technology where the base stations (BSs) are equipped with a very large number M of antennas to serve a multitude of user equipments (UEs) by spatial multiplexing [1], [2]. Exciting developments have occurred in the recent year. In industry, the technology has been integrated into the 5G New Radio standard [3]. In academia, the long-standing pilot contamination issue, which was believed to impose fundamental limitations [1], has ﬁnally been resolved [4]. More precisely, [4] showed that with optimal minimum mean squared error (MMSE) combining/precoding and a tiny amount of spatial channel correlation, the capacity increases without bound in uplink (UL) and downlink (DL) as the number of antennas increases. In this work, we propose to use deep learning for solving the max-min and max-prod power allocation problems in the DL of Massive MIMO networks. We are inspired by the recent explosion of successful applications of machine learning techniques [5] that demonstrate the ability of deep neural networks to learn rich patterns and to approximate arbitrary function mappings [5], [6]. Particularly, we aim to demonstrate that the positions of the UEs (which can be easily obtained via global positioning system) can be effectively used by a neural network to obtain near-optimum performance. This allows to reduce substantially the complexity of power allocation (since simple matrix-vector operations are required) and thus makes it possible to perform power allocation in realtime, i.e. following the variations of UEs’ positions. In addition The work of L. Sanguinetti work was supported by the University of Pisa under the PRA 2018-2019 Research Project CONCEPT and by the H2020ERC PoC-CacheMire project (grant 727682). The research of A. Zappone was supported by the H2020 MSCA IF BESMART, grant 749336. The work of M. Debbah was partly supported by the H2020 MSCA IF BESMART, grant 749336, and by the H2020-ERC PoC-CacheMire project, grant 727682. to this, training such a neural network is fairly convenient since training samples are easily obtainable by running off-the-shelf optimization algorithms. Deep learning for radio resource allocation in wireless networks has been also considered in [7], where the WMMSE algorithm for sum-rate maximization has been emulated by a fully-connected feedforward neural network, and in [8], where a convolutional neural network is used for user-cell association. II. MASSIVE MIMO NETWORK We consider the DL of a Massive MIMO network with L cells, each comprising a BS with M antennas and K UEs [9]. We denote by hj li ∈CM the channel between UE i in cell l and BS j and assume that hj li ∼NC \\x10 0M, Rj li \\x11 (1) where Rj li ∈CM×M is the spatial correlation matrix, known at the BS. The normalized trace βj li = 1/Mtr(Rj li) accounts for the average channel gain from an antenna at BS j to UE i in cell l and is modelled as (in dB) βj li = Υ −10α log10   dj',\n",
       " '1810.01185': 'There is no doubt that Machine Learning (ML) and, in particular, Deep Learning (DL) algorithms achieve impressive results on tasks where it is impossible to specify a procedural rule-set. Some examples are object recognition [176, 185, 80, 81], machine translation [33, 183] or speech recognition [204, 211, 117, 195]. Fuelled by the ease of adoption (through the increase of cheap computational power and development of high level APIs), DL algorithms are explored in a variety of new tasks and commercial applications. One of the most promising application, with a meaningful impact in the transportation industry, is the development of autonomous vehicles - systems that heavily rely on DL algorithms to perceive the environment and reason about it [22]. Facing commercial deployment and the possibility of use in safety-critical systems, new properties of DL algorithms become important. In particular, their ability to maintain performance whenever faced with data coming from slightly diﬀerent distributions than trained with. This property is deﬁned as the algorithm’s power to generalise outside the training dataset or, consistent with the optimisation literature, the algorithm’s robustness. In optimisation, a robust solution is one that has the ability to perform well under a certain level of uncertainty [15]. Recent discoveries in DL research [187] showed that neural networks exhibit low robustness and triggered an impressive wave of (sometimes controversial) publications. Notably, Deep Neural Networks (DNN) can be highly sensitive to small, intentional, distribution drifts - inputs which substantially decrease their performance, while being in close resemblance to training data. The term adversarial examples was ﬁrst used in [187] to describe such inputs. Since an intention is required, a substantial number of publications claim security consequences, e.g. [142, 110, 78, 146, 181, 84, 178, 55]. The same body of publications hypothesise that commercial deployment is hindered by low robustness. In contrast, recent publications [63] show these claims are sometimes exaggerated and demand clear security requirements for a correct evaluation. In between, a considerable number of publications investigate the existence of adversarial examples from a theoretical perspective and try to shed ∗a.serban@cs.ru.nl 1  light on this peculiar behaviour of DNN. Overall, there are two important reasons why adversarial examples are important: (1) because an attacker might exploit them and (2) because they suggest DNN are not robust. Another phenomenon revealed by the existence of adversarial examples is the power to use them against very diﬀerent ML techniques. This means an input designed to confuse DNN can trigger the same behaviour for kernel methods [145, 83]. From a security perspective, this property suggests an attacker does not need any information about the model under attack. Moreover, from a learning theory perspective, it suggests that (1) algorithms extrapolate similar discriminants, in spite of the diﬀerence in method and (2) high sensitivity to similar distribution drifts is an universal phenomenon, independent of method. The goal of this report is to provide a comprehensive and complete overview of this research ﬁeld. We aim to characterise the phenomenon from',\n",
       " '1707.09183': 'There are many successful applications of multiagent systems (MAS) in the real world. Examples are ubiquitous in energy applications, for example, to implement a network to distribute electricity (Pipattanasomporn et al., 2009) or to coordinate the charging of electric vehicles (Valogianni et al., 2015), in security, to patrol the Los Angeles airport (Pita et al., 2009) and in disaster management to assign a set of resources to tasks (Ramchurn et al., 2010). Multiagent systems include a set of autonomous entities (agents) that share 1 arXiv:1707.09183v2  [cs.MA]  11 Mar 2019  Hernandez-Leal, Kaisers, Baarslag and Munoz de Cote a common environment and where each agent can independently perceive the environment, act according to its individual objectives and as a consequence, modify the environment. How the environment changes as a consequence of an agent exerting an action is known as the environment dynamics. In order to act optimally with respect to its objectives these dynamics need to either be known (a priori) by the agent or otherwise be learned by experience, i.e., by interacting many times with the environment. Once the environment dynamics have been learned, the agent can then adapt its behaviour and act according to its target objective. We know a lot about the single agent case, where only one agent is learning and adapting its behaviour, but most of the results break apart when two or more agents share an environment and they all learn and adapt their behaviour concurrently. The problem with this concurrency is that the action executed by one agent aﬀects the goals and objectives of the rest, and vice-versa. To tackle this, each agent will need to account for how the other agents are behaving and adapt according to the joint behaviour. Needless to say, this joint behaviour needs to be learned by each agent, and due to the fact that all agents are performing the same operations of learning and adapting concurrently, the joint behaviour —and therefore the environment— is perceived by each agent as nonstationary. This non-stationarity (sometimes referred to as the moving target problem, see Tuyls and Weiss, 2012) sets multiagent learning apart from single-agent learning, for which it suﬃces to converge to a ﬁxed optimal strategy. Most learning algorithms to date are not well suited to deal with non-stationary environments,1 and usually, such non-stationarity is caused by changes in the behaviour of the participating agents. For example, a charging vehicle in the smart grid might change its behavioural pattern (Marinescu et al., 2015); robot soccer teams may change between pre-deﬁned behaviours depending on the situation (MacAlpine et al., 2012); and attackers change their behaviours to keep security guards guessing in domains involving frequent adversary interactions, such as wildlife and ﬁshery protection (Fang et al., 2015). Previous works in reinforcement learning (RL), MAS and multi-armed bandits (to name a few) have all acknowledged the fact that specialized targeted work is needed that explicitly addresses non',\n",
       " '1708.00065': 'Event sequence prediction is a task to predict the next event1 based on a sequence of previously occurred events. Event sequence prediction has a broad range of applications, e.g., next word prediction in language modeling (Józefowicz et al., 2016), next place prediction based on the previously visited places, or next app to launch given the usage history. Depending on how the temporal information is modeled, event sequence prediction often decomposes into the following two categories: discrete-time event sequence prediction and continuous-time event sequence prediction. Discrete-time event sequence prediction primarily deals with sequences that consist of a series of tokens (events) where each token can be indexed by its order position in the sequence. Thus such a sequence evolves synchronously in natural unit-time steps. These sequences are either inherently time-independent, e.g, each word in a sentence, or resulted from sampling a sequential behavior at an equally-spaced point in time, e.g., busy or not busy for an hourly trafﬁc update. In a discrete-time event sequence, the distance between events is measured as the difference of their order positions. As 1We use \"event\" in this paper for real world observations instead of \"token\" that is often used in sequence problems, e.g., words in a sentence. But they are equivalent to a sequence model. 1 arXiv:1708.00065v4  [cs.LG]  20 Jul 2018  Workshop track - ICLR 2018 a consequence, for discrete-time event sequence modeling, the primary goal is to predict what event will happen next. Continuous-time event sequence prediction mainly attends to the sequences where the events occur asynchronously. For example, the time interval between consecutive clinical visits of a patient may potentially vary largely. The duration between consecutive log-in events into an online service can change from time to time. Therefore, one primary goal of continuous-time event sequence prediction is to predict when the next event will happen in the near future. Although these two tasks focus on different aspects of a future event, how to learn a proper representation for the temporal information in the past is crucial to both of them. More speciﬁcally, even though for a few discrete-time event sequence prediction tasks (e.g., neural machine translation), they do not involve an explicit temporal information for each event (token), a proper representation of the position in the sequence is still of great importance, not to mention the more general cases where each event is particularly associated with a timestamp. For example, the next destination people want to go to often depends on what other places they have gone to and how long they have stayed in each place in the past. When the next clinical visit (Choi et al., 2016a) will occur for a patient depends on the time of the most recent visits and the respective duration between them. Therefore, the temporal information of events and the interval between them are crucial to the event sequence prediction in general. However, how to',\n",
       " '1809.01791': 'The ability of detailed feature extraction has become one of a common standard for convolutional neural networks (CNNs). Many researchers have tried to improve their feature extraction networks by making them deeper or wider, which is also the most common strategy for difﬁcult object detection tasks such as small objects and occluded ones. Recently, more and more object detection models choose to use the original size of image data with the purpose of obtaining more detail information. However, these methods bring in huge computation burden and it is not the best choice in real-world applications processing large-size image data. This paper proposes a novel framework, called MDCN, which covers wide-context receptive ﬁelds and extracts multiscale features by introducing inception modules to deep part of the network. These inception modules consist of multi-scale ﬁltering units whose responsive regions account for a larger proportion of the feature maps produced in the deep part of the network, and they will activate objects with different sizes of background. MDCN maintains a relatively small feature extraction structure and the proposed inception modules only process feature maps with smaller sizes as they are produced later through forward propagation, which enables computational efﬁciency and better portability over other models. In principle, MDCN is an intuitive extension of feature extraction, while constructing deep inception modules properly is critical to yield better results. Development in computer hardware enables the training of macro CNNs, which stimulates the research in CNN structures in the direction of deeper and wider for better detailed feature extraction [1], [2], [6]. The feature extraction ability of networks has been enhanced dramatically from the original LeNet [3] with only 5 layers, VGG16 [4] to GoogleNet [5], residual networks (ResNets) which have surpassed 100 layers [2], wide-residual networks [6]. For a very deep CNN network, problems of gradient vanishing and feature propagation emerge. The introduction of skipconnection, the propose of Highway networks [8], stochastic depth technology [9] and FractalNet [10] all tried to create shorter paths between earlier and later layers in order to avoid the two problems to certain degree. ResNet-101 [2], with skipconnection has become the most popular structure when being used as the base network which has shown its advantage of feature extraction and representation in object detection and segmentation tasks [13], [14] over other methods. Many researchers tried to adopt ResNet-101 as their main feature extraction network. Mask R-CNN utilizes ResNet-101 as the main body of its network [14]. DSSD [13] achieves its best performance with Residual-101 on PASCAL VOC2007 and PASCAL VOC2012 datasets. However, DSSD only yields 2 percent of increase of mAP (mean average precision) by replacing the original VGG-16 [4] base network with ResNet101 while its detection speed decreases from 19 FPS to 6.6 FPS [13]. Mask R-CNN also suffers from the unsatisfactory detection speed brought by ResNet-101 [14]. The corresponding approach towards being deeper is to increase',\n",
       " '1804.08042': 'Deep neural networks (DNN) are expressive machine learning models that have been effective on many difﬁcult computer vision tasks involving large amounts of image data. Being supervised machine learning models, DNNs are trained by minimizing the discrepancy between the model output and the original labels of the images in a training set. The goal, however, is to minimize the error in labeling previously unseen data known as the generalization error. Thus, training DNNs is an optimization problem where the training error serves as a proxy for the true objective: the generalization error [5]. When the complexity of the model is roughly the same as that of the task, the training error serves as a faithful proxy for the generalization error. However, with the expressive power of DNNs, even small architectures can capture the random noise in the training samples and therefore result in high generalization error. To overcome this problem, researchers have devised different strategies to prevent DNNs from misinterpreting random variations in the training data as patterns responsible for the labels. Increasing the training dataset size is one potential solution, but often not possible. Augmenting the data with new samples that are slight variations of the original samples is also a commonly used approach. Early-stopping, i.e. stopping the training process before the validation error starts ascending, is another effective way to stop overﬁtting. While early-stopping is the easiest to exercise, in practice it does not match the performance achieved by more sophisticated techniques that regularize the models [10]. The simplest model that ﬁts the training data will generalize better than more complex models. There is, however, no easy way to choose a simple model that will yield the best performance, and a simple model may perform worse due to sensitivity to initial conditions and the bias–variance tradeoff [27]. Therefore, a common approach is to start with a large neural network and then constrain the model in some way to prevent it from learning sampling noise. This process is known as regularization. Deterministic techniques either prune the network by removing less important neurons or impose a weight penalty on the magnitude of the weights of each layer. Penalizing the weights with the L1 norm can be seen as feature selection procedure, whereas, penalizing the L2 norm of the weights can be interpreted as continuous shrinkage of the weights, which prevents overly complicated decision boundaries. Stochastic regularization techniques approach overﬁtting by constructing an ensemble of poorly trained models and 1 arXiv:1804.08042v1  [cs.NE]  21 Apr 2018  then averaging their predictions. Given a neural network, for each training example in the training set, Dropout [30] sets the units in the network to zero with a probability 1−p. Thus each training example is used to train a slightly different network. At inference time, all the units in the network are kept but their outputs are scaled with p which serves as averaging the prediction of many',\n",
       " '1806.02246': 'Distributed machine learning is crucial for many settings where the data is possessed by multiple parties or when the quantity of data prohibits processing at a central location. It helps to reduce the computational complexity, improve both the robustness and the scalability of data processing. In a distributed setting, multiple entities/nodes collaboratively work toward a common optimization objective through an 1Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, Michigan, USA. Correspondence to: Xueru Zhang <xueru@umich.edu>, Mohammad Mahdi Khalili <khalili@umich.edu>, Mingyan Liu <mingyan@umich.edu>. Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018 by the author(s). interactive process of local computation and message passing, which ideally should result in all nodes converging to a global optimum. Existing approaches to decentralizing an optimization problem primarily consist of subgradientbased algorithms (Nedic et al., 2008; Nedic & Ozdaglar, 2009; Lobel & Ozdaglar, 2011), ADMM-based algorithms (Wei & Ozdaglar, 2012; Ling & Ribeiro, 2014; Shi et al., 2014; Zhang & Kwok, 2014; Ling et al., 2016), and composite of subgradient and ADMM (Bianchi et al., 2014). It has been shown that ADMM-based algorithms can converge at the rate of O( 1 k) while subgradient-based algorithms typically converge at the rate of O( 1 √ k), where k is the number of iterations (Wei & Ozdaglar, 2012). In this study, we will solely focus on ADMM-based algorithms. The information exchanged over the iterative process gives rise to privacy concerns if the local training data is proprietary to each node, especially when it contains sensitive information such as medical or ﬁnancial records, web search history, and so on. It is therefore highly desirable to ensure such iterative processes are privacy-preserving. A widely used notion of privacy is the ε-differential privacy; it is generally achieved by perturbing the algorithm such that the probability distribution of its output is relatively insensitive to any change to a single record in the input (Dwork, 2006). Several differentially private distributed algorithms have been proposed, including (Hale & Egerstedty, 2015; Huang et al., 2015; Han et al., 2017; Zhang & Zhu, 2017; Bellet et al., 2017). While a number of such studies have been done for (sub)gradient-based algorithms, the same is much harder for ADMM-based algorithms due to its computational complexity stemming from the fact that each node is required to solve an optimization problem in each iteration. To the best of our knowledge, only (Zhang & Zhu, 2017) applies differential privacy to ADMM, where the noise is either added to the dual variable (dual variable perturbation) or the primal variable (primal variable perturbation) in ADMM updates. However, (Zhang & Zhu, 2017) could only bound the privacy loss of a single iteration. Since an attacker can potentially use all intermediate results to perform inference, the privacy loss accumulates over time through the iterative process. It turns out that the tradeoff between the utility of the algorithm',\n",
       " '1507.08711': 'FAILED',\n",
       " '1804.06439': 'Predicting the next characters or words following a preﬁx has had multiple uses from helping handicapped people (Swifﬁn et al., 1987) to, more recently, helping search engine users (Cai et al., 2016). In practice, most search engines today use query auto completion (QAC) systems, consisting of suggesting queries as users type in the search box (Fiorini et al., 2017). The task suffers from high dimensionality, because the number of possible solutions increases as the length of the target query increases. Historically, the query prediction task has been addressed by relying on query logs, particularly the popularity of past queries (BarYossef and Kraus, 2011; Lu et al., 2009). The idea is to rely on the wisdom of the crowd, as popular queries matching a typed preﬁx are more likely to be the user’s intent. This traditional approach is usually referred to as MostPopularCompletion (MPC)(Bar-Yossef and Kraus, 2011). However, the performance of MPC is skewed: it is very high for popular queries and very low for rare queries. At the extreme, MPC simply cannot predict a query it has never seen. This becomes a bigger problem in academic search (Lankinen et al., 2016), where systems are typically less used, with a wider range of possible queries. Recent advances in deep learning, particularly in semantic modeling (Mitra and Craswell, 2015) and neural language modeling (Park and Chiba, 2017) showed promising results for predicting rare queries. In this work, we propose to improve the state-of-the-art approaches in neural QAC by integrating personalization and time sensitivity information as well as addressing current MPC limitations by diversifying the suggestions, thus approaching a production-ready architecture. 2 Related work 2.1 Neural query auto completion While QAC has been well studied, the ﬁeld has recently started to shift towards deep learningbased models, which can be categorized into two main classes: semantic models (using Convolutional Neural Nets, or CNNs) (Mitra and Craswell, 2015) and language models (using Recurrent Neural Nets, or RNNs) (Park and Chiba, 2017). Both approaches are frequently used in natural language processing in general (Kim et al., 2016) and tend to capture different features. In this work, we focus on RNNs as they provide a ﬂexible solution to generate text, even when it is not previously seen in the training data. Yet, recent work in this ﬁeld (Park and Chiba, 2017) suffers from some limitations. Most importantly, the probability estimates for full queries arXiv:1804.06439v3  [cs.CL]  9 May 2018  are directly correlated to the length of the suggestions, consequently favoring shorter queries in some cases and hampering some predictions (Park and Chiba, 2017). By appending these results to MPC’s and re-ranking the list with LambdaMART (Burges, 2010) in another step as suggested in previous work (Mitra and Craswell, 2015), they achieve state-of-the-art performance in neural query auto completion at the cost of a higher complexity and more',\n",
       " '1111.1051': 'Interference is a major performance-limiting factor in modern wireless communication systems. Many interference mitigation strategies have been proposed to improve network spectral efﬁciency. By allowing partial or full cooperation among interfering base stations, interference can effectively be managed and spectral efﬁciency can be improved. Joint beamforming [1] and network MIMO (or multicell processing) [2] among base stations have been shown to be effective interference mitigation techniques. However, if cooperation among transmitters is not allowed, orthogonal multiple access has been a traditional solution to interference. In a K-user single-input single-output (SISO) interference channel (IC), for example, each user can achieve 1/K degrees of freedom (DoF) by time division multiple access. In recent years, interference alignment (IA) techniques have received much attention [3]–[6]. The basic concept of IA is to align the interfering signals in a small dimensional subspace. In a K-user SISO IC, K/2 DoF have been shown to be achievable using IA [3]. Although IA provides a substantial asymptotic capacity gain in interference channels, there are many practical challenges for implementation. IA requires global channel state information at the transmitter (CSIT), and imperfect channel knowledge severely degrades the gain of IA. In some channel conﬁgurations, symbols should be extended in the time/frequency domain to align interfering signals. The high computational complexity is also considered as a major challenge. To ameliorate these difﬁculties, many IA algorithms have been proposed such as iterative IA [5] and a subspace IA [6]. For interference suppression, multiuser diversity can also be exploited by opportunistic user selection for minimizing interference. The interference reduction by multiuser diversity can be enjoyed without heavy burden on global channel knowledge because user selection in general requires only a small amount of feedback [7]–[14]. In this context, opportunistic interference alignment (OIA) has been recently proposed in [9] and has attracted much attention. In a 3-transmitter M × 2M MIMO interfering broadcast channel (IBC), the authors of [11] proved that αM (where α ∈[0, 1]) DoF per transmitter is achievable when the number of users scales as P αM. In [12] and [13], a K-transmitter 1 × 3 SIMO IBC and a K-transmitter 1 × (K −1) SIMO IBC have been studied, respectively. For SIMO interfering multiple access channel (IMAC) constituted by K-cell uplink channels with M transmit antennas and single antenna users, the authors of [14] showed that KM DoF are achievable when the number of users scales as P (K−1)M. In  3 these schemes, user dimensions are used to align the interfering signals; each transmitter opportunistically selects a user whose interfering signals are most aligned among the users associated with the transmitter. Contrary to the conventional opportunistic user selection techniques [7], [8], [15]–[18], the OIA scheme exploits the multiuser dimensions for interference alignment. In this paper, we investigate the optimal role of multiuser diversity for the target DoF in the IBC with K-transmitters and generalize the results of [12] [13]. For the K-transmitter SIMO',\n",
       " '1712.01496': 'Assessing pain is a difﬁcult but important task in clinical settings, which in practice relies on self-report by patients through simple subjective pain assessment measures like visual analog scale (VAS). Research has shown that facial expressions can serve as reliable indicators of pain across human lifespan [6] and there is also good consistency of facial expressions corresponding to pain stimuli. The Facial Action Coding System (FACS) is widely used in pain analysis because it provides an objective assessment to score and recognize Action Units (AUs), which represent the muscular activity that produces momentary changes in facial appearance [8]. Several studies [7], [17] using FACS have identiﬁed a collection of core Action Units, which are speciﬁc to pain and that occur singly or in combination as summarized in Table I. These results are also conﬁrmed in the study of facial expressions of pain suffered by cancer patients [23]. Note that although AU27 (mouth stretch) is included in [23], we did not include it in this study as it occurs infrequently. Facial expression annotation of videos using FACS is generally performed ofﬂine by trained experts who closely examine the video of a patient’s face. A long video is typically divided into multiple subsequences of ﬁxed length duration and AUs are coded at each time step (i.e. each video frame) within the video subsequence. Pain is assessed across the entire sequence based on the occurrence and frequency of pain-related AUs. However the Action Unit coding via human observations is very time consuming, which makes its real-time clinical use prohibitive [13],[1]. Therefore, the development of an efﬁcient real-time automated FACSbased pain detection would be a signiﬁcant innovation for enhanced patient care and clinical practice efﬁciency. TABLE I ACTION UNIT DEFINITION AND PAIN-RELATED AU COMBINATIONS AU Description Pain-Related Combinations 4 eye brow lower 6/7 6 cheek raiser 20 7 eye lid tightener 4+6/7/43 9 nose wrinkler 4+9/10 10 upper lip raiser 4+26 20 lip stretcher 9/10+26 26 jaw drop 43 eyes closed Progress in computer vision and machine learning (CVML) techniques over time has led to signiﬁcant development of general Automated Facial Expression Recognition (AFER) systems, although limited effort has been reported for its application in pain analysis. One major challenge is the difﬁculty in establishing a comprehensive annotated dataset with sufﬁcient examples of pain-related expressions. Most existing video datasets containing pain-related facial expressions are developed for targeted studies. These datasets are typically arXiv:1712.01496v2  [cs.LG]  20 Feb 2018  not publicly accessible. They are mostly small in size and lack sufﬁcient diversity to train a robust automated system in general. One development that has facilitated the research on spontaneous expressions recognition is the introduction of UNBC-McMaster Shoulder Pain Archive, which is the only publicly available comprehensive pain-oriented facial expression dataset. This dataset contains recordings of subjects experiencing shoulder pain in a clinical setting with complete labeling at both',\n",
       " '1504.01452': 'Wireless data trafﬁc over the Internet and mobile networks has been growing at an enormous rate due to the explosion of available video content and proliferation of devices with increased display capabilities. According to Cisco Visual Networking Index [1], the wireless data trafﬁc is expected to reach more than 24.3 Exabytes per month by 2019. Requests for massive data transmission over wireless systems, together with the time-varying nature of wireless connections and constraints on the available resources such as channel bandwidth and capacity, imposes signiﬁcant challenges [2]. One approach that addresses the challenges mentioned above is to bring part of the requested content closer to end users via caching [3] [4]. This is often referred to as the push method. More speciﬁcally, popular contents are delivered and pre-stored in caches during relatively idle periods of wireless networks, which are retrieved later at peak time to mitigate the network congestion problem. To further reduce the total volume of data trafﬁc, broadcast or multicast transmissions can be incorporated into the push technique. In particular, considering that popular contents are usually requested by a large number of users, we may utilize a shared channel to deliver them via broadcast or multicast networks [5]. The performance of this technique relies heavily on the push strategy due to the gain only comes from the cache. In contrast to pre-storing popular contents directly at caches closer to end users for future retrieval, a recently proposed implementation of the push technique relies on the idea of coded cache [6]. It can offer extra performance gain in terms of decrease in the network trafﬁc through creating codedmulticasting opportunities by jointly coding multiple data streams at different caches [7]. With coded cache, a careful selection of content overlap across caches can ensure that multiple requests for different contents can be addressed with a single coded stream. However, existing studies on the coded cache-based push method assumed the presence of a shared link, which is errorfree and can be accessed by every user. However, in realistic wireless systems, the shared link is capacity-constrained and more importantly, it may be of different channel conditions for various users. In this case, the system performance would be restricted by the user with the worst channel quality. For illustration, consider a simple scenario where the overlapped content comes from different users with different shared channel conditions. Additional delay will be induced because it could take the user with poorer channel condition longer to transmit the required data trunk, which leads to inefﬁcient use of wireless channel bandwidth. Therefore, an appropriate resource allocation method is needed to take full advantage of scarce bandwidth and power resources. In this paper, we shall consider the problem of optimal resource allocation for coded cache-based push systems with a shared fading channel to address the above drawback. The study will be conducted in the context of a broadcast/multicast network and investigate how the transport mode and the number',\n",
       " '1704.02201': 'Estimating the full articulated 3D pose of hands is becoming increasingly important due to the central role that hands play in everyday human activities. Applications in activity recognition [26], motion control [47], human– computer interaction [30], and virtual/augmented reality (VR/AR) require real-time and accurate hand pose estimation under challenging conditions. Spurred by recent developments in commodity depth sensing, several methods that use a single RGB-D camera have been proposed [38, 31, 35, 22, 4, 42]. In particular, methods that use Convolutional Neural Networks (CNNs), possibly in combinaFigure 1: We present an approach to track the full 3D pose of the hand from egocentric viewpoints (left), a challenging problem due to additional self-occlusions, occlusions from objects and background clutter. Our method can reliably track the hand in 3D even under such conditions using only RGB-D input. Here we show tracking results overlaid with color and depth map (center), and visualized from virtual viewpoints (right). tion with model-based hand tracking, have been shown to work well for static, third-person viewpoints in uncluttered scenes [39, 29, 18], i.e., mostly for free hand motion in midair, a setting that is uncommon in natural hand interaction. However, real-time hand pose estimation from moving, ﬁrst-person camera viewpoints in cluttered real-world scenes where the hand is often occluded as it naturally interacts with objects, remains an unsolved problem. We deﬁne ﬁrst-person or egocentric viewpoints as those that would typically be imaged by cameras mounted on the head (for VR/AR applications), shoulder, or chest (see Figure 1). Occlusions, cluttered backgrounds, manipulated objects, and ﬁeld-of-view limitations make this scenario particularly challenging. CNNs are a promising method to tackle this problem but typically require large amounts of annotated data which is hard to obtain since markerless hand tracking (even with multiple views), and manual annotation on a large scale is infeasible in egocentric settings due to (self-)occlusions, cost, and time. Even semiautomatic annotation approaches [17] would fail if large parts of the hand are occluded. Photorealistic synthetic data, 1 arXiv:1704.02201v2  [cs.CV]  5 Oct 2017  on the other hand, is inexpensive, easier to obtain, removes the need for manual annotation, and can produce accurate ground truth even under occlusion. In this paper, we present, to our knowledge, the ﬁrst method that supports real-time egocentric hand pose estimation in real scenes with cluttered backgrounds, occlusions, and complex hand-object interactions using a single commodity RGB-D camera. We divide the task of perframe hand pose estimation into: (1) hand localization, and (2) 3D joint location regression. Hand localization, an important task in the presence of scene clutter, is achieved by a CNN that estimates the 2D image location of the center of the hand. Further processing results in an image-level bounding box around the hand and the 3D location of the hand center',\n",
       " '1812.07394': 'As the popularity of smart mobile devices in the coming 5G era, mobile applications, especially for computation-intensive tasks such as online 3D gaming, face recognition and location-based augmented or virtual reality (AR/VR), have been greatly affected by the limited on-device computation capability [1]. Meanwhile, for the large number of low-power and resource-constrained wireless terminals serving in the emerging Internet of Things (IoT) [2] and Intelligent Transport Systems (ITS) [3], a huge amount of sensory data also needs to be pre-processed and analyzed. As a result, to meet the quality of experience (QoE) of these mobile applications, the technology of mobile edge computing (MEC) [4] has been proposed as a promising solution to bridge the gap between the limited resources on mobile devices and the ever-increasing demand of computation requested by mobile applications. Instead of the remote public clouds in conventional cloud computing systems such as Amazon Web Services and Microsoft Azure, MEC enhances the radio access networks (RANs), which is in close proximity to mobile users, with computing capability [5]–[7]. It enables mobile devices to ofﬂoad computation workloads to the MEC server associated with a base station (BS), and thus improves the QoE of mobile applications with considerably reduced latency and power consumption. Many researcher has been attracted from both the industry [8] and academia [9]– [11]. Nevertheless, computation ofﬂoading highly depends on the efﬁciency of wireless data transmission, which requires MEC systems to manage radio resources along with computation resources and complete computation tasks efﬁciently. In order to achieve higher energy efﬁciency or better computation experience, computation ofﬂoading strategies for MEC have been widely investigated in the literature recently. For shortterm optimization over quasi-static channels, some algorithms have been studied in [12]–[18]. In [12], optimal joint ofﬂoading selection and radio resource allocation for mobile task ofﬂoading was studied to minimize the overall execution time. For decentralized algorithms with reduced overhead, a game-theoretic computation ofﬂoading scheme was constructed in [13]. Moreover, with the dynamic voltage and frequency (DVFS) techniques, CPU-cycle frequency was ﬂexibly controlled with other features in [14], [15], where the system cost, deﬁned as weighted sum of energy consumption and execution time, has been reduced. Besides, energy-latency tradeoff has been discussed in [16] with jointly optimized communication and computation resource allocation under the limited energy and sensitive latency. Also, it has been shown the performance of MEC  3 can be further improved with adopting some other emerging technologies such as wireless power transfer [17] and non-orthogonal multiple access (NOMA) [18]. To cope with stochastic task arrivals and time-varying wireless channels, strategies for dynamic joint control of radio and computation resources in MEC systems become even challenging [19]– [28]. In [19], a threshold-based dynamic computation ofﬂoading policy was proposed to minimize energy consumption under stochastic wireless channels. For low-complexity online algorithms, Lyapunov optimization has been widely adopted. In [20], dynamic policies for ofﬂoading decision, clock speed and network',\n",
       " '1409.1411': 'Lip reading is used to understand or interpret speech without hearing it, a technique  especially mastered by people with hearing difficulties. The ability to lip read enables a  person with a hearing impairment to communicate with others and to engage in social  activities, which otherwise would be difficult. Recent advances in the fields of computer  vision, pattern recognition, and signal processing has led to a growing interest in  automating this challenging task of lip reading. Indeed, automating the human ability to lip  read, a process referred to as visual speech recognition (VSR) (or sometimes speech  reading), could open the door for other novel related applications.   VSR has received a great deal of attention in the last decade for its potential use  in  applications such as human-computer interaction (HCI), audio-visual speech recognition  (AVSR), speaker recognition, talking heads, sign language recognition and video  surveillance. Its main aim is to recognise spoken word(s) by using only the visual signal that  is produced during speech. Hence, VSR deals with the visual domain of speech and involves  image processing, artificial intelligence, object detection, pattern recognition, statistical  modelling, etc.  There are two different main approaches to the VSR problem, the visemic* approach and the  holistic approach, each with its own strengths and weaknesses. The traditional and most  common approaches to automatic lip reading are based on visemes. A Viseme is the mouth  shapes (or appearances) or sequences of mouth dynamics that are required to generate a  phoneme in the visual domain. However, several problems arise while using visemes in  visual speech recognition systems such as the low number of visemes (between 10 and 14)  compared to phonemes (between 45 and 53). Visemes cover only a small subspace of the  mouth motions represented in the visual domain, and many other problems. These  problems contribute to the bad performance of the traditional approaches; hence, the  visemic approach is something like digitising the signal of the spoken word, and digitising  causes a loss of information.   The holistic approach such as the “visual words” (Hassanat, 2009) considers the signature of  the whole word rather than only parts of it. This approach can provide a good alternative to  the visemic approaches to automatic lip reading. The major problem that faces this approach  is that for a complete English language lip reading system, we need to train the whole of the  English language words in the dictionary! Or to train (at least) the distinct ones. This                                                    * Related to a Viseme.  www.intechopen.com      Speech and Language Technologies    280  approach can be effective if it is trained on a specific domain of words, e.g. numbers,  postcodes, cities, etc.   A typical VSR system consists of three major stages: detecting/localizing human faces, lips  localization and lip reading. The accuracy of a VSR system is heavily dependent on accurate  lip localisation as well as the robustness of the extracted features. The lips and the mouth  region of a face reveal most of the relevant visual speech information for a VSR system',\n",
       " '1811.05187': 'In company with the big data explosion and hardware system evolution over the past decades, deep learning (DL) systems achieved tremendous success and human competitive performance in various cutting-edge applications, such as real-time strategy game [1,2], image processing [3–5], speech intelligent assistant (e.g., Siri, Alexa, Cortana) [6,7], autonomous vehicle [8,9], intelligent manufacturing [10], medicine discovery [11] and medical diagnostics [12]. DL has become the driving force of technology innovation of next generation, penetrating into many domains of industry manufacture arXiv:1811.05187v1  [cs.LG]  13 Nov 2018  process, renovating the industry practice and reshaping almost every aspect of our society and daily life. A deep neural network (DNN) plays the key role behind the recent success of DL systems. It leverages a data-driven programming paradigm to automatically learn the decision logic from the training data, which is represented in the form of a neural network and connection strengths among neurons. To transfer the learning theory into practice, diverse DL frameworks (e.g., TensorFlow [13], PyTorch [14], and Theano [15]) are developed towards realizing urgent industrial demands of intelligent solutions. Although most of existing DL frameworks share either static or dynamic computational paradigms [16, 17], the detailed architecture design and implementation across frameworks are quite different. In other words, even the same DNN architecture design with exactly the same runtime conﬁguration might result in different decision logic, when implemented under different DL frameworks. Until now, unfortunately, it still lacks a comparative study on what different impacts various frameworks exert on the DL software development process and activities. With the rapid market trend in developing and deploying the AI solutions to platforms such as mobile devices, web services, and edge computing devices, it further poses challenges when DL systems are migrated, customized and deployed across platforms, considering the diverse requirements and limitations of each platform. For example, while a computational intensive DL system could execute efﬁciently on PC or server with the GPU support, it might still be an inappropriate scheme when deployed on mobile devices where limited computing capacity and battery volume are available. Therefore, some DL frameworks are speciﬁcally designed for mobile platforms, such as the recently released DL runtime framework TensorFlow Lite [18] for Android and Core ML [19] for iOS. Similarly, variants of DL frameworks (e.g., TensorFlow.js [20]) catering for web application are also proposed. For traditional softwares, we have gone through compatibility and migration issues across platforms for many years, with extensive studies performed regarding issues across programming languages [21], platforms, and hardware systems [22,23]. When it comes to DL software, similar compatibility and migration issues, regarding heterogeneous DL frameworks, platforms and hardware systems, still persist or even potentially more severe due to the immature development and deployment DL framework supports. It is nowadays not clear how well do different platforms support DL applications in terms of accuracy, computational',\n",
       " '1812.10761': '1 2 Related work 3 3 Notations 3 4 Margin distribution rather than minimum margin 4 4.1 Error-resilience assumptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 4.2 Existed results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 4.3 Main results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 5 Proofs 9 5.1 Proof of Lemma 4.9 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10 5.2 Proof of Lemma 4.10 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12 5.3 Proof of Theorem 4.11 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13 6 Optimizing margin distribution measure 14 7 Experiments 14 7.1 Conﬁguration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14 7.2 Ablation study . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15 7.3 Feature visualization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15 7.4 Controlling capacity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16 7.5 Inﬂuence of the hyper-parameters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16 8 Conclusion 17  Improving Generalization of Deep Neural Networks by Leveraging Margin Distribution* Shen-Huan Lyu† Lu Wang‡ Zhi-Hua Zhou§ Abstract Recent research has used margin theory to analyze the generalization performance for deep neural networks (DNNs). The existed results are almost based on the spectrally-normalized minimum margin. However, optimizing the minimum margin ignores a mass of information about the entire margin distribution, which is crucial to generalization performance. In this paper, we prove a generalization upper bound dominated by the statistics of the entire margin distribution. Compared with the minimum margin bounds, our bound highlights an important measure for controlling the complexity, which is the ratio of the margin standard deviation to the expected margin. We utilize a convex margin distribution loss function on the deep neural networks to validate our theoretical results by optimizing the margin ratio. Experiments and visualizations conﬁrm the effectiveness of our approach and the correlation between generalization gap and margin ratio. 1 Introduction Deep neural networks (DNNs) are making major advances in solving problems that have resisted the best attempts of the artiﬁcial intelligence community for many years [LBH15], especially in the ﬁeld of computer vision [Gor22]. Recently, many research try to explain the practical success of DNNs via generalization, which is the ability of a classiﬁer to perform well on unseen samples. However, some new empirical evidence has started to question this explanation. Adversarial training samples can cause the model to misclassify seriously by slight feature perturbation [GSS15; Pap+17]. On the other hand, Zhang et al. [Zha+21] ﬁnd that the deep neural networks have enough complexity to ﬁt an arbitrarily corrupted data, and a small geometric transformation may cause networks deteriorating in performance [AW19]. This complex and fragile nature of DNNs leads to a key problem, how to use the data distribution and network parameters to estimate the generalization ability of DNNs. Although several regularization techniques, such as dropout [Sri+14], batch normalization [IS15], and weight decay [KH92], do improve the generalization performance of the over-parameterized deep models, Zhang et al. [Zha+21] show that these regularizers cannot solve this problem either. Consequently, several recent works [NTS15; BFT17; NBS18; Aro+18] have started to address this question, proving that we can control the capacity of DNNs via different upper bounds based on the minimum margin. However, the generalization bounds based on analyses of model complexity and noise stability only',\n",
       " '1406.1943': 'I N many areas across science and engineering, researchers are dealing with signals that are often inherently sparse with respect to a certain dictionary (also called basis or transform). The seminal paper by neuroscientists Olshausen and Field [1] points out that the receptive ﬁelds in human being’s visual cortex utilize sparse coding to extract meaningful information from images. In the signal processing domain, the emerging ﬁeld of Compressed Sensing (CS) [2] relies on the key assumption that the signal is sparse under some orthogonal transformations, such as the Fourier transform. Traditionally, dictionaries are designed for desired properties in spatial or frequency domain or both. Recently, a different methodology to learn the dictionary from data is explored, which could better capture data characteristics. There are two different directions for designing such a signal dependent dictionary: (i) Using data directly as the dictionary: Wright et al. [3] proposed a sparse representation-based classiﬁer (SRC) that concatenates the training data from different classes into Y. Suo, M. Dao, T. D. Tran are with The Johns Hopkins University, Baltimore, MD, 21218 USA. (email: ysuo1@jhu.edu.) U. Srinivas and V. Monga are with The Pennsylvania State University, University Park, USA. This work has been partially supported by NSF under Grant CCF-1117545, ARO under Grant 60219-MA, and ONR under Grant N00014-12-1-0765. a single dictionary and uses class-speciﬁc residue for face recognition. Besides supervised tasks, a data dictionary is also utilized to cluster the high dimensional data by ﬁnding intrinsic low dimensional structures with respect to itself [4]. (ii) Training a dictionary using data: Aharon et al. [5] proposed an algorithm called K-SVD that guarantees all training data to be sparsely represented by the learned dictionary and demonstrated its advantages in image processing tasks. Yu et al. [6] justiﬁed that encoding data with dictionary atoms in its neighborhood can guarantee a nonlinear function of the data to be well approximated by a linear function. In contrast to the former approach, the learned dictionary in the latter approach removes the redundant information in the learning process, therefore the size of the dictionary does not grow with the size of the data. In this paper, we will focus on the latter approach. Moreover, we assume that the data has been properly aligned, although data alignment [7], [8] is another active research area with growing interests. A. Dictionary Learning for Reconstruction Dictionary learning (DL) is ﬁrst attempted for the purpose of reconstruction. The learning process can be described by following optimization problem: min D,A N X i=1 (1 2||xi −Dai||2 2 + λ1||ai||q). Given training data xi ∈RM (i = 1, ..., N), the dictionary D ∈RM×K and corresponding sparse coefﬁcients A ∈ RK×N are both learned. Each column of D and A are denoted as dj (j = 1, ..., K) and ai (i = 1, ..., N), respectively. The dictionary size K is typically larger than signal dimension M. The parameter λ1 balances the trade-off between',\n",
       " '1808.01265': 'Adverse weather conditions create visibility problems for both people and the sensors that power automated systems [25,37,48]. While sensors and the downstreaming vision algorithms are constantly getting better, their performance is mainly benchmarked with clear-weather images. Many outdoor applications, however, can hardly escape from bad weather. One typical example of adverse weather conditions is fog, which degrades the visibility of a scene signiﬁcantly [36, 52]. The denser the fog is, the more severe this problem becomes. During the past years, the community has made a tremendous progress on image dehazing (defogging) to increase the visibility of foggy images [24,40,56]. The last few years have also witnessed a leap in object recognition. The semantic understanding of foggy scenes, however, has received little attention, despite its arXiv:1808.01265v1  [cs.CV]  3 Aug 2018  2 C. Sakaridis, D. Dai, S. Hecker, L. Van Gool Fig. 1. The illustrative pipeline of our approach for semantic scene understanding under dense fog importance in outdoor applications. For example, an automated car still needs to detect other traﬃc agents and traﬃc control devices in the presence of fog. This work investigates the problem of semantic foggy scene understanding (SFSU). The current “standard” policy for addressing semantic scene understanding is to train a neural network with many annotations of real images [11,47]. Applying the same protocol to diverse weather conditions seems to be problematic, as the manual annotation part is hard to scale. The diﬃculty of data collection and annotation increases even more for adverse weather conditions. To overcome this problem, two streams of research have gained extensive attention: 1) transfer learning [9] and 2) learning with synthetic data [46,48]. Our method falls into the middle ground, and aims to combine the strength of these two kinds of methods. In particular, our method is developed to learn from 1) a dataset with high-quality synthetic fog and corresponding human annotations, and 2) a dataset with a large number of images with real fog. The goal of our method is to improve the performance of SFSU without requiring extra human annotations. To this aim, this work proposes a novel fog simulator to generate high-quality synthetic fog into real images that contain clear-weather outdoor scenes, and then leverage these partially synthetic foggy images for SFSU. The new fog simulator builds on the recent work in [48], by introducing a semantic-aware ﬁlter to exploit the structures of object instances. We show that learning with our synthetic data improves the performance for SFSU. Furthermore, we present a novel method, dubbed Curriculum Model Adaptation (CMAda), which is able to gradually adapt a segmentation model from light synthetic fog to dense real fog in multiple steps, by using both synthetic and real foggy data. CMAda improves upon direct adaptation signiﬁcantly on two datasets with dense real fog.  Model Adaptation with Synthetic and Real Foggy Data 3 The main contributions of the paper are: 1) a new automatic and scalable pipeline to generate',\n",
       " '1803.00657': 'Generative adversarial networks (GAN) [11] are one of the main groups of methods used to learn generative models from complicated real-world data. As well as using a generator to synthesize semantically meaningful data from standard signal distributions, GANs (GAN and its variants) train a discriminator to distinguish real samples in the training dataset from fake samples synthesized by the generator. As the confronter, the generator aims to deceive the discriminator by producing ever more realistic samples. The training procedure continues until the generator wins the adversarial game; that is, the discriminator cannot make a better decision than randomly guessing whether a particular sample is fake or real. GANs have recently been successfully applied to image generation [4, 22, 9, 37], image editing [13, 31, 40, 32], video prediction[29, 8, 30], and many other tasks [38, 28, 17]. Although GANs already produce visually appealing samples in various applications, they are often diﬃcult to train. If the data distribution and the generated distribution do not substantially overlap (usually at the beginning of training), the generator gradients can point to more or less random directions or even result in the vanishing gradient issue. GANs also suﬀer from mode collapse, i.e., the generator assigns all its probability mass to a small region in the space [3]. In addition, appropriate hyper-parameters (e.g., learning rate and updating steps) and network architectures are critical conﬁgurations in GANs. Unsuitable settings 1 arXiv:1803.00657v1  [cs.LG]  1 Mar 2018  reduce GAN’s performance or even fail to produce any reasonable results. Many recent eﬀorts on GANs have focused on overcoming these training diﬃculties by developing various adversarial training objectives. Typically, assuming the optimal discriminator for the given generator is learned, diﬀerent objective functions of the generator aim to measure the distance between the data distribution and the generated distribution under diﬀerent metrics. The original GAN uses Jensen-Shannon divergence as the metric. A number of metrics have been introduced to improve GAN’s performance, such as least-squares [18], absolute deviation [39], Kullback-Leibler divergence [24, 23], and Wasserstein distance [2]. However, according to both theoretical analyses and experimental results, minimizing each distance has its own pros and cons. For example, although measuring Kullback-Leibler divergence largely eliminates the vanishing gradient issue, it easily results in mode collapse [24, 1]. Likewise, Wasserstein distance greatly improves training stability but can have non-convergent limit cycles near equilibrium [21]. To exploit the advantages and suppress the weaknesses of diﬀerent metrics (i.e., GAN objectives), we devise a framework that utilizes diﬀerent metrics to jointly optimize the generator. In doing so, we improve both the training stability and generative performance. We build an evolutionary generative adversarial network (E-GAN), which treats the adversarial training procedure as an evolutionary problem. Speciﬁcally, a discriminator acts as the environment (i.e., provides adaptive loss functions) and a population of generators evolve in response to the environment. During each adversarial (or evolutionary) iteration, the discriminator is still trained to recognize',\n",
       " '1708.06425': 'Machine learning and statistical inference are the primary building blocks for systems that predict the future from the past. Prediction algorithms have been tailored to ﬁt various applications as varied as analytics [1], health care [2], [3], and judicial decision making [4], [5]. One of the major concerns when utilizing prediction algorithms to automate risk-critical applications is reliability. To guarantee an error rate for an overall prediction system, a meta-algorithm should refuse to make a prediction when the meta-algorithm infers that the base prediction algorithm is likely enough to be in error. The implications of refusing to make a prediction may vary according to the application of interest. For example, in a medical diagnosis system, refusing to make a prediction may result in the collection of more information about the patient or a request to a human expert to make a decision based on a more thorough evaluation. Inspired by the prediction with expert advice framework [6], we propose SafePredict, an online meta-algorithm that accepts or refuses predictions of a base algorithm depending on the previous performance of the base algorithm. SafePredict asymptotically bounds the error to the desired level without any assumption on the data or the base predictor. When the error rate of the base predictor varies over time, SafePredict will adapt to those changes while preserving the error guarantee. • M. A. Kocak, D. Ramirez and E. Erkip are with the Department of Electrical and Computer Engineering, NYU Tandon School of Engineering, Brooklyn, NY, 11201. E-mail: {kocak, dar550, elza}@nyu.edu • D. E. Shasha is with Courant Institute of Mathematical Sciences New York University, New York, NY, 10012. E-mail: shasha@courant.nyu.edu 1.1 Prior Work The idea of allowing meta-algorithms to refuse to make predictions to reduce the error rate was ﬁrst introduced by Chow [7]. Chow mainly focused on the classiﬁcation problem, where data points have an object-label pair independently sampled from a ﬁxed and known probability distribution. Chow showed that the optimum error-refuse trade-off is achieved by a classiﬁer that refuses to predict when the posterior probability of the estimated label given the object is less than a certain threshold. The major challenge in applying Chow’s work is the need to know the data distribution, which is rarely available. The mainstream assumption is that the available data points are independently sampled from a ﬁxed but unknown distribution. Given these data points, the most common approach is to estimate the underlying distribution and to use it in the Chow framework. Estimating probability distributions in high dimensional and complex datasets can be harder even than classiﬁcation itself, see e.g. [8]. An alternative approach uses conﬁdence-based refusals. One can train a classiﬁcation algorithm with an arbitrary conﬁdence score (e.g. distance to the decision boundary) and refuse to make a prediction for points with low conﬁdence scores. Examples of this line of work are [9], [10], [11], [12]. Although',\n",
       " '1801.08186': 'Referring expressions are natural language utterances that indicate particular objects within a scene, e.g., “the woman in the red sweater” or “the man on the right”. For robots or other intelligent agents communicating with people in the world, the ability to accurately comprehend such expressions in real-world scenarios will be a necessary component for natural interactions. Referring expression comprehension is typically formulated as selecting the best region from a set of proposals/objects O = {oi}N i=1 in image I, given an input expression r. Most recent work on referring expressions uses CNN-LSTM based frameworks to model P(r|o) [19, 11, 32, 20, 18] or uses a joint vision-language embedding framework to model P(r, o) [22, 26, 27]. During test1Demo: vision2.cs.unc.edu/refer/comprehension 2Code: https://github.com/lichengunc/MAttNet Expression=“man in red  holding controller on the right” holding controller man in red on the right [\"#,%#,\"&,%&] ⨁ Subject Module Location Module scoresubj scoreloc scoreoverall Language Attention Network Relationship Module ⨂ ⨂ ⨂ Module Weights [0.49,\\'0.31,\\'0.20] scorerel Figure 1: Modular Attention Network (MAttNet). Given an expression, we attentionally parse it into three phrase embeddings, which are input to three visual modules that process the described visual region in different ways and compute individual matching scores. An overall score is then computed as a weighted combination of the module scores. ing, the proposal/object with highest likelihood/probability is selected as the predicted region. However, most of these work uses a simple concatenation of all features (target object feature, location feature and context feature) as input and a single LSTM to encode/decode the whole expression, ignoring the variance among different types of referring expressions. Depending on what is distinctive about a target object, different kinds of information might be mentioned in its referring expression. For example, if the target object is a red ball among 10 black balls then the referring expression may simply say “the red ball”. If that same red ball is placed among 3 other red balls then location-based information may become more important, e.g., “red ball on the right”. Or, if there were 100 red balls in the scene then the ball’s relationship to other objects might be the most distinguishing information, e.g., “red ball next to the cat”. Therefore, it is natural and intuitive to think about the com1 arXiv:1801.08186v3  [cs.CV]  27 Mar 2018  prehension model as a modular network, where different visual processing modules are triggered based on what information is present in the referring expression. Modular networks have been successfully applied to address other tasks such as (visual) question answering [2, 3], visual reasoning [8, 12], relationship modeling [10], and multi-task reinforcement learning [1]. To the best our knowledge, we present the ﬁrst modular network for the general referring expression comprehension task. Moreover, these previous work typically relies',\n",
       " '1712.02250': 'Open-domain human-computer dialog systems are attracting increasing attention in the NLP community. With the development of deep learning, sequence-to-sequence (Seq2Seq) neural networks, or more generally encoder-decoder frameworks, are among the most popular models for utterance generation in dialog systems (Shang et al., 2015; Li et al., 2016; Mou et al., 2016; Serban et al., 2017). Historically, Seq2Seq-like models are ﬁrst designed for machine translation (Sutskever et al., 2014; Bahdanau et al., 2015) and later widely applied to image captioning (Vinyals et al., 2015), text summarization (Rush et al., 2015), etc. When adapted to open-domain dialog systems, however, Seq2Seq models are less satisfactory. A severe problem is that the Seq2Seq model tends to generate short and meaningless replies, e.g., “I don’t know” (Li et al., 2016) and “Me too” (Mou et al., 2016). They are universally relevant to most utterances, called universal replies in Mou et al. (2016), and hence less desired in real-world conversation systems. ∗Equal contribution. In previous studies, researchers have proposed a variety of approaches to address the problem of universal replies, ranging from heuristically modiﬁed training objectives (Li et al., 2016), diversiﬁed decoding algorithms (Vijayakumar et al., 2016), to content-introducing approaches (Mou et al., 2016; Xing et al., 2016). Although universal replies have been alleviated to some extent, there lacks an empirical explanation to the curious question: Why does the same Seq2Seq model tend to generate shorter and less meaningful sentences in a dialog system than in a machine translation system? Considering the difference between dialog and translation data, our intuition is that the dialog system encounters a severe unaligned problem: an utterance may have multiple equally plausible replies, which may have different meanings. On the contrary, the translation datasets typically have a precise semantic matching between the source and target sides. This conjecture is casually expressed in our previous work (Mou et al., 2016), but is not supported by experiments. In this paper, we propose a method to verify the conjecture by mimicking the unaligned scenario in machine translation datasets. We propose to shufﬂe the source and target sides of the translation pairs to artiﬁcially build a conditional distribution of target sentences with multiple plausible data points. By doing so, we manage to shorten the length and lower the “information” of generated sentences in a Seq2Seq machine translation system. This shows evidence that the unaligned problem could be one reason that causes short and meaningless replies in neural dialog systems. To summarize, this paper systematically compares Seq2Seq dialog and translation systems, and provides an explanation to the question: Why do neural dialog systems tend to generate short and meaningless replies? Our study also sheds light on arXiv:1712.02250v1  [cs.CL]  6 Dec 2017  the future development of neural dialog systems as well as the application scenarios where Seq2Seq models are appropriate. In the rest of this paper, we ﬁrst describe our conjecture in Section 2. Then we design the exper',\n",
       " '1812.05313': 'Deep Neural Networks have been found to be quite effective for solving problems in the domain of computer vision [6, 7, 29, 32, 33, 10]. One main reason is that deep models can “digest” large-scale labeled dataset, which was quite difﬁcult using previous approaches. However, building a large image dataset can be very tedious and costly. Moreover, there are cases that image labels need expert experience and special devices. For example, medical images should be labeled by experienced doctors using speciﬁc medical instruments. Even then, some of the produced labels can be unreliable. As people always want better performance for free, the community started to focus on how to make use of unlabeled images which are cheap and plentiful. SemiSupervised Learning (SSL) is born with the ambition to learn from both labeled and unlabeled data simultaneously1. By introducing unlabeled data to the learning process, SSL is able to exploit the regularity hidden in the data. When combined with traditional supervised methods, SSL based approaches have shown their ability to enhance performance without importing noticeable supervision. Another technique for improving on training only with labeled examples, transfer learning, has been widely employed in various settings, especially computer vision related tasks. Unlike SSL, transfer learning is good at tackling learning problems arised in different domains. Thanks to the popularity of vast image datasets, e.g., the ImageNet [6] and Places [43] dataset, the source domain is often large enough to share similar representations with the target domain in both low-level and high-level features. Thus models pre-trained on these datasets often have good initialization, and which enables them to surpass models trained from scratch in various open problems and competitions [18, 27, 38, 17, 9]. If we come to the topic of representation learning, it is not clear whether combining SSL and transfer learning would lead to learning better features. Then it is natural to wonder: would SSL beneﬁt from transfer learning or would 1In this paper, we only focus on the applications of SSL in computer vision. Though SSL has shown its strength in other areas, we will leave the task of describing those to other papers. 1 arXiv:1812.05313v1  [cs.CV]  13 Dec 2018  Model Model Large-Scale Labeled Dataset Unlabeled Data Labeled Data SSL Transfer Learning (a) Model Large-Scale Labeled Dataset Unlabeled Data Labeled Data SSL Transfer Learning ？ (b) Figure 1: We present our core idea in this ﬁgure. From Figure 1a, we can see that the main difference between SSL and transfer learning is: SSL makes use of unlabeled images to facilitate the learning process in target domain, while transfer learning uses vast labeled dataset to learn generalizable representations in source domain. Since both two methods address learning better features for the target task, we want to check if they would have a conﬂict in real-world applications (as shown in Figure 1b). tra',\n",
       " '1511.04103': 'Humans possess the ability to recognize complex objects rapidly and accurately through the ventral visual stream. In a traditional feed-forward view, the ventral visual stream processes the input stimulus from the primary visual cortex (V1), carries the response through V2 and V4, and ﬁnally arrives at the interior temporal (IT) cortex, where a more invariant object representation for categorization is obtained (DiCarlo & Cox, 2007). Among all of the cortical regions, V1 is the best understood, as it can be well-characterized by 2-D Gabor ﬁlters (Carandini et al., 2005), and some subregions in IT are known to be activated by category-speciﬁc stimulus, such as faces (FFA and OFA; Kanwisher et al. (1997); Puce et al. (1996)), words (VWFA; McCandliss et al. (2003)), and scenes (PPA; Epstein et al. (1999)). Nevertheless, it remains unclear what the feature representations between V1 and IT are, or how the increasingly complex representations progress through the ventral stream hierarchy, although some answers have been proposed (Cox, 2014; G¨uc¸l¨u & van Gerven, 2015). In the past few years, the advances in deep learning, especially solving computer vision problems using deep convolutional neural networks (CNNs), has shed light on the representations in the ventral visual pathway. Deep CNNs stack computations in a hierarchical way, repeatedly forming 2-D convolutions over the input, applying pooling operation on local regions of the feature maps, and adding non-linearities to the upstream response. By building and training deep CNNs with millions of parameters using millions of images, these systems become the most powerful solutions to many computer vision tasks, such as image classiﬁcation (Krizhevsky et al., 2012; He et al., 2015a), object detection (Girshick et al., 2014), scene recognition (Zhou et al., 2014), and video categorization (Karpathy et al., 2014). Several studies have even shown that these systems are on a par with human performance, in tasks such as image classiﬁcation (He et al., 2015b), and face recog1 arXiv:1511.04103v3  [cs.CV]  7 Jan 2016  Under review as a conference paper at ICLR 2016 nition (Taigman et al., 2014). These results suggest their potential power to help us understand the ventral visual system. More recently, many studies have been done to optimize and improve the performance of deep CNNs, such as increasing the depth (Simonyan & Zisserman, 2014; Szegedy et al., 2015), optimizing the activation function (He et al., 2015b), pooling layers (Lee et al., 2015), and modifying the loss functions (Lee et al., 2014; Romero et al., 2014). Despite the huge success of these engineering approaches, very little has been done to link optimizing deep CNNs by adding guiding principles from the human brain on how visual object recognition is achieved. In fact, while deep CNNs have been used to model and explain the neural data in IT (Yamins et al., 2014; Cadieu et al., 2014; Agrawal et al., 2014; G¨uc¸l¨u & van Gerven, 2014; 2015), inspiration in the opposite direction has not been as evident. In this study, we examine the',\n",
       " '1003.1266': 'Given an undirected, weighted graph G = (V, E) with n vertices, the commute distance between two vertices u and v is deﬁned as the expected time it takes the natural random walk starting in vertex u to travel to vertex v and back to u. It is equivalent (up to a constant) to the resistance distance, which interprets the graph as an electrical network and deﬁnes the distance between vertices u and v as the eﬀective resistance between these vertices. See below for exact deﬁnitions and Doyle and Snell (1984), Klein and Randic (1993), Xiao and Gutman (2003), Fouss et al. (2006) for background reading. The commute distance is very popular in many diﬀerent ﬁelds of computer science and beyond. As examples consider the tasks of graph embedding (Guattery, 1998, Saerens et al., 2004, Qiu and Hancock, 2006, Wittmann et al., 2009), graph sparsiﬁcation (Spielman and Srivastava, 2008), social network analysis (Liben-Nowell and Kleinberg, 2003), proximity search (Sarkar et al., 2008), collaborative ﬁltering (Fouss et al., 2006), clustering (Yen et al., 2005), semisupervised learning (Zhou and Sch¨olkopf, 2004), dimensionality reduction (Ham et al., 2004), image processing (Qiu and Hancock, 2005), graph labeling (Herbster and Pontil, 2006, Cesa-Bianchi et al., 2009), theoretical computer science (Aleliunas et al., 1979, Chandra et al., 1989, Avin and Ercal, 2007, Cooper and Frieze, 2003, 2005, 2007, 2009), and various applications in chemometrics and bioinformatics (Klein and Randic, 1993, Ivanciuc, 2000, Fowler, 2002, Roy, 2004, Guillot et al., 2009). The commute distance has many nice properties, both from a theoretical and a practical point of view. It is a Euclidean distance function and can be computed in closed form. As opposed to the shortest path distance, it takes into account all paths between u and v, not just the shortest one. As a rule of thumb, the more paths connect u with v, the smaller their commute distance becomes. Hence it supposedly satisﬁes the following, highly desirable property: 1 arXiv:1003.1266v2  [cs.DS]  26 May 2011  Property (⋆): Vertices in the same “cluster” of the graph have a small commute distance, whereas vertices in diﬀerent clusters of the graph have a large commute distance to each other. Consequently, the commute distance is considered a convenient tool to encode the cluster structure of the graph. In this paper we study how the commute distance behaves when the size of the graph increases. Our main result is that if the graph is large enough, then in many graphs the hitting times and commute distances can be approximated by an extremely simple formula with very high accuracy. Namely, denoting by Huv the expected hitting time and by Cuv the commute distance between two vertices u and v, by du the degree of vertex u, and by vol(G) the volume of the graph, we show that if the graph gets large enough, for all vertices u ̸= v, 1 vol(G)Huv ≈1 dv and 1 vol(G)Cuv ≈1 du + 1 dv . On',\n",
       " '1812.10366': 'Fluorescence microscopy is a powerful technique that permeates all of biomedical research [15]. Confocal [23], two-photon [9], and wide-ﬁeld [26] microscopes are the most widely used ﬂuorescence microscopy modalities that are vital to the development of modern biology. Fluorescence microscopy images, however, are inherently noisy because the number of photons captured by a microscopic *Equal contribution. Single-Channel Multi-Channel Raw 8×Average  Ground Truth 2×Average  4×Average  16×Average  ROI ROI Full Frame Full Frame Figure 1. Examples of images with different noise levels and ground truth. The single-channel (gray) images are acquired with two-photon microscopy on ﬁxed mouse brain tissues. The multichannel (color) images are obtained with two-photon microscopy on ﬁxed BPAE cells. The ground truth images are estimated by averaging 50 noisy raw images. detector, such as a photomultiplier tube (PMT) or a charge coupled device (CCD) camera, is extremely weak (∼102 per pixel) compared to that in photography (∼105 per pixel [21]). Consequently, the measured optical signal in ﬂuorescence microscopy is quantized due to the discrete nature of photons, and ﬂuorescence microscopy images are dominated by Poisson noise, instead of Gaussian noise that denominates in photography [22]. One way to obtain clean images is to increase the power of the excitation laser or lamp, but the excitation power is not only limited by the dosage of light a biological sample can receive, but also fundamentally limited by the ﬂuorescence saturation rate; i.e., the ﬂuorescence signal will stop to increase when the excitation power is too high [32]. Alternatively, one can get clean images by increasing the imaging time, e.g., pixel dwell time, exposure time, number of line or frame averages; this, however, may cause photodamage to the sample. Moreover, for dynamic or real-time imaging, increasing the 1 arXiv:1812.10366v2  [cs.CV]  5 Apr 2019  imaging time may be impossible since each image has to be captured within tens of milliseconds. Therefore, developing an algorithm to effectively denoise (reduce the noise in) a ﬂuorescence microscopy image is of great importance to biomedical research. Meanwhile, a high-quality denoising dataset is necessary to benchmark and evaluate the effectiveness of the denoising algorithm. Most of the image denoising algorithms and datasets are created for Gaussian noise dominated images, with a recent focus on denoising with real noisy images, such as smart phones [1] or digital single-lens reﬂex camera (DSLR) images [24]. However, there is a lack of a reliable Poisson noise dominated denoising dataset comprising of real ﬂuorescence microscopy images. The goal of this work is to ﬁll this gap. More specially, we create a Poisson-Gaussian denoising dataset - the Fluorescence Microscopy Denoising (FMD) dataset - consisting of 12,000 real noisy microscopy images which cover the three most widely used imaging modalities, i.e., confocal, two-photon, and wide-ﬁeld, as well as three representative biological samples including cells, zebraﬁsh, and mouse brain tissues. With high-quality commercial microscopy, we',\n",
       " '1805.04625': 'A coding theorem in information theory characterizes the optimal rate such that there exists a code of that rate for the problem studied. Often, the ﬁrst version of such theorems are proved assuming a vanishing probability of error criterion. This criterion facilitates a simple proof relying on chain rules and Fano’s inequality. The strong converse holds for a coding theorem if the optimal rate claimed by the theorem cannot be improved even if a ﬁxed error is allowed. The ﬁrst strong converse was shown for the point-to-point channel coding theorem and source coding theorem by Wolfowitz (see [48]). A A preliminary version of this work was presented at the IEEE International Symposium on Information Theory, Vail, USA, 2018. †Department of Electrical Communication Engineering, Indian Institute of Science, Bangalore 560012, India. Email: htyagi@ece.iisc.ernet.in. ‡Department of Computer and Information Sciences, Tokyo University of Agriculture and Technology, Tokyo 184-8588, Japan. Email: shunwata@cc.tuat.ac.jp. August 22, 2019 DRAFT  2 general method for proving strong converse for coding theorems in multiterminal information theory was introduced in [4]. This method uses a strong converse for the image-size characterization problem, which is in turn shown using the blowing-up lemma; see [12] for a comprehensive treatment. The approach based on blowing-up lemma entails, in essence, changing the code to a list-code with a list-size of vanishing rate. Related recent works that involve a change in the underlying code, too, but use modern tools from functional inequalities and measure concentration literature include1 [15] and2 [30]. In this work, we present a simple method for proving strong converses for multiterminal problems that uses very similar steps as the weak converse proofs. Our method consists of two steps, both building on techniques available in the literature. The ﬁrst step is a change of measure argument3 due to Gu and Effros [19], [20]. The key idea is to evaluate the performance of a given code not under the original product measure, but under another modiﬁed measure which depends on the code and under which the code is error-free. Thus, when the standard rate bounds are applied along with Fano’s inequality, we get a bound involving information quantities for the tilted measure, but without the Fano correction term for the error. In [19], [20], Gu and Effros applied the change of measure argument for proving strong converse for source coding problems where there exists a terminal that observes all the random variables involved; a particular example is the Gray-Wyner (GW) problem [18]. A difﬁculty in extending this approach to other distributed source coding problems is the Markov chain constraints among random variables implied by the information structure of the communication. Speciﬁcally, these Markov chain constraints might be violated when the measure is switched. This technical difﬁculty was circumvented in [45] for the Wyner-Ahlswede-K¨orner (WAK) problem [5], [49], i.e., the problem of lossless source coding with coded side information, by relating',\n",
       " '1610.09028': 'The problem of recovering an unknown signal measured or transmitted by means of an inaccurate sensing model is of crucial importance for modern sensing strategies relying on the solution of inverse problems. In such problems, exact prior information on the sensing model is paramount to accurately reconstruct the original signal. Compressed Sensing (CS) [1] has emerged as a powerful framework to design new sensing strategies employing sub-Gaussian random matrix ensembles given their remarkable properties (see, e.g., [2]). However, model errors inevitably aﬀect its physical implementation and can signiﬁcantly degrade signal recovery, as ﬁrst studied by Herman and Strohmer [3]. In particular, such model errors may arise from physical causes such as unknown convolution kernels [4, 5, 6] aﬀecting the measurements; unknown attenuations or gains on the latter coeﬃcients, e.g., pixel response non-uniformity [7] or ﬁxedpattern noise in imaging systems; complex-valued (i.e., gain and phase) errors in sensor arrays [8, 9, 10]. Assuming such errors remain stationary throughout the sensing process, the use of linear random operators in CS does suggest that repeating the acquisition, i.e., taking several snapshots under new ∗VC and LJ are with Image and Signal Processing Group (ISPGroup), ICTEAM/ELEN, Universit´e catholique de Louvain (UCL). E-mail: laurent.jacques@uclouvain.be, valerio.cambareri@uclouvain.be. The authors are funded by the Belgian F.R.S.-FNRS. Part of this study is funded by the project AlterSense (MIS-FNRS). 1 arXiv:1610.09028v4  [cs.IT]  29 Nov 2017  independent draws of a random sensing operator could suﬃce to diversify the measurements and extract the information required to learn both the unknown signal and the model error. In this paper we adopt this general principle to achieve the blind calibration of sensor gains, that is the joint recovery of an unknown signal and some unknown multiplicative factors (i.e., the gains) not accounted for in the assumed sensing model. Our method is inspired by recent results on fast, provably convergent algorithms for phase retrieval [11, 12, 13] and entails solving a non-convex problem by means of a descent algorithm that is presented below. Most importantly, this paper is concerned with ﬁnding the conditions under which the convergence of our algorithm to the exact solution is guaranteed, i.e., a bound on the number of measurements m and snapshots p collected during the sensing process, along with some mild requirements on the entity of the gains. Hence, our main concern will be to establish a sample complexity, i.e., a lower bound on the total amount of observations collected during the sensing process: we will see that this bound must fulﬁl mp = O \\x00(m + n) log2(m(p + n)) \\x01 with n the dimensionality of the signal and m that of the gains, up to a condition on n = O(log mp). This methodology allows for provably exact blind calibration under some mild hypotheses on the gains for the sensing models we describe in the next section. 1.1 Sensing Models Our paper focuses on blind calibration for systems based on linear random sensing modalities',\n",
       " '1511.06147': 'Real-world computer vision systems are increasingly required to provide robust real-time performance under memory and bandwidth constraints for tasks such as tracking, on-the-ﬂy object detection, and visual search. Robots with visual sensors may be required to perform all of these tasks while interacting with their environment. On another extreme, IP cameras, life logging devices, and other visual sensors may want to hold a summary of the data stream seen over a long time. Hence, new algorithms that enable real-world computer vision applications under a tight space-time budget are a necessity. In this paper, we propose new algorithms with low space-time complexity for learning from streaming visual data, inspired by research in computational geometry. In recent years, computational geometry researchers have proposed techniques to obtain small representative sets of points from larger sets with constant or logarithmic space-time complexity [6], [14], [16]. We propose to adapt these techniques to retain a summary of visual data and train object appearance models in constant time and space from this summary. Speciﬁcally, we perform summarization of a video stream based on “coresets”, which are deﬁned as a small set of points that approximately maintain the properties of the original set with respect to the distance between the set and other structures in its ambient space with theoretical guarantees [18]. We demonstrate that the coreset formulation is useful for learning object appearance models for detection and tracking. Coresets have been primarily used as a technique to convert “big data” into manageable sizes [27]. In contrast, we employ coresets for reducing small data to “tiny data”, and perform real-time classiﬁer training. We use the object appearance model learned from the coreset representation, for visual tracking by detection. • Abhimanyu Dubey is an undergraduate student at the Indian Institute of Technology, New Delhi, India. • Rahul Sukthankar is a research scientist at Google. • Nikhil Naik, Dan Raviv, and Ramesh Raskar are with the Media Laboratory at Massachusetts Institute of Technology. Tracking systems typically retain just an appearance model for the object [20], [35] and optionally, data from some prior frames [15], [31]. In contrast, we compute a summary of all the previous frames in constant time (on average) and update our appearance model continuously with this summary. The summarization process improves the appearance model with time. As a result, our method is beneﬁcial for tracking objects in very long video sequences that need to deal with variation in lighting, background, and object appearance, along with the object leaving and re-entering the video. We demonstrate the potential of this technique with a simple tracker that combines detections from a linear SVM trained from the coreset with a Kalman ﬁlter. We call this no-frills tracker the “Coreset Adaptive Tracker (CAT).” CAT obtains competitive performance on three standard datasets, the CVPR2013 Tracking Benchmark [33], the Princeton Tracking Benchmark [30], and the TLD Dataset [21]. Our method is found to be superior to popular methods for tracking longer',\n",
       " '1812.09818': 'Energy-efﬁcient inference of neural networks is becoming increasingly important in both servers and mobile devices (e.g., smartphones, AR/VR devices, and drones). Recently, there have been active studies on ultra-low-precision inference using 1 to 4 bits (Rastegari et al., 2016; Hubara et al., 2016; Zhu et al., 2016; Zhou et al., 2016; 2017; Zhuang et al., 2018; Choi et al., 2018b; Liu et al., 2018; Choi et al., 2018a) and their implementations on CPU and GPU (Tulloch & Jia, 2017), and dedicated hardware (Park et al., 2018; Sharma et al., 2017). However, as will be explained in section 5.2, the existing quantization methods suffer from a problem called accumulated quantization error where large quantization errors get accumulated across layers, making it difﬁcult to enable ultra-low precision in deep neural networks. In order to address this problem, we propose a novel concept called precision highway where an end-to-end path of high-precision information reduces the accumulated quantization error thereby enabling ultra-low-precision computation. Our proposed work is similar to recent studies (Liu et al., 2018; Choi et al., 2018b) which propose utilizing pre-activation residual networks, where skip connections are kept in full precision while the residual path performs low-precision computation. Compared with these works, our proposed method offers a generalized concept of high-precision information ﬂow, namely, precision highway, which can be applied to not only the pre-activation convolutional networks but also both the post-activation convolutional and recurrent neural networks. Our contributions are as follows. • We propose a novel idea of network-level approach to quantization, called precision highway and quantitatively analyze its beneﬁts in terms of the propagation of quantization errors and the difﬁculty of convergence in training based on the shape of loss surface. 1 arXiv:1812.09818v1  [cs.CV]  24 Dec 2018  • We provide the detailed analysis of the energy and memory overhead of precision highway based on the state-of-the-art hardware accelerator model. According to our experiments, the overhead is negligible while offering signiﬁcant improvements in accuracy. • We apply precision highway to both convolution and recurrent networks. We report a 3-bit quantization of ResNet-50 without accuracy loss and a 2-bit quantization with a very small accuracy loss. We also provide the sub 4-bit quantization results of long short-term memory (LSTM) for language modeling. 2 RELATED WORK Migacz (2017) presented an int8 quantization method that selects an activation truncation threshold to minimize the Kullback-Leibler divergence between the distributions of the original and quantized data. Jacob et al. (2017) proposed a quantization scheme that enables integer-arithmetic only matrix multiplications (practically, 8-bit quantization for neural networks). These methods are implemented on existing CPUs or GPUs (Jacob et al., 2015; ACL). Hubara et al. (2016) presented a binarization method and demonstrated the performance beneﬁt on a GPU. Rastegari et al. (2016) proposed a binary network called XNOR-Net in which a weight-binarized AlexNet gives the same accuracy as',\n",
       " '1712.00371': 'FAILED',\n",
       " '1811.04151': 'Today’s IC fabrication technologies require satisfying many complex design rules to ensure manufacturability. Creating a layout that is clean of design rule violations has turned into a cumbersome task, requiring many iterations in the design ﬂow, and consequently impacting the time-to-market. Within the design ﬂow, Design Rule Check (DRC) is typically applied after detailed routing. However, the process of detailed routing can be rather tedious and expensive, which typically takes several hours, if not days, to ﬁnish. Therefore, it is highly desirable if an inexpensive DRC predictor is developed so that DRC hotspot locations on the layout may be predicted accurately at the earlier stages in the design ﬂow. In this way, a designer may leverage this early feedback without going through detailed routing and DRC phases each time. Recent research has focused on prediction of DRC hotspots, and on placement and/or global routing techniques to minimize the violations after detailed routing [1]–[3]. They have identiﬁed various features at the placement and/or global routing stages which can contribute to DRC violations. The process involves extracting these features during placement and/or global routing followed by machine learning for modeling. A signiﬁcant challenge during modeling is effective use of a large number of extracted features. Direct incorporation of all the features during modeling can cause overﬁtting issues, besides signiﬁcant increase in the time to do the modeling itself. To handle these challenges, Chan et al. proposed different schemes to deﬁne smaller subsets of features and conducted a study to ﬁnd the most useful subset [3]. These subsets however were deﬁned in an empirical / non-systematic manner. Recently, Tabrizi et al. used a Neural Network (NN) model for DRC hotspot prediction [1], where the network model was composed of only a single hidden layer. In this paper, we apply NN ensembles [4]–[6] on top of the baseline model in [1] to improve DRC hotspot prediction. To further improve the performance in NN ensembles, we propose a feature selection scheme based on principal component analysis (PCA) [7]. Related works on feature selection in NN ensembles include [8]–[11], which select features by using different training samples and/or are based on an objective function of the features that evaluates their ﬁtness. Our method differs from these works in that we randomly select the features in PCA-transformed linear subspace, which does not have any objective function to evaluate (which saves the training time), and does not require different training samples for each learner (which makes it easier to be embedded on the original NN). To summarize, our contributions are listed below. • Our workﬂow receives as input a wide range of features inspired by a comprehensive study of DRC prediction. The feature size is more than any single prior work. • We offer systematic techniques to generate useful feature subsets for use in our model by applying PCA, subset selection, and a smart random selection scheme. • These are incorporated within a proposed NN ensemble architecture',\n",
       " '1408.5601': 'Face anti-spooﬁng, as a security measure for face recognition system, are drawing increasing attentions in both academic and industrial ﬁelds. However, due to the diversity of spooﬁng types, including print-attacks, replay-attacks, maskattacks, etc., it is still a difﬁcult work to distinguish various fake faces. In Fig. 1, some randomly sampled genuine and fake face images are shown to evaluate the anti-spooﬁng ability of our eyes. Among all the face images, three are genuine and ﬁve are fake 1. Admittedly, no obvious visual cues are available for us to pick the genuine face images from the gallery. Recently, researchers are devoted to come up with more generalized and discriminative features for face antispooﬁng, such as LBP [23][35], HOG [20][35], LBP-TOP [11], DoG [30] [27], etc. In general, these features are all called hand-crafted features because they are designed manually. In this paper, however, we exploit deep convolutional neural network (CNN) for face anti-spooﬁng. To the best of our knowledge, this is the ﬁrst attempt. Compared with above hand-crafted features, the features learned from CNN are able to catch more discriminative cues in a data-driven manner. More importantly, according to the experimental results, it has the potential to learn more general features for various spooﬁng types. II. RELATED WORKS Due to the diversity of spooﬁng attacks, existing face antispooﬁng approaches can be mainly categorized into four Jianwei Yang, Zhen Lei, and Stan Z. Li are with Center for Biometrics and Security Research & National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, China. Email: {jwyang, zlei, szli}@cbsr.ia.ac.cn 1The second and third images in the top row, and the third image in the bottom row are genuine Fig. 1. Genuine and fake face images from REPLAY-ATTACK dataset. groups: texture based, motion based, 3D-shape based and multi-spectral reﬂectance based. Besides, some other works combined two or more of these methods to improve the antispooﬁng performance. 1) Texture-based Anti-Spooﬁng: In [22], Li et al. proposed a method based on the analysis of Fourier spectra. In this method, it is assumed that the photographs contain fewer high frequency components compared with genuine faces. In [30], Tan et al. used a variational retinex-based method and the difference-of-Gaussian (DoG) ﬁlers to extract latent reﬂectance features on face images. Inspired by Tan’s work, Peixoto et al. [27] combined the DoG ﬁlters and standard Sparse Logistic Regression Model for anti-spooﬁng under extreme illuminations. After that, M¨a¨att¨a et al. [23] proposed to use LBP features for anti-spooﬁng, which outperformed previous methods on the NUAA Photograph Imposter Database [31]. Furthermore, its efﬁciency on the REPLAYATTACK database was presented in [7]. In [11], Pereira et al. used a spatio-temporal texture feature called Local Binary Patterns from Three Orthogonal Planes (LBP-TOP). According to the experimental results on the REPLAY-ATTACK database',\n",
       " '0812.4487': 'Sequence design for good correlation ﬁnds many important applications in various transmission systems in communication networks, and radar systems. A. Low Correlation In code division multiple access (CDMA) applications of spread spectral communication, multiple users share a common channel. Each user is assigned a diﬀerent spreading sequence (or spread code) for transmission. At an intended receiver, despreading (recovering the original data) is accomplished by 0∗The work was conducted when Zilong Wang was a visiting Ph.D student at the Department of ECE in University of Waterloo from September 2008 to August 2009. 1  the correlation of the received spread signal with a synchronized replica of the spreading sequence used to spread the information where the spreading sequences used by other users are treated as interference, which is referred to as multiple access interference. This type of interference, which is diﬀerent from interference that arises in radio-frequency (RF) communication channels, can be reduced by proper design of a spreading signal set. The performance of a signal (or sequence) set used in a CDMA system is measured by the parameters L, the length or period of a sequence in the set, r, the number of time-shift distinct sequences, and ρ, the maximum magnitude of the out-of-phase autocorrelation of any sequence and cross correlation of any pair of the sequences in the set. This is referred to as an (L, r, ρ) signal set. The trade-oﬀof these three parameters is bounded by the Welch bound, established in 1974 by Welch [43]. The research for constructing good signal sets has ﬂourished in the literature. The reader is referred to [6, 1, 39, 32, 5, 9] for polyphase sequences with large alphabet sizes, [26, 20] for Z4 sequences, [12, 30] for interleaved sequences, and [36, 24, 13] in general, for example. B. Minimized Fourier Spectrum The orthogonal frequency division multiplexing (OFDM) utilizes the concept of parsing the input data into N symbol streams, and each of which in turn is used to modulate parallel, synchronous subcarriers. With an OFDM system having N subchannels, the symbol rate on each subcarrier is reduced by a factor of N relative to the symbol rate on a single carrier system that employs the entire bandwidth and transmits data at the same rate as OFDM. An OFDM signal can be implemented by computing an inverse Fourier transform and Fourier transform at the transmitter side and receiver side, respectively. A major problem with the multicarrier modulation in general and OFDM system in particular is the high peak-to-average power ratio (PAPR) that is inherent in the transmitted signal. A bound on PAPR through the magnitude of the discrete Fourier transform (DFT) spectrum of employed signals is shown in [28, 31]. (See [40] for details of Fourier transform.) One way to achieve low PAPR is to employ Golay complementary sequences, as ﬁrst shown by Davis and Jedwab in [8]. A tremendous amount of work has been done along this line since then. C. Low Valued',\n",
       " '1805.06956': 'Image understanding for object recognition and scene understanding have been very active topics in the last few years [8], [32], [33]. On the other hand, identifying object states has not captured much attention in computer vision and robotics research. In this study, we deﬁned objects states as characters into which the object could be transformed as a consequence of a human or robot activity. A state can be observed and described as a form, texture, or color. For example, a tomato can have many states, such as sliced, diced, and whole. A whole tomato can be sliced and then diced in a sequence of cooking activity such as slicing and dicing. Assuming a robot chef wants to make a salad using a tomato, if it is provided with a whole tomato, it would need to wash it, slice it, and then dice it. If it is provided with a sliced tomato to begin with, it would need only to dice it. The intelligent robot chef would need to plan its motion differently based on the state of the provided tomato. Therefore, it would be necessary to not only recognize the object as a tomato, but also to identify the state the tomato is in. This is important for both ﬁnegrained human activity understanding and robot task planning and manipulation control. Robots also need to perform different manipulations or grasps to achieve different states of a planned task [17], [16], [14], [15]. Different states of an object or transiting an object from one state to another requires different types of grasping; for example, a whole carrot is grasped differently than a sliced A. B. Jelodar, D. Paulius, and Y. Sun are with the Department of Computer Science and Engineering, University of South Florida, Florida FL, 33620 email: (ajelodar@mail.usf.edu). or grated carrot [25], [13], or holding a whole carrot for slicing, holding a half carrot for grating, or holding a juliennecut carrot for dicing each need unique types of grasping. Receiving on-line feedback from the environment would give the robot the sufﬁcient knowledge required to decide on the unique type of grasp it would choose for its manipulation of the environment. In this paper, we present our exploration on identifying object states in cooking-related images. First, we selected 17 of the most commonly-used cooking objects from more than 250 online cooking videos of two of the well known cooking datasets [21], [22] and identiﬁed their states in the videos, resulting in 11 different states for all 17 objects. Subsequently, we created our own state identiﬁcation dataset of 9309 images of these objects and their state labels. Using the dataset, we built and trained a Resnet-based deep neural network model starting from pre-trained weights. We evaluated our approach with the images in the ImageNet [6] and then assigned the images their state labels using a combination of our state identiﬁcation model and manual labeling. Our work has three main contributions: • We',\n",
       " '1808.08558': 'Currently, deep learning is the most promising approach adopted by various machine learning applications such as computer vision, natural language processing, and audio processing. Along with the rapid development of the deep learning techniques, its network structure is becoming considerably complicated. In addition to the model structure, the model size is also becoming larger, which prevents the implementation of deep neural network models in edge-computing ∗Copyright c⃝2020 International Joint Conferences on Artiﬁcial Intelligence (IJCAI). All rights reserved. devices for applications such as smartphone services, autonomous vehicle driving, and drone control. To overcome this problem, model compression techniques such as pruning, factorization [Denil et al., 2013; Denton et al., 2014], and quantization [Han et al., 2015] have been extensively studied in the literature. Among these techniques, pruning is a typical approach that discards redundant nodes, e.g., by explicit regularization such as ℓ1 and ℓ2 penalization during training [Lebedev and Lempitsky, 2016; Wen et al., 2016; He et al., 2017]. It has been implemented as ThiNet [Luo et al., 2017], Net-Trim [Aghasi et al., 2017], NISP [Yu et al., 2018], and so on [Denil et al., 2013]. A similar effect can be realized by implicit randomized regularization such as DropConnect [Wan et al., 2013], which randomly removes connections during the training phase. However, only few of these techniques (e.g., Net-Trim [Aghasi et al., 2017]) are supported by statistical learning theory. In particular, it unclear which type of quantity controls the compression ability. On the theoretical side, compressionbased generalization analysis is a promising approach for measuring the redundancy of a network [Arora et al., 2018; Zhou et al., 2019]. However, despite their theoretical novelty, the connection of these generalization error analyses to practically useful compression methods is not obvious. In this paper, we develop a new compression based generalization error bound and propose a new simple pruning method that is compatible with the generalization error analysis. Our method aims to minimize the information loss induced by compression; in particular, it minimizes the redundancy among nodes instead of merely looking at the amount of information of each individual node. It can be executed by simply observing the covariance matrix in the internal layers and is easy to implement. The proposed method is supported by a comprehensive theoretical analysis. Notably, the approximation error induced by compression is characterized by the notion of the statistical degrees of freedom [Mallows, 1973; Caponnetto and de Vito, 2007]. It represents the intrinsic dimensionality of a model and is determined by the eigenvalues of the covariance matrix between each node in each layer. Usually, we observe that the eigenvalue rapidly decreases (Fig. 1a) for several reasons such as explicit regularization arXiv:1808.08558v2  [stat.ML]  13 Jul 2020  (Dropout [Wager et al., 2013], weight decay [Krogh and Hertz, 1992]), and implicit regularization [Hardt et al., 2016; Gunasekar et al., 2018], which means that the amount of important information processed in each layer is not large. In',\n",
       " '1809.05884': 'Multi-label image classification (MLIC) [7, 29] is one of the pivotal and long-lasting problems in computer vision and multimedia. This task starts from the observation that real-world images always contain diverse semantic contents that need multiple visual concepts to classify. Except for the challenges shared with single-label image Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. MM ’18, October 22–26, 2018, Seoul, Republic of Korea © 2018 Association for Computing Machinery. ACM ISBN 978-x-xxxx-xxxx-x/YY/MM...$15.00 https://doi.org/10.1145/nnnnnnn.nnnnnnn Figure 1: The illustration of multi-label image classification (MLIC) and weakly-supervised detection (WSD). We show top-3 predictions, in which correct predictions are shown in blue and incorrect predictions in red. The MLIC model might not predict well due to poor localization for semantic instances. Although the detection results of WSD may not preserve object boundaries well, they tend to locate the semantic regions which are informative for classifying the target object, such that the predictions can still be improved. classification (e.g., inter-class similarity and intra-class variation), MLIC is more difficult because predicting the presence of multiple classes usually needs a more thorough understanding of the input image (e.g., associating classes with semantic regions and capturing the semantic dependencies of classes). Contemporary methods may simply finetune the multi-label classification networks pre-trained on the single-label classification datasets (e.g., ImageNet [24]). However, the classifiers trained for global image representations may not generalize well to the images in which objects from multiple classes are distributed in different locations, scales and occlusions. To mitigate this problem, the task of MLIC can be decomposed into multiple independent binary classification tasks, in which one classifier only focuses on one object label. In this way, though very efficient, the semantic dependencies among multiple classes, which is especially important for MLIC [32], are ignored (e.g., “cat” is more likely to be misclassified into the category of “dog” than falsely associated to “car”). Therefore, some prior works [4, 32, 38] tried to fix this drawback by explicitly capturing the class dependencies with a RNN or LSTM structure appended after CNN-based models. However, they usually suffer from the difficulty in back-propagating stable gradients [21]. Recently, some object localization techniques [34, 43, 44] are introduced into the MLIC task by simplifying the multi-label classification problem into multi-object detection',\n",
       " '1711.08267': 'Graph representation learning, also known as network embedding, aims to represent each vertex in a graph (network) as a low-dimensional vector, which could facilitate tasks of network analysis and prediction over vertices and edges. Learned embeddings are capable to beneﬁt a wide range of real-world applications such as link prediction (Gao, Denoyer, and Gallinari 2011), node classiﬁcation (Tang, Aggarwal, and Liu 2016), recommendation (Yu et al. 2014), visualization (Maaten and Hinton 2008), knowledge graph representation (Lin et al. 2015), clustering (Tian et al. 2014), text embedding (Tang, Qu, and Mei 2015), and social network analysis (Liu et al. 2016). Recently, researchers have ∗M. Guo is the corresponding author. Copyright c⃝2018, Association for the Advancement of Artiﬁcial Intelligence (www.aaai.org). All rights reserved. examined applying representation learning methods to various types of graphs, such as weighted graphs (Grover and Leskovec 2016), directed graphs (Zhou et al. 2017), signed graphs (Wang et al. 2017b), heterogeneous graphs (Wang et al. 2018), and attributed graphs (Huang, Li, and Hu 2017). In addition, several prior works also try to preserve speciﬁc properties during the learning process, such as global structures (Wang, Cui, and Zhu 2016), community structures (Wang et al. 2017c), group information (Chen, Zhang, and Huang 2016), and asymmetric transitivity (Ou et al. 2016). Arguably, most existing methods of graph representation learning can be classiﬁed into two categories. The ﬁrst is generative graph representation learning model (Perozzi, Al-Rfou, and Skiena 2014; Grover and Leskovec 2016; Zhou et al. 2017; Dong, Chawla, and Swami 2017; Li et al. 2017a). Similar to classic generative models such as Gaussian Mixture Model (Lindsay 1995) or Latent Dirichlet Allocation (Blei, Ng, and Jordan 2003), generative graph representation learning models assume that, for each vertex vc, there exists an underlying true connectivity distribution ptrue(v|vc), which implies vc’s connectivity preference (or relevance distribution) over all other vertices in the graph. The edges in the graph can thus be viewed as observed samples generated by these conditional distributions, and these generative models learn vertex embeddings by maximizing the likelihood of edges in the graph. For example, DeepWalk (Perozzi, Al-Rfou, and Skiena 2014) uses random walk to sample “context” vertices for each vertex, and tries to maximize the log-likelihood of observing context vertices for the given vertex. Node2vec (Grover and Leskovec 2016) further extends the idea by proposing a biased random walk procedure, which provides more ﬂexibility when generating the context for a given vertex. The second kind of graph representation learning method is the discriminative model (Wang et al. 2018; Cao, Lu, and Xu 2016; Wang, Cui, and Zhu 2016; Li et al. 2017b). Different from generative models, discriminative graph representation learning models do not treat edges as generated from an underlying conditional distribution, but aim to learn a classiﬁer for predicting the existence of edges directly. Typically, discriminative models consider two vertices vi and vj jointly',\n",
       " '1811.01926': 'There are many real-world situations in which we have to decide between multiple options, yet are only able to learn the best course of action by testing each option sequentially. In such situations, the underlying concept remains the same for each and every renewed decision: Do you stick to what you know and receive an expected result (\"exploit\") or choose an option you do not know all that much about and potentially learn something new (\"explore\")? As we all encounter such dilemma’s on a daily basis (Wilson, Geana, White, Ludvig, and Cohen 2014), it is easy to come up with examples - for instance: • When going out to dinner, do you explore new restaurants, or choose a favorite? • As a website editor, do you place popular or new articles at the top of your frontpage? • As a doctor, do you prescribe tried and tested medication, or do you also provide promising experimental drugs? • When visiting a casino, do you stay with the slot machine that just paid out, or do you try some of the other slot machines? Although people seem to navigate such explore-exploit problems with relative ease, this type of decision problem has proven surprisingly diﬃcult to solve analytically1 and has been studied extensively 1As Dr. Peter Whittle famously stated \"[the problem] was formulated during the [second world] war, and eﬀorts to solve it so sapped the energies and minds of Allied analysts that the suggestion was made that the problem be dropped over Germany, as the ultimate instrument of intellectual sabotage.\" (Whittle 1979) arXiv:1811.01926v4  [cs.LG]  1 Jan 2020  2 contextual since the 1930s (Robbins 1952; Bubeck, Cesa-Bianchi et al. 2012) under the umbrella of the \"multiarmed bandit\" (MAB) problem. The origin of the name is related to the casino example above: a one armed bandit is an old name for a slot machine in a casino, as they used to have one arm and tended to steal your money. A multi-armed bandit can then be understood as a set of one-armed bandit slot machines in a casino—in that respect, \"many one-armed bandits problem\" might have been a better ﬁt (Gelman 2018). Just like in the casino example, the crux of a multi-armed bandit problem is that you only receive a reward for the arm you pull—you remain in the dark about what rewards the other arms might have oﬀered. Consequently, you need some strategy or \"policy\" that helps you balance the exploration and exploitation of arms to optimize your rewards over repeated pulls. One option would, for instance, be to pull every available arm once and from then on exploit the arm that oﬀered you the highest reward. This reward might, however, be nothing more than a lucky ﬂuke. On the other hand, if you decide to keep exploring other arms, you may lose out on the winnings you might have received from the arm that had been doing so well. This active',\n",
       " '1608.03638': 'As a viable and cost-effective way to increase network capacity, heterogeneous networks (HetNets) that embed a large number of low-power nodes, called small cells (SCs), into an existing macro network has emerged with the aim to ofﬂoad trafﬁc from the macro cell (MC) to small cells [2–6] in hot spots or to solve coverage holes in MC. Conventionally deploying more macro base stations (BSs) in already dense networks may be prohibitively expensive and result in severe inter-cell interference [5]. However, due to the large number of potentially interfering nodes in the network, mitigating both the inter-cell and intra-cell interference becomes a crucial issue facing HetNet. Interference control has been intensively studied and applied in HetNet [7–9], including the coordinated multi-point (CoMP) transmission [7]. Although the CoMP transmission was shown to provide high spectral efﬁciency [10] with the backhaul among the coordinated tiers enabling both user data and channel state information (CSI) Y. Dai and X. Dong are with the Department of Electrical and Computer Engineering, University of Victoria, Victoria, V8P 5C2, Canada (Email: yongyu@uvic.ca, xdong@ece.uvic.ca). H. Lin is with the Department of Electrical and Information Systems, Osaka Prefecture University, Sakai, Osaka, 599-8531, Japan (Email: lin@eis.osakafu-u.ac.jp). Part of this work has been presented at the IEEE Global Communications Conference (GLOBECOM), San Diego, CA, USA, Dec. 2015 [1]. exchange, the high signaling overhead results in practical implementation limitations. Recently, multiple-input multiple-output (MIMO) transmission with large-scale antenna arrays at the BS has attracted substantial interest from both academia and industry. Using simple linear processing, such large-scale antenna arrays were proved to be able to substantially reduce the effects of the uncorrelated noise, small-scale fading and intracell interference [11, 12]. Then, the energy and spectral efﬁciency of very large multiuser MIMO uplink systems were investigated in [13], which showed that the power radiated by each terminal could be made inversely proportional to either the number of BS antennas or at least its square-root, considering both perfect and imperfect CSI. In [6], it was stated that the potential beneﬁts have elevated large-scale MIMO to a central position as a promising technology for the next generation of wireless systems. In a HetNet setting, [14, 15] proposed to use large scale antenna arrays at the BS and limited antennas at the SCs1 due to their smaller form factor. As variable structures of antenna arrays, such as a cylindrical array, requires less space [16], large-scale antenna arrays set at SCs becomes realizable. Recently, NEC Corporation announced that it has developed a prototype of A4-sized massive-element Active Antenna System for 5G small cell base stations, and it proposed the use of a massive-element antenna in small cells for capacity enhancement [17]. Up to date, few papers in the literature have studied the effect of employing massive MIMO at SCs. In [18], HetNet with large-scale antenna',\n",
       " '1512.02949': 'Automatic description of videos using sentences of natural language is a challenging task in computer vision. Recently, two large collections of video clips extracted from movies, together with natural language descriptions of their visual content, have been published for scientiﬁc purposes. A uniﬁed version of these data sets, namely M-VAD [19] and MPII-MD [16], has been provided for the purpose of the Large Scale Movie Description (LSMDC) Challenge 2015. In this paper, we describe the system we used while participating in LSMDC 20151. Our work builds on the static image captioning system based on recurrent neural networks and proposed in [22] and implemented in the NeuralTalk2 system [8]. We extend this framework for generating textual descriptions of small video clips utilizing both static image features and video1https://sites.google.com/site/describingmovies/ 2https://github.com/karpathy/neuraltalk Figure 1. Block diagram of our model speciﬁc features. We also study the use of visual content classiﬁers as a source of additional information for caption generation. We also make the source code for our work available online3 . 2. Model 2.1. Overview We propose to use a neural-network-based framework to generate textual captions for the given input video. Our pipeline consists of three distinct stages as seen in Figure 1. The ﬁrst stage is feature extraction, wherein we extract both whole video and keyframe image based features from the input video. As the whole video based feature we use dense trajectories [23, 24]. Keyframe image features are extracted by feeding these images through Convolutional Neural Networks (CNN) trained on the ImageNet database [3]. We use three different CNN architectures giving us a rich variety of features for the keyframe images. In many studies, including our own [9, 7], CNN-based features and especially late fusion combinations of them have been found to provide superior performance in many computer vision and image analysis tasks. In our current experiments, the CNN-based features are 3https://github.com/aalto-cbir/neuraltalkTheano 1 arXiv:1512.02949v1  [cs.CV]  9 Dec 2015  either directly input to LSTM, the Long short-term memory [6] recurrent neural network (RNN), or they are fed to a set of visual content classiﬁers which in turn produce 80dimensional class membership vectors that can then be used as LSTM inputs. For training the 80 classiﬁers we have used the training set images of the COCO 2014 collection [14]. The third stage consists of an LSTM network, taking one feature set and possibly the visual content classiﬁcation results as input and generating a sequence of words, i.e. a video caption, with the highest probability of being associated with the input features and thus the processed video clip. Next we will look at each of these processing stages in detail. 2.2. Video feature extraction As the video-level features we use the dense trajectories [23], [24] which have proven to have good performance in many video analysis tasks. We have used the',\n",
       " '1101.0064': 'Extracting secure uniform random number is an important task for cryptographic applications with the presence of quantum leaked information as well as that of classical leaked information. For the quantum setting, several extractors are proposed, e.g., 2-universal hashing [35], approximate 2universal hashing [40], sample-and-hash [28], one-bit extractors [27], and Trevisan’s extractor [1]. In this paper, we focus on universal2 hash functions [5] which has a variety of cryptographic applications, for example, for the information theoretically secure signatures, the hash functions for for privacy ampliﬁcation [39], [3], [15] and for the wiretap channel[20], [21]. The class of universal2 hash function families is the largest class of families of hash functions among known classes of families of hash functions guaranteeing the strong security. However, there might exist a larger class of The material in this paper was presented in part at QCRYPT 2011: First Annual Conference on Quantum Cryptography, Zurich, Switzerland, September 2011. T. Tsurumaru is with Mitsubishi Electric Corporation, Information Technology R&D Center, 5-1-1 Ofuna, Kamakura-shi, Kanagawa, 247-8501, Japan (e-mail: Tsurumaru.Toyohiro@da.MitsubishiElectric.co.jp). M. Hayashi is with Graduate School of Information Sciences, Tohoku University, Aobaku, Sendai, 980-8579, Japan, and Centre for Quantum Technologies, National University of Singapore, 3 Science Drive 2, Singapore 117542. (e-mail: hayashi@math.is.tohoku.ac.jp) hash functions guaranteeing the strong security. If such a class exists, we might realize a strongly secure privacy ampliﬁcation with a smaller complexity. It is known that the class of universal2 hash functions is included in the class of ε-almost universal2 hash functions[5], [43]. However, as is shown in Section VIII-B, there exists an example of ε-almost universal2 hash functions that cannot yield the strong security. Hence, we have to consider another type of generalization of the class of universal2 hash functions. In this paper, in order to seek such a larger class, we restrict our hash functions to linear functions on a ﬁnite-dimensional space over the ﬁnite ﬁeld F2 because a larger part of hash functions with a smaller complexity are linear. Under the restriction, we can ﬁnd a one-to-one correspondence between a hash function and a linear code by considering the kernel of the hash function. Focusing on the dual code of the code corresponding to the given hash function, we propose the class of ε-almost dual universal2 hash functions as a class of families of linear hash functions satisfying the following conditions: 1) The class of families of hash functions contains the class of universal2 hash functions. 2) Any family of hash functions in this class yields the strong security when the generating key rate is sufﬁciently small. Hence, the relation among class of families of hash functions is summarized as Fig. 1. strongly secure hash functions 㱑-almost universal2 hash functions universal2 hash functions 㱑-almost dual universal2 hash functions permuted code',\n",
       " '1807.01279': 'Many important real-world global optimization problems are so-called ‘black-box’ functions - that is to say that it is impossible either mathematically, or practically, to access the object of the optimization analytically - instead we are limited to querying the function at some point x and getting a (potentially noisy) answer in return. Some typical examples of black-box situations are the optimization of machine-learning model hyper-parameters [1], [2], or in experimental design of new products or processes. [3] One popular framework for optimization of black-box functions is Bayesian optimization. [1], [4], [5], [6], [7] In this framework, a Bayesian model (typically a Gaussian process[8], [1], although other models have been successfully used[9]) based on known responses of the black-box function is used as an ersatz, providing closed form access to the marginal means and variances. The optimization is then performed upon this ’response surface’ in place of the true surface. The model’s prior distribution is reﬁned sequentially as new data is gathered by conditioning it upon the acquired data, with the resulting posterior distribution then being sampled to determine the next point(s) to acquire. In this way, all else being equal, the accuracy of the response surface should start to increasingly resemble the true surface. This is in fact dependent upon some of the choices made in the construction of the Bayesian model; and it is worth noting that a poor initial construction of the prior, through for instance an inappropriate kernel choice, will lead to a poor optimization protocol. Since Bayesian optimization does not have analytical access properties traditionally used in optimization, such as the gradients, it relies upon an acquisition function being deﬁned for determining which points to select. This acquisition function takes the model means and variances derived from the posterior distribution and translates them into a measure of the predicted utility of acquiring a point. At each iteration of Bayesian optimization, the acquisition function is maximized, with those data points corresponding to maximal acquisition being selected for sampling. Bayesian optimization has particular utility when the function to be optimized is expensive, and thus the number of iterations the optimizer can perform is low. It also has utility as a ’ﬁxed-resource optimizer’ since - unlike traditional optimization methods - it is possible to set a strict bound on resources consumed without destroying convergence criteria. Indeed, in abstract, the Bayesian optimization protocol of observe, hypothesize, validate is much closer in spirit to the scientiﬁc method than other optimization procedures. A. Acquisition Functions A good choice of acquisition function is critical for the success of Bayesian optimization, although it is often not clear a priori which strategy is best suited for the task. Typical acquisition strategies fall into one of two types - improvement based strategies, and information based strategies. An improvement based strategy is analogous to the traditional optimization task in that it seeks to locate the global minimum/maximum as quickly as possible. An',\n",
       " '1611.05128': 'In recent years, deep convolutional neural networks (CNNs) have become the state-of-the-art solution for many computer vision applications and are ripe for real-world deployment [1]. However, CNN processing incurs high energy consumption due to its high computational complexity [2]. As a result, battery-powered devices still cannot afford to run state-of-the-art CNNs due to their limited energy budget. For example, smartphones nowadays cannot even run object classiﬁcation with AlexNet [3] in real-time for more than an hour. Hence, energy consumption has become the primary issue of bridging CNNs into practical computer vision applications. In addition to accuracy, the design of modern CNNs is starting to incorporate new metrics to make it more favorable in real-world environments. For example, the trend is to simultaneously reduce the overall CNN model size and/or simplify the computation while going deeper. This is achieved either by pruning the weights of existing CNNs, i.e., making the ﬁlters sparse by setting some of the weights to zero [4–14], or by designing new CNNs with (1) highly bitwidth-reduced weights and operations (e.g., XNOR-Net and BWN [15]) or (2) compact layers with fewer weights (e.g., Network-in-Network [16], GoogLeNet [17], SqueezeNet [18], and ResNet [19]). However, neither the number of weights nor the number of operations in a CNN directly reﬂect its actual energy consumption. A CNN with a smaller model size or fewer operations can still have higher overall energy consumption. This is because the sources of energy consumption in a CNN consist of not only computation but also memory accesses. In fact, fetching data from the DRAM for an operation consumes orders of magnitude higher energy than the computation itself [20], and the energy consumption of a CNN is dominated by memory accesses for both ﬁlter weights and feature maps. The total number of memory accesses is a function of the CNN shape conﬁguration [21] (i.e., ﬁlter size, feature map resolution, number of channels, and number of ﬁlters); different shape conﬁgurations can lead to different amounts of memory accesses, and thus energy consumption, even under the same number of weights or operations. Therefore, there is still no evidence showing that the aforementioned approaches can directly optimize the energy consumption of a CNN. In addition, there is currently no way for researchers to estimate the energy consumption of a CNN at design time. arXiv:1611.05128v4  [cs.CV]  18 Apr 2017  The key to closing the gap between CNN design and energy efﬁciency optimization is to directly use energy, instead of the number of weights or operations, as a metric to guide the design. In order to obtain realistic estimate of energy consumption at design time of the CNN, we use the framework proposed in [21] that models the two sources of energy consumption in a CNN (computation and memory accesses), and use energy',\n",
       " '1206.6682': 'I N multi-cell wireless networks, besides the intra-cell interference caused by spatial multiplexing within each cell, another impediment arises from inter-cell interference due to the ever-shrinking cell sizes. Alleviating the effects of intercell interference requires the base stations (BSs) to adjust their transmission schemes collectively. In fact, inter-cell interference mitigation has been identiﬁed as a key issue for future wireless networks. In particular, for downlink transmissions, if the inter-cell interference is mitigated via coordinated processing across multiple BSs, signiﬁcant performance gains can be possibly obtained, especially for the users at the cell edges. Therefore, recently, there has been a rapidly growing interest in shifting the design paradigm from the conventional single-cell Manuscript received October 30, 2010; accepted August 29, 2011. This work was supported in part by the National Science Foundation of China (NSFC) under grants 60702081, 60873020, 61002016, by the Joint Research Fund for Overseas Chinese, Hong Kong and Macao Young Scholars under grant 61028001, by the Key Project of Chinese Ministry of Education under grant 212066, and by the Zhejiang Provincial Science Foundation under grants Z1080702, Y1090980, Y12F020196. W. Xu is with School of Information Science & Technology, Zhejiang SciTech University, Hangzhou, 310018, P. R. China. (email: wqxu@zstu.edu.cn). X. Wang is with the Department of Electrical Engineering, Columbia University, New York, NY, 10027, USA. (e-mail: wangx@ee.columbia.edu). to the cooperative multi-cell networks [1]. Various methods, such as [2], [3], [4], have been proposed to provide networkwide, macroscopic cooperation among different BSs. In these studies, it is assumed that the BSs in a multi-cell network are connected via backhaul links to a central processing unit, which has the global knowledge of the transmitted data from all the users in the network and the downlink channels from each BS to all the users. Such a fully coordinated case is sometimes referred to as networked MIMO. However, for large and dense networks, networked MIMO obviously incurs a substantial infrastructural and computational overhead, which increases the system costs and hinders the practical implementations. This motivates the problem of constrained cooperation, taking into account many practical factors, e.g., limited backhaul capacity [5], local cooperation [6], processing complexity and delay [7], imperfect channel state information (CSI) [8] [9], and feedback errors [10]. On the other hand, future cellular networks are envisioned to be distributed systems with autonomous and self-coordinated cells. Each BS can make independent and rational decisions in a decentralized manner, with limited information exchange with the neighboring BSs. This motivates the study of distributed multi-cell interference mitigation, which requires only the local and neighboring CSI at each BS, without the need of a central controller, and is therefore much easier to implement. Based on a generalization of uplink-downlink duality to the multi-cell setting, an iterative algorithm is proposed in [11] to optimally solve the multicell downlink beamforming problem for minimizing either the total weighted transmit',\n",
       " '1706.06802': 'The JAva TExt Categorization System (JaTeCS) has been developed in the past years by our research group as the main software tool to perform research on a broad range of automatic text categorization [1] and other text mining problems. Research on text mining has gained new momentum in the last decade as the explosion of Social Networks (SNs1) largely increased the amount of textual data generated on the Web and also accelerated the speed at which it is generated and consumed. This scenario asked for novel methods to eﬀectively and eﬃciently process such huge and novel streams of information, to sift down the relevant information with respect to a speciﬁc information need. Moreover, the textual 1Here we broadly mean any platform that acts as a large-scale gatherer of usergenerated content, thus ranging from Twitter to TripAdvisor, from Facebook to Amazon’s user feedback. arXiv:1706.06802v1  [cs.CL]  21 Jun 2017  content generated in SNs is rich of information related to personal opinions and subjective evaluations, which are of great practical and commercial interest. This aspect led to the growth of new disciplines such as Sentiment Analysis and Opinion Mining (SAOM, [2]). SAOM methods transform into a structured form the unstructured opinion-related information expressed by means of natural language in text, enabling the successive application of data mining methods on the structured information. This transformation can be performed by processing text at various levels: processing each document as a single and atomic entity (e.g., classiﬁcation), performing aggregated analysis on entire collections (e.g., quantiﬁcation), extracting multiple piece of information for a document (e.g., information extraction). JaTeCS mainly consists of a Java library that implements many of the tools needed by a researcher to perform experiments on text analytics problems. It covers all the steps and components that are usually part of a complete text mining pipeline: acquiring input data, processing text by means of NLP/statistical tools, converting it into a vectorial representation, applying optimizations in the vector space (e.g., projections into smaller space through matrix decomposition methods), application of machine learning algorithms (and the optimization of their parameters), and the application of the learned models to new data, evaluating their accuracy. The development of JaTeCS started with a speciﬁc focus on topic-oriented text categorization, but soon expanded toward many other text-categorization related problem, including sentiment analysis, transfer learning, distributional language modeling and quantiﬁcation. JaTeCS is published at https://github.com/jatecs/jatecs, and it is released under the GPL v3.0 license1. In the following we describe the design concepts that drove the development of JaTeCS (Section 2), the core components (Section 3, and how they can be combined to solve diﬀerent text mining problems (Section 4). We conclude comparing JaTeCS with similar software currently available (Section 5). 2 Design concepts In an input dataset suitable for text analysis tasks, it is possible to describe its data by using 3 logical concepts and the relations among',\n",
       " '1709.05480': 'Multi-label learning addresses supervised learning problems where each instance can be tagged with more than one labels at the same time [20]. Apart from tasks that fall inherently into this category, such as image or text classiﬁcation, prior work [24, 1] has shown that recommendation and ranking problems can also be formulated as multi-label learning problems. A great body of prior work has dealt with developing methods for multi-label tasks [29, 22, 17, 16, 23, 9, 10], however the majority of these algorithms struggle to scale to problems having more than a few thousand labels. Since the ever increasing ﬂow and volumes of data in modern-day applications directly aﬀect the area of multi-label learning, algorithms that can eﬀectively and eﬃciently scale up to large-scale problems are required. Extreme multi-label classiﬁcation is an emerging ﬁeld that attempts to address the above challenge, by proposing algorithms that can tackle problems with extremely large label sets (> 104 labels). We modify an already existing algorithm, Labeled ∗Aristotle University of Thessaloniki †Aristotle University of Thessaloniki Latent Dirichlet Allocation (LLDA) to successfully deal with such tasks. LLDA was introduced by [16] as an extension of standard, unsupervised Latent Dirichlet Allocation (LDA) [4], to deal with multi-label learning tasks. LLDA proceeds exactly as its unsupervised predecessor with the only diﬀerence that during training LLDA constraints the topics for each instance to be the instance’s labels. [18] have proposed two extensions of LLDA, the ﬁrst incorporating label frequencies in the corpus (Prior–LDA) and the second taking into account label dependencies (Dep–LDA). In Section 2.2, we describe the above algorithms in detail. Apart from delivering results competitive with stateof-the-art multi-label algorithms, LLDA’s training is by design particularly ﬁt for large-scale and extreme learning problems. Speciﬁcally, unlike most other algorithms, during training LLDA’s time complexity is not dependent of the label set size L, but on the label cardinality LM, i.e. the average number of labels assigned per instance. Given that LM is typically in the order of 101, it is valid to assume that LLDA’s training complexity will only be aﬀected by the training set size and the number of features per instance. On the other hand, during testing, LLDA is equivalent to LDA and the algorithm is linearly dependent of L, which makes the algorithm unﬁt for large-scale multi-label classiﬁcation. In order to make LLDA appropriate for tasks with very large L, we propose an extension to LLDA, Subset LLDA. We conduct extensive experiments on four small scale data sets and four large scale data sets, with L ranging from 101 to 670,000 comparing our approach to Prior–LDA and Dep–LDA as well as two of the top performing extreme classiﬁcation algorithms, Fast XML and PfastreXML. The results show a consistent advantage of our method compared to the other LLDA algorithms and competitive results with the extreme classiﬁcation methods',\n",
       " '1611.08991': 'Object detection and semantic segmentation are both important tasks in computer vision. The goal of object detection is to predict the bounding box as well as the semantic class of each object, whereas semantic segmentation focuses on predicting the semantic class of the individual pixels in an image. In general, object detection does not provide accurate pixel-level object segmentation and semantic segmentation ignores to distinguish different objects in the same class. Instance segmentation has recently become an important task, which is more challenging than both object detection and semantic segmentation tasks, since its goal is to label as well as provide pixel-level segmentation to each object in the image. Figure 1 shows an illustration of intance segmentation on images from two benchmark datasets, namely PASCAL VOC [10], and the gland segmentation benchmark [34]. In the standard semantic labeling task [31], each Figure 1. Illustration of the instance segmentation problem we are tackling here. The ﬁrst, the second, and the third column show input images, the semantic labeling maps, and the corresponding instance labeling maps, respectively. The ﬁrst and the second row display typical examples from PASCAL VOC 2012 [10], and MICCAI 2015 Gland segmentation dataset [34], respectively. pixel in an image is assigned with an object class label e.g. sky, road, car etc.; in the instance segmentation problem, each pixel is additionally associated with an instance ID indicating which object it belongs to. Therefore, there are two sets of labeling maps for each image: (1) a semantic class labeling map (this is a classiﬁcation problem), and (2) an instance ID labeling map (this is a segmentation problem). For the remainder of this paper, we refer to semantic labeling as the task of predicting per-pixel object class label and refer to instance labeling as the job of assigning an instance ID to each region. On one hand, object labeling and instance labeling are two different tasks, as explained above. On the other hand, the two tasks are highly correlated. If every object instance forms a connected component (not being cut into two disjoint parts due to occlusion which rarely happens in practice) and no two objects belonging to the same class are connected to each other, then a semantic labeling map can be readily converted into an instance labeling map by obtaining the connected component of each instance. This happens frequently but it is not always true, as we can see in Figure 1. Instance segmentation methods can be roughly divided into two categories: (1) those detection-based methods that perform bounding box detection [25, 26, 8, 7, 15, 21, 19]; and (2) those segmentation-based methods that use dense per-pixel features [32, 28, 40]. Detection-based methods 1 arXiv:1611.08991v2  [cs.CV]  29 Nov 2016  typically perform proposal and object detection, followed by instance masking. These methods require objects being tightly bounded by rectangular boxes, which is a strong condition',\n",
       " '1812.04920': 'Deep network-based semantic segmentation algorithms have signiﬁcantly enhanced the performance, but they demand heavy computational costs. It is basically because semantic segmentation is a pixel-wise classiﬁcation problem. Most of the semantic segmentation models usually have an encoder-decoder structure where the encoder reduces the size of the feature map to obtain a large enough receptive ﬁeld, while the decoder recovers original resolution and spatial information from the small-sized feature map. Recent segmentation studies have actively used dilated convolutions to obtain a wide receptive ﬁeld without increasing the number of parameters and to reduce the burden of the decoder while enhancing the speed and accuracy. However, even though many models utilized dilated convolutions, some models are still heavy for an embedded system. There have been other kinds of researches which have made efforts to develop a lightweight model [12, 10, 11, 17]. Among the lightweight models, ESPNet [14] shows the best segmentation performance by adopting a well-designed series of spatial pyramid dilated convolutions. For further slimming the segmentation network towards embedded systems, a practical choice would be to apply the depth-wise separable convolution (ds-Conv) [3, 6], which is a popular method to reduce the number of parameters and the computational complexity, to the dilated convolution. However, we observed that this combination commonly leads to huge performance degradation as shown in Figure 1, and there is no in-depth analysis of this problem so far. Figure 1 (c), (d) and (e) use different basic convolution blocks in an ESPNet-based structure. Figure 1 (c) and (e) are the results of ESPNet-based networks with the same encoder-decoder structure, but (d) increases the number of layers in the encoder for similar complexity with (e). Figure 1 (d) is obtained using simple depth-wise separable dilated convolution (ds-Dilate) blocks, which has less accuracy than ours. The reason of this performance degradation can be attributed to 1) inexact approximation of the standard convolution with the ds-Conv and 2) information loss on the neighboring pixels in a feature map due to the use of arXiv:1812.04920v3  [cs.CV]  28 Jul 2019  (a) Input image (b) Ground Truth (c) Result of ESPNet (Param : 0.364M) (d) Result of ds-Dilate (Param : 0.187M) (e) Result of our C3 block (Param : 0.198M) Figure 1. Illustrations of performance degradation from depthwise separable dilated convolution (ds-Dilate). (c): Original ESPNet [14], (d): ESPNet with increased layers using ds-Dilate, (e): Our model using C3 blocks with the same encoder-decoder structure as (c). Param denotes the number of parameters for each model. The numbers are the number of parameters and mIOU calculated by the test set on Cityscapes benchmark. the dilated convolution. The combination of the two methods further leads to a too-sparse operation and loss of information. Our proposed method resolves this problem and Figure 1(e) shows',\n",
       " '1101.4450': 'Submodular functions play an important role in discrete optimization. Many important problems, such as facility location [1], coverage [2], inﬂuence maximization [3], and experimental design [4] can be reduced to constrained maximization of a submodular set function. Submodularity, informally, is an intuitive notion of diminishing returns, which states that adding an element to a small set helps more than adding that same element to a larger (super-)set. While maximizing submodular functions in general is NP-hard, a celebrated result of Nemhauser et al. [1] shows that a simple greedy algorithm is guaranteed to ﬁnd a near-optimal solution to the problem of maximizing a submodular function subject to cardinality constraints; the value of the greedy solution obtains at least a constant fraction of (1 −1/e) of the optimal value. Nemhauser and Wolsey [5] furthermore show that, in general, obtaining better approximation guarantees requires evaluating the objective function on an exponential number of sets. Beyond cardinality constraints, the greedy algorithm also obtains guarantees for maximizing a monotone submodular function subject to p matroid constraints [6], and, more generally, p-independence systems [7]. In both cases, the greedy algorithm achieves at least a constant fraction of 1/(p + 1) of the optimal value. Submodular optimization provides a uniﬁed framework for many important non–adaptive optimization problems. In many practical optimization problems, however, one needs to adaptively make a sequence of decisions, taking into account observations about the outcomes of past decisions. Often these outcomes are uncertain, and one may only know a probability distribution over them. Finding optimal policies for decision making in such partially observable stochastic optimization problems is notoriously intractable (see, e.g., [8]). The classical notion of submodular set functions does not allow one to handle such adaptive optimization problems. In recent work [9, 10], we introduced the concept of adaptive submodularity, a natural generalization of submodular set functions to adaptive policies, and prove that if a partially observable stochastic optimization problem satisﬁes this property, a simple adaptive greedy algorithm is guaranteed to obtain near-optimal solutions in the case of cardinality constraints. The concept has several useful applications, including active learning, machine diagnosis, adaptive viral marketing, and sensor placement [10, 11]. In this article, we prove that the adaptive greedy algorithm is guaranteed to obtain a 1/(p + 1)-approximation for the more general problem of maximizing an adaptive submodular function over p-independence systems (and therefore subject to p matroid constraints). Our results generalize those obtained by Asadpour et al. [12] for optimizing a particular instance of adaptive submodular functions to a single matroid constraint to arbitrary adaptive monotone submodular functions and to arbitrary p-independence systems. We illustrate the usefulness of this result on adaptive match–making problems such as online dating. We show that the constraint system in this application is a 2-independence system, and thus the adaptive greedy algorithm provides a 1/3-approximation. 2. Background We ﬁrst review background on submodular optimization, as',\n",
       " '1506.05187': 'Acquiring the depth information of 3D scenes is essential for many applications in computer vision and graphics such as 3D modeling, 3DTV and augmented reality. Recently Time-of-Flight (ToF) cameras have shown impressive results and become more and more popular, e.g., Kinect v2.0 sensor. They can obtain dense depth measurements at a high frame rate. However, the resolution is generally very low and the depth map is often corrupted by strong noise. Tremendous efforts have been put for improving the resolution of depth maps acquired by ToF cameras. The solutions usually go to three categories. In the ﬁrst category, single low resolution depth map is upsampled through different data-driven approaches. It may be achieved by Figure 1. 8× upsampling result patches of Art from the Middleburry dataset [16]. (a) The noisy low resolution depth map patch and the corresponding color image. (b) The ground truth. (c) The upsampling result by the state-of-art method in [2]. The upsampling result by our method (d) without adaptive bandwidth selection and (e) with adaptive bandwidth selection. (f) The corresponding bandwidth map obtained by our method. exploiting similarity across relevant depth patches in the same depth map [6]. The resolution can also be synthetically increased by exploiting an existing generic database containing large numbers of high resolution depth patches [8][11] which were inspired by the work in [3][4]. The second approach upsamples the low resolution depth map by integrating multiple low resolution depth maps of the same scene, which may be acquired at the same time but from slightly different views [15][17] or at the different sensing time [5]. These existing methods assume that the scene is static. The third category achieves upsampling through the supports of the high resolution guided color image [1][2][7][12][13][21][22][23]. In this category, it is assumed that the depth discontinuity on the depth map and the color edge on the color image co-occur on the corresponding regions. 1 arXiv:1506.05187v1  [cs.CV]  17 Jun 2015  Image guided upsampling methods have several advantages against the other two categories and are popular in recent years. They can yield much better upsampling quality than single depth map upsampling [6]. Besides, they can achieve larger upsampling factor and do not need any prior database compared with the existing methods [11][8]. Also when compared with the second category, image guided upsampling is not subject to static scene and does not need complicated camera calibration process. Despite the obvious advantages against the ﬁrst two categories of the solutions, the main issues of image guided upsampling are: 1) texture copy artifacts on the smooth depth region when the corresponding color image is highly textured; 2) blurring depth discontinuity when the corresponding color image is more homogeneous; 3) performance drops for the case of highly noisy depth maps. In this paper',\n",
       " '1803.05768': 'In this paper we study several forms of logical inference for predicting plausible missing facts in relational data. While a variety of approaches have already been studied for this task, ranging from (relational versions of) probabilistic graphical models [19, 5] to neural-network architectures [24, 20] and graph-based methods [15, 16], logic-based inference has several advantages over these other forms of inference. For example, logic-based inference is explainable: there is a proof for any derived statement, which can, in principle, be shown to a human user. It is also more transparent than most other methods, in the sense that a knowledge base as a whole can be understood and modiﬁed by domain experts. On the other hand, classic logical inference can be very brittle when some of the rules which are used are imperfect, or some of the initial facts may be incorrect. Statistical relational learning approaches, such as Markov logic networks [19] or probabilistic logic programming [5], offer a solution to this latter problem, but they require learning a joint probability distribution over the set of possible worlds. This distribution is typically estimated from one or several large examples using maximum likelihood, which essentially corresponds to ﬁnding a maximum-entropy distribution given by a set of sufﬁcient statistics. However, there are usually no guarantees on the learned distributions beyond guarantees for the sufﬁcient statistics (see, e.g., [12]), which means that we do not have much control over the quality of the predictions. Moreover, these models are not easy to modify, and are not always easy to explain because the way in which probabilities are computed can simply be too complex. In this paper we focus on forms of inference that stay as close to classical logic as possible while not breaking completely when the given theory happens to be “mildly” inconsistent with the data. This problem of reasoning under inconsistency has a long tradition in the ﬁeld of artiﬁcial intelligence, with common solutions including the use of paraconsistent logics [3, 18], belief revision [8] (and related inconsistency repair mechanisms [11]), and argumentation-basedinference [7, 2]. In contrast to these approaches, however, our speciﬁc aim is to study forms of inference that can allow us to bound the (expected) number of mistakes that are made. To this end, we introduce two inference relations called k-entailment and voting entailment, both of which are close to classical logic, and in particular do not require rules to be weighted. We deﬁne them such that errors produced by imperfect rules would not necessarily propagate too much in the given relational data. As our main contribution, we are able to show that in a relational learning scenario from [12], in which a (large) training example and a test example are sampled from a hidden relational structure, there are non-trivial PACtype bounds on the number of errors that a theory learned on the training example',\n",
       " '1808.06289': 'Reading comprehension is a challenging task which requires the deep understanding of natural language. Cloze test is a particular form of reading comprehension: given a passage with blanks, an examinee is required to ﬁll in the missing word (or phrase) that best ﬁts the context surrounding the blank. Recently, cloze-style reading comprehension has drawn growing interests from NLP research communities, since such a task meets the practical requirements and is relatively easy to design. The research of cloze-style reading comprehension is ﬁrst advanced by two large-scale corpora: the CNN/Daily Mail (Hermann et al., 2015) and CBT (Hill et al., 2015) datasets, which are automatically constructed by randomly or periodically deleting a word from original passage. Though the automatically generated datasets usually consist of a large quantity of labeled data and make it possible to train large neural network models, they are in nature far away from real-world language understanding problems and have serious ambiguity issues (Chen et al., 2016). As a result, the state-of-the-art system of cloze test almost reaches the performance ceiling and loses its improvement direction due to the limitation of the corpus (Chen et al., 2016). In such situation, Xie et al. (2017) argues that it is a more reliable means to assess language proﬁciency with carefully designed questions by professional teachers, and releases a novel corpus CLOTH. The CLOTH dataset brings the new challenge of exploring a comprehensive evaluation of language proﬁciency and speciﬁcally divides the questions into several types including matching, reasoning and grammar etc. Table 1 shows several example questions from CLOTH. From experiments by Xie et al. (2017), we can see that the Stanford attention reader (Chen et al., 2016) of having the near state-of-the-art performance (with an accuracy of about 0.74) on CNN/Daily Mail only gets an accuracy of 0.487 on CLOTH and there exists a huge performance gap between human and popular machine learning models. The main reason is that attention models are mainly good at processing matching questions (e.g., the ﬁrst example in Table 1 has matching between “police” and “accident”, “man died”), which occupy a less percentage in CLOTH than in CNN/Daily Mail. Xie This work is licensed under a Creative Commons Attribution 4.0 International License. License details: http:// creativecommons.org/licenses/by/4.0/ arXiv:1808.06289v1  [cs.CL]  20 Aug 2018  question type ...... As a Senior student, I have to many exams. ...... A: ﬁnish B: win C: take D: join collocation I am calling from the station ....... “ There was an accident, and a man died .” ...... A: post B: bus C: police D: railway matching a student reported that I made an error ...... He was and after thanking him for his honesty ...... he said angrily . A: wise B: right C: rigid D: angry reasoning ...... They are used to messages by computers and smart phones. ...... A: sending B: send C: sent D: sends grammar Table 1: Example questions and their corresponding types',\n",
       " '1802.01666': 'Recent years have witnessed great progress on the performance of computer vision algorithms on tasks such as object classiﬁcation and detection, with state-ofthe-art models achieving super-human performance on many of these tasks [1,2]. In addition, for more challenging tasks, such as viewpoint estimation and ﬁnegrained classiﬁcation, the community has found that a hybrid intelligence approach— incorporating both human and machine intelligence—outperforms “computeronly” approaches [3,4]. While hybrid approaches often outperform fully-automated approaches, they do not scale as well; it is easy to run a model 10x more times, but it can be expensive to ask a human 10x more questions. A clear solution to this problem is to ask the human better questions. arXiv:1802.01666v3  [cs.CV]  25 Oct 2018  2 M. El Banani and J. J. Corso If you had to determine the pose of the bicycle above,  which keypoint would you ask for ?  Seat or Left Handle  Front View Back View Fig. 1. Some keypoints are more informative than others. Accurate pose estimation of the bicycle in the center above is diﬃcult due to the blurred out image features. Given access to an oracle, it is clear that one should ask for the location of the left handle rather than the seat to resolve the ambiguity. Consider the task of determining the pose of the bicycle shown at the center of Figure 1. Due to its symmetry and truncation, pose estimation algorithms ﬁnd such examples challenging [5]. Szeto and Corso [4] have shown that providing such a system with the location and identity of a keypoint on the object allows it to better tackle those examples. However, not all keypoints are equally informative. While the location of the seat would be the same in both possible poses, the location of the left handlebar allows one to break the symmetry which resolves the ambiguity. Hence, some queries will allow the hybrid-model to perform better than others. In this paper, we ask the question: how can we determine the best question for a hybrid computer vision model to ask a human? One approach is to ﬁnd the question that would maximize information gain with respect to the model’s belief [3,6] or an arbitrary utility function [7]. While those approaches can handle a wide range of inputs, they require knowledge of the conditional probability functions between the input and/or intermediate variables, which makes it diﬃcult to handle high-dimensional inputs such as images [3]. They also require the model to have some explicit representation of its belief about the current image. However, deep learning deals with high-dimensional inputs in an end-to-end manner, such that the structure to the problem is learned implicitly. Hence, it is not clear how extendable the previous approaches are to modern deep learning computer vision algorithms. Ideally, we would want to assume nothing about the hybrid-intelligence model, a',\n",
       " '1712.08467': 'P ULSE propagation in optical ﬁbers is severely impaired by nonlinear effects that should be either compensated or utilized for the design of the communication system. The nonlinear Fourier transform (NFT) [1] provides a method to transform a signal from the time domain into a nonlinear frequency domain (spectrum), where the channel acts as a multiplicative ﬁlter on the signal. The nonlinear spectrum consists of a continuous and a discrete part. Both parts can be used to transmit information, either separately or jointly, and several schemes have been presented in theory and practice [1]–[6]. However, very little is known so far about the probability density function (PDF) of the received signal in the nonlinear spectral domain when it is contaminated by channel noise. In [7], a simpliﬁed communication system modulating only the imaginary part of the eigenvalues in the discrete nonlinear spectrum was presented. For this scheme, an approximation for the conditional PDF of the channel can be obtained in closed form. In general, for a given channel, the capacityachieving distribution is not known and is often different This work was funded by the European Union’s Horizon 2020 research and innovation programme under the Marie Skłodowska-Curie grant agreement No. 676448. A. Buchberger is with the Department of Electrical Engineering, Chalmers University of Technology, Gothenburg, SE-412 96, Sweden and Nokia Bell Labs, Lorenzstr. 10, 70435 Stuttgart, Germany, e-mail: andreas.buchberger@chalmers.se. A. Graell i Amat is with the Department of Electrical Engineering, Chalmers University of Technology, Gothenburg, SE-412 96, Sweden, e-mail: alexandre.graell@chalmers.se. V. Aref and L. Schmalen are with Nokia Bell Labs, Lorenzstr. 10, 70435 Stuttgart, Germany, e-mail: {ﬁrstname.lastname}@nokia-bell-labs.com. from the conventional distribution with equispaced signal points and uniform signaling. Hence, some form of shaping is required [8]. Two popular methods of shaping are probabilistic shaping and geometric shaping. In geometric shaping, the capacity-achieving distribution is mimicked by optimizing the position of the constellation points for equiprobable signaling [9] whereas probabilistic shaping uses uniformly spaced constellation points and approximates the capacity-achieving distribution by assigning different probabilities to different constellation points [8]. The main drawback of probabilistic shaping is its practical implementation. An abundance of probabilistic shaping schemes have been presented, most suffering from high decoding complexity, low ﬂexibility in adapting the spectral efﬁciency, or error propagation. For a literature review on probabilistic shaping, we refer the reader to [10, Section II]. Recently, a new scheme called probabilistic amplitude shaping (PAS) has been proposed in [10]. Compared to other shaping schemes, PAS yields high ﬂexibility and close-tocapacity performance over a wide range of spectral efﬁciencies for the additive white Gaussian noise (AWGN) channel while still allowing bit-metric decoding. Although originally introduced for the AWGN channel, PAS can be applied to other channels with a symmetric capacity-achieving input distribution assuming a sufﬁciently high spectral efﬁciency. In this paper, we consider a similar',\n",
       " '1512.06492': 'In the last decade, we witness increasing interests for remote monitoring technologies in health care. Remote monitoring captures the activity and other anthropometric data from the subjects. It can perform online analysis of these data, provide health-care feedback to the subjects monitored, and also represent the data to the doctor for further analysis. One typical application is in the physical therapy, especially for the elderly subjects, the doctors need to monitor the subjects physical performance at home during the training sessions and provide further treatments based on the subjects performance. ∗This research was supported by the National Science Foundation (NSF) under Grant No. 1111965. Human performance capture systems have been widely studied and applied in many applications. However, traditional motion capture systems require particular system setup and markers attached to the subjects monitored which make it impractical for recording motion data at home. Other motion sensors, like the inertia sensors are sensitive to the noise make them also not suitable for motion capture in human daily activities. The emerging accessible and affordable sensing technologies, e.g. the depth sensor, such as Microsoft Kinect, make it possible to capture the humans motion data at home [1]. Recently, we built an interactive exercise coaching system based on Microsoft Kinect [2] intended to encourage elderly adults to perform physical therapy at home. Since this type of sensors were not designed for medical purpose, the acquired motion data are usually noisy with low ﬁdelity for the motion analysis. For example, the joint position data from Microsoft Kinect usually exhibits signiﬁcant jitters caused by low depth accuracy, occlusions, ambiguity, and loss of tracking. The body segment lengths are also vary during the motion. In order to perform online analysis of subjects performance and feedback to the subjects, we further studied the motion data accuracy from Microsoft Kinect. We also studied the kinematic parameter extraction from the motion data captured by Kinect. This paper is organized as following: Section 2 introduces the interactive system we have built for the remote physical therapy; Section 3 introduces the work we have done on motion data accuracy evaluation of Microsoft Kinect; Section 4 describes our work on the human kinematic parameters extraction from Kinect motion data; Conclusions are summarized in Section 5. 1 arXiv:1512.06492v1  [cs.CV]  21 Dec 2015  Figure 1. Architecture of our interactive health coaching system. 2. Interactive Exercise Coaching System This system is built for automated exercise coaching of elderly users that would motivate them and track their physical performance when they perform physical therapy at home. The system contain four main modules: data acquisition, data processing, performance evaluation, and feedback. The pipeline of this system is shown in Fig. 1. In the data acquisition module, we use the Microsoft Kinect camera to record the subjects motion. Microsoft Kinect capture both the texture and depth information of the scene and provide real-time human skeletal joint data [zhengyou zhang]. Based on the skeletal data estimated by',\n",
       " '1811.11881': '3 2 Related work 5 2.1 Simultaneous and independent work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7 3 Preliminaries 8 4 A new algorithm for Stochastic BwK 10 4.1 Linear relaxation and Lagrange functions . . . . . . . . . . . . . . . . . . . . . . . . . . . 10 4.2 Our algorithm: repeated Lagrangian game . . . . . . . . . . . . . . . . . . . . . . . . . . . 11 4.3 Performance guarantees . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12 5 A simple algorithm for Adversarial BwK 14 5.1 Analysis: proof of Theorem 5.1 and Lemma 5.7 . . . . . . . . . . . . . . . . . . . . . . . . 15 6 High-probability algorithm for Adversarial BwK 19 6.1 Full proof of Theorem 6.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21 6.2 Proof of Lemma 6.9: last full phase offers sufﬁcient rewards . . . . . . . . . . . . . . . . . 25 6.3 Proof of Lemma 6.5 (IPS estimators are good) . . . . . . . . . . . . . . . . . . . . . . . . . 25 7 Extensions 28 7.1 BwK with full feedback . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29 7.2 Combinatorial Semi-Bandits with Knapsacks . . . . . . . . . . . . . . . . . . . . . . . . . 29 7.3 Contextual Bandits with Knapsacks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30 7.4 Bandit Convex Optimization with Knapsacks . . . . . . . . . . . . . . . . . . . . . . . . . 32 8 Lower bounds 33 8.1 Warm-up: example from the Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . 34 8.2 The main lower bound: proof of Theorem 8.1(b) . . . . . . . . . . . . . . . . . . . . . . . . 35 8.3 Best dynamic policy: proof of Theorem 8.1(c) and Theorem 8.3 . . . . . . . . . . . . . . . 38 8.4 Best ﬁxed arm: proof of Theorem 8.1(d) . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40 9 Open Questions and Follow-Up Work 41 References 42 A Standard tools 48 A.1 Concentration Inequalities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48 A.2 Lagrangians: proof of Lemma 4.2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48 A.3 The stopped LP for Adversarial BwK: proof of Eq. (5.4) . . . . . . . . . . . . . . . . . . . 49 A.4 Regret minimization in games: proof of Lemma 3.1 . . . . . . . . . . . . . . . . . . . . . . 49 B Table of notation 51 2  1 Introduction Multi-armed bandits is a simple abstraction for the tradeoff between exploration and exploitation, i.e., between making potentially suboptimal decisions for the sake of acquiring new information and using this information for making better decisions. Studied over many decades, multi-armed bandits is a very active research area spanning computer science, operations research, and economics (Cesa-Bianchi and Lugosi, 2006; Bergemann and V¨alim¨aki, 2006; Gittins et al., 2011; Bubeck and Cesa-Bianchi, 2012; Slivkins, 2019; Lattimore and Szepesv´ari, 2020). In this paper, we focus on bandit problems which feature supply or budget constraints, as is the case in many realistic applications. For example, a seller who experiments with prices may have a limited inventory, and a website optimizing ad placement may be constrained by the advertisers’ budgets. This general problem is called Bandits with Knapsacks (BwK) since, in this model, a bandit algorithm needs effectively to solve a knapsack problem (ﬁnd an optimal packing of items into a limited-size knapsack) or generalization thereof. The BwK model was introduced in Badanidiyuru et al. (2018) as a common generalization of numerous motivating examples, ranging from dynamic pricing to ad allocation to repeated auctions to network routing/scheduling. Various special cases with budget/supply constraints were studied previously, (e.g., Besbes and Zeevi, 2009; Babaioff et al., 2015; Badanidiyuru et al., 2012; Singla and Krause, 2013; Combes et al., 2015). In BwK, the algorithm is end',\n",
       " '1812.08972': 'T HERE are various kinds of networks in the real world like computer networks, biological networks and social networks, where elements or users are represented by nodes and the connections between the elements or users are represented by links. Representing network data is a crucial step before using off-the-shelf machine learning models to conduct advanced analytic tasks such as classiﬁcation [1], [2], clustering [3], [4], link prediction [5], [6] and personalized recommendation [7], [8]. Conventional methods present a network by its adjacency matrix, which is hard to be adopted for many machine learning applications due to its sparsity [2]. Recently, network embedding, which aims to learn the low-dimensional representation for each vertex in a network, alleviates the sparsity problem and attracts increasing attention. Network embedding preserves the network structures, the information of nodes [9], [10] and links [11] from original networks. Following the predeﬁned proximity measures, similar nodes are mapped to the neighboring regions in the embedding space. As large-scale online social networks such as Facebook1, Twitter2, and Sina Weibo3 are developing rapidly, a largescale real-world network typically contains millions of nodes and billions of edges. Most existing network embed- • Zhengyan Zhang, Cheng Yang, Zhichong Fang, Zhiyuan Liu (corresponding author) and Maosong Sun are with the Department of Computer Science and Technology, Tsinghua University, Beijing 100084, China. E-mail: {zhangzhengyan14, cheng-ya14, fzc14}@mails.tsinghua.edu.cn, liuzy@tsinghua.edu.cn, sms@mail.tsinghua.edu.cn • Bo Zhang and Leyu Lin are with the Search Product Center, WeChat Search Application Department, Tencent, Beijing 100080, China. Email: {nevinzhang, goshawklin}@tencent.com 1. http://www.facebook.com 2. http://www.twitter.com 3. http://www.weibo.com ding algorithms do not scale for networks of this size. There are three reasons: (1) The majority of network embedding algorithms rely on what we call embedding lookup [12] to build the embedding for each node. We denote the set of nodes by V . The mapping function form likes f(v)=E · v, where v is the target node, E ∈Rd×|V | is a matrix containing the embedding vectors for all nodes, d is the dimension of vectors, |V | is the size of nodes and v ∈IV is a one-hot indicator vector indicating the column of E corresponding to node v. When the size of nodes grows, the dimension of vectors needs to reduce to keep the memory usage not exceed the limit. On the assumption that we have a network containing 100 million nodes and each node is represented by a 128-dimension ﬂoating-point vector, the memory storage of E is more than 100GB. As the dimension becomes fairly small, the parameters of a model can not preserve enough information about original network and have bad performance on the downstream machine learning tasks. (2) Most embedding algorithms suffer from the cold-start item problem: if a node has only a few edges to other nodes, chances are that the',\n",
       " '1412.8060': 'With the dawn of the big data age, there has been a growing interest in solving optimization problems of unprecedented sizes. It was soon realized that traditional approaches, which work extremely well for problems of moderate sizes and when solutions of high accuracy are required, are not eﬃcient for modern problems of large enough size and for applications where only rough or moderate accuracy solutions are suﬃcient. The focus of the optimization, numerical analysis and machine learning communities, and of practitioners in the sciences and industry, shifted to ﬁrst-order (gradient) algorithms [23]. However, once the size of problems becomes truly big, it is necessary to turn to methods which are able to output a reasonably good solutions after an amount of work roughly equivalent to reading the data describing the problem a few times. For this to be possible, methods need to be able to progress while reading only a small part of the data describing the problem, which often means that a single iteration needs to be based on less information than that contained in the gradient of the objective (loss) function. The most popular methods of this type are stochastic gradient methods ∗The authors acknowledge support from the EPSRC Grant EP/K02325X/1, Accelerated Coordinate Descent Methods for Big Data Optimization. Most of the material of this paper was obtained by the authors in Spring 2014, and was presented by PR in June 2014 at the “Khronos Days Summer School” focused on “High-Dimensional Learning and Optimization” in Grenoble, France [27]; http://www.maths.ed.ac.uk/%7Eprichtar/docs/cdm-talk.pdf. †School of Mathematics, The University of Edinburgh, United Kingdom (e-mail: zheng.qu@ed.ac.uk) ‡School of Mathematics, The University of Edinburgh, United Kingdom (e-mail: peter.richtarik@ed.ac.uk) 1  [44, 22, 34, 38, 46], randomized coordinate descent methods [4, 8, 31, 32, 38, 40, 39, 7, 28, 5, 46, 36, 37, 14, 26, 11] and semi-stochastic gradient descent methods [33, 43, 9, 12, 18, 19, 3, 42, 10, 11]. 1.1 Randomized coordinate descent In this paper we focus on randomized coordinate descent methods. After the seminal work of Nesterov [24], which provided an early theoretical justiﬁcation of these methods for unconstrained convex minimization, the study has been successively extended to L1-regularized [35, 30], proximal [31, 17], parallel [32, 6], distributed [28, 5, 26] and primal-dual [38, 26] variants of coordinate descent. Accelerated coordinate decent—characterized by its O(1/k2) complexity for non-strongly convex problems—was studied in [24, 17]. However, these methods are of theoretical nature only due to the fact that they rely on the need to perform full-dimensional vector operation at every iteration, which destroys the main advantage of coordinate descent – its ability to reduce the problem into subproblems of smaller sizes. A theoretically and practically eﬃcient accelerated coordinate descent methods were proposed recently by Lee and Sidford [13] and Fercoq and Richt´arik [6], the latter work (APPROX',\n",
       " '1106.4507': 'In wireless communications, Orthogonal Frequency Division Multiplexing (OFDM) is a well-known solution for overcoming the problem of multipath fading channels [1], [2]. However, this solution is effective only when the receiver is provided with tools to estimate the Channel Frequency Response (CFR). To this end, the transmitter should send some predeﬁned data in a predeﬁned order that the receiver is a priori aware of. These predeﬁned data are usually called pilots. There are two main approaches for inserting pilot data in OFDM signals. In block-type pilots, all the subcarriers in some OFDM blocks (the whole spectrum) are reserved as pilot tones. In comb-type pilot models, some predeﬁned subcarriers in each block serve as pilots. Hence, CFR at these subcarriers can be estimated using methods such as Least Square (LS) or Minimum Mean Square Error (MMSE). Now for estimating the CFR at non-pilot subcarriers, interpolation methods ranging from simple linear or second order techniques [3] to time domain [4] and even more complex approaches are used. It is clear that by decreasing the frequency gap between the adjacent pilot subcarriers, the performance of the interpolation techniques improves. Therefore, the pilots are preferably put at equidistant subcarriers to provide uniformity. Considering the inherent sparsity in the impulse response of the wireless channels which is due to the sparse structure of the scattering objects, it is possible to estimate the Channel Impulse Response (CIR) more accurately even from non-uniform pilot patterns. The common estimation techniques in this case are those introduced in the ﬁeld of compressed sensing such as basis pursuit [5] and OMP [7]. Unlike the interpolation case, equidistant pilot locations are not the best choices here. In [8], using the results of [5] for sparse signal recovery, it is mentioned that uniformly random pilot locations1 can provide the possibility of perfect channel reconstruction with 1That means all possible choices of pilot indices are equally likely overwhelming probability. Although this is an important theoretical result, it is not practical. In this paper, we suggest a deterministic structure for the pilot locations in sparsity-based channel estimation methods which minimizes the inter-atom interference in DFT submatrices. Simulation results conﬁrm the efﬁciency of the proposed pilot allocation method when greedy methods are used for channel estimation. Also, we propose an iterative thresholding method for channel estimation which results in appropriate performance in time-variant frequency selective OFDM channels. 2. PROBLEM STATEMENT In OFDM systems with comb-type pilot arrangement, ignoring the effects of Inter-Symbol Interference (ISI) and Inter-Carrier Interference (ICI), the received data at the kth subcarrier (1 ≤k ≤N) of the nth OFDM frame can be formulated as: Y(n,k) = X(n,k)·H(n,k)+W (n,k), (1) where X(n,k) is the transmitted OFDM symbol, H(n,k) is the channel frequency response and W(n,k) is the AWGN noise.If P denotes the',\n",
       " '1802.02568': 'Image recognition has rapidly progressed in the last ﬁve years. It was shown in the ground-breaking work of [22] that deep convolutional neural networks (CNNs) are extremely effective at recognizing objects and images. The development of deeper neural networks with over a hundred layers has kept improving performance on the ImageNet dataset [7], and we have arguably achieved human performance on this task [35]. These developments have become mainstream and may lead to the perception of image recognition as a solved ∗Work was done while the author was an intern at Flickr, Yahoo Research. problem. However, image recognition remains an area of active research. ImageNet is indeed biased towards single objects appearing in the middle of the image, which is in contrast with the photos we take with our mobile phones that typically contain a range of objects that appear in context. Also, the list of object categories in ImageNet is a subset of the lexical database WordNet [29]. This makes ImageNet biased towards certain categories such as breeds of dogs, and does not match the scope of more general image recognition tasks such as object detection and localization in context. Datasets such as MS COCO [25] or Visual Genome [21] have been constructed such that photos are typically composed of multiple objects appearing at a variety of positions and scales. They provide a more realistic benchmark for image recognition systems that are intended for consumer photography products such as Flickr or Google Photos. MS COCO currently contains 300K images and 80 object categories, whereas Visual Genome contains 100K images and thousands of object categories. CNNs are also showing the best performance on these datasets [34, 21]. As training deep neural networks requires a large amount of data and the size of MS COCO and Visual Genome is an order of magnitude smaller than ImageNet, the CNN weights are initialized using the weights of a model that was originally trained on ImageNet. In this paper we focus on improving image recognition performance on MS COCO and Visual Genome. The labels in MS COCO and Visual Genome are obtained via crowdsourcing platforms such as Amazon Mechanical Turk. Hence it is time-consuming and expensive to obtain additional labels. However, we have access to huge quantities of unlabeled or weakly labeled images. For example, the Yahoo Flickr Creative Commons 100M dataset (YFCC) [40] is comprised of a hundred million Flickr photos with userprovided annotations such as photo tags, titles, or descriptions. In this paper, we present a simple yet effective semisupervised learning algorithm that is able to leverage labeled and unlabeled data to improve classiﬁcation accuracy on the MS COCO and Visual Genome datasets. We ﬁrst train a fully convolutional network using the multi-labeled data 1 arXiv:1802.02568v1  [cs.CV]  7 Feb 2018  Figure 1. The t-SNE [27] map of the whole set of images (including MS COCO and YFCC images) labeled as ‘Bus’ category after applying our proposed VISER',\n",
       " '1808.00931': 'FAILED',\n",
       " '1001.2596': 'Generally, in analog source transmission, the end-to-end distortion (EED), i.e., the distortion in the recovered analog source at the receiver, is the primary metric for measuring the performance of an entire transmission system including source and channel coding. There are various scenarios with different source-to-channel bandwidth ratios (SCBR), Ws/Wc. For instance, a video transmission system would be at a high SCBR whereas the channel-parameter feedback procedure would be at a low SCBR. Caire-Narayanan [1], [2] and Gunduz-Erkip [3] derived the optimum distortion exponent in the optimum expected EED for outage-free systems over spatially uncorrelated MIMO blockfading ﬂat channels. We derived the optimum asymptotic expected EED for high SNR, comprised of the optimum distortion exponent and the multiplicative optimum distortion factor for both cases of spatially uncorrelated and correlated block-fading ﬂat channels [4]–[6]. Concurrently, Tuninetti et al. also showed that the spatial correlation degrades the achievable expected EED in power-offset, i.e., distortion factor, but not affects the distortion exponent [7]. A wideband channel can be considered as a set of parallel narrow-band ﬂat subchannels [8], [9]. The approaches of multicarrier aggregation, OFDM modulation with subcarrier interleaving and spread-spectrum have been employed to harness the frequency diversity. For an outage-suffering system, it has been demonstrated that the frequency diversity can mitigate the outage probability. In this paper, based on our preceding results on ﬂat channels [4]–[6], we investigate the impact of frequency diversity on EED in wideband MIMO systems. We will see that frequency diversity beneﬁts wideband systems on EED, though it has no effect on ergodic capacity. We will give an elaborative analysis on the asymptotic optimum expected EED for high SNR. Its lower bound with inﬁnite frequency diversity will be provided. We will see that the tendency of the asymptotic optimum expected EED reﬂects well the behavior of the optimum expected EED. Our results can be easily extended to the case of time diversity, a counterpart to frequency diversity. So, it is not surprising to see that our result of the optimum distortion exponent with respect to frequency diversity order is identical to Gunduz and Erkip’s result in [10] with respect to time diversity order. However, via introducing the multiplicative optimum distortion factor, we obtain more information on the impact of the diversity order and thus give a more clear guidance on wideband-system design. Throughout the paper, vectors and matrices are indicated by bold, |A| denotes the determinant of matrix A, Ex{·} denotes expectation over the random variable x, the superscript † denotes conjugate transpose, and (a)n denotes Γ(a+n)/Γ(a). II. SYSTEM MODEL Assume that a continuous-time white Gaussian source s(t) of bandwidth Ws Hz and source power Ps Watts per second is to be transmitted over a frequency-selective block-fading Nt-input Nr-output channel of bandwidth Wc Hz which can be divided into L independent subchannels of coherence',\n",
       " '1612.05001': 'Semi-supervised learning is a classiﬁcation problem that aims to make use of unlabelled data, as well as the labelled data typically used to train supervised models. A common approach is graph-based semi-supervised learning (GSSL) [2, 19, 38, 45, 46], in which (often independent) data are represented as a similarity graph, such that a vertex is a data instance and an edge indicates similarity between two instances. By utilising the graph structure, of labelled and unlabelled data, it is possible to accurately classify the unlabelled vertices using a relatively small set of labelled instances. Here we consider semi-supervised learning in the context of relational networks. These networks are a type of graph that consist of nodes representing entities (e.g. people, user accounts, documents) and links representing pairwise dependencies or relationships (e.g. friendships, contacts, references). Here class labels are discretevalued attributes (e.g. gender, location, topic) that describe the nodes and our task is to predict these labels based on the network structure and a subset of nodes already labelled. This problem of classifying nodes in networks is often treated as a GSSL problem because the objective, to predict missing node labels, and the input, a graph, are the same. Sometimes this approach works well due to assortative mixing, or homophily, a feature frequently observed in networks, particularly in social net- ∗leto.peel@uclouvain.be (a) (b) (c) (d) FIG. 1. Diﬀerent patterns of links between class labels {red, black}: (a) nodes with the same label tend to be linked (assortative), (b) links connect nodes with diﬀerent labels (linkheterogeneity), (c) some nodes are assortative and some are not (class-heterogeneity), (d) missing labels (white) obscures the pattern of links. works. Homophily is the eﬀect that linked nodes share similar properties or attributes and occurs either through a process of selection or inﬂuence. However, not all node attributes in relational networks are assortative. For example, in a network of sexual interactions between people it is likely that some attributes will be common across links, e.g. similar demographic information or shared interests, but other attributes will be diﬀerent, e.g. links between people of diﬀerent genders. Furthermore, the pattern of similarity or dissimilarity of attributes across links may not be consistent across the whole network, e.g. in some parts of the network links will occur between people of the same gender. In situations where we have a sparsely labelled network and do not know the pattern of interaction between nodes of diﬀerent classes, the problem of predicting the class labels of the remaining nodes is hard. Figure 1 shows a toy arXiv:1612.05001v1  [cs.SI]  15 Dec 2016  2 example in which nodes are assigned red or black labels and Fig. 1(a)–(c) show possible arrangements of labels that become indistinguishable if certain labels are missing (Fig. 1(d)). Tasks such as fraud detection face this type of problem, where',\n",
       " '1704.05120': 'The planted clique problem is perhaps the most famous example of a computational-statistical gap—while it is information-theoretically possible to recover planted cliques even of size 2 log2(n), the best efﬁcient recovery algorithms require the clique to have size Ω(√n). It has long been conjectured that no polynomialtime algorithm can ﬁnd cliques of size n1/2−ǫ, with recent breakthrough work by Barak et al. (2016) establishing this for the class of sum-of-squares algorithms. There thus appears to be an exponential gap between what is possible statistically and what is tractable computationally. In this paper we revisit this gap, and question whether recovering cliques of size s ≪√n is actually meaningful, or if it can only be done by over-exploiting the particular details of the planted clique model. Recall that in the planted clique model, a set S of vertices is chosen at random and all vertices in S are connected; the remaining edges are then each included independently with probability 1 2. While this model is convenient in its simplicity, it also has a number of peculiarities—for instance, simply returning the highest-degree nodes already performs nearly as well at recovering S as sophisticated spectral algorithms. Feige and Kilian (2001) argue that it is more realistic to consider a semi-random model, in which edges that do not touch any vertices in the clique are allowed to vary arbitrarily. This forces recovery algorithms to be more robust by not relying on simple heuristics such as maximum degree to identify the planted clique. It is then natural to ask—once we require such robustness, how large must a clique be to be statistically identiﬁable? To this end, we establish a strong information-theoretic lower bound: Theorem. In the semi-random model, it is information-theoretically impossible to even approximately recover planted cliques of size o(√n). Moreover, it is information-theoretically possible to exactly recover cliques of size ω( p n log(n)). It is interesting that the information-theoretic threshold in the semi-random model essentially matches the computational threshold of √n in the standard model. It is tempting to hope that, in the semi-random model, the computational and statistical thresholds in fact coincide—i.e., that there is an efﬁcient algorithm for recovering cliques of size p n log(n). In such a case, the previous exponential gap between the statistical and computational limits would vanish entirely. The best upper bound we are aware of is via the results of Charikar et al. (2017) on robust estimation in the ℓ2-norm, which allows recovery of cliques of size ˜Ω(n2/3). While this does not match the ˜Θ(√n) information-theoretic threshold, in a sense this is a much smaller gap than before—in the non-robust case there was an exponentially large gap of log(n) versus √n, whereas here the gap is now at most √n versus n2/3. Moreover, the algorithm in Charikar',\n",
       " '1707.00995': 'In machine translation, neural networks have attracted a lot of research attention. Recently, the attention-based encoder-decoder framework (Sutskever et al., 2014; Bahdanau et al., 2014) has been largely adopted. In this approach, Recurrent Neural Networks (RNNs) map source sequences of words to target sequences. The attention mechanism is learned to focus on different parts of the input sentence while decoding. Attention mechanisms have shown to work with other modalities too, like images, where their are able to learn to attend the salient parts of an image, for instance when generating text captions (Xu et al., 2015). For such applications, Convolutional Neural Networks (CNNs) such as Deep Residual (He et al., 2016) have shown to work best to represent images. Multimodal models of texts and images empower new applications such as visual question answering or multimodal caption translation. Also, the grounding of multiple modalities against each other may enable the model to have a better understanding of each modality individually, such as in natural language understanding applications. In the ﬁeld of Machine Translation (MT), the efﬁcient integration of multimodal information still remains a challenging task. It requires combining diverse modality vector representations with each other. These vector representations, also called context vectors, are computed in order the capture the most relevant information in a modality to output the best translation of a sentence. To investigate the effectiveness of information obtained from images, a multimodal machine translation shared task (Specia et al., 2016) has been addressed to the MT community1. The best results of NMT model were those of Huang et al. (2016) who used LSTM fed with global visual features or multiple regional visual features followed by rescoring. Recently, Calixto et al. (2017) proposed a doubly-attentive decoder that outperformed this baseline with less data and without rescoring. Our paper is structured as follows. In section 2, we brieﬂy describe our NMT model as well as the conditional GRU activation used in the decoder. We also explain how multi-modalities can be implemented within this framework. In the following sections (3 and 4), we detail three attention mechanisms and explain how we tweak them to work as well as possible with images. Finally, we report and analyze our results in section 5 then conclude in section 6. 1http://www.statmt.org/wmt16/multimodal-task.html arXiv:1707.00995v1  [cs.CL]  4 Jul 2017  2 Neural Machine Translation In this section, we detail the neural machine translation architecture by Bahdanau et al. (2014), implemented as an attention-based encoder-decoder framework with recurrent neural networks (§2.1). We follow by explaining the conditional GRU layer (§2.2) - the gating mechanism we chose for our RNN - and how the model can be ported to a multimodal version (§2.3). 2.1 Text-based NMT Given a source sentence X = (x1, x2, . . . , xM), the neural network directly models the conditional probability p(Y |X',\n",
       " '1611.06788': 'Both sequence structured and tree structured neural models have been applied to NLP problems. Seminal work employs convolutional neural network (Collobert and Weston, 2008), recurrent neural network (Elman, 1990; Mikolov et al., 2010) and recursive neural network (Socher et al., 2011) for sequence and tree modeling. Recently, Long ShortTerm Memories (LSTM) have received increasing research attention, giving signiﬁcantly improved accuracies in a variety of sequence tasks (Sutskever et al., 2014; Bahdanau et al., 2014) compared to vanilla recurrent neural networks. Addressing diminishing gradients effectively, they have been extended to tree structures, achieving promising results for tasks such as syntactic language modeling (Zhang et al., 2015), sentiment analysis (Li et al., 2015; Zhu et al., 2015b; Le and Zuidema, 2015; Tai et al., 2015) and relation extraction (Miwa and Bansal, 2016). According to the node type, typical tree structures in NLP can be categorized to constituent trees and dependency trees. A salient difference between the two types of tree structures is in the node. While dependency tree nodes are input words themselves, constituent tree nodes represent syntactic constituents. Only leaf nodes in constituent trees correspond to words. Though LSTM structures have been developed for both types of trees above, we investigate constituent trees in this paper. There are three existing methods for constituent tree LSTM (Zhu et al., 2015b; Tai et al., 2015; Le and Zuidema, 2015), which make essentially the same extension from sequence structure LSTMs. We take the method of Zhu et al. (2015b) as our baseline. A contrast between the sequence structured LSTM of Hochreiter and Schmidhuber (1997) and the tree-structured LSTM of Zhu et al. (2015b) is shown in Figure 1, which illustrates the input (x), cell (c) and hidden (h) nodes at a certain time step t. The most important difference between Figure 1(a) and Figure 1(b) is the branching factor. While a cell in the sequence structure LSTM depends on the single previous hidden node, a cell in the treestructured LSTM depends on a left hidden node and a right hidden node. Such tree-structured extension of the sequence structure LSTM assumes that the arXiv:1611.06788v1  [cs.CL]  21 Nov 2016  Figure 1: Topology of sequential and tree LSTMs. (a) nodes in sequential LSTM; (b) non-leaf nodes in tree LSTM; (c) leaf nodes in tree LSTM. Shaded nodes represent lexical input vectors. White nodes represent hidden state vectors. constituent tree is binarized, building hidden nodes from the input words in the bottom-up direction. The leaf node structure in shown in Figure 1(c). A second salient difference between the two types of LSTMs is the modeling of input words. While each cell in the sequence structure LSTM directly depends on its corresponding input word, only leaf cells in the tree structure LSTM directly depend on corresponding input words. This corresponds well to the constituent tree structure, where there is no direct association between non-leaf constituent nodes and input words. However, it leaves',\n",
       " '1708.05478': 'Let pm be a power of an odd prime p. Denote Fpm the ﬁnite ﬁeld with pm elements and F ∗ pm the multiplicative group of Fpm. If C is a k-dimensional Fp-vector subspace of Fpn, then it is called an [n, k, d] p-ary linear code with length n and minimum Hamming distance d [10]. For linear code C, the concept of generalized Hamming weights(GHW) dr(C)(0 < r ≤k) can be viewed as the extension of Hamming weight (see [13, 18]). Let [C, r]p be the set of all r-dimensional Fp-vector subspaces of C. For V ∈[C, r]p, deﬁne Supp(V ) = {i|xi ̸= 0 for some x = (x1, x2, · · · , xn) ∈V }. Then we deﬁne the r-th generalized Hamming weight(GHW) dr(C) of linear code C by dr(C) = min{|Supp(V )|V ∈[C, r]p}, This research is supported in part by National Natural Science Foundation of China (Grant Nos.61602342). Fei Li E-mail: cczxlf@163.com Faculty of School of Statistics and Applied Mathematics, Anhui University of Finance and Economics, Bengbu, Anhui Province, 233041, P.R.China  2 Fei Li In particular, d1(C) = d. And {di(C)|1 ≤i ≤k} is called the weight hierarchy of C. Generalized Hamming weight of linear codes has been an interesting topic in both theory and practice for many years. In 1991, Wei in the paper [18] presented his classic results, in which GHW was shown that it can characterise the cryptography performance of linear codes used on the wire-tap channel of type II. From then on, much more attention was paid to the generalized Hamming weight. A detailed survey on the results up to 1995 about GHW can be found In [17]. Afterwards lots of authors devoted themselves to generalized Hamming weight about particular classes of codes [1,2,3,6,9,11,12,19, 20]. Recently, Minghui Yang et al. in their work [20] gave a very constructive method for the GHWs of irreducible cyclic codes. Generally, it is hard to settle the weight hierarchy of a linear code. Ding et al. proposed a generic construction of linear code as below ([4,5]). Let T r be the trace function from Fpm to Fp and D = {d1, d2, · · · , dn} be contained in F ∗ pm. Deﬁne a p-ary linear code CD with length n as following. CD = {(T r(xd1), T r(xd2), . . . , T r(xdn)) : x ∈Fpm} (1) and D is called the deﬁning set. Many classes of linear codes with few weights were obtained by choosing properly deﬁning sets [8,15,21,22,24]. In this paper, we discuss the generalized Hamming weights of a class of p-ary linear codes CD, whose deﬁning set was chosen to be D = Da = {x ∈F ∗ pm|f(x) = a}, a ∈Fp. (2) Here f is a non-degenerate quadratic form over Fpm. And the weight hierarchy of CD0 can be deduced by Theorem 9 in',\n",
       " '1812.03031': 'Let X and Y be a pair of random variables with alphabets X and Y, respectively, and a given distribution PXY . This paper deals with the problem of quantizing Y into M < |Y| values, under the objective of maximizing the mutual information between the quantizer’s output and X. With a slight abuse of notation1, we will denote the value of the mutual information attained by the optimal M-ary quantizer by I(X; [Y ]M) ≜ sup ˜Y ∈[Y ]M I(X; ˜Y ). (1) where [Y ]M is the set of all (deterministic) M-ary quantizations of Y , [Y ]M ≜{f(Y ) | f : Y →[M]} and [M] ≜{1, 2, . . ., M}. When X and Y are thought of as the input and output of a channel, this problem corresponds to determining the highest available information rate for M-level quantization. It is therefore not surprising that this problem has received considerable attention. For example, it is well known [2, Section 2.11] that when X is ±1 equiprobable and Y = X + Z for Gaussian Z, A. Bhatt is with the University of California, San Diego, CA, USA (email: a2bhatt@eng.ucsd.edu). B. Nazer is with Boston Univerity, Boston, MA, USA (email: bobak@bu.edu) O. Ordentlich is with the School of Computer Science and Engineering, Hebrew University of Jerusalem, Israel (email: or.ordentlich@mail.huji.ac.il). Y. Polyanskiy is with the Massachusetts Institute of Technology, MA, USA (email: yp@mit.edu) This work was supported, in part, by ISF under Grant 1791/17, by the NSF CAREER award CCF-12-53205, the Center for Science of Information (CSoI), an NSF Science and Technology Center, under grant agreement CCF-09-39370, and NSF grants CCF-1618800, CCF-17-17842, and ECCS-1808692. The material in this paper was presented in part at the 2017 International Symposium on Information Theory [1]. 1This notation is meant to suggest the distance from a point to a set.  2 statistically independent of X, it holds that I(X; [Y ]2) ≥2 πI(X; Y ), which is achieved by taking f(·) to be the maximum a posteriori (MAP) estimator of X from Y .2 A characterization of (1) is also required for the construction of good polar codes [4], since the large output cardinality of polarized channels makes it challenging to evaluate their respective capacities (and identify “frozen” bits). Efﬁcient techniques for channel output quantization that preserve mutual information have been developed to overcome this obstacle, and played a major role in the process of making polar codes implementable [5]–[7]. One byproduct of these efforts is a sharp characterization of the additive gap. Speciﬁcally, it was recently shown in [7] that, for arbitrary PXY , it holds that I(X; Y ) −I(X; [Y ]M) = O(M −2/(|X |−1)), whereas [8] demonstrates that there exist PXY such that I(X; Y ) −I(X; [Y ]M) = Ω(M −2/(|X |−1)). The works [5]–[7], among others, also provided polynomial-complexity, sub-optimal algorithms for',\n",
       " '1807.04067': 'This work is aimed at estimating the two-dimensional (2D) poses of multiple people in a given image. Any solution to this problem has to tackle a few subproblems: detecting body joints (or keypoints1, as they are called in the inﬂuential COCO [1] dataset) such as wrists, ankles, etc., grouping these joints into person instances, or detecting people and assigning joints to person instances. Depending on which sub-problem is tackled ﬁrst, there have been two major approaches in multi-person 2D estimation: bottom-up and top-down. Bottom-up methods [2–8] ﬁrst detect body joints without having any knowledge as to the number of people or their locations. Next, detected joints are grouped to form individual poses for person instances. On the other hand, top-down methods [9–12] start by detecting people ﬁrst and then for each person detection, a single-person pose estimation method (e.g. [13–16]) is executed. Single-person pose estimation, i.e. detecting body joints conditioned on the information that there is a single person in the given input (the top-down approach), is typically a more costly process than grouping the detected joints (the bottom-up approach). Consequently, the top-down methods tend to be slower than the bottom-up methods, since 1 We use “body joint” and “keypoint” interchangeably throughout the paper. arXiv:1807.04067v1  [cs.CV]  11 Jul 2018  2 they need to repeat the single-person pose estimation for each person detection; however, they usually yield better accuracy than bottom-up methods. Keypoint Subnet FPN FPN C5 C4 C3 C2 P7 P6 P5 P4 P3 Person Detection Subnet Backbone Anchors cls reg Pose Residual Net D features K5 K4 K3 K2 Pose Residual Net Fig. 1. MultiPoseNet is a multi-task learning architecture capable of performing human keypoint estimation, detection and semantic segmentation tasks altogether eﬃciently. In this paper, we present a new bottom-up method for multi-person 2D pose estimation. Our method is based on a multi-task learning model which can jointly handle the person detection, keypoint detection, person segmentation and pose estimation problems. To emphasize its multi-person and multi-task aspects of our model, we named it as “MultiPoseNet.” Our model (Fig. 1) consists of a shared backbone for feature extraction, detection subnets for keypoint and person detection/segmentation, and a ﬁnal network which carries out the pose estimation, i.e. assigning detected keypoints to person instances. Our major contribution lies in the pose estimation step where the network implements a novel assignment method. This network receives keypoint and person detections, and produces a pose for each detected person by assigning keypoints to person boxes using a learned function. In order to put our contribution into context, here we brieﬂy describe the relevant aspects of the stateof-the-art (SOTA) bottom-up methods [2, 8]. These methods attempt to group detected keypoints by exploiting lower order relations either between the group and keypoints',\n",
       " '1511.06939': 'Session-based recommendation is a relatively unappreciated problem in the machine learning and recommender systems community. Many e-commerce recommender systems (particularly those of small retailers) and most of news and media sites do not typically track the user-id’s of the users that visit their sites over a long period of time. While cookies and browser ﬁngerprinting can provide some level of user recognizability, those technologies are often not reliable enough and moreover raise privacy concerns. Even if tracking is possible, lots of users have only one or two sessions on a smaller e-commerce site, and in certain domains (e.g. classiﬁed sites) the behavior of users often shows session-based traits. Thus subsequent sessions of the same user should be handled independently. Consequently, most session-based recommendation systems deployed for e-commerce are based on relatively simple methods that do not make use of a user proﬁle e.g. itemto-item similarity, co-occurrence, or transition probabilities. While effective, those methods often take only the last click or selection of the user into account ignoring the information of past clicks. The most common methods used in recommender systems are factor models (Koren et al., 2009; Weimer et al., 2007; Hidasi & Tikk, 2012) and neighborhood methods (Sarwar et al., 2001; Koren, 2008). Factor models work by decomposing the sparse user-item interactions matrix to a set of d dimensional vectors one for each item and user in the dataset. The recommendation problem is then treated as a matrix completion/reconstruction problem whereby the latent factor vectors are then used to ﬁll the missing entries by e.g. taking the dot product of the corresponding user–item latent factors. Factor models are hard to apply in session-based recommendation due to the absence ∗The author spent 3 months at Telefonica Research during the research of this topic. †This work was done while the author was a member of the Telefonica Research group in Barcelona, Spain 1 arXiv:1511.06939v4  [cs.LG]  29 Mar 2016  Published as a conference paper at ICLR 2016 of a user proﬁle. On the other hand, neighborhood methods, which rely on computing similarities between items (or users) are based on co-occurrences of items in sessions (or user proﬁles). Neighborhood methods have been used extensively in session-based recommendations. The past few years have seen the tremendous success of deep neural networks in a number of tasks such as image and speech recognition (Russakovsky et al., 2014; Hinton et al., 2012) where unstructured data is processed through several convolutional and standard layers of (usually rectiﬁed linear) units. Sequential data modeling has recently also attracted a lot of attention with various ﬂavors of RNNs being the model of choice for this type of data. Applications of sequence modeling range from test-translation to conversation modeling to image captioning. While RNNs have been applied to the aforementioned domains with remarkable success little attention, has been paid to the area of recommender',\n",
       " '1505.01740': 'S PECTRAL unmixing (SU) aims at decomposing a set of n multivariate measurements X = [x1, . . . , xn] into a collection of m elementary signatures E = [e1, · · · , em], usually referred to as endmembers, and estimating the relative proportions A = [a1, . . . , an] of these signatures, called abundances. SU has been advocated as a relevant multivariate analysis technique in various applicative areas, including remote sensing [1], planetology [2], microscopy [3], spectroscopy [4] and gene expression analysis [5]. In particular, it has demonstrated a great interest when analyzing multi-band (e.g., hyperspectral) images, for instance for pixel classiﬁcation [6], material quantiﬁcation [7] and subpixel detection [8]. In this context, several models have been proposed in the literature to properly describe the physical process underlying the observed measurements. Under some generally mild assumptions [9], these measurements are supposed to result from linear combinations of the elementary spectra, according Part of this work has been supported by the Chinese Scholarship Council, the Hypanema ANR Project n◦ANR-12-BS03-003, the ANR-11-LABX-0040CIMI Project, in particular during the ANR-11-IDEX-0002-02 program within the thematic trimester on image processing, and the Portuguese Science and Technology Foundation under Projects UID/EEA/50008/2013 and PTDC/EEIPRO/1470/2012. Qi Wei, Nicolas Dobigeon and Jean-Yves Tourneret are with University of Toulouse, IRIT/INP-ENSEEIHT, 31071 Toulouse cedex 7, France (e-mail: {qi.wei, nicolas.dobigeon, jean-yves.tourneret}@enseeiht.fr). Jos´e Bioucas-Dias is with Instituto de Telecomunicac¸ ˜oes and Instituto Superior T´ecnico, Universidade de Lisboa, Portugal (e-mail: bioucas@lx.it.pt). to the popular linear mixing model (LMM) [10]–[12]. More precisely, each column xj ∈Rnλ of the measurement matrix X = [x1, . . . , xn] can be regarded as a noisy linear combination of the spectral signatures leading to the following matrix formulation X = EA + N (1) where • E ∈Rnλ×m is the endmember matrix whose columns e1, · · · , em are the signatures of the m materials, • A ∈Rm×n is the abundance matrix whose jth column aj ∈Rm contains the fractional abundances of the jth spectral vector xj, • N ∈Rnλ×n is the additive noise matrix. As the mixing coefﬁcient ai,j represents the proportion (or probability of occurrence) of the the ith endmember in the jth measurement [10], [11], the abundance vectors satisfy the following abundance non-negativity constraint (ANC) and abundance sum-to-one constraint (ASC) aj ≥0 and 1T maj = 1, ∀j = 1, · · · , n (2) where ≥means element-wise greater or equal and 1T m ∈ Rm×1 represents a vector with all ones. Accounting for all the image pixels, the constraints (2) can be rewritten in matrix form A ≥0 and 1T mA = 1T n. (3) Unsupervised linear SU boils down to estimating the endmember matrix E and abundance matrix A from the measurements X following the LMM (1). It can be regarded as a special instance of (constrained) blind source separation, where the endmembers are the sources [13]. There',\n",
       " '1111.6278': 'Let Ps−1 be a projective space over a ﬁnite ﬁeld Fq. An evaluation code, also known as a generalized Reed-Muller code, is a linear code obtained by evaluating the linear space of homogeneous d-forms on a set of points X ⊂Ps−1 (see Deﬁnition 2.1). A linear code obtained in this way, denoted by CX(d), has length |X|. Evaluation codes have been the object of much attention in recent years. To describe their basic parameters (length, dimension and minimum distance), many authors have been using tools coming from Algebraic Geometry and Commutative Algebra, see [2, 3, 7, 11, 17, 19, 22]. Let Ts−1 be a projective torus in Ps−1. A parameterized linear code is a special type of generalized Reed-Muller code obtained when X ⊂Ts−1 ⊂Ps−1 is parameterized by a set of monomials (see Deﬁnition 2.5), in this case X is called an algebraic toric set because it generalizes the notion of a projective torus. Parameterized linear codes were introduced and studied in [15]. The extra structure on X yields alternative methods to compute the basic parameters of CX(d). In this article we focus on linear codes parameterized by the edges of a graph G (see Deﬁnition 2.6). For the study of algebraic toric sets parameterized by the edges of a clutter, which is a natural generalization of the concept of graph, we refer the reader to [17, 18]. Not much is known about the parameterized linear codes associated to a general graph. The ﬁrst results in this direction appear in [10], where the length, dimension and minimum distance of the codes associated to complete bipartite graphs are computed. In [15], one can ﬁnd a formula for the length of the code associated to a connected graph (see this formula in Proposition 2.7) and also a bound for the minimum distance of the code associated to a connected non-bipartite graph. An important algebraic invariant associated to a parameterized linear code is the regularity of the ring S/I(X), where S is the coordinate ring of Ps−1, i.e., a polynomial ring in s variables, and I(X) is the vanishing ideal of X (see Deﬁnition 2.2). The knowledge of the regularity of S/I(X) is important for applications to coding theory: for d ≥reg S/I(X) the code CX(d) 2010 Mathematics Subject Classiﬁcation. Primary 13P25; Secondary 14G50, 14G15, 11T71, 94B27, 94B05. The ﬁrst author was partially supported by CMUC and FCT (Portugal), through European program COMPETE/FEDER. The second author is a member of the Center for Mathematical Analysis, Geometry and Dynamical Systems. The third author was partially supported by SNI. 1  2 JORGE NEVES, MARIA VAZ PINTO, AND RAFAEL H. VILLARREAL coincides with the underlying vector space F|X| q and has, accordingly, minimum distance equal to 1. I',\n",
       " '1603.08631': 'Alzheimer’s disease is a neurological, irreversible, progressive brain disorder and multifaceted disease that slowly destroys brain cells causing memory and thinking skills loss, and ultimately the ability to carry out the simplest tasks. The cognitive decline caused by this disorder ultimately leads to dementia. For instance, the disease begins with mild deterioration and gets progressively worse in a neurodegenerative type of dementia. Diagnosing Alzheimer’s disease requires very careful medical assessments such as patients? history, Mini Mental State Examination (MMSE) and physical and neurobiological exam. In addition to those evaluations, resting state functional magnetic resonance imaging (rs-fMRI) provides a non-invasive method to measure functional brain activity and changes in the brain [13]. There are two imporData used in preparation of this article were obtained from the Alzheimer’s Disease Neuroimaging Initiative (ADNI) database (adni.loni.usc.edu). As such, the investigators within the ADNI contributed to the design and implementation of ADNI and/or provided data but did not participate in analysis or writing of this report. A complete listing of ADNI investigators can be found at: http://adni.loni.usc.edu/wpcontent/uploads/how to apply/ADNI Acknowledgement List.pdf Saman Sarraf was with the Department of Electrical and Computer Engineering, McMaster University, Hamilton, ON, L8S 4L8, Canada. samansarraf@ieee.org Ghassem Toﬁghi is with the Electrical and Computer Engineering Department, Ryerson University, Toronto, ON M5B 2K3 Canada. gtofighi@ryerson.ca tant concepts about resting-state fMRI. First of all, as patients do not need to do any task and there is no simulation, the procedure will be more comfortable than a normal fMRI and secondly, rs-fMRI data acquisition can be performed during a clinical scan and most researchers are interested in brain network analysis and extraction from rs-fMRI data [8] [9] [11] [6] [2]. However, development of an assistant tool or algorithm to classify fMRI data and more importantly to recognize brain disorder data from healthy subjects has been always clinicians? interests. Any machine learning algorithm which is able to classify Alzheimer’s disease assists scientists and clinicians to diagnose this brain disorder. In this work, the convolutional neural network (CNN) which is one of the Deep Learning Network architecture is utilized in order to classify the Alzheimer’s brains and healthy brains and to produce a trained and predictive model. II. BACKGROUND AND ALGORITHMS A. Data Acquisition and Preprocessing For this study, Alzheimer‘s Disease (AD) patients and 15 elderly normal control subjects (24 female and 19 male) with a mean age of 74.9 5.7 years were selected from ADNI dataset. The AD patients had MMSE over 20 reported by *ADNI and all normal participants were healthy and had no reported history of medical or neurological conditions. Scanning was performed on a Siemens Trio 3 Tesla MRI scanner. Anatomical scans were acquired with a 3D MPRAGE sequence (TR=2s, TE=2.63 ms, FOV=25.6 cm, 256 x 256 matrix, 160 slices',\n",
       " '1901.09671': 'Much of the recent empirical success of machine learning has been enabled by distributed computation. In order to contend with the size and scale of modern data and models, many production-scale machine learning solutions employ distributed training methods. Ideally, distributed implementations of learning algorithms lead to speedup gains that scale linearly with the number of compute nodes. Unfortunately, in practice these gains fall short of what is theoretically possible even with a small number of compute nodes. Several studies, starting with [9] extending to more recent ones [23, 12], have consistently reported a tremendous gap between ideal and realizable speedup gains. There are many causes of this phenomenon. A notable and well-studied one is the presence of communication bottlenecks [9, 26, 28, 23, 1, 12, 30], while another is the presence of straggler nodes. These are compute nodes whose runtime is signiﬁcantly slower than the average node in the system. This straggler eﬀect can be observed practically in many real world distributed machine learning applications. Figure 1 illustrates one running example of straggler eﬀect. In this work, we focus on the latter. Stragglers become a bottleneck when running synchronous distributed algorithms that require explicit synchronization between tasks. This is the case for commonly used synchronous optimization methods, including mini-batch stochastic gradient descent (SGD), and gradient descent (GD), where the overall runtime is determined by the slowest response time of the distributed tasks. Straggler mitigation for general workloads has received signiﬁcant attention from the systems community, with techniques ranging from job replication approaches, to predictive job allocation, straggler detection, and straggler dropping mechanisms [2, 34, 6]. In the context of model training, one could use asynchronous techniques such as Hogwild! [25], but these may suﬀer from reproducibility issues due to system randomness, making them potentially less desirable in some production environments [6]. Recently, coding theory has provided a popular tool set for mitigating the eﬀects of stragglers. Codes have recently been used in the context of machine learning, and applied to problems such as data shuﬄing [19, 17], distributed matrix-vector and matrix-matrix multiplication [17, 10], as well as distributed training [20, 32, 15, 11, 22, 7, 33]. 1 arXiv:1901.09671v1  [cs.LG]  28 Jan 2019  0 50 100 150 200 250 300 T (sec) 0.0 0.2 0.4 0.6 0.8 1.0 Pr(completion time < T) Median Runtime 98% Runtime 100% Runtime > 2x > 8x Figure 1: Probability of job completion time per worker. Setup: 148 worker nodes on AWS EC2 t2.small instances, running distributed SGD with batch size 1024 on CIFAR-10, and a simple variation of the cuda-covnet model. Observe that 100% completion time corresponds to 8× the median. In the context of distributed, gradient-based algorithms, Tandon et al. [29] introduced gradient coding as a means to mitigate straggler delays. They show that with n compute nodes, one can assign c gradients to compute node such that the sum of the n gradients can be recovered',\n",
       " '1310.8487': 'Multi-rate systems are ubiquitously used in digital systems to increase (upsample) or decrease (downsample) the rate at which a signal is processed. Especially downsampling is a critical operation since it can introduce aliasing, like sampling, and thus can cause information loss. Standard textbooks on signal processing deal with this issue by recommending an anti-aliasing ﬁlter prior to downsampling – resulting in a cascade which is commonly known as a decimator [1, Ch. 4.6]. In these books, this anti-aliasing ﬁlter is usually an ideal lowpass ﬁlter with a cut-off frequency of π/M, for an M-fold decimation system (cf. Fig. 1). Unser [2] showed that this choice is optimal in terms of the mean-squared reconstruction error (MSE) only if the input process is such that the passband portion of its power spectral density (PSD) exceeds all aliased components. Similarly, as it was shown by Tsatsanis and Giannakis [3], the ﬁlter minimizing the MSE is piecewise constant, M-aliasing-free (i.e., the aliased components of the M-fold downsampled frequency response do not overlap), and has a passband depending on the PSD of the input process. Speciﬁcally, the ﬁlter which permits most of the energy to pass aliasing-free is optimal in the MSE sense. In this paper we consider a design objective vastly different from the MSE: information. The fact that information, compared to energy, can yield more successful system designs has long been recognized, e.g., for (non-linear) adaptive ﬁlters [4] or for state estimation using linear ﬁlters [5]. Mutual information has been used as a design objective for transceiver ﬁlter design, too: In [6], Al-Dhahir et al. derived a sub-optimal block transmission ﬁlter whose output approximates the optimal input statistics of a dispersive, noisy channel. Scaglione et Bernhard C. Geiger (geiger@ieee.org) and Gernot Kubin are with the Signal Processing and Speech Communication Laboratory, Graz University of Technology. Parts of this work have been presented at the IEEE Forum on Signal Processing for RF-Systems 2013 and at the 2014 Int. Z¨urich Seminar on Communications. X H ↓M Y ˜X Fig. 1. Decimation system consisting of a linear ﬁlter H and an M-fold downsampler. al. [7] later showed that the resulting non-stationarity of the channel input can be achieved by an FIR ﬁlter bank, both for FIR and ARMA channels. Recently, Chen et al. [8] derived the capacity of sub-Nyquist sampled additive Gaussian noise channels for various sampling mechanisms: sampling after a ﬁlter, a ﬁlterbank, and a modulated ﬁlterbank. They showed that the capacity-maximizing sampling ﬁlter is piecewise constant and both maximizes the signal-to-noise ratio and minimizes the MSE of the reconstructed signal, thus building a bridge between information-theoretic and energetic ﬁlter design. All these works, however, consider either a signalplus-noise model or assume that all processes are Gaussian. We extend the existing literature in three different aspects: First, we present results for the case',\n",
       " '1502.05680': '1.1 Motivation The problem of ﬁnding a highly connected subset of vertices in a large graph arises in a number of applications across science and engineering. Within social network analysis, a highly connected subset of nodes is interpreted as a community [For10]. Many approaches to data clustering and dimensionality reduction construct a ‘similarity graph’ over the data points. A highly connected subgraph corresponds to a cluster of similar data points [VL07]. A closely related problem arises in the analysis of matrix data, e.g. in microarray data analysis. In this context, researchers are often interested in a submatrix whose entries have an average value larger (or lower) than the rest [SWPN09]. Such an anomalous submatrix is interpreted as evidence of association between gene expression levels and phenotypes (e.g. medical conditions). If we ∗Department of Electrical Engineering and Department of Statistics, Stanford University 1 arXiv:1502.05680v2  [stat.ML]  30 Jul 2015  consider the graph adjacency matrix, a highly connected subset of vertices corresponds indeed to a principal submatrix with average value larger than the background. The special case of ﬁnding a completely connected subset of vertices (a clique) in a graph has been intensely studied within theoretical computer science. Assuming P̸=NP, the largest clique in a graph cannot be found in polynomial time. Even a very rough approximation to its size is hard to ﬁnd [Has96, Kho01]. In particular, it is hard to detect the presence of a clique of size N1−ε in a graph with N vertices. Such hardness results motivated the study of random instances. In particular, the so-called ‘planted clique’ or ‘hidden clique problem’ [Jer92] requires to ﬁnd a clique of size k that is added (planted) in a random graph with edge density 1/2. More precisely, for a subset of vertices S ⊆ [N], all edges (i, j), with {i, j} ⊆S are present. All other edges are present independently with probability 1/2. Such a clique can be found reliably by exhaustive search as soon as k ≥2(1 + ε) log2 N [GM75]. However, despite many eﬀorts, no algorithm is known that achieves this goal for k ≪ √ N [AKS98, FK00, DGGP14]. In other words, the problem of ﬁnding cliques of size 2 log2 N ≪k ≪ √ N is solvable, but possibly hard. Proving that indeed it is computationally hard to ﬁnd cliques in this regime is an outstanding problem in theoretical computer science. For general polynomial algorithms, it is known since [AKS98] that a clique of size δ √ N can be found in time NO(log(1/δ)) for any δ > 0 ﬁxed. Hence, if we allow any time complexity polynomial in N, then the question is whether the planted clique can be found for k = o( √ N). A more stringent computational constraint requires that the clique is found in nearly-linear time, i.e. in time of order O(N2(log N)c). Note that the number of bits required to encode an instance of the problem is of order',\n",
       " '1512.00142': 'Recently, massive multiple-input multiple-output (MIMO) has attracted signiﬁcant interests for 5th generation (5G) wireless systems, as it is able to achieve dramatic gain in spectral efﬁciency (SE) [1], [2]. In receiver radio-frequency (RF) circuits, massive analog-to-digital converters (ADCs) corresponding to massive antennas are used to convert the received RF signal to the baseband. A typical ﬂash ADC with b-bit resolution and the sampling frequency fs operates fs2b conversion steps per second, which means the power consumption of ADCs scales exponentially with the resolution and linearly with the sampling rate [3]. Therefore, ADCs with high-speed (e.g., 1 GSample/s) and high-resolution (e.g., 812 bits) will put a heavy burden on the power consumption of massive MIMO systems, which is considered as the bottleneck to realize massive MIMO in practice [4]. To solve the power consumption problem, the timeinterleaved ADC can be used to reduce the sampling rate, but such solution causes an inevitable error ﬂoor of the system performance. Another promising solution is to employ lowresolution ADCs (e.g., 1-3 bits) at RF chains. Great efforts have been made to understand the effects of low-resolution ADCs on the performance of MIMO systems [5]–[8]. For This work was supported in part by the International Science & Technology Cooperation Program of China (Grant No. 2015DFG12760), the National Natural Science Foundation of China (Grant Nos. 61571270 and 61271266), the Beijing Natural Science Foundation (Grant No. 4142027), and the Foundation of Shenzhen government. J. Zhang is with the School of Electronics and Information Engineering, Beijing Jiaotong University, Beijing 100044, P. R. China (e-mails: jiayizhang@bjtu.edu.cn). L. Dai, S. Sun and Z. Wang are with Department of Electronic Engineering as well as Tsinghua National Laboratory of Information Science and Technology (TNList), Tsinghua University, Beijing 100084, P. R. China. conventional small-scale MIMO systems, the impact of ADC resolution on the SE was studied by using an additive quantization noise model (AQNM), which takes into account the dependency of ADC power on the bit resolution [5]. The SE of ﬂat fading MIMO channels with one-bit ADCs has been analyzed in [6], while the impact of one-bit ADCs on the SE of massive MIMO systems was recently investigated in [7], [8]. Unfortunately, the aforementioned works only consider Rayleigh fading channels and one-bit resolution. The assumption of Rayleigh fading channels is often violated in an lineof-sight (LoS) path dominated practical wireless propagation scenarios, where the Rician fading model is more accurate, and massive MIMO has found its very promising application in such scenarios [9], [10]. However, the effect of low-resolution ADCs has been ignored in [9], [10]. Moreover, the analysis of the effect of more than one-bit resolution (e.g., 2-3 bits) on massive MIMO systems is still limited. Only recently, [11] investigated the uplink performance of massive MIMO systems with 1-2 bits resolution ADCs and perfect',\n",
       " '1503.01102': 'A. Motivation Coordination among base stations (BSs) is a powerful approach for mitigating inter-cell interference in cellular systems [1]. It has been shown that the sum spectral efﬁciency scales linearly with the signal-to-noise ratio (SNR) when all the BSs are coordinated [2]. In practice, however, coordination with a large number of BSs may not be feasible due to excessive overhead associated with the coordination, e.g., complexity, channel estimation and channel feedback [3]. One practical solution for implementing multicell coordination is to form a BS cluster so that a limited number of BSs are coordinated to control intra-cluster interference with a reasonable amount of overhead [3], [4]. Unfortunately, when clustering-based BSs coordination is applied in a static way [5], [6], or equivalently in a random way [7] independent to users’ conditions, the performance is mainly limited by unmanageable out-of-cluster interference [3], [5], [6]. Dynamic clustering, where a BS cluster is dynamically made by users, was proposed in [8] to overcome the performance limitation of static clustering. While dynamic clustering improves the signal-to-interference and noise ratio (SINR) of J. Park and R. W. Heath Jr. are with the Wireless Networking and Communication Group (WNCG), Department of Electrical and Computer Engineering, The University of Texas at Austin, TX 78701, USA. (E-mail: {jeonghun, rheath} @utexas.edu) N. Lee is with Intel Labs, 2200 Mission College Blvd, Santa Clara, CA 95054, USA (Email:namyoon.lee@intel.com) This research was supported by a gift from Huawei Technologies Co. Ltd. a user signiﬁcantly, there are several challenges that make it difﬁcult to realize. In particular, different users who share the same spectrum can select the same BS at the same time. We refer to this as “the BS selection conﬂict problem.” To resolve this, users in a network need to send feedback regarding desirable BS clusters and a global scheduler is required to schedule BSs and users based on this feedback information. For this reason, performance chieﬂy depends on the choice of this scheduler. The scheduling itself, however, requires a lot of feedback overhead from the users and a substantial amount of coordination of all the BSs and the users, which causes huge system overhead. To solve the BS selection conﬂict problem without requiring global coordination, semi-static clustering was proposed in [9], [10]. In this method, multiple predeﬁned BS clusters are used with different time-frequency resources. A set of BS clusters that use the same time-frequency resource is referred as “a BS cluster pattern.” For instance, in a square grid BS topology, four BS cluster patterns are required to cover the whole region without the BS selection conﬂict problem. Using the semistatic clustering, users can communicate with their favorable BS set. The main limitation of the existing work [9], [10] is that the BS clustering methods are applicable for a regular BS topology where each BS is located regularly on a grid. In practice, however, the BS topology of',\n",
       " '1711.05165': 'Humans can rapidly process complex scenes containing multiple objects despite having limited computational resources. The visual system uses various forms of attention to prioritize and selectively process subsets of the vast amount of visual input [6]. Computational models and various forms of psychophysical and neuro-biological evidence suggest that this process may be implemented using various \"maps\" that topographically encode the relevance of locations in the visual ﬁeld [17, 39, 13]. Under these models, visual input is compiled into a saliency-map that encodes the conspicuity of locations based on bottom-up features, computed in a parallel, feed-forward process [20, 17]. Top-down, goal-speciﬁc relevance of locations is then incorporated to form a priority map, which is then used to select the next target of attention [39]. Thus processing a scene with multiple attentional shifts may be interpreted as a feed-forward process followed by sequential, recurrent stages [23]. Furthermore, the allocation of attention can be separated into covert attention, which is deployed to regions without eye movement and precedes eye movements, and overt attention associated with an eye movement [6]. Despite their evident importance to human visual attention, the notions of incorporating saliency to decide attentional targets, integrating covert and overt attention mechanisms, and using multiple, sequential shifts while processing a scene have not been fully addressed by modern deep learning architectures. Motivated by the model of Itti et al. [17], we propose a hierarchical visual architecture that operates on a saliency map computed by a feed-forward process, followed by a recurrent process that uses a combination of covert and overt attention mechanisms to sequentially focus on relevant regions and take additional glimpses within those regions. We propose a novel attention mechanism for implementing the covert attention. Here, the architecture is used for multi-label image classiﬁca31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA. arXiv:1711.05165v1  [cs.CV]  14 Nov 2017  tion. Unlike conventional multi-label image classiﬁcation models, this model can perform multiset classiﬁcation due to the proposed reinforcement-learning based training. 2 Related Work We ﬁrst introduce relevant concepts from biological visual attention, then contextualize work in deep learning related to visual attention, saliency, and hierarchical reinforcement learning (RL). We observe that current deep learning models either exclusively focus on bottom-up, feed-forward attention or overt sequential attention, and that saliency has traditionally been studied separately from object recognition. 2.1 Biological Visual Attention Visual attention can be classiﬁed into covert and overt components. Covert attention precedes eye movements, and is intuitively used to monitor the environment and guide eye movements to salient regions [6, 21]. Two particular functions of covert attention motivate the Gaussian attention mechanism proposed below: noise exclusion, which modiﬁes perceptual ﬁlters to enhance the signal portion of the stimulus and mitigate the noise; and distractor suppression, which refers to suppressing the representation strength outside an attention area [6]. Further inspiring the proposed attention mechanism is evidence from cueing [1], multiple object tracking',\n",
       " '1811.02539': 'Deep convolutional neural networks (CNNs) are considered the state-of-the-art for image segmentation problems [1, 2, 3]. One limitation of deep CNNs is that they requires large volumes of training data in order to generalize well [4]. Unfortunately, acquisition of manual segmentation labels is a time-consuming process that requires domain expertise to produce an acceptable ground truth. This is most notable in the domain of medical images, for which accurate delineation of structures require many years of experience on the part of the annotator. In contrast, spatial localization of the same structure of interest is often relatively simple, exhibits lower variance, and takes signiﬁcantly less time to perform. In this work, we explore the potential of CNNs to learn transferable features from easily-labeled data to tasks that would normally require larger quantities of expertly-labeled data to achieve the same performance. To demonstrate our approach, we consider the task of segmenting the optic disc from retinal fundus photographs. The optic disc is readily discernible from fundus photographs and can have differing coloration and morphology as a consequence of both normal variation and pathology such as glaucoma [5]. Segmentation of the optic disk allows for such characteristics to be readily quantiﬁed from conventional fundus images. Preprint. Work in progress. arXiv:1811.02539v2  [cs.CV]  10 Nov 2018  Figure 1: Diagram of the U-net architecture and two phase training scheme for optic localization and segmentation. 2 Materials and Methods Our method consists of a two phase training scheme of the widely used U-net [6] architecture, as shown in Figure 1. In the ﬁrst phase of training, the encoding arm of the U-net is trained independently as an optic disc localization network. After convergence, the network’s weights are frozen and the decoding arm is trained as an optic disc segmentation network, re-using the features learned during localization training. We posit that the semantic information learned during training of the encoding arm are transferable to the segmentation task, such as the shape, texture and boundary characteristics of the disc. 2.1 Data and preprocessing Training, validation, and test data sets were created from a database of more than 10,000 de-identiﬁed retinal images obtained using a commercially available camera (RetCam; Natus Medical Incorporated) as part of the [details of institution redacted]. We used 9047 images with optic disc center location annotations for the localization task, and a further 92 images labeled with optic disc binary masks for the segmentation task. Images were preprocessed with grayscale conversion, normalization, contrast limited adaptive histogram equalization and gamma correction [7]. 2.2 Optic disc localization We formulate the localization task as a regression problem using the encoding arm of a U-net in Figure 1. Pre-processed fundus photographs are provided as input to the network, which undergoes a series of convolutional and pooling operations to produce a volume of image features. These features are passed to a fully connected network without activation (linear) to produce',\n",
       " '1210.2440': 'A. Motivation and Background One of the most fundamental of problems in statistical data analysis is to learn the relationship between the samples of a dependent or response variable (e.g., the malignancy of a tumor, the health of a network) and the samples of independent or predictor variables (e.g., the expression data of genes, the trafﬁc data in the network). This problem was relatively easy in the data-starved world of yesteryears. We had n samples and p predictors, and our inability to observe too many variables meant that we lived in the “n greater than or equal to p” world. Times have changed now. The data-rich world of today has enabled us to simultaneously observe an unprecedented number of variables per sample. It is nearly impossible in many of these instances to collect as many, or more, samples as the number of predictors. Imagine, for example, collecting hundreds of thousands of thyroid tumors in a clinical setting. The “n smaller than p” world is no longer a theoretical construct in statistical data analysis. It has ﬁnally arrived; and it is here to stay. This paper concerns statistical inference in the “n smaller than p” setting for the case when the response variable This work and the ﬁrst author are supported in part by the National Science Foundation under grant CCF-1218942. depends linearly on the predictors. Mathematically, a model of this form can be expressed as yi = p X j=1 xi,jβ0 j + εi, i = 1, . . . , n. (1) Here, yi denotes the i-th sample of the response variable, xi,j denotes the i-th sample of the j-th predictor, εi denotes the error in the model, and the parameters {β0 j } are called regression coefﬁcients. This relationship between the samples of the response variable and those of the predictors can be expressed compactly in matrix-vector form as y = Xβ0 + ε. The matrix X in this form, termed the design matrix, is an n × p matrix whose j-th column comprises the n samples of the j-th predictor. In tumor classiﬁcation, for example, an entry in the response variable y could correspond to the malignancy (expressed as a numerical number) of a tumor sample, while the corresponding row in X would correspond to the expression level of p genes in that tumor sample. The linear model y = Xβ0 + ε, despite its mathematical simplicity, continues to make profound impacts in countless application areas [1]. Such models are used for various inferential purposes. In this paper, we focus on the problem of model selection in high-dimensional linear models, which involves determining a small subset of p predictors that are responsible for majority (or all) of the variation in the response variable y. High-dimensional model selection can be used to implicate a small number of genes in the development of cancerous tumors, identify a small number of genes that primarily affect prognosis of a disease, etc. B. Group Model Selection and Our Contributions There exist many applications in statistical model selection',\n",
       " '1501.07867': 'Image classiﬁcation is an important problem that has been studied for over three decades. Practical applications span a wide variety of areas such as general texture or object categorization [1,2] , face recognition [3,4] and automatic target recognition in hyperspectral or radar imagery [5, 6]. Various methods of feature extraction ( [7, 8] for example) as well as classiﬁers [1,9] have been investigated. The advent of of compressive sensing (CS) [10] has inspired research in the direction of applying the central analytical formulation of CS to classiﬁcation problems. Sparse representation-based classiﬁcation (SRC) [11] is arguably the most well-known such tool that has demonstrated robust performance even in the presence of high pixel distortion, occlusion or noise. Extensions of SRC have been proposed along two lines of thought: (i) by adding regularizer and priors which prevent overﬁtting issue by introducing additional information to the problem and (ii) by exploiting joint information and complementary data in multitask cases. We are also moving along this direction to use the advantages of using priors as well as joint information. Copyright c⃝2010 IEEE. Personal use of this material is permitted. However, permission to use this material for any other purposes must be obtained from the IEEE by sending a request to pubs-permissions@ieee.org. Motivation and Contribution: Advances in sensing technology have facilitated the easy acquisition of multiple different measurements of the same underlying physical phenomena. Often there is complimentary information embedded in these different measurements which can be exploited for improved performance. For example, in face recognition or action recognition we could have different views of a person’s face captured under different illumination conditions or with different facial postures [2, 12–15]. In automatic target recognition, multiple SAR (synthetic aperture radar) views are acquired [16]. The use of complimentary information from different color image channels in medical imaging has been demonstrated in [17]. In border security applications, multi-modal sensor data such as voice sensor measurements, infrared images and seismic measurements are fused [18] for activity classiﬁcation tasks. The prevalence of such a rich variety of applications where multi-sensor information manifests in different ways is a key motivation for our contribution in this paper. Speciﬁcally, we extend recent work in class-speciﬁc sparse prior-based classiﬁcation by Srinivas et al. [19] to a multitask framework. We extend the Bayesian framework in [19] in a hierarchical manner in order to capture joint information across multiple tasks (or measurements). As observed in [19], an important challenge is to develop a framework based on spike-andslab priors that can capture a general notion of signal sparsity while also leading to tractable optimization problems. Our contribution successfully addresses both these issues via a generalized collaborative Bayesian hierarchical method. Expectedly it results in a hard non-convex optimization problem. We propose an efﬁcient solution using Monte Carlo Markov Chain (MCMC) method',\n",
       " '1510.04935': 'Relations are a key concept in artiﬁcial intelligence and cognitive science. Many of the structures that humans impose on the world, such as logical reasoning, analogies, or taxonomies, are based on entities, concepts and their relationships. Hence, learning from and with relational knowledge representations has long been considered an important task in artiﬁcial intelligence (see e.g., Getoor and Taskar (2007); Muggleton (1991); Gentner (1983); Kemp et al. (2006); Xu et al. (2006); Richardson and Domingos (2006)). In this work we are concerned with learning from knowledge graphs (KGs), i.e., knowledge bases which model facts as instances of binary relations (e.g., bornIn(BarackObama, Hawaii)). This form of knowledge representation can be interpreted as a multigraph, where entities correspond to nodes, facts correspond to typed edges, and the type of an edge indicates the kind of the relation. Modern knowledge graphs such as YAGO (Suchanek, Kasneci, and Weikum, 2007), DBpedia (Auer et al., 2007), and Freebase (Bollacker et al., 2008) contain billions of facts about millions of entities and have found important applications in question answering, structured search, and digital assistants. Recently, vector space embeddings of knowledge graphs have received considerable attention, as they can be used to create statistical models of entire KGs, i.e., to predict the probability of any possible relation instance (edge) in the graph. Such models can be used to derive new knowledge from known facts (link prediction), to disambiguate entities (entity resolution), to extract taxonomies, and for probabilistic question answering (see e.g., (Nickel, Tresp, and Kriegel, 2011; Bordes et al., 2013; Krompaß, Nickel, and Tresp, 2014)). Furthermore, embeddings of KGs have been used to support machine reading and to assess the trustworthiness of web sites (Dong et al., 2014, 2015). However, existing embedding models that can capture rich interactions in relational data are often limited in their scalability. Vice versa, models that can be computed efﬁciently are often considerably less expressive. In this work, we approach learning from KGs within the framework of compositional vector space models. We introduce holographic embeddings (HOLE) which use the circular correlation of entity embeddings (vector representations) to create compositional representations of binary relational data. By using correlation as the compositional operator HOLE can capture rich interactions but simultaneously remains efﬁcient to compute, easy to train, and scalable to very large datasets. As we will show experimentally, HOLE is able to outperform state-of-the-art embedding models on various benchmark datasets for learning from KGs. Compositional vector space models have also been considered in cognitive science and natural language processing, e.g., to model symbolic structures, to represent the semantic meaning of phrases, and as models for associative memory (see e.g., Smolensky (1990); Plate (1995); Mitchell and Lapata (2008); Socher et al. (2012)). In this work, we do not only draw inspiration from these models, but we will also highlight the connections of HOLE to holographic models of associative memory. Compositional Representations In',\n",
       " '1806.01313': 'Annually, millions of women depend on pathologists’ interpretive accuracy to determine whether their breast biopsies are benign or malignant [4]. Diagnostic errors are alarmingly frequent, lead to incorrect treatment recommendations, and can cause signiﬁcant patient harm [2]. Pathology as a ﬁeld has been slow to move into the digital age, but in April 2017, the FDA authorized the marketing of the Philips IntelliSite Pathology Solution (PIPS), the ﬁrst whole slide imaging system for interpreting digital surgical pathology slides on the basis of biopsy tissue samples, thus changing the landscape4. Convolutional neural networks (CNNs) produce state-of-the-art results in natural [12,6] and biomedical classiﬁcation and segmentation [8,11] tasks. Training CNNs directly on whole slide images (WSIs) is diﬃcult due to their massive size. Sliding-window-based approaches for classifying [8,5] and segmenting [11,10] 4 https://www.fda.gov/NewsEvents/Newsroom/PressAnnouncements/ucm552742. htm arXiv:1806.01313v1  [cs.CV]  4 Jun 2018  medical images have shown promising results. Segmentation and classiﬁcation are usually separate steps in automated diagnosis systems. Segmentation-based methods consider tissue structure, such as size and distribution, to help inform class boundary decisions. However, these segmentation methods suﬀer from two major drawbacks. First, labeled data is scarce because the labeling of biopsy images is time-consuming and must be done by domain experts. Second, segmentation-based approaches are not able to weigh the importance of diﬀerent tissue types. The latter limitation is particularly concerning in biopsy images, because not every tissue type in biopsy images is relevant for cancer detection. On the other hand, though classiﬁcation-based methods fail to provide structureand tissue-level information, they can identify regions of interest inside the images that should be used for further analysis. In this paper, we combine the two diﬀerent methods, segmentation and classiﬁcation, and introduce a new network called Y-Net that simultaneously generates a tissue-level segmentation mask and a discriminative (or saliency) map. Y-Net generalizes the U-Net network [11], a well-known segmentation network for biomedical images. Y-net includes a plug-and-play functionality that enables the use of diﬀerent types of convolutional blocks without changing the network topology, allowing users to more easily explore the space of networks and choose more eﬃcient networks. For example, Y-Net delivers the same segmentation performance as that of [10] while learning 6.6× fewer parameters. Furthermore, the discriminative tissue-level segmentation masks produced using Y-Net provide powerful features for diagnosis. Our results suggest that Y-Net is 7% more accurate than state-of-the-art segmentation and saliency-based methods [10,5]. Statement of problem: The problem we wish to solve is the simultaneous segmentation and diagnosis of whole slide breast cancer biopsy images. For this task, we used the breast biopsy dataset in [2,10] that consists of 240 whole slide breast biopsy images with heamatoxylin and eosin (H&E) staining. A total of 87 pathologists diagnosed a randomly assigned subset',\n",
       " '1210.2159': 'The characterization of the information-theoretic limits of coordination in networks has recently been investigated in [1]. The coordinated actions of nodes in the network are modeled by joint probability distributions, and the level of coordination is measured in terms of how well these joint distributions approximate a target joint distribution. Two types of coordination have been introduced: empirical coordination, which only requires the empirical distribution of coordinated actions to approach a target distribution, and strong coordination, which requires the total variational distance of coordinated actions to approach a target distribution. The concept of coordination sheds light into the fundamental limits of several problems, such as distributed control or task assignment in a network. The design of practical and efﬁcient coordination schemes approaching the fundamental limits predicted by information theory has attracted little attention to date. One of the hurdles faced for code design is that the metric to optimize is not a probability of error but a variational distance between distributions. Nevertheless, polar codes [2] have recently been successfully adapted [3] for empirical coordination, with an analysis based on results from lossy source coding with polar codes [4]. In this paper, we construct polar codes that are able to achieve strong coordination in some cases. Unlike the construction in [3], which solely relies on source coding with polar codes, our construction also exploits polar codes for channel resolvability [5]. Channel resolvability characterizes the bit rate required to simulate a process at 1M. Bloch is with the School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA 30332, USA and with the GT-CNRS UMI 2958, Metz, France. matthieu.bloch@ece.gatech.edu 2L. Luzzi was with the Department of Electrical and Electronic Engineering, Imperial College London, London SW7 2AZ, United Kingdom. She is now with Laboratoire ETIS (ENSEA - Universit´e de CergyPontoise - CNRS), 6 Avenue du Ponceau, 95014 Cergy-Pontoise, France. laura.luzzi@ensea.fr 3J. Kliewer is with the Klipsch School of Electrical and Computer Engineering, New Mexico State University, Las Cruces, NM, 88003, USA. jkliewer@nmsu.edu the output of a channel and plays a key role in the analysis of the common information between random variables [6], secure communication over wiretap channels [7], [8], and coordination [1, Lemma 19]. By remarking that polar codes can be used for channel resolvability, we are able to provide a constructive alternative to the information-theoretic proof in [1]. The remainder of the paper is organized as follows. Section II sets the notation and recalls known results for polar codes. Section III shows that polar codes provide channel resolvability for symmetric channels by leveraging results in [9]. Section IV proves that polar codes achieve strong coordination for simple two-node networks with symmetric actions. Finally, Section V concludes the paper with a discussion of potential improvements and extensions. II. NOTATION AND PRELIMINARIES First, a word about notation. Given a length n vector x = (x1, · · · , xn) and i ∈J1, nK, we use the notation xi 1 a',\n",
       " '1810.11957': 'Massive amounts of high-dimensional data collected by contemporary information processing systems create new challenges in the ﬁelds of signal processing and machine learning. High dimensionality of data presents computational and memory burdens and may adversely affect performance of the existing data analysis algorithms. An important unsupervised learning problem encountered in such settings deals with ﬁnding informative parsimonious structures characterizing large-scale high-dimensional datasets. This task is critical for detection of meaningful patterns in complex data and enabling accurate and efﬁcient clustering. The problem of extracting low-dimensional structures for the purpose of clustering is encountered in many applications including motion segmentation and face clustering in computer vision [1], [2], image representation and compression in image clustering [3], [4], robust To appear in IEEE Journal of Selected Topics in Signal Processing, Special Issue on Data Science: Robust Subspace Learning and Tracking, vol. 12, no. 6, December 2018. Authors are with the Department of Electrical and Computer Engineering, University of Texas at Austin, Austin, TX 78712 USA (e-mail: abolfazl@utexas.edu; hvikalo@ece.utexas.edu). arXiv:1810.11957v1  [cs.CV]  29 Oct 2018  2 principal component analysis (PCA), and robust subspace recovery and tracking [5]–[9]. In these settings, the data can be thought of as being a collection of points lying on a union of low-dimensional subspaces. In addition to having such structural properties, data is often acquired at multiple points in time. Exploiting the underlying temporal behavior provides more informative description and enables improved clustering accuracy. For example, it is well-known that feature point trajectories associated with motion in a video lie in an afﬁne subspace [10]. Motion during any given short time interval is related to the motion in recent past. Therefore, in addition to the union of subspaces structure of the video data, there exists an underlying evolutionary structure characterizing the motion. Therefore, it is of interest to design and investigate frameworks that exploit both union of subspaces and temporal smoothness structures to perform fast and accurate clustering, particularly in real-time applications where a clustering solution is required at each time step. In this paper, we formulate and study evolutionary subspace clustering – the task of clustering data points that lie on a union of evolving subspaces. We provide a mathematical formulation of evolutionary subspace clustering and introduce the convex evolutionary self-expressive model (CESM), an optimization framework that exploits the selfexpressiveness property of data and learns sparse representations while taking into account prior representations. The task of learning parameters of the CESM leads to a non-convex optimization problem which we solve approximately by relying on the alternating minimization ideas. In the process of learning data representation, we automatically tune a smoothing parameter which characterizes the signiﬁcance of prior representations, i.e., quantiﬁes similarity of the representation in successive time steps. The smoothing parameter is reﬂective of the rate of evolution of the data and signiﬁes the amount of temporal changes in consecutive data snapshots. Note that although we only',\n",
       " '1603.06141': 'While ﬂocking is a popular topic, algorithms for shepherding are less well-studied. Existing approaches to shepherding typically train a predictive model as in [1], or employ predeﬁned strategies which may be combined to achieve a goal [2]. Typically, the goal of shepherding is to herd the ﬂock to some location which we will refer to as the ‘pen’. In our approach, the shepherding system has no predeﬁned strategies nor predictive modeling. Using standard genetic programming techniques, we evolve the expression 1 arXiv:1603.06141v1  [cs.AI]  19 Mar 2016  tree for a pure (stateless) function which acts as the ‘force update’ for each simulated sheep dog at each time step. The parameters of this function can include some combination of the dog’s position, the position of the other dogs (in cooperative herding), the position of the nearest ‘free’ (uncaptured) sheep, the center of mass of the ﬂock, and a ‘steering point,’ a position such that the line between the steering point and entrance to the pen crosses some sheep [4]. Our simulated sheep all obey the same simple, ﬁxed ﬂocking rules designed such that the sheep attempt to cluster with each other and avoid the sheep dog(s). The ﬁtness of the evolved ‘dog-AI’ is the fraction of the sheep ‘captured’ after some ﬁxed number of simulation steps. 2 Related Work (Lien et. al, 2005) studies shepherding behavior in an environment with multiple shepherds cooperating to control a ﬂock [4]. Shepherds, which exert a repulsive force on the ﬂock, must ﬁnd steering points to inﬂuence the direction of the ﬂock as desired. The steering points for the group of shepherds form either a line or an arc on a side of the ﬂock, and each shepherd chooses a steering point to approach based on one of several proposed heuristics. (Sumpter et. al, 1998) presents a machine vision system that models the position and velocity of a ﬂock of animals [1]. A Point Distribution Mode is used to generate features based on input from a camera mounted on a ”Robotic Sheepdog,” and these features are then used to estimate a probability distribution of the movement of the ﬂock over time, conditional on its previous locations and velocities. This probability distribution is estimated using competitive learning in a neural network. Finally, the robot can herd a ﬂock of animals toward a goal by a maximum likelihood estimate of the robot’s own path. (Bennet and Trafankowski, 2012) provides an analysis of ﬂocking and herding algorithms, and also introduces a herding algorithm based on speciﬁc strategies inspired by real sheepdogs[2]. [2] also considers using one of several ﬂocking strategies for the animals being herded, and ﬁnds that the success of diﬀerent a herding algorithm is often dependent on the ﬂocking behavior. (Cowling and Gmeinwieser, 2010) uses a combined top-down and bottom-up approach to provide realistic sheep herdin',\n",
       " '1801.09500': 'FAILED',\n",
       " '1203.3887': 'FAILED',\n",
       " '1512.06789': '3 1.1 A Short Algorithmic Illustration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 1.2 Outlook . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 2 Preliminaries in Expected Utility Theory 7 2.1 Variational principles . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7 2.2 Subjective expected utility . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8 2.3 Two open problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10 3 The Mathematical Structure of Boundedness 12 3.1 Meta-reasoning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12 3.2 Incomplete Information and Interrupted Deliberation . . . . . . . . . . . . . . . . . . . . . . . 13 3.3 Commensurability of utility and information . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14 4 Single-Step Decisions 18 4.1 Bounded-rational decisions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18 4.2 Stochastic choice . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20 4.3 Equivalence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24 4.4 Comparison . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27 5 Sequential Decisions 28 5.1 Bounded-rational decision trees . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29 5.2 Derivation of the free energy functional . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32 5.3 Bellman recursion and its solution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34 5.4 Recursive rejection sampling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35 6 Discussion 38 6.1 Relation to literature . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38 6.2 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40 A Proofs 41 A.1 Proof to Theorem 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41 2  Information-Theoretic Bounded Rationality 1. Introduction It is hard to overstate the inﬂuence that the economic idea of perfect rationality has had on our way of designing artiﬁcial agents [Russell and Norvig, 2010]. Today, many of us in the ﬁelds of artiﬁcial intelligence, control theory, and reinforcement learning, design our agents by encoding the desired behavior into an objective function that the agents must optimize in expectation. By doing so, we are relying on the theory of subjective expected utility (SEU), the standard economic theory of decision making under uncertainty [Von Neumann and Morgenstern, 1944, Savage, 1954]. SEU theory has an immense intuitive appeal, and its pervasiveness in today’s mindset is reﬂected in many widely-spread beliefs: e.g. that probabilities and utilities are orthogonal concepts; that two options with the same expected utility are equivalent; and that randomizing can never improve upon an optimal deterministic choice. Put simply, if we ﬁnd ourselves violating SEU theory, we would feel strongly compelled to revise our choice. Simultaneously, it is also well-understood that SEU theory prescribes policies that are intractable to calculate save for very restricted problem classes. This was recognized soon after expected utility theory was formulated [Simon, 1956]. In agent design, it became especially apparent more recently, as we continue to struggle in tackling problems of moderate complexity in spite of our deeper understanding of the planning problem [Duﬀ, 2002, Hutter, 2004, Legg, 2008, Ortega, 2011] and the vast computing power available to us. For instance, there are eﬃcient algorithms to calculate the optimal policy of a known Markov decision process (MDP) [Bertsekas and Tsitsiklis, 1996], but no eﬃcient algorithm to calculate the exact optimal policy of an unknown MDP or a partially observable MDP [Papadimitriou and Tsitsiklis, 1987]. Due to this, in practice we either make severe domain-speciﬁc simpliﬁcations, as in linear-quadratic-Gaussian control problems [Stengel, 1994]; or we approximate the “gold standard” prescribed by SEU theory, exempliﬁed by the reinforcement learning algorithms based on stochastic approximations [Sutton and Barto, 1998, Szepesv´ari, 2010] and Monte-Carlo tree search [Kocsis and Szepesv´ari, 2006, Veness et al',\n",
       " '1805.01167': 'Scene text detection is one of the most challenging tasks in many computer vision applications such as multilingual translation, image retrieval, and automatic driving. The ﬁrst challenge is scene text contains various kinds of images, such as street views, posters, menus, indoor scenes, etc. Furthermore, the scene text has large variations in both foreground texts and background objects, and also with various lighting, burring, and orientation. In the past years, there have been many outstanding approaches focus on scene text detection. The key point of text detection is to design features to distinguish text and non-text regions. Most of the traditional methods such as MSER [Neumann and Matas, 2010] and FASText [Busta et al., 2015] use manually designed text features. These methods are not robust enough to handle complex scene text. Recently, Convolutional Neural Network (CNN) based methods achieve the state-of-the-art results in text detection and recognition [He et al., 2016b; Tian et al., 2016; Zhou et al., 2017; 1https://market.aliyun.com/products/ 57124001/cmapi020020.html He et al., 2017]. CNN based models have a powerful capability of feature representation, and deeper CNN models are able to extract higher level or abstract features. In the literature, there are mainly two types of approaches for scene text detection, namely indirect and direct regressions. Indirect regression methods predict the offsets from some box proposals, such as CTPN [Tian et al., 2016] and RRPN [Ma et al., 2017]. These methods are based on FasterRCNN [Ren et al., 2015] framework. Recently, direct regression methods have achieved high performance for scene text detection, e.g. East [Zhou et al., 2017] and DDR [He et al., 2017]. Direct regression usually performs boundary regression by predicting the offsets from a given point. In this paper, we solve this problem from an instance-aware segmentation perspective that mainly draws on the experience of FCIS [Li et al., 2016]. Different from common object detection, scene text often suffers from a large variance of scale, aspect ratio, and orientation. Therefore, we design a novel Inception-Text module to deal with these challenges. This module is inspired by Inception module [Szegedy et al., 2015] in GoogLeNet, we choose multi branches of different convolution kernels to deal with the text of different aspect ratios and scales. At the end of each branch, we add a deformable convolution layer to adapt multi orientations. Another improvement is that we replace the PSROI pooling in FCIS with deformable PSROI pooling [Dai et al., 2017a]. According to our experiments, deformable PSROI pooling has better performance in the classiﬁcation task. Our main contributions can be summarized as follows: • We propose a new Inception-Text module for multioriented scene text detection. According to our experiments, this module shows a signiﬁcant increase in accuracy with little computation cost. • We propose to use deformable PSROI pooling module to deal with multi-oriented text. The qualitative study of learned offset parts',\n",
       " '1804.08333': 'A variety of modern AI products are powered by cuttingedge machine learning (ML) technologies, which range from face detection and language translation installed on smartphones to voice recognition and speech synthesis used in virtual assistants such as Amazon Alexa and Google Home. Therefore, the development of such AI products typically necessitates large-scale data, which are essential for training high-performance ML models such as a deep neural network. Arguably, a massive amount of IoT devices, smartphones, and autonomous vehicles with high-resolution sensors, all of which are connected to a high-speed network, can serve as promising data collection infrastructure in the near future (e.g., [1]). Researchers in the ﬁeld of communication and mobile computing have started to interact with data science communities in the last decade and have proposed mobile edge computing (MEC) frameworks that can be used for large-scale data collection and processing [2]. Typically, MEC frameworks assume that all data resources are transferred from data collection clients (IoT devices, smartphones, and connected vehicles) to computational infrastructure (high-performance servers) through cellular networks to perform their tasks [3], [4]. However, this assumption is not always acceptable when private human activity data are 1. Downloading model parameters 3. Uploading the new parameters 2. Updating the model with own data Server MEC platform 4. Aggregating client updates Base station Clients Cellular network Fig. 1. Federated learning [5] enables one to train machine learning models on private client data through the iterative communications of model parameters between a server and clients. How can we implement this training process in practical cellular networks with heterogeneous clients? collected, such as life-logging videos, a history of e-mail conversations, and recorded phone calls. On one hand, such private activity data would be a key factor for improving the quality of AI products that support our daily life, which include not only AI-related apps on smartphones and virtual assistants but also AI-powered smart cities. On the other hand, uploading these data directly to computational infrastructure is problematic as the data could be eavesdropped by malicious users in a network to compromise client’s privacy. To address this fundamental privacy concern, one work has recently been presented by the ML community: Federated Learning (FL) [5]. As illustrated in Fig. 1, FL iteratively asks random clients to 1) download parameters of a trainable model from a certain server, 2) update the model with their own data, and 3) upload the new model parameters to the server, while asking the server to 4) aggregate multiple client updates to further improve the model. In exchange for requiring data collection clients to install a certain level of computational resources (e.g., a laptop equipped with reasonable GPUs, autonomous vehicles with moderate computational capacities [1]), the FL protocol allows the clients to keep their data secure in their local storage. In this work, we focus on the implementation of the abovementioned FL protocol in practical MEC frameworks. We believe that our',\n",
       " '1805.08019': 'Many machine learning solutions are supervised, requiring well-annotated training datasets. Such annotations can be overly expensive to attain for the amount of data required for plausible performance by today’s deep neural networks. Domain adaptation approaches attempt to compensate for lack of annotated data in a target domain, by adapting information from a source domain, for which annotated data is easier to obtain. For example, in many cases, it is easy to generate synthetic data (source domain) with inherent annotations, and use this data for the supervised training of a network that is ultimately intended for carrying out a task over real data (the target domain). While the source data may closely resemble the real target data, there are typically inevitable differences between the two domains, and domain adaptation faces the challenge of overcoming such domain shifts. In this work, we target the unsupervised domain adaptation scenario, where the source domain data, either synthetic or real, is fully annotated, while the target domain data has no annotations whatsoever. Existing approaches to domain adaptation, which are reviewed in more detail in the next section, can be broadly classiﬁed into two categories: methods based on domain transfer (e.g., by translating data from one domain to another), and those based on embedding both domains in a common feature space. The goal of the current work is to propose a framework which improves the performance of methods in the latter category. Preprint. Work in progress. arXiv:1805.08019v1  [cs.CV]  21 May 2018  In domain adaptation, it is typically assumed that there is a signiﬁcant commonality between the source and the target domains in aspects relevant to the task at hand [1] (e.g., classiﬁcation). Thus, data items in each of the two domains can be conceptually factored into their task-relevant common features and their domain-speciﬁc features. Domain adaptation could thus be achieved by training a model on the common features extracted from the annotated source domain, and applying it on the common features extracted from the target domain at test time. However, neither the common features, nor the domain-speciﬁc ones are given explicitly. Rather, these features are typically latent, and thus it is necessary to train a model to extract the common features, regardless of the domain of the input, in order to obtain good performance on target domain data. Several existing methods attempt to embed both domains in a shared feature space, which effectively amounts to extracting their common features. In this paper, we present a framework for boosting the performance of such methods by iterative interleaving of domain adaptation and disentanglement analysis. The key idea is that rather than focusing solely on extracting the common feature, we attempt to extract a disentangled latent representation of the data from both domains, i.e., to explicitly obtain its common and speciﬁc features. The ability to disentangle both the source and the target domain data paves the way for attribute swapping [14], or disentangled synthesis [9, 12], which enables',\n",
       " '1804.02322': 'Connections between rough sets and probability theories are of much interest from theoretical and practical perspectives. A number of hybrid and analogical models for handling three-way decision making [1] and neoBayesian reasoning are known. Membership functions have also been extensively studied in rough sets (RST) relative to these motivations. More information can be found in these papers [2, 3] for example. In simple terms, they express the degree to which an object belongs to a set. These have been interpreted in probabilistic perspectives from both Bayesian and nonBayesian perspectives [4, 5, 6, 7, 2, 8, 9]. In the recent paper [10], these interpretations have been critically reviewed and diﬀerent new problems and methodologies have been proposed by the present author. These are in the light of her work on the contamination problem [11, 12], advances in the philosophy of probability theory [13, 14, 15] and possibility theory. The concept of rough membership is also generalized to granular operator spaces (see [16, 17, 18, 19]) and characterized by the present author [10]. Connections with the rough membership function based semantics [20] have also been considered in the latter research. At the practical level, contamination is about making less assumptions about data and modeling vagueness as closely as is possible to the object level. The dependence predicate [12, 21, 22, 23], used instead of a probability 2  function, is not directly comparable with the rough dependence functions [12] as an additional layer for comparison becomes necessary. This predicate is replaced by a new dependence function based deviant probability theory for easy comparison by the present author in the research papers [10, 24]. This approach is shown to lead to improved methods in three-way decision making. It should be mentioned that while the concept of deviant probability has some relation to probability functions, the focus of the present paper is on measurable spaces. This can be helpful from the perspectives of likelihood and possibility theory [25, 26]. In the present research, the framework for the approach is improved further by using a common language and model through duality results. The interpretation and meaning are also considered in detail. It is shown that comparison of implication like operations are justiﬁed. This is because fragments of full mathematical dualities are alone meaningful in the context because of ontology. The limitations of the framework invented in this research is explored in much detail and new problems are posed. Both the relation-based and cover-based approach to general rough sets suﬀer from the problem of permitting unreal objects into the discourse - this may or may not be an issue. This is related to absence of related restrictions in information tables. For example, in big data, incompatible attributes that do not correspond to real objects can lead to wastage of resources in computing. While granular operator spaces and generalizations thereof can handle this and other key problems through granulations, it is a fact that not all approximations are granular. A',\n",
       " '1212.4093': 'FAILED',\n",
       " '1709.02975': 'Unmanned aerial vehicles (UAVs) equipped with communication transceivers have found increasingly more applications in wireless communication, such as for information broadcasting, relaying, data collection, etc [1]. This is mainly attributed to the ﬂexible deployment and high mobility of UAVs, as well as their line-of-sight (LoS) communication links with the ground terminals (GTs) at moderate altitude. There are mainly two lines of research in the existing literature on UAV-to-Ground (U2G)/Ground-to-UAV (G2U) communications, depending on whether the D. Yang is with the Information Engineering School, Nanchang University, Nanchang 330031, China. (e-mail: yangdingcheng@ncu.edu.cn). Q. Wu, Y. Zeng, and R. Zhang are with the Department of Electrical and Computer Engineering, National University of Singapore, Singapore 117583 (e-mail:{elewuqq, elezeng, elezhang}@nus.edu.sg).  2 z y x H r r O* O (a) Circular ﬂight x y z % $ T% T$ H H O (b) Straight ﬂight Fig. 1. A ground-to-UAV wireless communication system with circular or straight ﬂight UAV trajectory. UAV’s mobility is fully exploited or not. One line of works mainly focus on optimizing the placement/deployment of static or quasi-static UAVs, to achieve the maximum communication coverage of GTs [2]–[6]. The other research thrust aims to fully exploit the high mobility of UAVs via their trajectory design and optimization, which brings a new degree of freedom in optimizing the performance of wireless communication systems. To this end, joint communication and UAV trajectory optimization has been studied for various wireless systems, such as mobile relaying [7], multiple access channel (MAC) and broadcast channel (BC) [8], [9]. On the other hand, energy saving has been recognized as an important metric in designing future wireless communication systems [10]. For instance, prior works [11]–[14] have studied the energy minimization of the UAVs and/or GTs in various U2G/G2U communication systems. However, these works only focus on minimizing the communication energy consumption as in the conventional terrestrial wireless communication [10]. For UAVs in practice, their communication energy consumption is usually much lower compared to propulsion energy consumption, which is required to maintain the UAVs aloft and enable their mobility. Due to the limited on-board energy of UAVs, their propulsion energy consumption becomes the dominant factor that needs to be taken into account for achieving energy-efﬁcient UAV communications [15]. To this end, the authors in [15] developed a mathematical model for the propulsion energy consumption of ﬁxedwing UAVs, based on which energy-efﬁcient UAV trajectories were designed in various U2G/G2U communication systems [15], [16]. In this paper, we study a G2U wireless communication system, where a UAV is dispatched as a mobile data collector to gather a given amount of data from a ﬁxed GT at known location. Intuitively, the GT will consume less uplink transmission energy to send the data if the UAV can ﬂy closer to it to establish better G2U channels [11]. However, such movement usually requires more propulsion energy consumption',\n",
       " '1503.03163': 'Large and balanced datasets are normally crucial for learning classiﬁers. In real-world scenarios, however, one always struggles to ﬁnd adequate amounts of labeled data. Even with the help of crowdsourcing, e.g., Amazon Mechanical Turk (AMT), it is often difﬁcult to collect a large quantity of labeled instances with high quality that is necessary for training a classiﬁer for a real-world problem. In terms of quantity, it has been shown that the amount of available training data, per object class, roughly follows a Zipf distribution [35]. That means a small number of object classes account for most of the available training instances. In terms of quality, some domains, such as the analysis of satellite images (e.g. the comet images from Rosetta), require extensive and detailed expert user annotation [32], [48]. Large volume of LiDAR point cloud data have to be labeled before they can be used to train some classiﬁers [49]. Such labeling process usually is very time consuming and requires expert-level labeling efforts or expensive equipments. Practically only a very limited portion of the data points can be obtained. To solve the problem of lacking enough training samples, attributes [22], [30], [13] have been introduced to transfer the knowledge held by majority classes to instances in minority classes. Nevertheless, for certain tasks, such shared attributes [14], [12], [25], [10], [46] may simply be unavailable or nontrivial to deﬁne. In contrast, rather than using such a ‘learning to learn’ [38] framework, humans can generalize and associate the similar patterns from images. This ability inspires us to circumvent the problem of lacking enough training data and solve it from a different angle: utilizing the synthetic • Xi Zhang, Andi Zang, and Gady Agam are with the Illinois Institute of Technology Chicago, IL 60616. Email: {xzhang22,zang}@hawk.iit.edu, and agam@iit.edu. • Yanwei Fu, and Leonid Sigal are with Disney Research, Pittburgh, PA, 15213. Email: {yanwei.fu, lsigal}@disneyresearch.com (a) Real roof edges (b) Synthetic roof edges Figure 1. Examples of (a) real roof edge vs. corresponding (b) synthetic roof edge images. The synthetic data is generated by the algorithms in Sec. 4. The examples are randomly drawn from the SRC dataset. data (e.g. the synthetic roof edges in Fig. 1) associated with real data (e.g. real roof edges in Fig. 1) in order to learn a better classiﬁer. The idea of associating synthetic data with real data has a long history and is associated with the development of cognitive psychology, artiﬁcial intelligence, and computer vision. For example, cognitive psychology studied a case that an infant learns to understand and imitate a facial expression from parents’ examples. In the computing domain, exemplar SVM [26] tries to associate images with training exemplars. Different from these previous works, we create synthetic images to associate them with the real images whilst previous works associate ‘new’ real data with ‘old’ real data. By contrast, our approach is a ’free lunch’ in the sense that',\n",
       " '1501.02917': 'The Internet of Things (IoT) is expected to foster the development of 5G wireless networks and requires efﬁcient access of sporadic trafﬁc generating devices. Such devices are most of the time inactive but regularly access the Internet for minor/incremental updates with no human interaction, e.g., machine-type-communication (MTC). Sporadic trafﬁc will dramatically increase in the 5G market and, obviously, such trafﬁc should not be forced to be integrated into the bulky synchronization procedure of current 4G cellular systems [2], [3]. The new conceptional approach in this paper is to use an extended physical layer random access channel (PRACH), which achieves device acquisition and (possibly small) payload transmission ”in one shot”. Similar to the implementation in UMTS, the goal is to transmit small user data packets using the PRACH, without maintaining a continuous connection. So far, this is not possible in LTE, where data is only carried using the physical uplink shared channel (PUSCH) so that the resulting control signaling effort renders scalable sporadic trafﬁc (e.g., several hundred nodes in the cell) infeasible. By contrast, in our design a data section is introduced between synchronous PUSCH and standard PRACH, called DPRACH (Data PRACH) supporting asynchronous data transmission [1]. Clearly, by doing so, sporadic trafﬁc is removed from standard uplink data pipes resulting in drastically reduced signaling overhead and complexity. In addition, this would improve operational capabilities and network performance as well as user experience and life time of autonomous MTC nodes [2], [3]. Waveform design in this context is a very timely and important topic [4], [5], [1]. Of particular importance is also the line of work in the EU projects METIS (www.metis2020.eu) and 5GNOW (www.5gnow.eu). We assume that each D-PRACH’s data resource contains only a very few number of subcarriers (about 5-20 subcarriers). In addition, in a 5G system, we can expect that there is a massive number of MTC devices, which will concurrently employ these data resources in an uncoordinated fashion. In the simplest approach, the D-PRACH uses the guard bands between PRACH and PUSCH, which is the focus of this paper2. We show that waveform design in such a setting is necessary since the OFDM waveform used in LTE cannot handle the highly asynchronous access of different devices with possible negative delays or delays beyond the cyclic preﬁx (CP). Clearly, guards could be introduced between the individual (small) data sections and to the PUSCH which, though, makes the approach again very inefﬁcient. Our results indeed show that up to four subcarriers can be obtained compared to a standard 4G OFDM setting. For waveform design, we propose a bi-orthogonal frequency division multiplexing (BFDM) based approach where we replace orthogonality of the set of transmit and receive pulses with bi-orthogonality, i.e., they are pairwise (not individually) orthogonal. Thus, there is more ﬂexibility in designing the transmit prototype pulse (or waveform), e.g., in terms of side-lobe suppression and',\n",
       " '1412.1587': 'Let K ⊂Rn be a convex body, namely a compact convex set with a non-empty interior. Our main result is: Theorem 1 Let f : Rn →R be deﬁned for θ ∈Rn by f(θ) = log \\x12Z x∈K exp(⟨θ, x⟩)dx \\x13 . (1) Then the Fenchel dual f ∗: int(K) →R, deﬁned for x ∈int(K) by f ∗(x) = supθ∈Rn⟨θ, x⟩−f(θ), is a (1 + εn)n-self-concordant barrier on K, with εn ≤100 p log(n)/n, for any n ≥80. In Section 2 we recall the deﬁnition of a ν-self-concordant barrier and its importance in mathematical optimization. We give another point of view on f ∗in Section 3, where we show that it corresponds to the negative entropy of a speciﬁc element in a canonical exponential family for K. For this reason we refer to f ∗as the entropic barrier for K. Finally, we prove Theorem 1 in Section 4. Technical lemmas on log-concave distributions are gathered in Section 5, where in particular we derive the sharp bound EX3 ≤2 for a real isotropic log-concave random variable X. ∗Microsoft Research and Princeton University; sebubeck@microsoft.com. †Weizmann Institute of Science; roneneldan@gmail.com. 1  2 Context and related work For a C3-smooth function g : Rn →R, denote by ∇2g[·, ·] its Hessian which we understand as a bilinear form over Rn. Likewise, by ∇3g[·, ·, ·] we denote its third derivative tensor. We ﬁrst recall the deﬁnition, introduced in Nesterov and Nemirovski [1994], of a self-concordant barrier. Deﬁnition 1 A function g : int(K) →R is a barrier for K if g(x) −−−→ x→∂K +∞. A C3-smooth convex function g : int(K) →R is self-concordant if for all x ∈int(K), h ∈Rn, ∇3g(x)[h, h, h] ≤2(∇2g(x)[h, h])3/2. (2) Furthermore it is ν-self-concordant if in addition for all x ∈int(K), h ∈Rn, ∇g(x)[h] ≤ p ν · ∇2g(x)[h, h]. (3) Self-concordant barriers are central objects in the theory of Interior Point Methods (IPMs). The latter class of algorithms has revolutionized mathematical optimization, starting with Karmarkar [1984]. Roughly speaking, an IPM minimizes the linear function x ∈K 7→⟨c, x⟩(for some given c ∈Rn) by tracing the central path (x(t))t∈(0,+∞) of a self-concordant barrier g for K, where x(t) ∈argminx⟨c, x⟩+ 1 tg(x). The key property of ν-self-concordant barriers is that a step of Newton’s method on the function x 7→⟨c, x⟩+ 1 tg(x) allows to move from x((1 −1/√ν)t) to (approximately) x(t), see e.g. Nesterov [2004] for more details. In other words in O(√ν) steps of Newton’s method on g one can approximately minimize a linear function on K. From a theoretical point of view, one of the most important results in the theory of IPM is Nesterov and Nemirovski’s construction of',\n",
       " '1011.3516': 'Relationships between information theory and statistical physics have been widely recognized in the last few decades, from a wide spectrum of aspects. These include conceptual aspects, of parallelisms and analogies between theoretical principles in the two disciplines, as well as technical aspects, of mapping between mathematical formalisms in both ﬁelds and borrowing analysis techniques from one ﬁeld to the other. One example of such a mapping, is between the paradigm of random codes for channel coding and certain models of magnetic materials, most notably, Ising models and spin glass models (see, e.g., [1],[11],[13],[14], and many references therein). Today, it is quite widely believed that research in the intersection between information theory and statistical physics may have the potential of fertilizing both disciplines. This paper is more related to the former aspect mentioned above, namely, the relationships between the two areas in the conceptual level. However, it has also ingredients from the second aspect. In particular, let us consider two questions in the two ﬁelds, which at ﬁrst glance, may seem completely unrelated, but will nevertheless turn out later to be very related. These are special cases of more general questions that we study later in this paper. The ﬁrst is a simple question in statistical mechanics, and it is about a certain extension of a model described in [8, page 134, Problem 13]: Consider a one–dimensional chain of n connected elements (e.g., monomers or whatever basic units that form a polymer chain), arranged along a straight line (see Fig. 1), and residing in thermal equilibrium at ﬁxed temperature T0. The are two types of elements, which will be referred to as type ‘0’ and type ‘1’. The number of elements of each type x (with x being either ‘0’ or ‘1’) is given by n(x) = nP(x), where P(0) + P(1) = 1 (and so, n(0) + n(1) = n). Each element of each type may be in one of two diﬀerent states, labeled by ˆx, where ˆx also takes on the values ‘0’ and ‘1’. The length and the internal energy of an element of type x at state ˆx are given by d(x, ˆx) and ǫ(ˆx) (independently of x), respectively. A contracting force λ < 0 is applied to one edge of the chain while the other edge is ﬁxed. What is the minimum amount of mechanical work W that must be carried out by this force, along an isothermal process at temperature T0, in order to shrink the chain from its original length nD0 (when no force was applied) into a shorter length, nD, where D < D0 is a given constant? type ‘1’ type ‘0’ d(1, 1) d(0, 0) λ nD d(0, 1) d(1, 0) Figure 1. A chain with various types of elements and various lengths. The second question is in information theory. In particular, it is the classical  A statistical–mechanical view on source coding 3 problem of lossy source coding, and some',\n",
       " '1801.06700': 'Conversational agents - including chatbots and personal assistants - are becoming increasingly ubiquitous. In 2016, Amazon proposed an international university competition with the goal of building a socialbot: a spoken conversational agent capable of conversing with humans on popular topics, such as entertainment, fashion, politics, sports, and technology.3 This article describes the experiments by the MILA Team at University of Montreal, with an emphasis on reinforcement learning. Our socialbot is based on a large-scale ensemble system leveraging deep learning and reinforcement learning. The ensemble consists of deep learning models, template-based models and external API webservices for natural language retrieval and generation. We apply reinforcement learning — including value function and policy gradient methods — to intelligently combine an ensemble of retrieval and generation models. In particular, we propose a novel off-policy model-based reinforcement learning procedure, which yields substantial improvements in A/B testing experiments with real-world users. On a rating scale 1−5, our best performing system reached an average user score of 3.15, while the average user score for all teams in the competition was only 2.92.4 Furthermore, our best performing system averaged 14.5−16.0 turns per conversation, which is signiﬁcantly higher than all other systems. 1School of Computer Science, McGill University. 2CIFAR Fellow. 3See https://developer.amazon.com/alexaprize. 4Throughout the semi-ﬁnals, we carried out several A/B testing experiments to evaluate different variants of our system (see Section 5). The score 3.15 is based on the best performing system in these experiments. 31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA. arXiv:1801.06700v1  [cs.CL]  20 Jan 2018  As shown in the A/B testing experiments, a key ingredient to achieving this performance is the application of off-policy deep reinforcement learning coupled with inductive biases, designed to improve the system’s generalization ability by making a more efﬁcient bias-variance tradeoff. 2 System Overview Early work on dialogue systems [Weizenbaum, 1966, Aust et al., 1995, McGlashan et al., 1992, Simpson and Eraser, 1993] were based mainly on states and rules hand-crafted by human experts. Modern dialogue systems typically follow a hybrid architecture, which combines hand-crafted states and rules with statistical machine learning algorithms [Suendermann-Oeft et al., 2015]. Due to the complexity of human language, however, it is impossible to enumerate all of the states and rules required for building a socialbot capable of conversing with humans on open-domain, popular topics. In contrast to such rule-based systems, our core approach is built entirely on statistical machine learning. We believe that this is the most plausible path to artiﬁcially intelligent conversational agents. The system architecture we propose aims to make as few assumptions as possible about the process of understanding and generating natural language. As such, the system utilizes only a small number of hand-crafted states and rules. Meanwhile, every system component has been designed to be optimized (trained) using machine learning algorithms. By optimizing these',\n",
       " '1806.01337': 'Stochastic gradient descent (SGD) and its minibatch variants are ubiquitous in virtually all learning tasks [1, 13]. SGD enables deep learning to scale to large datasets, decreases training time and improves generalization. However, there are many problems where there exists a large amount of information but the data is packaged in a small number of information-rich samples. These problems cannot take full advantage of the beneﬁts of SGD as the number of training samples is limited. Examples of these include learning from high resolution medical images, satellite imagery and GIS data, cosmological simulations, lattice simulations for quantum systems, and many others. In all of these situations, there are relatively few training samples, but each training sample carries a tremendous amount of information and can be intuitively considered as being comprised of many independent subsamples. Since the beneﬁts of SGD require the existence of a large number of samples, efﬁciently employing these techniques on the above problems requires careful analysis of the problem in order to restructure the information-rich data samples into smaller independent pieces. This is not always a straightforward procedure, and may even be impossible without destroying the structure of the data [27, 29]. This motivates us to introduce backdrop, a new technique for stochastic gradient optimization which does not require the user to reformulate the problem or restructure the training data. In this method, the loss function is unmodiﬁed and takes the entirety of each sample as input, but the gradient is computed stochastically on a fraction of the paths in the backpropagation pipeline. A closely related class of problems, which can also beneﬁt from backdrop, is optimization objectives deﬁned via non-decomposable loss functions. The rank statistic, a differentiable approximation of the ROC AUC is an example of such loss functions [10]. Here again, minibatch SGD optimization is not viable as the loss function cannot be well approximated over small batch sizes. Backdrop can also be applied in these problems to signiﬁcantly improve generalization performance. Main contributions. In this paper, (a) we establish a means for stochastic gradient optimization which does not require a modiﬁcation to the forward pass needed to evaluate the loss function and is Preprint. Work in progress. arXiv:1806.01337v1  [stat.ML]  4 Jun 2018  particularly useful for problems with non-trivial subsample structure or with non-decomposable loss. (b) We explore the technique empirically and demonstrate the signiﬁcant gains that can be achieved using backdrop in a number of synthetic and real world examples. (c) We introduce the “multiscale GP texture generator”, a ﬂexible synthetic texture generator with clear hierarchical subsample structure which can be used as a benchmark to measure performance of networks and optimization tools in problems with hierarchical subsample structure. The source code for our implementation of backdrop and the multi-scale GP texture generator is available at github.com/dexgen/backdrop. 1.1 Related work Non-decomposable loss optimization. The study of optimization problems with complex nondecomposable loss functions has been the subject',\n",
       " '1805.10528': 'Human language comprehension is an important and challenging task for machines that requires semantic understanding and reasoning over clues. The goal of this general task is to read and comprehend the given document and answer queries. Recently, the cloze-style reading comprehension problem has received increasing attention from the NLP community. A cloze-style query (Taylor, 1953) is a short passage of text containing a blank part, which we must ﬁll with an appropriate token based on the reading and understanding of a related document. The recent introduction of several large-scale datasets of cloze-style question answering made it feasible to train deep learning systems for such task (Onishi et al., 2016; Hill et al., 2015; Hermann et al., 2015). Various deep learning models have been proposed and achieved reasonable results for this task (Yang et al., 2017; Dhingra et al., 2017; Munkhdalai and Yu, 2017; Cui et al., 2017; Trischler et al., 2016; Kadlec et al., 2016; Chen et al., 2016; Cui et al., 2016; Sordoni et al., 2016). The success of recent models are mostly due to two factors: 1) Attention mechanisms (Bahdanau et al., 2014), which allow the model to sharpen its understanding and focus on important and appropriate subparts of the given context; 2) Multi-hop architectures, which read the document and/or the query in multiple passes, allowing the model to re-consider and refocus its understanding in later iterations. Intuitively, both attention mechanisms and multi-hop reading fulﬁll the necessity of considering the dependency aspects of the given document and the query. Such a consideration enables the model to pay attention to the relevant information and ignore the irrelevant details. Human language comprehension is often performed by jointly reading the document and query to leverage their dependencies and stay focused in reading and avoid losing relevant contextual information. Current state-of-the-art models also attempt to capture this by using the reading of the query to guide the reading of the document (Yang et al., 2017; Dhingra et al., 2017), or using the memory of the document to help interpret the query (Munkhdalai and Yu, 2017). However, these systems only consider uni-directional dependencies. Our primary hypothesis is that we can gain further improvements by considering bidirectional dependencies. In this paper, we present a novel multi-hop neural network architecture, called Dependent Gated Reading (DGR), which addresses the aforementioned gap and performs dependent reading in both directions. Our model begins with an initial reading step that encodes the given query and document, followed by an iterative reading module (multi-hop) that employs soft attention to extract the most relevant information from the document and query encodings to augment each other’s representation, which are then passed arXiv:1805.10528v2  [cs.CL]  1 Jun 2018  Accepted as a long paper at COLING 2018 onto the next iteration of reading. Finally, the model performance a ﬁnal round of attention allocate and aggregate to rank all possible candidates and make prediction. We',\n",
       " '1807.08333': 'Impressive improvement has been made in the past two years to address Temporal Action Localization (TAL) in untrimmed videos [23,15,46,67,68,51,50,36,22,73,17, These methods were proposed for the fully-supervised setting: the model training requires the full annotation of the ground truth temporal boundary (start time and end time) for each action instance. However, untrimmed videos are usually very long with substantial background content in time. Therefore, manually annotating temporal boundaries for a new large-scale dataset is very expensive Source code and models can be found at https://github.com/zhengshou/AutoLoc arXiv:1807.08333v2  [cs.CV]  16 Dec 2018  2 Z. Shou, H. Gao, L. Zhang, K. Miyazawa, S.-F. Chang Supervision Minimize OIC loss (Outer-Inner-Contrastive) =  avg(outer) – avg(inner) Training videos time Testing videos time Weakly-supervised  Temporal Action  Localization Model Video-level label only: CliffDiving Action classification  over time Predict both (1) action  class and (2) boundary  (start time and end time) Class Activation Sequence (CAS):  CliffDiving Fig. 1. We study the weakly-supervised temporal action localization problem: during training we only have videos with the video-level labels, but during testing we need to predict both (1) the action class and (2) the temporal boundary of each action instance. In order to obtain the segment-level supervision for training the action localization model to predict the boundary directly, we design a novel Outer-Inner-Contrastive (OIC) loss based on the action Class Activation Sequence. We denote the predicted action segment boundary as the inner boundary. The outer boundary is obtained by extending the inner boundary to include its surrounding area. A desirable boundary prediction should have high activations in the inner green area but low activations in the outer red area. Consequently, the OIC loss can be used to approximately determine the needed segment-level supervision for training the localization model and time-consuming [72], and thus might prohibit applying the fully-supervised methods to the new domains that lack enough training data with full annotations. This motivates us to develop TAL methods that require signiﬁcantly fewer ground truth annotations for training. As illustrated in Fig. 1, in this paper we focus on the following scenario: during training, we only have the video-level labels, which are much easier to collect , compared to the boundary annotations; during testing, we still aim to predict both (1) the action class and (2) the temporal boundary (i.e. start time and end time) of each action instance. We refer this scenario as the weakly-supervised setting that this paper works on. Recently, a few methods have been proposed to tackle TAL in such a weaklysupervised setting. UntrimmedNet [64] and Hide-and-Seek [56] achieve the stateof-the-art performances and carry out the localization in a similar manner. Given a training video, several segments are randomly sampled and are fed into a network together to yield a video-level class prediction',\n",
       " '1808.07931': 'Aspect-based sentiment analysis (ABSA) is a way to systematically mine opinions given a body of text. Unlike regular sentiment analysis, ABSA allows for far more granular levels of opinion mining. For example, one common application of ABSA is to dissect product or service reviews and determine sentiment on sometimes unrelated aspects, such as a quality or price. Rarely are product reviews as simple as good or bad. They are nuanced with conﬂicting positive and negative opinions based on what aspect of the product is being reviewed. We ﬁnd the ﬁeld of ﬁnance to be a signiﬁcantly under-explored domain for ABSA. Similar to product reviews, ﬁnancial investment opportunities are commonly written as free-form essays; these write-ups are generally nuanced with positive and negative opinions on speciﬁc aspects of a certain investment opportunity. Being able to identify these topics and to subsequently determine the associated sentiment could be beneﬁcial in downstream models to auto-summarize predeﬁned aspects, allowing users to obtain structured information from an unstructured set of write-ups. Another use case could be to employ the aspectbased sentiments as features to classify future performance or volatility of investment ideas. The under-explored nature of ﬁnancial related ABSA also manifests itself in a lack of large, highquality datasets on which to train. Current ABSA techniques and model architectures do not accurately scale down to small data sizes, presenting an opportunity for transfer learning that can leverage larger, domain-related datasets. Successful inductive transfer learning allows these larger datasets that have no sentiment or aspect annotations to be used to improve results on the main ABSA task. 2 Related Work ABSA is not a new idea. There have been extensive bodies of work, starting from the original rulebased methods (Thet et al., 2010) to more recent deep learning methods (Wang and Liu, 2015). In general, the state-of-the-art consists of a few subtasks. First, a model identiﬁes the entity and its aspects. Then, sentiment analysis is performed on the body of text before combining the two tasks. Sentiment analysis for ﬁnance – without considering aspects – has also been explored (Cortis et al., 2017). Unlike ABSA, more general sentiment analysis cannot determine if a statement is positive or negative by each aspect – it must choose an overall sentiment. Until recently, it has been difﬁcult to perform arXiv:1808.07931v1  [cs.CL]  23 Aug 2018  the kind of analysis in Wang and Liu (2015) in the ﬁnancial domain due to both a lack of wellannotated datasets and the necessary quantity of data. Unlike the larger product review dataset (Pontiki et al., 2016) used in Wang’s study, we speculate it would be expensive to annotate as many examples for the ﬁnancial domain, as it would require extensive domain expertise. However, as part of the companion proceedings for WWW ’18 conference, Maia et al. (2018) released a',\n",
       " '0708.4311': 'FAILED',\n",
       " '1407.0088': 'Over the last decade, the problem of high-dimensional data inference from limited observations has received signiﬁcant consideration, with many applications arising from signal processing, computer vision, and machine learning. In these problems, it is not unusual that the data often lies in hundreds of thousands or even million dimensional spaces while the number of collected samples is suﬃciently smaller. Exploiting the fact that data arising in real world applications often has very low intrinsic complexity and dimensionality, such as sparsity and low-rank structure, recently developed statistical models have been shown to perform accurate estimation and inference. These models often require solving the following optimization with the constraint that the model parameter is sparse: min w F(w) subject to ∥w∥0 ≤k. (1) Here, F(w) is the objective function that measures the model discrepancy, ∥w∥0 is the ℓ0-norm that counts the number of non-zero elements of w, and k is a parameter that controls the sparsity of w. In this paper, we study a more uniﬁed optimization that can be applied to a broader class of sparse models. First, we deﬁne a more general notion of sparsity. Given the set D = {d1, d2, ...} consisting of vectors or matrices di, which we call atoms, we say that the model parameter is sparse if it can be described as a combination of only a few elements from the atomic set D. Speciﬁcally, let w ∈Rn be represented as w = k X i=1 αidi, di ∈D, (2) 1Linear convergence is sometime called exponential convergence 1  where αi are called coeﬃcients of w; then, w is called sparse with respect to D if k is relatively small compared to the ambient dimension n. Here, D could be a ﬁnite set (e.g. D = {ei}n i=1 where ei’s are basic vectors in Euclidean space), or D could be inﬁnite (e.g. D = {uiv∗ i }∞ i=1 where uiv∗ i ’s are unit-norm rank-one matrices). This notion is general enough to handle many important sparse models such as group sparsity and low rankness (see [12], [33] for some examples). Our focus in this paper is to develop algorithms for the following optimization: min w 1 M M X i=1 fi(w) | {z } F (w) subject to ∥w∥0,D ≤k, (3) where fi(w)’s, w ∈Rn, are smooth functions which can be non-convex; ∥w∥0,D is deﬁned as the norm that captures the sparsity level of w. In particular, ∥w∥0,D is the smallest number of atoms in D such that w can be represented by them: ∥w∥0,D = min k {k : w = X i∈T αidi with |T| = k}. (4) Also in (3), k is a user-deﬁned parameter that controls the sparsity of the model. The formulation (3) arises in many signal processing and machine learning problems, for instance, compressed sensing (e.g. [16], [8]), Lasso ([39]), sparse logistic regression, and sparse graphical',\n",
       " '1612.04759': 'We present the probabilistic module interface, which allows encapsulation of complex latent variable models with custom stochastic approximate inference machinery. The modules interface can be seen as a generalization of previously proposed interfaces for “elementary” random procedures in probabilistic programming languages: it does not require the module author to specify a marginal input-output density. Instead, module authors are only obligated to (i) provide a way to stochastically “regenerate” traces of the internal latent variables, subject to constraints on the module’s output, and (ii) provide a way to calculate a weight for this regeneration. We show this is sufﬁcient for constructing sound approximate inference algorithms over networks of modules, including a Metropolis-Hastings procedure that can be seen as the module-level analogue of the single-site Metropolis-Hastings procedures that are commonly used with “lightweight” implementations of probabilistic programming languages [1], [2]. This paper illustrates module networks by deﬁning the mathematical interface and providing an example application to linear regression with outliers. This application contains two modules: (i) a complex prior over a binary “model selection” variable determining the prior prevalence of outliers, using a learned bottom-up network for regeneration, and (ii) a linear regression model with binary outlier indicators, using sequential Monte Carlo for regeneration of the outlier indicators (thereby avoiding an exponential sum over all possible indicator settings). 2 The probabilistic module interface In several existing probabilistic programming systems1 [1], [5], [6], [7], probabilistic modeling primitives implement a simulator procedure (simulate) which samples outputs z given inputs x from a distribution p(z; x) and log-density evaluation procedure (logpdf), which evaluates log p(z; x). Together, these two procedures enable inference programs to run valid approximate inference algorithms such as MCMC and SMC over the composite probabilistic model. This interface is summarized in Figure 2a. 1Univariate versions of this interface are used in [3] and [4] arXiv:1612.04759v2  [cs.AI]  6 May 2017  (a) (b) (c) Figure 1: Encapsulating latent variables in a probabilistic model into a probabilistic module: (a) shows the original probabilistic model, with the latent variables uc 1, uc 2, uc 3 that are to be abstracted away in a dashed box. (b) shows the model in which the latent variables uc 1, uc 2, uc 3 have been made into the internal auxiliary variables u := (uc 1, uc 2, uc 3) of a probabilistic module with output z := c and input x := (a, b). (c) shows the declarative semantics of the resulting module network. We propose a stochastic generalization of this interface, called the probabilistic modules interface, that replaces logpdf with a stochastic generalization called regenerate. Unlike the simulate and logpdf interface, the probabilistic modules interface, summarized in Figure 2b, is able to represent probabilistic computations u, z ∼p(u, z; x) that involve internal ‘auxiliary’ random variables u that cannot be exactly marginalized out to compute the log-density p(z; x) = P u p(u, z; x). This is made possible by implementing a sampler',\n",
       " '1802.09405': 'Efﬁcient processing of graph-structured data (e.g., citation networks) has a range of different applications, going from bioinformatics to text analysis and sensor networks, among others. Of particular importance is the design of learning methods that are able to take into account both numerical characteristics of each node in the graph and their inter-connections [1]. While graph machine learning techniques have a long history, recently we witness a renewed interest in models that are deﬁned and operate directly in the graph domain (as compared to a Euclidean space), instead of including the graph information only a posteriori in the optimization process (e.g., through manifold regularization techniques [2]), or in a pre-processing phase via graph embeddings [3]. Examples of native graph models include graph linear ﬁlters [4], their kernel counterparts [5], and graph neural networks (GNNs) [6]. GNNs are particularly interesting because they promise to bring the performance of deep learning models [7] to graphbased domains. In particular, convolutional neural networks (CNNs) are nowadays the de-facto standard for processing image data. CNNs exploit the image structure by performing spatial convolutions (with a limited receptive ﬁeld) on the image, thus increasing parameter sharing and lowering their complexity. A number of authors recently have explored the possibility of extending CNNs to the graph domain by several generalizations of the convolution operator, a trend which has been generically called ‘geometric deep learning’ [6]. In one of the ﬁrst proposals [8], graph Fourier transform was used at every layer of the network to perform ﬁltering operations in a graph-frequency domain. However, this approach was not scalable as it scaled linearly with the size of the graph. Defferard et al. [9] extended this approach by using polynomial ﬁlters on the frequency components, which can be rewritten directly in the graph domain, avoiding the use of the graph Fourier transform. A further set of modiﬁcations was proposed by Kipf and Welling [10] (described more in depth in Section II), resulting in a generic graph convolutional network (GCN). GCN has been successfully applied to several real-world scenarios, including semi-supervised learning [10], matrix completion [11], program induction [12], modeling relational data [13], and several others. Like most neural networks, GCNs interleave linear layers, wherein information is adaptively combined according to the topology of the graph, with nonlinear activation functions that are applied element-wise. The information over the nodes can then be combined to obtain a graph-level prediction, or kept separate to obtain a node-speciﬁc inference (e.g., predictions on unlabeled nodes from a small set of labeled ones). Most literature for GCNs has worked with very simple choices for the activation functions, such as the rectiﬁed linear unit (ReLU) [10]. However, it is well known that the choice of the function can have a large impact on the ﬁnal performance of the neural network. Particularly, there is a large literature for standard neural networks on the design of ﬂexible schemes for adapting the activation functions',\n",
       " '1707.06480': 'Recent advances in neural language modeling (NLM) are connected with character-aware models (Kim et al., 2016; Ling et al., 2015b; Verwimp et al., 2017). This is a promising approach, and we propose the following direction related to it: We would like to make sure that in the pursuit of the most ﬁne-grained representations one has not missed possible intermediate ways of segmentation, e.g., by syllables. Syllables, in our opinion, are better supported as linguistic units of language than single characters. In most languages, words can be naturally split into syllables: ES: el par-la-men-to a-po-y´o la en-mien-da RU: par-la-ment pod-der-ˇzal po-prav-ku (EN: the parliament supported the amendment) Based on this observation, we attempted to determine whether syllable-aware NLM has any advantages over character-aware NLM. We experimented with a variety of models but could not ﬁnd any evidence to support this hypothesis: splitting words into syllables does not seem to improve the language modeling quality when compared to splitting into characters. However, there are some positive ﬁndings: while our best syllable-aware language model achieves performance comparable to the competitive character-aware model, it has 18%–33% fewer parameters and is 1.2–2.2 times faster to train. 2 Related Work Much research has been done on subword-level and subword-aware1 neural language modeling when subwords are characters (Ling et al., 2015b; Kim et al., 2016; Verwimp et al., 2017) or morphemes (Botha and Blunsom, 2014; Qiu et al., 2014; Cotterell and Sch¨utze, 2015). However, not much work has been done on syllable-level or syllable-aware NLM. Mikolov et al. (2012) show that subword-level language models outperform character-level ones.2 They keep the most frequent words untouched and split all other words into syllable-like units. Our approach differs mainly in the following aspects: we make predictions at the word level, use a more linguistically sound syllabiﬁcation algorithm, and consider a variety of more advanced neural architectures. We have recently come across a concurrent paper (Vania and Lopez, 2017) where the authors systematically compare different subword units (characters, character trigrams, BPE (Sennrich et al., 2016), morphemes) and different representation models (CNN, Bi-LSTM, summation) on languages with various morphological typology. However, they do not consider syllables, and they experiment with relatively small models on small data sets (0.6M–1.4M tokens). 1Subword-level LMs rely on subword-level inputs and make predictions at the level of subwords; subword-aware LMs also rely on subword-level inputs but make predictions at the level of words. 2Not to be confused with character-aware ones, see the previous footnote. arXiv:1707.06480v1  [cs.CL]  20 Jul 2017  unconstitutional conditions on stack of two LSTMs word vector Highway layers (optional) Syllable-aware word embedding model Syllable embeddings un con sti tu tional imposes unconstitutional conditions Figure 1: Syllable',\n",
       " '1307.1960': 'A. Structural Health Monitoring systems Over the past decade, more than 5 million commercial buildings [1], 130 million housing units [2], and 0.6 million bridges [3] have been built in the United States. In any structure, damage caused over time by continuous use is inevitable. In order to maintain safely operable structures for as long as possible, periodic inspections are a must. When damage is detected, some structures can be repaired, while others must be taken out of service immediately. Due to the quantity, size, and complexity of structures, the task of inspection is labor intensive, costly, and time consuming. Consequently, there have been signiﬁcant efforts in the structural engineering community to automate this process. Structural Health Monitoring (SHM) systems are precisely designed to address this issue. Although the details of SHM systems vary, some features are shared among many methods [4], [5]. A typical SHM system monitors an in-service structure in real-time. To do so, it makes use of a network of sensors installed on the structure to collect vibration data for damage detection. This may include strain data, acceleration data, velocity data, or displacement data. The acquired data from each sensor is transmitted over a network to the central data repository where JYP and ACG are with the Department of Electrical Engineering and Computer Science at the University of Michigan. Email: jaeypark,annacg@umich.edu. MBW is with the Department of Electrical Engineering and Computer Science at the Colorado School of Mines. Email: mwakin@mines.edu. This work was partially supported by NSF grants CCF1161233 and CIF-0910765, AFOSR grant FA9550-09-1-0465, and NSF CAREER grant CCF-1149225. damage detection algorithms are run to detect, localize, or classify possible damage in the structure. An important part of damage detection is a process called modal analysis. This process is used to infer properties such as the modal frequencies, mode shapes, and modal damping ratios of the structure. Such modal parameters describe the vibrational characteristics when external forces such as wind, earth quakes, or vehicle loadings are applied to the structure. For example, if a structure is forced to vibrate close to a modal frequency, the shape of the structure’s vibration will be dominated by the corresponding mode shape. This vibration will eventually die out in the absence of external force, and the modal damping ratio will determine rate of decay. Many damage detection algorithms make use of modal parameters to detect, localize, and assess the severity of damage. Brieﬂy speaking, these methods rely on the notion that when a structure is damaged, its modal parameters will change. Assuming that one has the modal parameters from the time when the structure was healthy, these can be compared to the current estimates of modal parameters to judge whether or not damage has occurred. A comprehensive survey of damage detection methods is presented in [4], [5]. B. Wireless SHM systems In the early designs of SHM systems, sensors were linked via coaxial cables',\n",
       " '1401.3737': 'Coordinate Descent (CD) algorithms are becoming increasingly important for solving machine learning tasks. They have superseded other gradient-based approaches such as stochastic gradient descent (SGD) for solving certain types of problems, such as training of linear support vector machines (SVMs) as well as LASSO regression and other L1 regularized learning problems [8, 15, 6]. There is growing interest in machine learning applications of CD in the ﬁeld of optimizaation, see e.g. [24, 27]. Natural competitors for solving large scale convex problems are (trust region/pseudo) Newton methods and (stochastic) gradient descent. In contrast 1  to these approaches, CD needs only a single component of the full gradient per iteration and is thus particularly eﬃcient if such a partial derivative is much faster to compute than the gradient vector. This is often the case in machine learning problems. The diﬀerence in computational eﬀort per step can be huge, diﬀering by a factor as big as the number of data points. Stochastic gradient descent (SGD) has the very same advantage over (plain) gradient descent. An ubiquitous problem of SGD is the need to set a learning rate parameter, possibly equipped with a cooling schedule. This is a cumbersome task, and success of a learning method—at least within reasonable computational limits—can well depend on this choice. CD algorithms do also have parameters. The most generic such parameter is the frequency of choosing a coordinate for descent, e.g., in randomized CD algorithms. This parameter is not obvious from a machine learning perspective because uniform coordinate selection is apparently dominant in all kinds of applications of CD. This is diﬀerent in the optimization literature on CD where non-uniform distributions have been considered. This literature also oﬀers a few criteria for choosing selection probabilities (see e.g. [24, 28] and refer to the more detailed discussion in section 2). Interestingly these recommendations are all static in nature, i.e., the selection probabilities are set before the start of the optimization run and are then kept constant. This proceeding may be suitable for simple (i.e., quadratic) objectives, however, it is diﬃcult to propose good settings of the parameters for realistic optimization scenarios. In contrast, for SGD there have been a number of proposals for adapting such parameters online during the optimization run for optimal progress (see [30] and references therein). This does not only eﬀectively remove the need to adjust parameters to the problem instance before the run, which is anyway often diﬃcult due to missing information. It also allows to react to changing requirements during the optimization run. Similarly, trust region methods and many other optimization strategies take online information into account for adapting their parameters to the local characteristics of the problem instance they are facing. The present paper proposes an online adaptation technique for the coordinate selection probability distribution of CD algorithms. We refer to this technique as Adaptive Coordinate Frequencies (ACF), and to the resulting coordinate descent scheme as ACF-CD. We have',\n",
       " '1806.09202': 'The personalization of content online can lead to opinion bubbles and polarization [Flaxman et al., 2016]. As a user clicks on content of a particular type (e.g., links from liberal media outlets), the content delivery system learns these preferences, and in the future presents the user with more items of that type. In doing so, many content delivery engines polarize completely, displaying a very narrow range of content to each user. This can lead to polarization and the formation of opinion bubbles in which people are only exposed to content that matches their pre-existing beliefs [Matakos et al., 2017], and can lead people to mistrust information that does not match their opinion [H. Ribeiro et al., 2017]. Personalization leading to polarization has been observed in social media feeds [Flaxman et al., 2016], product recommendation [De Myttenaere et al., 2015], online advertising [Datta et al., 2015] and other media that pervades the internet. Moreover, diverse search results might be desirable from the point-of-view of user satisfaction [Celis and Tekriwal, 2017]. Our goal in this work is to show that show that an alternative exists: Balanced content delivery systems are feasible, and one can even give the user the information and freedom to control their balance of content. In this demo, as an example, we take news search in the US diversiﬁed across liberal and conservative content. Balanced News is our prototype 1 2 3 aimed at demonstrating novel bandit-based constrained personalization algorithms that can be used for delivering diverse content while 1Corresponding author: L. Elisa Celis. 2Demo video: http://y2u.be/Zvum0t1EYtQ 3Demo website: https://bit.ly/2H1vroP Figure 1: Balanced news search demo for a liberal-favoring user. A traditional system (unﬁltered news) on the left would learn about the user and only display liberal-favoring articles. Our constrained system (balanced news) on the right similarly learns the user preferences, but still displays some conservative articles in order to provide more diversiﬁed content. (Liberal-favoring articles in blue, conservative-favoring articles in red.) still allowing for personalization. A feature of this recent work is that the algorithms are scalable despite constraints, allowing for real-time systems to be balanced in this manner. The algorithms optimize content in the presence of constraints, that is, limits on how much or how little content of a particular type is displayed. We consider news search in the US and classify the content into two types: liberal-favoring and conservative-favoring. Figure 1 shows a screenshot of the demo website. For showcasing the types that each article belongs to, articles belonging to the liberal type have blue hyperlinks, whereas articles belonging to the conservative type have red hyperlinks. There are two news feeds shown in the demo – the unﬁltered feed that runs a standard Bandit algorithm used for personalization, and the balanced feed that runs the constrained Bandit algorithm from [Celis and Vishnoi, 2017; Celis',\n",
       " '1801.05931': 'The technological developments and the availability of a number of data sources have evolved the data into ‘Big Data’, where the meaning of ‘Big’ in ‘Big Data’ is continuously changing because of increasing of size of datasets. Big data has multiple aspects, like, volume, velocity, variety and veracity etc., and one aspect, namely, volume, i.e., size of datasets have posed a challenge to the machine learners to train the models over these large datasets. These problems which can be called as large-scale or big data problems, have large number of data points or large number of features in each data point, or both, which lead to slow training of models. So nowadays, the major challenge is to develop eﬃcient and scalable learning algorithms for dealing with big data problems [33, 3, 5]. The training time of models have two major components [28] as: training time = time to access data + time to process data. (1) As it is known that for processing any data or running any program, it should be ﬁrst brought into memory, more precisely into RAM (Random Access Memory), from hard disk. The time taken in brining the data or program from hard disk into memory is called access time. Access time has, further, three components, namely, seek time (it is the time taken by the reading head to move from current position up to the track containing the data), rotational latency time (it is the time taken by the reading head from the current position to reach up to the sector/block containing the data) and transfer time (it is the time taken to transfer data from sector/block over the disk to memory). Moreover, data is not read content wise rather block-wise, where each block can have multiple sectors. Now, it is interesting to note that for data stored on the contiguous memory or in the close proximity, has lesser data access time as compared with the data dispersed far away from each other. This is due to lesser seek, latency and transfer times. In case of SSD (Solid State Disk) and RAM (Random Access Memory), there are no seek and latency times because they do not have moving parts and they are based on direct access mechanism, but transfer time still plays its role. Since data are read/written block-wise so for contiguous data access, there would be one or two transfer times but dispersed data access would require more number of transfer times. Moreover, cache memory strategies also favor the contiguous memory access and make it faster as compared to dispersed data access. Thus contiguous data access time is faster than dispersed data access, in all the cases whether data is stored on RAM, SSD or HDD. But the diﬀerence in access time would be more prominent for HDD. The second component of training time is processing (learning) time which is the time taken by the CPU (Central Processing Unit) to process the data to solve for model parameters. Due',\n",
       " '1711.11556': 'With the exciting vision of autonomous driving, semantic segmentation of urban scenes, as a key module, has gained increasing attention from both academia and industry. However, collecting and labeling training data for semantic segmentation task is a laborious and expensive process, as it requires per-pixel annotation. This issue becomes even more severe with the surge of deep learning techniques, which usually require a large amount of training data. Therefore, it becomes much desired to exploit low cost ways to acquire data for semantic segmentation. One way that becomes recently prevalent is to collect photo-realistic synthetic data from video games, where pixel-level annotation can be automatically generated at a much lower cost. For example, Richter etal.[32] constructed a large scale synthetic urban scene dataset for semantic segmentation from the GTAV game. While the cost of acquiring training data and annotation is largely reduced, synthetic data still suffers from a considerable domain difference from the real data, which usually leads to a signiﬁcant performance drop when applying the segmentation model to real world urban scenes [17, 49]. The main reasons are two-fold. First, from the perspective of representation, since the model is trained on synthetic images, the convolutional ﬁlters tend to overﬁt to synthetic style images, making them incompetent to extract informative features for real images. Second, from the distribution perspective, synthetic and real data suffers a considerable distribution mismatch, which makes the model biased to synthetic domain. To overcome such problems, we propose Reality Oriented ADaptation Networks(ROAD-Net) for semantic segmentation of urban scenes by learning from synthetic data. We address the above two issues respectively by a target guided distillation module for real style orientation, and a spatial-aware adaptation module for real distribution orientation, which are described respectively as follows, • real style orientation: To prevent the segmentation model from overﬁtting to synthetic images, we propose to use the target real images to imitate a pretrained real style model. This can be achieved using the model distillation strategy by enforcing the output from segmentation model similar with the output of a pretrained model. On one hand, this encourages convolutional ﬁlters to ﬁt to the real images through the distillation task. On the other hand, it also enforces the segmentation network to preserve good discriminative for real images by approaching the semantic output from the pretrained model. We refer to it as target guided distillation. • real distribution orientation: To deal with the dis1 arXiv:1711.11556v2  [cs.CV]  7 Apr 2018  Figure 1. Illustration of our Reality Oriented Adaptation networks(ROAD-Net) for semantic segmentation of urban scenes. Our network is built upon conventional semantic segmentation networks, and incorporates a target guided distillation module for real style orientation, and a spatial-aware adaptation module for real distribution orientation. tribution mismatch for semantic segmentation, several recent works [17, 49] applied domain adaptation methods',\n",
       " '1611.06241': 'The Large Hadron Collider (LHC) is the largest and the most powerful particle collider ever built. It was designed and constructed as a joint eﬀort of the international scientiﬁc collaboration of the European Organization for Nuclear Research (CERN) [1, 2]. The whole architecture of the LHC is unique and most of its components were custom manufactured speciﬁcally for this particular application. Consequently, malfunctions and failures of the components usually result in long and costly repairs. This, in turn, aﬀects the availability of the particle beams for physics experiments carried out at the LHC. Therefore, maintenance and faults prevention is critical and dedicated solution named Machine Protection System (MPS) was created. The MPS system comprises many subsystems, including beam and equipEmail addresses: wielgosz@agh.edu.pl (Maciej Wielgosz), skoczen@fis.agh.edu.pl (Andrzej Skocze´n), matej.mertik@um.si (Matej Mertik) ment monitoring, a system to safely stop beam operation and an interlock system providing the glue between these systems. The goal is to ensure a safe operation to the accelerator and to maximise a time when particle beams are delivered to interaction points. One of the most crucial components of the LHC is a set of superconducting magnets which keep the bunches of protons in a right trajectory inside the vacuum beam pipes in the 27 km long accelerator tunnel [1, 2]. A voltage on each of the superconducting magnets in the LHC is measured by dedicated digital voltmeter [3] and sent to the central database. The generated stream of the voltage data is used to monitor performance and detect anomalies in the behaviour of superconducting elements. One of the most dangerous phenomenon, which can take place at any time in a superconducting electrical circuit, is a quench. It occurs when a part of the superconducting cable becomes normally-conducting [4]. The quench may happen at any time randomly and may occur for many reasons. Usually, it is due to a mechaniPreprint submitted to Nuclear Inst. and Methods in Physics Research, A June 26, 2017 arXiv:1611.06241v2  [physics.ins-det]  22 Jun 2017  cal event inside a superconducting cable or coil, related to the release of stresses generated during production, transportation, and assembly of a magnet. Another phenomenon which may lead to a quench is a deposition of energy of particles which escaped from the beam (so called beam losses). When the Quench Protection System (QPS) detects an increased resistance, the huge amount of energy stored in the magnet chain is extracted and dumped into a specially designed resistor. Currently the QPS is the highly dependable system speciﬁcally designed for the LHC. The instruments of this system perform acquisition of total voltage across superconducting elements (magnet coils, bus bars, current leads) and extract resistive component of this voltage. The system [3, 5] requires a number of settings. Two the most important settings are: • resistive voltage threshold at which actuators are triggered when the quench event',\n",
       " '1410.8349': 'Consider the following 2-player cooperative game: Two players toss a coin with each player seeing the outcome of the coin toss of the other player (but not their own). Then, they simultaneously guess the outcome of their own coin toss. The ∗School of Electronic Engineering and Computer Science, Queen Mary, University of London, London, E1 4NS, U.K. Email: rahilbaber@hotmail.com. †School of Sciences, UCLan Cyprus, 7080 Pyla, Cyprus. Email: d.christoﬁdes@uclan.ac.uk ‡School of Electronic Engineering and Computer Science, Queen Mary, University of London, London, E1 4NS, U.K. Email: anh.dang@eecs.qmul.ac.uk §School of Electronic Engineering and Computer Science, Queen Mary, University of London, London, E1 4NS, U.K. Email: s.riis@qmul.ac.uk ¶School of Electronic Engineering and Computer Science, Queen Mary, University of London, London, E1 4NS, U.K. Email: e.vaughan@qmul.ac.uk 1  players win the game if they both guess correctly. Of course, if they both guess at random, then the probability of winning is 1/4. It turns out that the players can use the extra information they have in order to improve the probability of success. For example, if they agree beforehand to follow the strategy ‘guess what you see’ then the probability of success increases to 1/2. We can generalise this game (see Section 2) to guessing games with multiple players in which each player sees the outcome of the coin tosses (or more generally of many-sided dice throws) of other players, according to an underlying digraph. These guessing games [9, 10] emerged from studying network coding problems [1] where the network is multiple unicast, i.e. where each sender has precisely one corresponding receiver who wishes to obtain the sender’s message, and a constrain that only one message can be sent through each channel at a time. A multiple unicast can be represented by a directed acyclic graph with n inputs/outputs and m intermediate nodes. By merging the vertices which represent the senders with their corresponding receiver vertices we can create an auxiliary directed graph which has the nice property that there is no longer any distinction between router, sender, or receiver vertices. Due to the way guessing games are deﬁned, coding functions on the original network can be translated into strategies for the guessing game on the auxiliary graph and vice versa. The performance of the optimal strategy for a guessing game is measured by the guessing number which we will deﬁne precisely in Section 2. One of the ﬁrst applications of guessing games was the disproval in [9] of two conjectures raised by Valiant [11] in circuit complexity in which he asked about the optimal Boolean circuit for a Boolean function. In this paper we provide a counterexample to a conjecture of Christoﬁdes and Markstr¨om given in [3] which states that the optimal strategy for the guessing game of an undirected graph is based on the fractional clique cover number of the graph',\n",
       " '1502.06644': 'A ﬁnite mixture model is a probability law based on a ﬁnite number of probability measures, µ1, . . . , µm, and a discrete distribution w1, . . . , wm. A realization of a mixture model is ﬁrst generated by ﬁrst generating a component at random k, 1 ≤k ≤m, and then drawing from µk. A mixture model can be associated with a probability measure on probability measures, which we denote P. Mixture models are used to model data throughout statistics and machine learning. A primary theoretical question concerning mixture models is identiﬁability. A mixture model is said to be identiﬁable if no other mixture model (of equal or lesser complexity) explains the distribution of the data. Some previous work on identiﬁability considers the situation where the observations are drawn iid from the mixture model, and conditions on µ1, . . . , µm are imposed, such as Gaussianity (Dasgupta and Schulman, 2007; Anderson et al., 2014). In this work we make no assumptions on µ1, . . . , µm. Instead, we assume the observations are grouped, such that realizations from the same group are known to be iid from the same component. We call these groups of samples “random groups.” We deﬁne a random group to be a random collection Xi, where Xi = Xi,1, . . . , Xi,n iid ∼µi and µi iid ∼P. Consider the set of all mixtures of probability measures which yield the same distribution over the random groups as does P. If some element of this set other than P has no more components than P then P is not identiﬁable. In other words, there is no way to differentiate P from another model of equal or lesser complexity. Fortunately, with a sufﬁcient number of samples in each © R.A. Vandermeulen & C.D. Scott.  VANDERMEULEN SCOTT random group, P becomes the most simple model which describes the data. In this paper we show that, for any sample space, any mixture of probability measures with m components is identiﬁable when there are 2m −1 samples per random group. Furthermore we show that this bound cannot be improved, regardless of sample space. 1.1. Applications of Probability Measures over Probability Measures Though a somewhat mathematically abstract object, probability measures over spaces of probability measures arise quite naturally in many statistical problems. Any application which use mixture models, for example clustering, is utilizing a probability measure over probability measures. Moreover mixture models are a subset of a larger class of models known as latent variable models. One problem in latent variable models which has seen signiﬁcant interest recently is topic modeling. Topic modelling is concerned with the extraction of some sort of topical structure from a collection of documents. Many popular methods for topic modelling assume that each document in question has a latent variable representing a “topic” or a random convex combination of topics which determines the distribution of words in that document (Blei et al., 2003; Anandkumar et al., 2014; Arora et al., 2012). Another statistical problem which often utilizes a probability measure over probability measures is transfer learning. In transfer learning one is interested in utilizing several different but related',\n",
       " '1806.09445': 'Image classification is a classical Computer Vision problem. Although the advent of Deep Convolutional Neural Networks gave a dramatic push forward, there is an increasing interest to describe images and its properties in a richer way. In this vein, more attention has been drawn to multi-label problems and also to the exploration of label relations. Such rich descriptions are fundamental in several e-commerce businesses. Since it is inherently a very visual domain, specifically for items search, exploring visual information for image categorisation is key to enhancing product exploration and retrieval. In fact, in these businesses, it is crucial to retrieve relevant images (with the desired characteristics) from the users’ textual queries. Moreover, considering the continuous stream of new products being added to the catalogues, the automatic generation of image labels can alleviate the workload of human annotators, improve quick access to relevant products, and help generate textual product descriptions. Specifically, we take advantage of a priori structural knowledge together with the rich relational information that exists among product labels and associated concept semantics to improve image classification, thus enhancing product categorisation and consequent retrieval. We will focus on a real use case that can be easily generalised for any e-commerce platform. Namely, at Farfetch, a key player in the luxury fashion market, we aim to improve product categorisation and attribute prediction exclusively from visual features. arXiv:1806.09445v1  [cs.CV]  25 Jun 2018  KDD Workshop on AI for Fashion, 2018, London, UK Beatriz Quintino Ferreira et. al The current Farfetch category tree has five levels (gender, family, category, sub-category, and attributes), where all levels but one (attributes level) are mutually exclusive. Thus, the challenge we propose to address is to simultaneously estimating class predictions for all levels of the category tree for an image, while explicitly exploring the structure provided by the mentioned semantic hierarchy (Figure 1). Our motivation is to reduce the number of specialized classification models to train, without compromising (or even, preferably, improving) the performance. Furthermore, for multi-label classification at the attribute level, we face a large label space with imbalanced distribution and variable length prediction, which hinders traditional models. The contributions of this work are as follows: • A new method to categorise and predict attributes of fashion items exclusively from visual features; • The proposed method is a unified end-to-end deep model that jointly predicts different concept levels from a hierarchy tree, thus incorporating the concepts structure; • We show experimentally that the unified approach outperforms state-of-the-art models specialised for each concept level. The remainder of this paper is organised as follows. In Section 2 we briefly review related works. In Section 3 we introduce and provide details of our baseline and final model for structured output image classification. Section 4 presents and discusses the experimental results. Finally, in Section 5 we draw the conclusions. 2 RELATED WORK Powered by the creation of large-scale annotated image',\n",
       " '1807.11648': 'Given a graph G with n vertices {1, . . . , n}, we say a subgraph H is a α-(combinatorial) spanner if for every pair of vertices u, v of G, distH(u, v) ≤α · distG(u, v), where distG(u, v) is the shortest path distance between u, v in G. It has been shown that for any α, G has an α-spanner with only n1+O(1)/α many edges and that can be found efﬁciently [EP04]. Such a spanner can be found by a simple algorithm which repeatedly ﬁnds and adds an edge f = (u, v) where distH(u, v) > α. Combinatorial spanners have many applications in distributed computing [Pel00, FJJ+01, KK00], optimization [DK99, AGK+98], etc. In this paper we deﬁne and study a spectral generalization of this property. Given a set of vectors V ⊆Rd, we say a set U ⊆V is an α-spectral d-spanner of V if for any vector v ∈V , there exists a probability distribution µv on the vectors in U such that vv⊺⪯α · Eu∼µvuu⊺ equiv ⟨x, v⟩2 ≤α · Eu∼µv⟨x, u⟩2, ∀x ∈Rd. To see that this is a generalization of the graph case, let bu,v = eu −ev be the vector corresponding to an edge {u, v} of G, where eu is the indicator vector of the vertex u. It is an exercise to show that for V = {be}e∈E(G) and for any α-combinatorial spanner H of G, the set U = {be}e∈E(H) is an α2-spectral spanner of V . The following theorem is a special case of our main theorem. Theorem 1.1 (Main theorem for k = d). There is an algorithm that for any set of vectors V ⊆Rd ﬁnds an ˜O(d)-spectral d-spanner of size ˜O(d) in time polynomial in d and size of |V | 1. Our algorithm is a spectral generalization of the greedy algorithm mentioned above for ﬁnding combinatorial spanners. We further study generalizations of our spectral spanners to weaker forms of PSD inequalities. For two matrices A, B we write A ⪯k B if for every projection matrix Π onto a d −k + 1 dimensional linear subspace, ⟨A, Π⟩≤⟨B, Π⟩. For example, if A ⪯k B, then sum of the top k eigenvalues of A is at most the sum of the top k eigenvalues of B. Analogously, we say U ⊆V is an α-spectral k-spanner of V , if for any v ∈V , there is a distribution µv on U such that vv⊺⪯k α · Eu∼µvuu⊺. In our main theorem we generalize the above statement to all k ≤d and we show that to construct an ˜O(k) spectral k-spanner we only need to use ˜O(k) many vectors independent of the ambient dimension of the space. Theorem 1.2 (Main). There is an algorithm that for any set of vectors V ⊆Rd ﬁnds an ˜O(k)-spectral k-spanner of size',\n",
       " '1805.10572': 'Multivariate time series data are abundant in many application areas, such as ﬁnancial marketing [5, 4], health-care [10, 22], meteorology [31, 26], and trafﬁc engineering [29, 35]. Time series are widely used as signals for classiﬁcation/regression in various applications of corresponding areas. However, missing values in time series are very common, due to unexpected accidents, such as equipment damage or communication error, and may signiﬁcantly harm the performance of downstream applications. Much prior work proposed to ﬁx the missing data problem with statistics and machine learning approaches. However most of them require fairly strong assumptions on missing values. We can ﬁll the missing values using classical statistical time series models such as ARMA or ARIMA (e.g., [1]). But these models are essentially linear (after differencing). Kreindler et al. [19] assume that the data are smoothable, i.e., there is no sudden wave in the periods of missing values, hence imputing missing values can be done by smoothing over nearby values. Matrix completion has also been used to address missing value problems (e.g., [30, 34]). But it typically applies to only static data and requires strong assumptions such as low-rankness. We can also predict missing values by ﬁtting a parametric data-generating model with the observations [14, 2], which assumes that data of time series follow the distribution of hypothetical models. These assumptions make corresponding imputation algorithms less general, and the performance less desirable when the assumptions do not hold. In this paper, we propose BRITS, a novel method for ﬁlling the missing values for multiple correlated time series. Internally, BRITS adapts recurrent neural networks (RNN) [16, 11] for imputing missing Preprint. Work in progress. arXiv:1805.10572v1  [cs.LG]  27 May 2018  values, without any speciﬁc assumption over the data. Much prior work uses non-linear dynamical systems for time series prediction [9, 24, 3]. In our method, we instantiate the dynamical system as a bidirectional RNN, i.e., imputing missing values with bidirectional recurrent dynamics. In particular, we make the following technical contributions: • We design a bidirectional RNN model for imputing missing values. We directly use RNN for predicting missing values, instead of tuning weights for smoothing as in [10]. Our method does not impose speciﬁc assumption, hence works more generally than previous methods. • We regard missing values as variables of the bidirectional RNN graph, which are involved in the backpropagation process. In such case, missing values get delayed gradients in both forward and backward directions with consistency constraints, which makes the estimation of missing values more accurate. • We simultaneously perform missing value imputation and classiﬁcation/regression of applications jointly in one neural graph. This alleviates the error propagation problem from imputation to classiﬁcation/regression. Additionally, the supervision of classiﬁcation/regression makes the estimation of missing values more accurate. • We evaluate our model on three real-world datasets, including an air quality dataset, a health-care dataset and a localization dataset of human activities. Experimental results show that our model outperforms the',\n",
       " '1703.01842': 'Analyzing neuroimaging data is a major challenge due to several intrinsic limitations of neuroimaging datasets (i.e. high sensitivity to noise, large number of dimensions for few observations per subject, etc.). While many discoveries in neuroscience have been made using massively univariate statistics, there has been a recent paradigm shift towards the application of multivariate analysis and machine learning to “decode” brain functions [1]. The relevance of considering multivariate dependencies in brain signals is further justiﬁed by the rapidly growing literature on the application of network science and graph theory for studying brain connectivity [2]. Surprisingly, few analysis methods take into account both the multivariate aspect and connectivity features of the brain, such as structural connectivity (white matter tracts), functional connectivity (i.e. statistical dependencies between signals over time) or simply geometrical relationships between observations. A promising avenue to address this important gap resides in Graph Signal Processing (GSP) [3]. GSP is an emerging subﬁeld of signal processing whose objective is to take into account the underlying graphical structure of multivariate data, in order to generalize common signal processing techniques (such as ﬁltering, deconvolution, denoising, or time-frequency analysis) to irregular graph/network domains. GSP is built on the idea that the eigenvectors of the graph Laplacian matrix are analogous to Fourier modes, and can thus be used to provide a spectral representation of signals deﬁned on a graph, through the so-called Graph Fourier Transform operator (GFT). In this paper, we evaluate the application of GSP for the analysis of neuroimaging data. More speciﬁcally, we assess whether GSP can lead to more accurate supervised classiﬁcation, as well as whether GSP can be used for dimensionality reduction. Methods for GSP are still under active research, with applications such as the analysis of temperature sensor data [4] or epidemiology [5]. Also, GSP-based methods have recently been applied to neuroimaging using fMRI [6] and EEG/MEG data [7], [8], [9]. Huang and collaborators [6] have applied graph frequency analysis to fMRI data in order to observe how brain activity changes during a learning task. Graph frequency analysis allows to study spatial variation of the signal, with low graph frequencies representing smooth and regular variations across the brain network, whereas high graph frequencies represent important spatial variations, described by the authors as randomness. After decomposing fMRI data into graph frequency bands, Huang et al. observed that during learning, low graph frequencies correlate with the learning rate at the start of the training, while higher frequencies correlate with participants’ familiarity with the task. Other studies have applied GSP techniques to EEG/MEG signals, for instance for noise suppression [8], dimensionality reduction [7], [8], [10] and classiﬁcation [7], [10]. The authors of the latter article compared classiﬁcation accuracy when building graphs using different connectivity measures. They showed that projecting the data into the eigenspace associated with the graph strongest eigenvalues in order to reduce dimensions leads to better classiﬁcation results than Principal Component Analysis (PCA) and Linear Discriminant Analysis (LDA) [7]. While',\n",
       " '1405.0203': 'The two-user Interference Channel (IC) introduced in [2] is a canonical example to study the impact of interference in communication networks. There exists an extensive body of work on this problem under various assumptions (e.g., [3]– [11]). In this work, we focus on a speciﬁc conﬁguration of this network, named the two-user Binary Fading Interference Channel (BFIC) as depicted in Fig. 1 in which the channel gains at each time instant are in the binary ﬁeld according to some Bernoulli distribution. The input-output relation of this channel at time instant t is given by Yi[t] = Gii[t]Xi[t] ⊕G¯ii[t]X¯i[t], i = 1, 2, (1) where ¯i = 3 −i, Gii[t], G¯ii[t] ∈{0, 1}, and all algebraic operations are in F2. This model was ﬁrst introduced in [12]. A. Vahid is with the School of Electrical and Computer Engineering, Duke University, Durham, NC, USA. Email: alireza.vahid@duke.edu. Mohammad Ali Maddah-Ali is with the Department of Electrical Engineering, Sharif University of Technology, Tehran, Iran. Email: maddah ali@sharif.edu. A. S. Avestimehr is with the School of Electrical and Computer Engineering, University of Southern California, Los Angeles, CA, USA. Email: avestimehr@ee.usc.edu. Yan Zhu is with Aerohive Networks Inc., Sunnyvale, CA, USA. Email: zhuyan79@gmail.com. Preliminary parts of this work was presented in the 2014 International Symposium on Information Theory (ISIT) [1]. Copyright (c) 2014 IEEE. Tx1 Tx2 Rx1 Rx2 X1[t] X2[t] Y1[t] Y2[t] G11[t] G22[t] G12[t] G21[t] Fig. 1. Two-user Binary Fading Interference Channel (BFIC). The motivation for studying the Binary Fading (or Erasure) Interference Channel is twofold. First as demonstrated in [13], it provides a simple yet useful physical layer abstraction for wireless packet networks in which whenever a collision occurs, the receiver can store its received analog signal and utilize it for decoding the packets in the future (for example, by successive interference cancellation techniques). In this context, the binary fading model is motivated by a shadow fading environment in which each link is either “on” or “off” (according to the shadow fading distribution), and the multiple access (MAC) is modeled such that if two signals are transmitted simultaneously and the links between the corresponding transmitters and the receiver are not in deep fade, then a linear combination of the signals is available to the receiver. The study of the BFIC in [13] has led to several coding opportunities that can be utilized by the transmitters to exploit the available signal at the receivers for interference management. Moreover, this model allows researchers to focus on other interesting challenges in interference channels such as spatial correlation [14] and locality of channel state knowledge [15], [16]. The second motivation for studying the BFIC is that it can be a ﬁrst step towards understanding the capacity of the fading interference channels with no knowledge of the channel state information at the',\n",
       " '0903.4443': 'Reference [1] considered the use of network coding in channels in which time division duplexing is necessary, i.e. when a node can only transmit or receive, but not both at the same time. This type of channel is usually called halfduplex, but we will use the term time division duplexing (TDD) to emphasize that the transmitters and receivers may not use the channel half of the time each, i.e. the amount of time allocated to transmit and receive may vary. Examples of TDD channels are infrared devices, and underwater acoustic modems. High latency channels, e.g. in satellite, and deep space communications, can also take advantage of these ideas. In particular, Reference [1] studied the case of transmitting a block of M data packets through a link using random linear network coding with the objective of minimizing the mean time to complete transmission of that block of packets. Reference [2] extended the analysis for the problem of energy consumption of the scheme. Reference [1] and [2] showed that there exists, an optimal number of coded data packets to be transmitted backto-back before stopping to wait for an acknowledgment (ACK), under the minimum time and minimum energy criterion, respectively. Reference [2] showed that choosing the number of coded data packets to optimize mean completion time, as in [1], provides a very good trade-oﬀ between energy consumption and completion time. We analyze the problem of broadcast under the TDD constrain and using a similar random linear network coding scheme to that in [1], i.e. we provide an extension of the scheme to the case of several receivers. We assume that the receivers are not allowed to cooperate in order to share their received coded packets in order to decode the information, which is to say that each receiver must be able to decode the information from the coded packets sent directly from the transmitter. We provide a bound to the number of stops to wait for ACKs in order to complete the transmission to all receivers with arbitrary high probability. Also, we study the mean completion time and energy of the broadcast scheme and compare it to optimal scheduling policies. Finally, we provide simple heuristics to determine the number of coded data packets to be transmitted back-to-back before stopping to wait for an ACK, with a considerable reduction in the computation time. The paper is organized as follows. In Section II, we outline the set up of the problem. We provide a proof for the bound on the number of stops to listen for ACK packets. In Section III, we study the mean completion time and heuristics to determine the number of coded packets. In Section IV, we present comparison schemes based on optimal scheduling policies. Section V presents numerical results for various broadcast scenarios. Conclusions are summarized in Section VI. II. Random Network Coding for Broadcast in TDD channels A sender wants to broadcast',\n",
       " '1207.3790': 'The comparison of classification algorithms is a complex  and open problem. First, the notion of performance can be  defined in many ways: accuracy, speed, cost, readability, etc.  Second, an appropriate tool is necessary to quantify this  performance. Third, a consistent method must be selected to  compare the measured values.   Performance is most of the time expressed in terms of  accuracy, which is why, in this work, we focus on this point.  The number of accuracy measures appearing in the  classification literature is extremely large. Some were  specifically designed to compare classifiers [1], but most were  initially defined for other purposes, such as measuring the  association between two random variables [2], the agreement  between two raters [3] or the similarity between two sets [4].  Furthermore, the same measure may have been independently  developed by different authors, at different times, in different  domains, for different purposes, leading to very confusing  typology and terminology. Besides its purpose or name, what  characterizes a measure is the definition of the concept of  accuracy it relies on. Concretely, this means  that measures are   designed to focus  on  a specific  aspect of the overall   classification results [5]. This leads to measures with different  interpretations, and some do not even have any clear  interpretation. Finally, the measures may also differ in the  nature of the situations they can be applied to: binary vs.  multiclass problem, mutually exclusive classes vs. fuzzy  classes [6], sampling design used to retrieve the data [7], etc.  Many different measures exist, but yet, there is no such  thing as a perfect measure, which would be the best in every  situation [8]: an appropriate measure must be chosen according  to the classification context and objectives. Because of the  overwhelming number of measures and of their heterogeneity,  choosing the most adapted one is a difficult problem.  Moreover, it is not always clear what the measures properties  are, either because they were never rigorously studied, or  because specialists do not agree on the question (e.g. the  question of chance-correction [9]). Maybe for these reasons,  authors very often select an accuracy measure by relying on the  tradition or consensus observed in their field. The point is then  more to use the same measure than their peers rather than the  most appropriate one.  In this work, we reduce the complexity of choosing an  accuracy measure by restraining our analysis to a very specific  but widespread, situation. We discuss the case where one wants  to select the best classification algorithm to process a given  data set. An appropriate way to perform this task would be to  study the data properties first, then to select a suitable  classification algorithm and determine the most appropriate  parameter values, and finally to use it to build the classifier.  But not everyone has the statistical expertise required to  perform this analytic work. Therefore, in practice, the most  popular method consists in sampling a training set from the  considered data, building various classifiers with different  classification algorithms and parameters, and then comparing  their performances',\n",
       " '1707.09074': 'Action recognition has been signiﬁcantly improved in recent years. Most existing methods [23, 34, 38, 39] rely on supervised learning and, therefore, require large-scale, diverse and representative action datasets for training. Collecting such datasets, however, is a difﬁcult task given the high costs of manual search and annotation of the video. Notably, the largest action datasets today are still orders of magnitude smaller (UCF101 [36], ActivityNet [7]) compared to large image datasets, they often contain label noise and target speciﬁc domains such as sports (Sports1M [20]). Weakly supervised learning aims to bypass the need of manually-annotated datasets using readily-available, but possibly noisy and incomplete supervision. Examples of such methods include learning of person names from image captions or video scripts [3, 10, 35, 37]. Learning actions from movies and movie scripts has been approached in [4, 5, 9, 23]. Most of the work on weakly supervised person and action learning, however, has been limited to one or a few movies. Therefore the power of leveraging large-scale 1D´epartement d’informatique de l’ENS, ´Ecole normale sup´erieure, CNRS, PSL Research University, 75005 Paris, France. 3Czech Institute of Informatics, Robotics and Cybernetics at the Czech Technical University in Prague. Figure 1: We automatically recognize actors and their actions in a of dataset of 66 movies with scripts as weak supervision. weakly annotated video data has not been fully explored. In this work we aim to scale weakly supervised learning of actions. In particular, we follow the work of [4] and learn actor names together with their actions from movies and movie scripts. While actors are learned separately for each movie, differently from [4], our method simultaneously learns actions from all movies and movie scripts available for training. Such an approach, however, requires solving a large-scale optimization problem. We address this issue and propose to scale weakly supervised learning by adapting the Block-Coordinate Frank-Wolfe approach [21]. Our optimization procedure enables action learning from tens of movies and thousands of action samples, readily available from our subset of movies or other recent datasets with movie descriptions [30]. This, in turn, results in large improvements in action recognition. Besides the optimization, our work introduces a new model for background class in the form of a constraint. It enables better and automatic modeling of the background class (i.e. unknown actors and actions). We evaluate our method on 66 movies and demonstrate signiﬁcant improvements for both actor and action recognition. Example results are illustrated in Figure 1. 1 arXiv:1707.09074v1  [cs.CV]  27 Jul 2017  1.1. Related Work This section reviews related work on discriminative clustering, Frank-Wolfe optimization and its applications to the weakly supervised learning of people and actions in video. Discriminative clustering and Frank-Wolfe. The Frank-Wolfe algorithm [11, 15] allows to minimize large convex problems over convex sets by solving a sequence of linear problems. In computer',\n",
       " '0807.1267': 'Communication complexity studies the communication required to solve a computational problem in a distributed setting. Consider a relation f ⊆X × Y × Z. In a two-party protocol to solve f, ⋆A preliminary version of this paper with many results mentioned here appeared in the 20th IEEE Conference on Computational Complexity, 2005. ⋆⋆Research supported in part by ARO/NSA USA. Part of this work was done while the author was at U.C. Berkeley, Berkeley, USA, where it was supported by Army Research Oﬃce (ARO), North California, under grant DAAD 19-03-1-00082. Part of the work done while the author was at Tata Institute of Fundamental Research, Mumbai, India. ⋆⋆⋆Part of the work done while the author was at Toyota Technological Institute Chicago, USA. † Work done while the author was at University of Waterloo, Waterloo, Canada.  one party say Alice would be given input x ∈X, and the other party say Bob would be given input y ∈Y. The goal for Alice and Bob would be to communicate and ﬁnd an element z ∈Z that satisﬁes the relation, i.e., to ﬁnd a z such that (x, y, z) ∈f. The protocols they follow could be deterministic, randomized or quantum leading to diﬀerent notions of deterministic, randomized and quantum communication complexity. Please refer to Sec. 2.2 for detailed exposition to various models, deﬁnitions and notations related to classical and quantum communication complexity. 1.1 Direct Sum Let us consider a natural question in communication complexity as follows. Suppose Alice and Bob wish to solve several, say k, instances of relation f simultaneously, with constant success on the overall output. A Direct Sum theorem states that the communication required for accomplishing this would be at least k time the communication required for solving single instance of f, with constant success. It is a natural and fundamental question in communication complexity. Although they seem highly plausible, it is well-known that Direct Sum results fail to hold for some settings of communication. For example for the Equality function (EQn), in which Alice and Bob need to determine if their n-bit inputs are equal or not, its randomized private-coins communication complexity, denoted R(EQn) does not satisfy the Direct Sum property. It is known that R(EQn) = Θ(log n) whereas for testing Equality of k = log n 4 pairs of n-bit strings R(EQ⊕k n ) = O(k log k + log n) = O(log n log log n) (see, e.g., [KN97, Example 4.3, page 43]), where we might expect R(EQ⊕k n ) = Ω(k log n) = Ω(log2 n). Similarly, Shaltiel [Sha03] gives an example for which a related notion called the Strong Direct Product property fails to hold for average case (i.e., distributional) communication complexity. (A Strong Direct Product theorem would show that even with probability of success that is exponentially small in k, the cost of solving k instances of f, would be k times the cost of solving one instance.) Previous works: Notwithstanding these examples, Direct Sum results have met with some success',\n",
       " '1708.04299': 'Human emotions have been widely studied in the realm of psychological and behavioral sciences as well as computer science (Strapparava and Mihalcea, 2008). A wide variety of researches have been conducted in detecting emotions from facial expressions and audio waves (Yu et al., 2001; Zeng et al., 2006; Lucey et al., 2010). The recent advent of natural language processing and machine learning has made the task of emotion detection on text possible, yet since emotions are not necessarily conveyed on text, quantifying different types of emotions using only text is generally challenging. Another challenging aspect about this task is due to the lack of annotated datasets. There are few publicly available datasets (Strapparava and Mihalcea, 2007; Alm, 2008; Mohammad and Bravo-Marquez, 2017; Buechel and Hahn, 2017). However, in order to further explore the feasibility of text-based emotion detection on dialogue, a more comprehensive dataset would be desired. This paper presents a new corpus that comprises transcripts of the TV show, Friends, where each utterance is annotated with one of the seven emotions: sad, mad, scared, powerful, peaceful, joyful, and neutral. Several annotation tasks are conducted through crowdsourcing for the maintenance of a high quality dataset. Dialogues from these transcripts include disﬂuency, slangs, metaphors, humors, etc., which make this task even more challenging. To the best of our knowledge, this is the largest text-based corpus providing ﬁnegrained emotions for such long sequences of consecutive utterances in multiparty dialogue. Convolutional neural networks (CNN) have been popular for several tasks on document classiﬁcation. One of the major advantages of CNN is found in its capability of extensive feature extraction through deep-layered convolutions. Nonetheless, CNN are often not used for sequence modeling (Waibel et al., 1989; LeCun et al., 1995; Gehring et al., 2017) because their basic architecture does not take previous sequence information into account. One common approach to alleviate this issue is using recurrent neural networks (Sutskever et al., 2014; Liu et al., 2016). However, RNNs typically perform slower and require more training data to avoid overﬁtting. To exploit the sequence information embedded in our corpus yet to employ the advantages of CNN, sequenced-based CNN (SCNN) are proposed along with attention mechanisms, which guide CNN to fuse features form the current state with features from the previous states. The contributions of this research are summarized as follows: • We create a new corpus providing ﬁne-grained emotion annotation on dialogue and give thorough corpus analytics (Section 3) . arXiv:1708.04299v1  [cs.CL]  14 Aug 2017  Speaker Utterance A1 A2 A3 A4 Monica He is so cute . So , where did you guys grow up ? Peaceful Joyful Joyful Joyful Angela Brooklyn Heights . Neutral Neutral Neutral Neutral Bob Cleveland . Neutral Neutral Neutral Neutral Monica How , how did that happen ? Peaceful Scared Neutral Neutral Joey Oh my god . Joyful Sad Scared Scared Monica What ? Neutral Neutral Neutral Neutral Joey I suddenly had the feeling that I was falling . But I ’m not . Scared Scared',\n",
       " '1711.08819': 'FAILED',\n",
       " '1804.02692': 'Private information retrieval (PIR) protocols, ﬁrst introduced by Chor, Goldreich, Kushilevitz, and Sudan in [5], allow a user to retrieve a data item from a database without revealing any information about the identity of the item to any single server. The original formulation of the PIR problem considers replicating a binary string on several noncommunicating servers. The objective is to optimize the communication cost, including both the upload cost and the download cost, for privately retrieving one single bit. In recent years, the information-theoretic reformulation of the PIR problem assumes the more practical scenario in which the ﬁles are of arbitrarily large size. Under this setup, the number of uploaded bits can be neglected with respect to the corresponding number of downloaded bits since the upload does not depend on the size of the ﬁle [4]. This reformulation introduces the rate of a PIR scheme to be the ratio between the size of the retrieved ﬁle and the total number of downloaded bits from all servers. The supremum of achievable rates over all PIR schemes is deﬁned as the PIR capacity. In their pioneering work [13] Sun and Jafar determine the exact PIR capacity of the classical PIR model of replication. Starting from [12], the research of PIR has been combined with distributed storage system instead of the replicationbased system. This brings in the other important parameter, i.e., the storage overhead of the distributed storage system, deﬁned as the ratio between the total number of bits stored on all the servers and the number of bits of the database. Several papers have been studying the relation between the storage overhead and the rate of a PIR scheme. Chan et al. [4] offer a tradeoff between the storage overhead and rate for linear PIR schemes. They show that when each server stores a fraction 0 < ϵ ≤1 of the database, then the rate of a linear PIR scheme should be at most N−1/ϵ N , where N is the number of server. Tajeddine et al. [16] propose a PIR scheme achieving this upper bound when the storage code is an arbitrary (N, K)-MDS code, so ϵ = 1 K and the PIR rate is N−K N . Banawan and Ulukus [2] show that the exact PIR capacity when using an arbitrary (N, K)-MDS storage code is (1+ K N +· · ·+ KM−1 N M−1 )−1, a value dependent on the number of ﬁles M and tends to N−K N when M approaches inﬁnity. However, similar to the scheme of Sun and Jafar [13], this optimal scheme can be implemented only if the ﬁle size L is an exponential function of M [14], [18]. For a more practical setting we are more interested in the case when L is at most a polynomial value in terms of M and the scheme of Tajeddine et al. [16] works for this setup. Recall the development of the research on distributed storage systems: Besides optimizing repair bandwidth',\n",
       " '1803.06975': 'Machine learning (ML) systems are widely deployed in safety-critical domains that carry incentives for potential adversaries, such as ﬁnance [14], medicine [18], the justice system [32], cybersecurity [1], or self-driving cars [6]. An ML classiﬁer automatically learns classiﬁcation models using labeled observations (samples) from a training set, without requiring predetermined rules for mapping inputs to labels. It can then apply these models to predict labels for new samples in a testing set. An adversary knows some or all of the ML system’s parameters and uses this knowledge to craft training or testing samples that manipulate the decisions of the ML system according to the adversary’s goal—for example, to avoid being sentenced by an ML-enhanced judge. Recent work has focused primarily on evasion attacks [4, 45, 17, 52, 36, 9], which can induce a targeted misclassiﬁcation on a speciﬁc sample. As illustrated in Figures 1a and 1b, these test time attacks work by mutating the target sample to push it across the model’s decision boundary, without altering the training process or the decision boundary itself. They are not applicable in situations where the adversary does not control the target sample—for example, when she aims to inﬂuence a malware detector to block a benign app developed by a competitor. Prior research has also shown the feasibility of targeted poisoning attacks [35, 33]. As illustrated in Figure 1c, these attacks usually blend crafted instances into the training set to push the model’s boundary toward the target. In consequence, they enable misclassiﬁcations for instances that the adversary cannot modify. These attacks appear to be very effective, and the defenses proposed against them are often bypassed in follow-on work [8]. However, to understand the actual security threat introduced by them, we must model the capabilities and limitations of realistic adversaries. Evaluating poisoning and evasion attacks under assumptions that overestimate the capabilities of the adversary would lead to an inaccurate picture of the security threat posed to real-world applications. For example, test time attacks often assume white-box access to the victim classiﬁer [9]. As most security-critical ML systems use proprietary models [1], these attacks might not reﬂect actual capabilities of a potential adversary. Black-box attacks consider weaker adversaries, but they often make rigid assumptions about the adversary’s knowledge when investigating the transferability of an attack. TransferabilarXiv:1803.06975v2  [cs.CR]  8 Mar 2019  Training Instances Pristine Decision Boundary Target (a) Testing Instances Adversarial Example (b) Poisoning Instances Poisoned Decision Boundary (c) Testing Instances (d) Figure 1: Targeted attacks against machine learning classiﬁers. (a) The pristine classiﬁer would correctly classify the target. (b) An evasion attack would modify the target to cross the decision boundary. (c) Correctly labeled poisoning instances change the learned decision boundary. (d) At testing time, the target is misclassiﬁed but other instances are correctly classiﬁed. ity is a property of attack samples crafted locally, on a',\n",
       " '1704.07352': 'Our focus in this paper is on learning structured low-rank matrices and we consider the following problem: min W∈Rd×T CL(Y, W) + ∥W∥2 ∗, subject to W ∈D, (1) where Y ∈Rd×T is a given matrix, L : Rd×T × Rd×T →R is a convex loss function, ∥· ∥∗denotes the nuclear norm regularizer, C > 0 is the cost parameter, and D is the linear subspace corresponding to structural constraints. It is well known the nuclear norm regularization promotes low rank solutions since ∥W∥∗is equal to the ℓ1-norm on the singular values of W (Fazel et al., 2001). The linear subspace D in problem (1) is represented as D := {W : A(W)♦0}, where A : Rd×T →Rn is a linear map and ♦represents equality (=) or greater than equal to (≥) constraint. Low-rank matrices are commonly learned in several machine learning applications such as matrix completion (Abernethy et al., 2009; Boumal and Absil, 2011), multi-task learning (Argyriou et al., 2008; Zhang and Yeung, 2010; Jawanpuria and Nath, 2012), multivariate regression (Yuan et al., 2007; Journ´ee et al., 2010), to name a few. In addition to the low-rank constraint, other structural constraints may exist, e.g., entry-wise non-negative/bounded constraints (Kannan et al., 2012; Marecek et al., 2017; Fang et al., 2017). Several linear dynamical system models require learning a low-rank Hankel matrix (Fazel et al., 2013; Markovsky and Usevich, 2013). A Hankel matrix has the structural constraint that all its anti-diagonal entries are the same. In robust matrix completion and robust PCA problems 1 arXiv:1704.07352v5  [stat.ML]  15 Jun 2018  (Wright et al., 2009), the matrix is learned as a superimposition of a low-rank matrix and a sparse matrix. This sparse structure is modeled eﬀectively by choosing the loss function as the ℓ1-loss (Cambier and Absil, 2016). Similarly, low-rank 1-bit matrix completion solvers employ the logistic loss function (Davenport et al., 2014; Bhaskar and Javanmard, 2015) to complete a 0/1 matrix. We propose a generic framework to the structured low-rank matrix learning problem (1) that is well suited for handling a variety of loss functions L (including non-smooth ones such as the ℓ1-loss), structural constraints W ∈D, and is scalable for large-scale problem instances. Using the duality theory, we introduce a novel modeling of structured low-rank matrix W of rank r as W = UU⊤(Z + A), where U ∈Rd×r and Z, A ∈Rd×T . Our factorization naturally decouples the low-rank and structural constraints on W. The low-rank of W is enforced with U, the structural constraint is modeled by A, and the loss function speciﬁc structure is modeled by Z. The separation of low-rank and structural constraints onto separate factors makes the optimization conceptually simpler. To the best of our knowledge, such a decoupling of constraints has not been studied in the existing structured low-rank matrix learning literature (Fazel et al., 2013',\n",
       " '1807.11254': 'In recent years, CNNs have achieved great success on several computer vision tasks, such as image classiﬁcation [19], object detection [27], instance segmentation [25] and many others. However, deep neural networks with high performance also suﬀer from a huge amount of computation cost, restricting applications of these networks on the resource-constrained devices. One of the classic networks, VGG16 [30] with 130 million parameters needs more than 30 billion FLOPs to classify a single 224×224 image. The heavy computation and memory cost can hardly be aﬀorded by most of embedding-systems on real-time tasks. To address this problem, lots of studies have been proposed during last few years, including network compressing and accelerating [4,5,21,41], or directly designing more eﬃcient architectures [10,14,37,40]. Low-rank decomposition is a common method to compress network by matrix or tensor factorization. A series of works [4,16,38,41] have achieved great progress on increasing eﬃciency of networks by representing the original weights as a form of low-rank. However, these methods couldn’t reach an extreme compression ratio with good performance since they may suﬀer from degeneration problem [26,29], which is harmful for the convergence and performance of the arXiv:1807.11254v2  [cs.CV]  31 Jul 2018  2 Bo Peng, Wenming Tan, Zheyang Li, Shun Zhang, Di Xie, Shiliang Pu Fig. 1. The ﬁlter group structure is a linear combination of W 1 and W 2. X is the input feature with Cin channels and h × w spatial size. W 1 is a ﬁlter group convolutional layer with each ﬁlter size of n × k × k, W 2 is a 1 × 1 convolutional layer. Y 1 and Y 2 are outputs of W 1 and W 2 respectively network. Filter group convolution [19] is another way to compact the network while keeping independencies among ﬁlters, which can alleviate the limitation of degeneration. In this work, we will show a novel method, which decompose a regular convolution to ﬁlter group structure [14] (Fig. 1), while achieve good performance and large compression ratio at the same time. The concept of ﬁlter group convolution was ﬁrst used in AlexNet [19] due to the shortage of GPU’s memory. Surprisingly, independent ﬁlter groups in CNN learned a separation of responsibility, and the performance was close to that of corresponding network without ﬁlter groups, which means this lighter architecture has an equal ability of feature representation. After this work, ﬁlter group and depthwise convolution were widely used in designing eﬃcient architectures [2,10,14,28,37,40] and achieved state-of-the-art performance among lightweight models. However, all of those well-designed architectures need to be trained from scratch with respect to speciﬁc tasks. Huang et al.[12] introduced CondenseNet, which learns ﬁlter group convolutions automatically during the training process, while several complicated stages with up to 300 epochs’ training are needed to reach both sparsity and regularity of ﬁlters. In this paper, we will',\n",
       " '1810.09390': 'The breadth of applications requiring independent sampling from a probability distribution is sizable. Numerous classical statistical results, and in particular those involved in machine learning, rely on the independence assumption. For some densities, direct sampling may not be tractable, and the evaluation of the density at a given point may be costly. Rejection sampling (RS) is a well-known Monte-Carlo method for sampling from a density f on Rd when direct sampling is not tractable (see Von Neumann, 1951, Devroye, 1986). It assumes access to a density g, called the proposal density, and a positive constant M, called the rejection constant, such that f is upper-bounded by Mg, which is called the envelope. Sampling from g is assumed to be easy. At every step, the algorithm draws a proposal sample X from the density g and a point U from the uniform distribution on [0, 1], and accepts X if U is smaller than the ratio of f(X) and Mg(X), otherwise it rejects X. The algorithm outputs all accepted samples, which can be proven to be independent and idenarXiv:1810.09390v1  [stat.ML]  22 Oct 2018  Achdou et al. tically distributed samples from the density f. This is to be contrasted with Markov Chain Monte Carlo (MCMC) methods which produce a sequence of non dependent samples—and fulﬁll therefore a diﬀerent objective. Besides, the application of rejection sampling includes variational inference: Naesseth et al. (2016, 2017) generalize the reparametrization trick to distributions which can be generated by rejection sampling. 1.1 Adaptive rejection sampling Rejection sampling has a very intuitive geometrical interpretation. Consider the variable Z = (X, Mg(X)U), where X, M, g and U are deﬁned as above. As shown in Figure 4 in the Supplementary Material, Z has a uniform distribution on the region under the graph of Mg, and the sample is accepted if it falls into the region under the graph of f. Conditional to acceptance, Z is then drawn uniformly from the area under the graph of f. Thus X is drawn from the distribution with density f. The acceptance probability is the ratio of the two areas, 1/M. This means that the closer g is to f —and M to 1—, the more samples are accepted. The goal is hence to ﬁnd a good envelope of f in order to obtain a number of rejected samples as small as possible. In the absence of prior knowledge on the target density f, the proposal is typically the uniform density on a set including the support of f (here assumed to be compact), and the rejection constant M is set as an upper bound on f. Consequently, this method leads to rejecting many samples in most cases and f is evaluated many times uselessly. Adaptive rejection sampling is a variant motivated by the high number of rejected samples mentioned above. Given n, a budget of evaluations of f, the goal is to maximize ˆn, the number of',\n",
       " '1502.05742': 'OCT is a powerful imaging system for non-invasive acquisition of 3D volumetric images of tissues [1], with applications in ophthalmology, dermatology, coronary imaging etc. Due to its underlying physics, which is common in narrow-band detection systems like Synthetic-Aperture Radar (SAR) and ultrasound, OCT images usually suﬀer from a granular pattern called speckle. Not only the optical properties of the system, but also the motion of the subject to be imaged, size and temporal coherence of the light source, multiple scattering, phase deviation of the beam and aperture of the detector can aﬀect the speckle [2]. Fig. 1 shows a sample retinal OCT image, highly degraded by speckle noise. Speckle is considered to be multiplicative noise, in contrast to the additive Gaussian noise. Limited dynamic range of displays requires us to compress the OCT signals usually by a logarithmic transform, which converts the multiplicative speckle noise to additive noise [3]. Two major classes of speckle noise reduction techniques are: 1) methods of noise reduction during the acquisition time and 2) post-processing techniques. In the ﬁrst class multiple uncorrelated recordings are averaged. This includes spatial [4], angular [5], polarization [6] and frequency [7] compounding techniques. As for postprocessing, anisotropic diﬀusion-based techniques [3] and multi-scale/multiresolution geometric representation techniques [8] are of high interest between scholars. Use of compressive sensing and sparse representation have also been explored in the past few years [9]. For a more complete review on the different image analysis techniques in OCT image processing, including noise reduction, the reader is referred to [10] and references therein. Post-processing averaging/median ﬁltering is also an interesting method for speckle reduction. In such techniques, multiple B-scans of the same location are acquired and then the average/median is taken. The misalignment between the diﬀerent B-scans is usually compensated with a parametric image registration technique. Theoretically, having N B-scans with uncorrelated speckle, SNR can be improved by a factor of √ N. The works presented in [11, 12] can be mentioned as examples. Recently the use of sparse and low-rank decomposition based batch image alignment was explored by the authors [13]. In this paper the use of Independent Component Analysis (ICA) techniques for speckle noise reduction of retinal OCT images is explored, which to the best of our knowledge has never been investigated before. Having 2  Figure 1: Sample retinal OCT image degraded by speckle noise; selected ROIs are shown with blue rectangles. multiple B-scans of the same location in retina, the eye movement is compensated by considering a rigid transformation between consecutive B-scans using ImageJ [14]. Having negligible eye motion within each B-scan, the need for deformable registration techniques [15, 16] can be eliminated. Then, several ICA techniques are used for extracting the noise-free image from multiple noisy B-scans. SNR, CNR and ENL are considered as metrics for comparing the performance of diﬀerent methods. Investigating',\n",
       " '1702.02034': 'Joint processing CoMP, whereby multiple cooperating TXs share the data streams and perform joint precoding [1], are considered for use in current and next generation wireless networks. Theoretically, with perfect data and CSI sharing, TXs at different locations can be seen as a unique virtual multiple-antenna array serving all RXs in a multiple-antenna broadcast channel (BC) fashion and well known precoding algorithms from the literature can be used [2]. However, in real systems both the feedback through the wireless medium and the information exchange through the backhaul place a burden on overall resources and must be limited. Joint processing CoMP under limited feedback and imperfect backhaul (or fronthaul for cloud radio access network, a.k.a C-RAN systems) has been investigated in many works. In [3], [4], the capacity limited backhaul is considered and an information theoretic analysis of the system performance for joint processing CoMP is provided. In [5]–[7], the compress-andforward schemes, cooperative beamforming and resource allocation for a C-RAN with capacitylimited fronthaul links are considered. In [8]–[10], the effect of imperfect CSIT due to limited feedback and/or delay is investigated in a single TX multiple antennas broadcast channel setting. In [11], [12], precoder designs for the joint processing CoMP with limited backhaul are provided. However, most of these contributions typically assume a centralized CSIT setting, i.e., the precoding is done on the basis of a single imperfect channel estimate which is commonly known at every TX. This assumption of a centralized computing unit is relevant in the so-called C-RAN architecture, yet it is more and more challenged in other forms of networks where a pre-existing optical ﬁber backhaul is lacking or is considered too expensive in terms of CAPEX. Other emerging deployment scenarios are those with a fully heterogeneous infrastructure where the network’s edge is composed of not just ﬁxed macro base stations but also small cell base stations, mobile (possibly ﬂying [13]) access points or relays. In such settings, exchanging CSI over limited and unreliable backhaul is likely to lead to additional quantization noise and latencies. As a result, the global downlink CSI estimate collected by any TX is unique to that TX, although the CSI noise can exhibit some degree of correlation from TX to TX. In the rest of this paper, we refer  3 to this setting as a Distributed CSI setting, which considers implicitly the possible correlation between the estimates. In this context we are interested in the design of a distributed precoder whereby each TX computes the elements of the precoder used for its transmission based solely on its own channel estimate. From an information theoretic perspective, the study of joint processing CoMP in D-CSI setting raises several intriguing and challenging questions. First, while the JP-CoMP with perfect user message sharing is akin to the information theoretic MISO broadcast channel, the capacity region of the broadcast channel under a general D-CSI setting is unknown',\n",
       " '1704.04613': 'Combining multi-modal features for the recognition or index of visual data is the inevitable way to automatically understanding image/video content in the recent years. The multi-modal visual data are often correlated and complementary to each other in visual understanding, especially when they originate from the same source. In this paper, we are concerned on how to efﬁciently integrate visual and textual cues for ﬁne-grained image classiﬁcation with convolutional neural networks. The goal of ﬁne-grained classiﬁcation is to assign the labels to the images having subtle differences in visual appearance such as animal species, product types, and place types. Such a problem is quite challenging, as relevant differences that are not obvious may not be accurately distinguished by a typical classiﬁcation model. Even for human perception, domain speciﬁc knowledge is often required for ﬁne-grained classiﬁcation. Scene text, which frequently appears in natural scenes including road signs, street views, product packages, and Xiang Bai, Mingkun Yang, Penyuan Lyu, and Yongchao Xu are with the School of Electronic Information and Communications, Huazhong University of Science and Technology (HUST), Wuhan, 430074, China. Email: {xbai, yangmingkun, lvpyuan, yongchaoxu}@hust.edu.cn. Yongchao Xu is also with EPITA Research and Development Laboratory, 14-16 rue Voltaire, FR-94270 Le Kremlin-Bicetre, France Jiebo Luo is with the Department of Computer Science, University of Rochester, Rochester, NY 14627 USA. Email: jiebo.luo@gmail.com. license plates, often possesses rich and precise meanings that are highly related to semantics of the object or scene in the same image. For instance, texts on the buildings or wrapping bags are quite useful for distinguishing among their categories. With the recent developments in text detection and recognition in the wild [1], [2], it has been shown that textual cues are very beneﬁcial to ﬁne-grained classiﬁcation, especially in the classiﬁcation of business places such as bakery, cafe and bookstore [3]. Scene text detection and recognition has been an active research area in both computer vision and document analysis communities. A large number of novel approaches are proposed for the localization and recognition of the text embodied in natural images and videos. Such approaches enable us to automatically extract the text information, which can be considered as an additional information for image classiﬁcation. In this paper, the recognized words in natural scenes are used as a kind of input features for an image classiﬁcation model. However, given an image, not every recognized word must have the relation to it. As shown in Figure 1, the recognized words such as ‘restaurant’, ‘bakery’, ‘pharmacy’, ‘bread’, ‘hotel’ are very relevant to the scene semantics, but some words like ‘grand’, ‘great’, ‘edison’ don’t have the direct connection to them. This requires a model to measure the relevance of each recognized word to the semantics of objects or scenes, in order to make full use of textual information in image classiﬁcation. It should be mentioned that the existing robust reading system can not guarantee that all the',\n",
       " '1711.01941': 'Deletion and insertion errors are experienced in various communication and storage systems. These errors are often associated with various forms of loss of synchronization [2]–[5]. In many applications, the deletion and insertion errors tend to occur in bursts (consecutive errors), or are localized within certain parts of the information. This happens for example when synchronization is lost for a certain period of time, resulting in a series of errors within that time frame. Another example is in ﬁle synchronization, in applications such as Dropbox, where large ﬁles are often edited by deleting and inserting characters in a relatively small part of the text (such as editing a paragraph), resulting in errors that are localized within that part of the ﬁle. Motivated by these applications, in this paper we focus on the problem of constructing codes that can correct localized deletions. A. Related work Deletion errors were ﬁrst explored in the 1960s [6]–[8]. In 1966, Levenshtein [7] showed that the codes constructed by Varshamov and Tenengolts (VT codes) [6] are capable of correcting a single deletion. Also in [7], Levenshtein derived non-constructive asymptotic bounds on the redundancy needed to correct deletions. The bounds showed that the redundancy needed to correct δ bit deletions in a codeword of length n bits is asymptotically cδ log n, for some constant c > 0. Moreover, This work was done while the ﬁrst author was with the ECE Department, Rutgers University, USA. This paper was presented in part at the 55th Annual Allerton Conference on Communication, Control, and Computing, 2017 [1]. This work was supported in part by NSF Grant CCF 15-26875. for the case of a burst of exactly δ consecutive deletions, Levenshtein showed that at least log n + δ −1 redundant bits are required. Levenshtein’s bounds were later improved by Cullina and Kiyavash [9] for the general case of δ unrestricted deletions. Schoeny et al. [10] applied similar techniques as in [9] to derive a non-asymptotic lower bound for the case of a burst of δ deletions. The non-asymptotic bound derived in [10] matched Levenshtein’s asymptotic bound. Several previous works studied the general problem of constructing binary codes that correct multiple unrestricted deletions (δ > 1) [11]–[17]. Intuitively, correcting a burst of two deletions is an easier problem compared to correcting two deletions that are not necessarily consecutive (unrestricted). This idea is also reﬂected through Levenshtein’s bounds on the redundancy, which suggest that less redundancy would be required when the deletions occur in a burst. A separate line of work has focused on the problem of correcting deletions that occur in a single burst, i.e., consecutive deletions. Levenshtein [18] constructed asymptotically optimal codes that can correct a burst of at most two deletions. Cheng et al. [19] provided three constructions of codes that can correct a burst of exactly δ > 2 deletions. The lowest redundancy achieved by the codes in [19] is δ log(n/δ + 1). The fact that the number',\n",
       " '1004.3692': 'FAILED',\n",
       " '1804.08228': 'NLP for social media messages is challenging, requiring domain adaptation and annotated datasets (e.g., treebanks) for training and evaluation. Pioneering work by Foster et al. (2011) annotated 7,630 tokens’ worth of tweets according to the phrase-structure conventions of the Penn Treebank (PTB; Marcus et al., 1993), enabling conversion to Stanford Dependencies. Kong et al. (2014) further studied the challenges in annotating tweets and presented a tweet treebank (TWEEBANK), consisting of 12,149 tokens and largely following conventions suggested by Schneider et al. (2013), fairly close to Yamada and Matsumoto (2003) dependencies (without labels). Both annotation efforts were highly inﬂuenced by the PTB, whose guidelines have good grammatical coverage on newswire. However, when it comes to informal, unedited, user-generated text, the guidelines may leave many annotation decisions unspeciﬁed. Universal Dependencies (Nivre et al., 2016, UD) were introduced to enable consistent annotation across different languages. To allow such consistency, UD was designed to be adaptable to different genres (Wang et al., 2017) and languages (Guo et al., 2015; Ammar et al., 2016). We propose that analyzing the syntax of tweets can beneﬁt from such adaptability. In this paper, we introduce a new English tweet treebank of 55,607 tokens that follows the UD guidelines, but also contends with social media-speciﬁc challenges that were not covered by UD guidelines.1 Our annotation includes tokenization, part-of-speech (POS) tags, and (labeled) Universal Dependencies. We characterize the disagreements among our annotators and ﬁnd that consistent annotation is still challenging to deliver even with the extended guidelines. Based on these annotations, we nonetheless designed a pipeline to parse raw tweets into Universal Dependencies. Our pipeline includes: a bidirectional LSTM (bi-LSTM) tokenizer, a word cluster–enhanced POS tagger (following Owoputi et al., 2013), and a stack LSTM parser with character-based word representations (Ballesteros et al., 2015), which we refer to as our “baseline” parser. To overcome the noise in our annotated 1We developed our treebank independently of a similar effort for Italian tweets (Sanguinetti et al., 2017). See §2.5 for a comparison. arXiv:1804.08228v1  [cs.CL]  23 Apr 2018  data and achieve better performance without sacriﬁcing computational efﬁciency, we distill a 20parser ensemble into a single greedy parser (Hinton et al., 2015). We show further that learning directly from the exploration of the ensemble parser is more beneﬁcial than learning from the gold standard “oracle” transition sequence. Experimental results show that an improvement of more than 2.2 points in LAS over the baseline parser can be achieved with our distillation method. It outperforms other state-of-the-art parsers in both accuracy and speed. The contributions of this paper include: • We study the challenges of annotating tweets in UD (§2) and create a new tweet treebank (TWEEBANK V2), which includes tokenization, part-of-speech tagging, and labeled Universal Dependencies. We also',\n",
       " '1811.11103': 'Novel approaches for applying convolutional neural networks to graph-structured data have emerged in recent years. Commencing with the work in (Bruna et al. 2013; Henaff, Bruna, and LeCun 2015), there have been numerous developments and improvements. Although these graph convolutional neural networks (GCNNs) are promising, the current implementations have limited capability to handle uncertainty in the graph structure, and treat the graph topology as ground-truth information. This in turn leads to an inability to adequately characterize the uncertainty in the predictions made by the neural network. In contrast to this past work, we employ a Bayesian framework and view the observed graph as a realization from a parametric random graph family. The observed adjacency matrix is then used in conjunction with features and labels to perform joint inference. The results reported in this ∗These authors contributed equally to this work. Copyright c⃝2019, Association for the Advancement of Artiﬁcial Intelligence (www.aaai.org). All rights reserved. paper suggest that this formulation, although computationally more demanding, can lead to an ability to learn more from less data, a better capacity to represent uncertainty, and better robustness and resilience to noise or adversarial attacks. In this paper, we present the novel Bayesian GCNN framework and discuss how inference can be performed. To provide a concrete example of the approach, we focus on a speciﬁc random graph model, the assortative mixed membership block model. We address the task of semi-supervised classiﬁcation of nodes and examine the resilience of the derived architecture to random perturbations of the graph topology. 2 Related work A signiﬁcant body of research focuses on using neural networks to analyze structured data when there is an underlying graph describing the relationship between data items. Early work led to the development of the graph neural network (GNN) (Frasconi, Gori, and Sperduti 1998; Scarselli, Gori, and others 2009; Li et al. 2016b). The GNN approaches rely on recursive processing and propagation of information across the graph. Training can often take a long time to converge and the required time scales undesirably with respect to the number of nodes in the graph, although recently an approach to mitigate this has been proposed by (Liao, Brockschmidt, and others 2018). Graph convolutional neural networks (GCNNs) have emerged more recently, with the ﬁrst proposals in (Bruna et al. 2013; Henaff, Bruna, and LeCun 2015; Duvenaud, Maclaurin, and others 2015). A spectral ﬁltering approach was introduced in (Defferrard, Bresson, and Vandergheynst 2016) and this method was simpliﬁed or improved in (Kipf and Welling 2017; Levie, Monti, and others 2017; Chen, Ma, and Xiao 2018). Spatial ﬁltering or aggregation strategies were adopted in (Atwood and Towsley 2016; Hamilton, Ying, and Leskovec 2017). A general framework for training neural networks on graphs and manifolds was presented by (Monti, Boscaini, and others 2017) and the authors explain how several of the other methods can be interpreted as special cases. The performance of the',\n",
       " '1804.08229': 'In a general purpose planning system, task planning problems are tackled by problem-independent solvers based on a description of the domain in a declarative language. Such planning systems are extremely useful in application domains where many diﬀerent planning goals need to be accomplished, or the domain description evolves over time. For instance, in an application domain such as robotics, a mobile service robot may need to solve planning tasks such as collecting documents, making deliveries, or providing navigation assistance to visitors (Cambon et al., 2009; Erdem et al., 2012; Khan- † Corresponding author c⃝Zhejiang University and Springer-Verlag GmbH Germany, part of Springer Nature 2018 delwal et al., 2017). It is convenient to achieve all these tasks using knowledge declared in a single description of the domain, and general purpose planning systems are well suited to the task. In order to design a general purpose planning system, a declarative language for formalizing the domain ﬁrst needs to be selected, followed by the selection of a suitable solver which supports this language. Many diﬀerent factors aﬀect this selection process. Every language has its limitations in representing task planning problems, and given a particular language, speciﬁc language-dependent techniques may need to be employed to succinctly formalize a particular planning problem. For instance, not all languages support default reasoning, which might bring diﬃculties in formalizing some planning arXiv:1804.08229v3  [cs.AI]  25 Feb 2019  Jiang et al. / Front Inform Technol Electron Eng 2019 ??(?):0-0 1 problems. A solver is also typically tied to a particular language, but may not support all features in that language, requiring careful construction of the domain description using only supported features. Additionally, the properties of the domain can affect how quickly a given pair of language and solver can solve planning problems. For instance, some domains include many objects and their properties, which can be challenging to some planning systems. Finally, given a language, a solver and a planning problem, there can be many ways of formalizing the problem using the language. For these reasons, careful consideration needs to be given to the selection of language and solver. This article aims to help in the language selection process, given a task planning problem at hand. Speciﬁcally, we compare two declarative languages: the Planning Domain Deﬁnition Language (PDDL) (McDermott et al., 1998), the most popular language in the planning community, and Answer Set Programming (ASP) (Gelfond and Kahl, 2014; Lifschitz, 2008), a popular general knowledge representation and reasoning (KRR) language that has been recently used in a variety of task planning problems (Lifschitz, 2002; Yang et al., 2014; Erdem et al., 2016), including robotics (Erdem and Patoglu, 2018). PDDL was created for the explicit purpose of solving planning problems, whereas the development of ASP has focused on a broader set of reasoning tasks, such as inference and diagnosis, as well as planning. The',\n",
       " '1610.05735': 'Probabilistic models provide a framework for describing abstract prior knowledge and using it to reason under uncertainty. Probabilistic programs are a powerful tool for probabilistic modeling. A probabilistic programming language (PPL) is a deterministic programming language augmented with random sampling and Bayesian conditioning operators. Performing inference on these programs then involves reasoning about the space of executions which satisfy some constraints, such as observed values. A universal PPL, one built on a Turing-complete language, can represent any computable probability distribution, including open-world models, Bayesian non-parameterics, and stochastic recursion [6, 19, 33]. If we consider a probabilistic program to deﬁne a distribution p(x, y), where x are (latent) intermediate variable and y are (observed) output data, then sampling from this distribution is easy: just run the program forward. However, computing the posterior distribution p(x|y) is hard, involving an intractable integral. Typically, PPLs provide means to approximate the posterior using Monte Carlo methods (e.g. MCMC, SMC), dynamic programming, or analytic computation. These inference methods are expensive because they (approximately) solve an intractable integral from scratch on every separate invocation. But many inference problems have shared structure: it is reasonable to expect that computing p(x|y1) should give us some information about how to compute p(x|y2). In fact, there is reason to believe that this is how people are able to perform certain inferences, such as visual perception, so quickly—we have perceived the world many times before, and can leverage that accumulated knowledge when presented with a new perception task [3]. This idea of using the results of previous inferences, or precomputation in general, to make later inferences more efﬁcient is called amortized inference [3, 28]. arXiv:1610.05735v1  [cs.AI]  18 Oct 2016  Learning a generative model from many data points is a particularly important task that leads to many related inferences. One wishes to update global beliefs about the true generative model from individual data points (or batches of data points). While many algorithms are possible for this task, they all require some form of ‘parsing’ for each data point: doing posterior inference in the current generative model to guess values of local latent variable given each observation. Because this local parsing inference is needed many many times, it is a good candidate for amortization. It is plausible that learning to do local inference via amortization would support faster and better global learning, which gives more useful local inferences, leading to a virtuous cycle. This paper proposes a system for amortized inference in PPLs, and applies it to model learning. Instead of computing p(x|y) from scratch for each y, our system instead constructs a program q(x|y) which takes y as input and, when run forward, produces samples distributed approximately according to the true posterior p(x|y). We call q a guide program, following terminology introduced in previous work [11]. The system can spend time up-front constructing a good approximation q so that at inference time, sampling from q is both fast and accurate',\n",
       " '1804.00815': 'Convolutional neural networks (CNN) trained for object recognition tasks are similar to the visual cortex in many ways. For example, early layers show Gabor-like receptive ﬁelds similar to V1 [1], late layers that are highly predictive of V4, and inferior temporal cortex (IT) responses [2]. However, these networks lack the correlated variability of neuron responses in the human brain, among other major differences. In this paper, we discuss methods to incorporate correlated variability into deep convolutional networks and analyze its effect on recognition performance. Studying stochastic neurons is interesting because the effect of stochasticity on learning and computation in artiﬁcial neural systems may help us in modeling biological neurons. In population coding schemes in the brain, the joint activities of many neurons encode the value of a quantity. One advantage of population coding is that the noise can be averaged out over many neurons. However, the observation of correlation in spike variability [3] is concerning because it can prevent noise averaging and strongly affect cortical processing. The function of correlated variability in the brain is unclear. Our goal is to understand if correlated variability has beneﬁts that can be realized in artiﬁcial neural networks by studying its inﬂuence on certain tasks. One example of such a task is the long-standing problem of object recognition under partial occlusion. This requires the ability to robustly model invariance to certain transformations of the input. The primary method of gaining invariance to transformations is data driven, either by attempting to collect instances of the object under a wide variety of conditions, or augmenting the existing dataset via synthetic transformations. The authors in [4] suggest that the right way to learn invariance is not by adding data, as occlusions follow a long-tail distribution which cannot be covered, even by large-scale efforts in collecting data. This motivates the need to modify the structure of the network to learn invariance. We hypothesize that correlated variability might improve recognition performance in the challenging setting of partial occlusion. A common approach for regularizing deep neural networks is to inject noise during training; for example, adding or multiplying noise to the hidden units of the neural network, like in dropout [5]. Most solutions include additive or multiplicative independent noise in the hidden units. This is widely used because of its simplicity and effectiveness. We are motivated to consider correlated noise that is dependent on the weights of the network, such as our proposal to add noise sampled from a correlated distribution, where the correlation is a function of the differences in spatial position and selectivity of neurons, similar to the visual cortex. One of the major concerns of stochasticity in neural networks is the tendency to break differentiability, which prevents gradient computation via back-propagation. Depending on the noise distribution, one may simply ignore stochasticity in back-propagation (e.g. the straight-through estimator in the case of binary stochastic neurons [6]), or one may apply computationally convenient estimators for non-differentiable modules. For',\n",
       " '1808.07118': 'With the rise of social media, the amount of mineable data is rising rapidly. Countries where bilingualism is popular, we see users often switch back and forth between two languages while typing, a phenomenon known as code-mixing or codeswitching. For analyzing such data, language tagging acts as a preliminary step and its accuracy and performance can impact the system results to a great extent. Though a lot of work has been done recently targeting this task, the problem of language tagging in code-mixed scenario is still far from being solved. Code-mixing scenarios where one of the languages have been typed in its transliterated from possesses even more challenges, especially due to inconsistent phonetic typing. On such type of data, context capture is extremely hard as well. Proper context capture can help in solving problems like ambiguity, that is word forms which are common to both the languages, but for which, the correct tag can be easily understood by knowing the context. An additional issue is a lack of available code-mixed data. Since most of the tasks require supervised models, the bottleneck of data crisis affects the performance quite a lot, mostly due to the problem of over-ﬁtting. In this article, we present a novel architecture, which captures information at both word level and context level to output the ﬁnal tag. For word level, we have used a multichannel neural network (MNN) inspired from the recent works of computer vision. Such networks have also shown promising results in NLP tasks like sentence classiﬁcation (Kim, 2014). For context capture, we used Bi-LSTM-CRF. The context module was tested more rigorously as in quite a few of the previous work, this information has been sidelined or ignored. We have experimented on BengaliEnglish (Bn-En) and Hindi-English (Hi-En) codemixed data. Hindi and Bengali are the two most popular languages in India. Since none of them have Roman as their native script, both are written in their phonetically transliterated from when code-mixed with English. 2 Related Work In the recent past, a lot of work has been done in the ﬁeld of code-mixing data, especially language tagging. King and Abney (2013) used weakly semi-supervised methods for building a world level language identiﬁer. Linear chain CRFs with context information limited to bigrams was employed by Nguyen and Do˘gru¨oz (2013). Logistic regression along with a module which gives code-switching probability was used by Vyas et al. (2014). Multiple features like word context, dictionary, n-gram, edit distance were used by Das and Gamb¨ack (2014). Jhamtani et al. (2014) combined two classiﬁers into an ensemble model for Hindi-English code-mixed LID. The ﬁrst classiﬁer used modiﬁed edit distance, word frequency and character n-grams as features. The second classiﬁer used the output of the ﬁrst classiﬁer for the current word, along with language',\n",
       " '1507.03641': 'Neural network-based approaches to structured NLP tasks have both strengths and weaknesses when compared to more conventional models, such conditional random ﬁelds (CRFs). A key strength of neural approaches is their ability to learn nonlinear interactions between underlying features. In the case of unstructured output spaces, this capability has led to gains in problems ranging from syntax (Chen and Manning, 2014; Belinkov et al., 2014) to lexical semantics (Kalchbrenner et al., 2014; Kim, 2014). Neural methods are also powerful tools in the case of structured 1System available at http://nlp.cs.berkeley.edu output spaces. Here, past work has often relied on recurrent architectures (Henderson, 2003; Socher et al., 2013; ˙Irsoy and Cardie, 2014), which can propagate information through structure via realvalued hidden state, but as a result do not admit efﬁcient dynamic programming (Socher et al., 2013; Le and Zuidema, 2014). However, there is a natural marriage of nonlinear induced features and efﬁcient structured inference, as explored by Collobert et al. (2011) for the case of sequence modeling: feedforward neural networks can be used to score local decisions which are then “reconciled” in a discrete structured modeling framework, allowing inference via dynamic programming. In this work, we present a CRF constituency parser based on these principles, where individual anchored rule productions are scored based on nonlinear features computed with a feedforward neural network. A separate, identicallyparameterized replicate of the network exists for each possible span and split point. As input, it takes vector representations of words at the split point and span boundaries; it then outputs scores for anchored rules applied to that span and split point. These scores can be thought of as nonlinear potentials analogous to linear potentials in conventional CRFs. Crucially, while the network replicates are connected in a uniﬁed model, their computations factor along the same substructures as in standard CRFs. Prior work on parsing using neural network models has often sidestepped the problem of structured inference by making sequential decisions (Henderson, 2003; Chen and Manning, 2014; Tsuboi, 2014) or by doing reranking (Socher et al., 2013; Le and Zuidema, 2014); by contrast, our framework permits exact inference via CKY, since the model’s structured interactions are purely discrete and do not involve continuous hidden state. Therefore, we can exploit a neural net’s capacity to learn nonlinear features without modifying arXiv:1507.03641v1  [cs.CL]  13 Jul 2015  S NP VP DT NNP VBZ NP … W The Fed issued Structured inference\\t \\r (discrete) Feature extraction (continuous) fo h φ fw v(fw) Figure 1: Neural CRF model. On the right, each anchored rule (r, s) in the tree is independently scored by a function φ, so we can perform inference with CKY to compute marginals or the Viterbi tree. On the left, we show the process for scoring an anchored rule with neural features: words in fw (see Figure 2) are embedded, then fed through a neural',\n",
       " '1708.05123': 'Click-through rate (CTR) prediction is a large-scale problem that is essential to multi-billion dollar online advertising industry. In the advertising industry, advertisers pay publishers to display their ads on publishers’ sites. One popular payment model is the cost-perclick (CPC) model, where advertisers are charged only when a click occurs. As a consequence, a publisher’s revenue relies heavily on the ability to predict CTR accurately. Identifying frequently predictive features and at the same time exploring unseen or rare cross features is the key to making good predictions. However, data for Web-scale recommender systems is mostly discrete and categorical, leading to a large and sparse feature space that is challenging for feature exploration. Tis has limited most large-scale systems to linear models such as logistic regression. Linear models [3] are simple, interpretable and easy to scale; however, they are limited in their expressive power. Cross features, on the other hand, have been shown to be signiﬁcant in improving the models’ expressiveness. Unfortunately, it ofen requires manual feature engineering or exhaustive search to identify such features; moreover, generalizing to unseen feature interactions is diﬃcult. In this paper, we aim to avoid task-speciﬁc feature engineering by introducing a novel neural network structure – a cross network – that explicitly applies feature crossing in an automatic fashion. Te cross network consists of multiple layers, where the highestdegree of interactions are provably determined by layer depth. Each layer produces higher-order interactions based on existing ones, and keeps the interactions from previous layers. We train the cross network jointly with a deep neural network (DNN) [10, 14]. DNN has the promise to capture very complex interactions across features; however, compared to our cross network it requires nearly an order of magnitude more parameters, is unable to form cross features explicitly, and may fail to eﬃciently learn some types of feature interactions. Jointly training the cross and DNN components together, however, eﬃciently captures predictive feature interactions, and delivers state-of-the-art performance on the Criteo CTR dataset. 1.1 Related Work Due to the dramatic increase in size and dimensionality of datasets, a number of methods have been proposed to avoid extensive taskspeciﬁc feature engineering, mostly based on embedding techniques and neural networks. Factorization machines (FMs) [11, 12] project sparse features onto low-dimensional dense vectors and learn feature interactions from vector inner products. Field-aware factorization machines (FFMs) [7, 8] further allow each feature to learn several vectors where each vector is associated with a ﬁeld. Regretably, the shallow structures of FMs and FFMs limit their representative power. Tere have been work extending FMs to higher orders [1, 18], but one downside lies in their large number of parameters which yields undesirable computational cost. Deep neural networks (DNN) are able to learn non-trivial high-degree feature interactions due to embedding vectors and nonlinear activation functions. Te recent success of the Residual Network [5] has enabled training of very deep networks',\n",
       " '1105.0286': 'Recently, there is an intense research interest in the area of interference channels and the interference mitigation techniques. Interference alignment (IA) was proposed in [1], [2] to reduce the effect of multi-user interference and is extended to deal with interference in MIMO X-channels [3] and K pairs interference channels [4]. The key idea of IA is to reduce the dimension of the aggregated interference by aligning interference from different transmitters into a lower dimension subspace at each receiver. Using inﬁnite dimension extension on the time dimension (time selective fading), it is shown that the IA could achieve the optimal October 25, 2018 DRAFT  1 Degrees-of-Freedom (DoF) of KN 2 in K-pair MIMO ergodic interference channels [4] with N antennas at each node. In [5], the authors proposed the concept of ergodic alignment, which also utilizes symbol extension exploiting time-selective fading of interference channels. One important challenge of IA scheme is the feasibility condition. For instance, the IA schemes in [4] requires O((KN)2K2N2) dimensions of signal space to achieve the KN 2 total DoF. To avoid such huge dimensions of signal space, some researchers have studied IA designs for quasi-static MIMO interference channels. With limited signal space dimensions, the achievable DoF of each transmitter-receiver pair in MIMO interference channels is upper bounded by Nt+Nr K+1 (where K is the number of transmitter-receiver pairs, Nt, Nr are the number of antennas at each transmitter and receiver, respectively) [6]. Unlike the timeselective or frequency-selective MIMO interference channels, total DoF of quasi-static MIMO interference channel does not scale with K. Furthermore, it is quite challenging to design precoders and decorrelators that satisfy the IA requirements in limited dimension MIMO interference channels due to the feasibility problems [6]. In [7], an iterative precoders and decorrelators design based on alternating optimization is proposed for quasi-static MIMO interference channels. In [8], [9], some constructive methods to design precoders and decorrelators are proposed, but these schemes can only achieve 1 DoF per transmitter. In fact, the technical challenge on the feasibility issue in limited dimension MIMO interference channels is highly related to the full connectivity in the interference graph. In practice, the interference channels are usually partially connected due to path loss, shadowing as well as spatial correlation. Most of the existing literatures have assumed fully connected MIMO interference channels such as equal path loss and spatially uncorrelated MIMO channels. Intuitively, partial connectivity may contribute to limiting the aggregate interference and this may translate into DoF gains in the system. In this paper, we are interested to study the potential beneﬁt of partially connectivity in a K-pair MIMO interference network with quasi static fading. There are several important technical challenges involved. • How to exploit partial connections in interference mitigation? Traditionally, it is well-known that partial connection (due to path loss, shadowing or spatial correlation) is detrimental to point-to-point MIMO performance [10], [11] because it reduces',\n",
       " '1602.04567': 'Ranking is one of the fundamental problems that has proved crucial in a wide variety of contexts—social choice [1], [2], web search and information retrieval [3], recommendation systems [4], ranking individuals by group comparisons [5] and crowdsourcing [6], to name a few. Due to its wide applicability, a large volume of work on ranking has been done. The two main paradigms in the literature include spectral ranking algorithms [3], [7], [8] and maximum likelihood estimation (MLE) [9]. While these ranking schemes yield reasonably good estimates which are faithful globally w.r.t. the latent preferences (i.e., low ℓ2 loss), it is not necessarily guaranteed that this results in optimal ranking accuracy. Accurate ranking has more to do with how well the ordering of the estimates matches that of the true preferences (a discrete/combinatorial optimization problem), and less to do with how well we can estimate the true preferences (a continuous optimization problem). In applications, a ranking algorithm that outputs a total ordering of all the items is not only overkill, but it also unnecessarily increases complexity. Often, we pay attention to only a few signiﬁcant items. Thus, recent work such as that by Chen and Suh [10] studied the top-K identiﬁcation task. Here, one aims to recover a correct set of top-ranked items only. This work characterized the minimax limit on the sample size required (i.e., the sample complexity) for reliable top-K ranking, assuming the Bradley-Terry-Luce (BTL) model [11], [12]. While this result is concerned with practical issues, there are still limitations when modeling other realistic scenarios. The BTL model considered in [10] assumes that the quality of pairwise comparison information which forms the basis of the model is the same across annotators. In reality (e.g., crowdsourced settings), however, the quality of the information can vary signiﬁcantly across different annotators. For instance, there may be a nonnegligible fraction of spammers who provide answers in an adversarial manner. In the context of adversarial web search [13], web contents can be maliciously manipulated by spammers for commercial, social, or political beneﬁts in a robust manner. Alternatively, there may exist false information such as false voting in social networks and fake ratings in recommendation systems [14]. As an initial effort to address this challenge, we investigate a so-called adversarial BTL model, which postulates the existence of two sets of populations—the faithful and adversarial populations, each of which has proportion C. Suh is with the School of Electrical Engineering at Korea Advanced Institute of Science and Technology (email: chsuh@kaist.ac.kr). V. Y. F. Tan is with the Department of Electrical and Computer Engineering and the Department of Mathematics, National University of Singapore. (email: vtan@nus.edu.sg). R. Zhao is with the Department of Electrical and Computer Engineering, National University of Singapore. (email: elezren@nus.edu.sg). C. Suh is supported by a gift from Samsung. V. Y. F. Tan and R. Zhao gratefully acknowledge ﬁnancial support from the',\n",
       " '1812.00477': 'In recent years, accurate localization and consistent tracking in a large crowd, including the shopping mall, urban street, airport, and public park, possibly involved with interaction for identiﬁcation of speciﬁc requests, are extensively needed, especially for visually impaired people [33] and urban navigation with high accuracy localization request [1]. However, the requirement of large storage for pre-recorded feature map [20] limits its usage in a large open area. Besides, the problem of view block and the lack of static features for tracking also make it harder to be implemented in urban areas [11]. It is highly required to have a stable and mobile capable approach to solve this problem in a high accuracy. In this paper, we propose to use a mobile camera and Figure 1. The architecture of the proposed ego-downward and third view assist system. The ego-downward camera (not able to be blocked) is used to localize the person in the third view. a static third view camera system as illustrated in Fig.1 to address this problem. We assume that the person wears a head-mount camera which observing a downward narrow area (a case for VR game headset). We aim to verify how an ego downward camera and a third view camera can be used for veriﬁcation and localization in the wild. Note that there are some existing works on third and ego-centric view matching analysis for the human. All of these approaches, however, focusing on using two streams siamese or triplet network structure [14, 27, 5] to learn to identify between third and ego view. In these models, the most recent approaches including 3D convolutional neural network [29, 31, 23] and segmental consensus for crossdomain veriﬁcation [31, 14, 27] are deployed. However, these approaches cannot generalize the knowledge of pose and motion for human tracking and cross view veriﬁcation. Thus, pure visual features are not capable to model the variance of the human action across views toward tracking, especially the ego-downward view can only visualize the human itself. Unlike the top-and-forward view [5] and third-forward view [14] cases, the ego-downward mounting faces the following challenges : 1) appearance veriﬁcation across different views does not hold under this situation since it is not pointing out to scenario; 2) clothes texture veriﬁcation will not work since in large crowd there should have the simi1 arXiv:1812.00477v1  [cs.CV]  2 Dec 2018  lar dressing or occlusion; 3) the same action with different initial pose state (in world coordinate system) will also mislead the model since the ego-downward frames will not tell the difference (in Fig.3). Thus, using a general siamese or triplet model to correlate the two views with temporal and spatial information would fail [14]. Moreover, the graph solution using relative view insight will not happen under this situation [5]. In this paper, we proposed a novel action and motion feature based model',\n",
       " '1810.09150': 'The starting point of this work is to apply UCT [KS06], an eﬃcient algorithm well-known in the machine learning and computer games communities, and originally designed for planning, on classical planning problems. UCT is designed for MDP, and based on bandit decision making [ACBF02]. In the background of the current paper that stresses time constraints, the interesting feature of UCT is its anytime property in a strong meaning. At any time, UCT is able to return the ﬁrst action of a plan, a partial plan, a solution plan, or an optimal plan according to the given time. However, [KS06] did not give known successful applications in the classical planning domain yet [GNT04]. Instead, UCT gave tremendous results in computer games, and speciﬁcally in Computer Go with the Go playing program Mogo [GWMT06]. In Computer Go, UCT is eﬃcient because the Go complexity is high, and because the Go games are played in real time, which ﬁts the anytime property of UCT. Therefore, this paper focuses on 1 arXiv:1810.09150v1  [cs.AI]  22 Oct 2018  how to give value to UCT-like algorithms in a sub-ﬁeld of planning dealing with time constraints. The state of the art of planning is huge [RH09], and we roughly divide it into two categories, oﬀ-line and on-line planning. In the context of oﬀ-line planning, the planners build solution plans, and then execute the actions of the plan. An important aspect is the existence of very good heuristic functions that drive the search eﬃciently toward the goal. The heuristic functions are built with the help of a planning graph [BF97]. The state-of-the-art planners use variants of depth ﬁrst search, i.e., Enforced Hill Climbing [HN01], and may ﬁnd a solution plan very quickly from the initial state to the goal state. However, although they ﬁnd solution plans very quickly on suﬃciently easy problems, these planners are not real-time planners, and they may fall if they have not enough time to ﬁnd a solution plan. Conversely, in the context of on-line planning, the planners make their decision in constant time, and then execute the corresponding action, or sequence of actions, in the world. The literature distinguishes two approaches, one based on MDP applied to non-deterministic problems, e.g., [BBS95, HZ01] and the other based on Real-Time Search (RTS), e.g., [Kor90]. If the ﬁrst approach was recently applied to planning [FFB+07], the second approach RTS has been strongly linked, since the pioneering Korf’s work on puzzles, to the development of video games in which the agents need good path-ﬁnding algorithms running in real time. This last approach was not broadened to the classical planning problems. Classically, there are several real-time searches, e.g., mini-min [Kor88], γ-Trap [Bul04], LRTS [BL06] or even A* [HNR68]. These algorithms perform action selection by using heuristic search. Since the action selection time is limited, these algorithms explore a small',\n",
       " '1110.2417': 'FAILED',\n",
       " '1603.07252': 'The need to access and digest large amounts of textual data has provided strong impetus to develop automatic summarization systems aiming to create shorter versions of one or more documents, whilst preserving their information content. Much effort in automatic summarization has been devoted to sentence extraction, where a summary is created by identifying and subsequently concatenating the most salient text units in a document. Most extractive methods to date identify sentences based on human-engineered features. These include surface features such as sentence position and length (Radev et al., 2004), the words in the title, the presence of proper nouns, content features such as word frequency (Nenkova et al., 2006), and event features such as action nouns (Filatova and Hatzivassiloglou, 2004). Sentences are 1Resources are available for download at http:// homepages.inf.ed.ac.uk/s1537177/resources.html typically assigned a score indicating the strength of presence of these features. Several methods have been used in order to select the summary sentences ranging from binary classiﬁers (Kupiec et al., 1995), to hidden Markov models (Conroy and O’Leary, 2001), graph-based algorithms (Erkan and Radev, 2004; Mihalcea, 2005), and integer linear programming (Woodsend and Lapata, 2010). In this work we propose a data-driven approach to summarization based on neural networks and continuous sentence features. There has been a surge of interest recently in repurposing sequence transduction neural network architectures for NLP tasks such as machine translation (Sutskever et al., 2014), question answering (Hermann et al., 2015), and sentence compression (Rush et al., 2015). Central to these approaches is an encoderdecoder architecture modeled by recurrent neural networks. The encoder reads the source sequence into a list of continuous-space representations from which the decoder generates the target sequence. An attention mechanism (Bahdanau et al., 2015) is often used to locate the region of focus during decoding. We develop a general framework for singledocument summarization which can be used to extract sentences or words. Our model includes a neural network-based hierarchical document reader or encoder and an attention-based content extractor. The role of the reader is to derive the meaning representation of a document based on its sentences and their constituent words. Our models adopt a variant of neural attention to extract sentences or words. Contrary to previous work where attention is an intermediate step used to blend hidden units of an encoder to a vector propagating additional information to the decoder, our model applies attention directly to select sentences or words of the input document as the output summary. Similar neural attention architectures have been previously used for geometry reasoning (Vinyals et al., 2015), under the name Pointer Networks. arXiv:1603.07252v3  [cs.CL]  1 Jul 2016  One stumbling block to applying neural network models to extractive summarization is the lack of training data, i.e., documents with sentences (and words) labeled as summary-worthy. Inspired by previous work on summarization (Woodsend and Lapata, 2010; Svore et al., 2007',\n",
       " '1606.01455': 'Visual question-answering tasks provide a testbed to cultivate the synergistic proposals which handle multidisciplinary problems of vision, language and integrated reasoning. So, the visual questionanswering tasks let the studies in artiﬁcial intelligence go beyond narrow tasks. Furthermore, it may help to solve the real world problems which need the integrated reasoning of vision and language. Deep residual learning [6] not only advances the studies in object recognition problems, but also gives a general framework for deep neural networks. The existing non-linear layers of neural networks serve to ﬁt another mapping of F(x), which is the residual of identity mapping x. So, with the shortcut connection of identity mapping x, the whole module of layers ﬁt F(x) + x for the desired underlying mapping H(x). In other words, the only residual mapping F(x), deﬁned by H(x) −x, is learned with non-linear layers. In this way, very deep neural networks effectively learn representations in an efﬁcient manner. Many attentional models utilize the residual learning to deal with various tasks, including textual reasoning [25, 21] and visual question-answering [29]. They use an attentional mechanism to handle two different information sources, a query and the context of the query (e.g. contextual sentences or an image). The query is added to the output of the attentional module, that makes the attentional module learn the residual of query mapping as in deep residual learning. In this paper, we propose Multimodal Residual Networks (MRN) to learn multimodality of visual question-answering tasks exploiting the excellence of deep residual learning [6]. MRN inherently uses shortcuts and residual mappings for multimodality. We explore various models upon the arXiv:1606.01455v2  [cs.CV]  31 Aug 2016  Q V A RNN  CNN softmax Multimodal Residual Networks What kind of animals  are these ?  sheep  word embedding Figure 1: Inference ﬂow of Multimodal Residual Networks (MRN). Using our visualization method, the attention effects are shown as a sequence of three images. More examples are shown in Figure 4. A Linear Tanh Linear Tanh Linear Tanh Linear Q V H1 Linear Tanh Linear Tanh Linear Tanh Linear H2 V Linear Tanh Linear Tanh Linear Tanh Linear H3 V Linear Softmax ⊙ ⊕ ⊙ ⊕ ⊙ ⊕ Softmax Figure 2: A schematic diagram of Multimodal Residual Networks with three-block layers. choice of the shortcuts for each modality, and the joint residual mappings based on element-wise multiplication, which effectively learn the multimodal representations not using explicit attention parameters. Figure 1 shows inference ﬂow of the proposed MRN. Additionally, we propose a novel method to visualize the attention effects of each joint residual mapping. The visualization method uses back-propagation algorithm [22] for the difference between the visual input and the output of the joint residual mapping. The difference is back-propagated up to an input image. Since we use the pretrained visual features, the pretrained CNN is augmented for visualization. Based on this, we argue that MRN is an implicit attention model without explicit attention parameters. Our contribution',\n",
       " '1610.05551': 'Bayesian networks, BNs for short, have been a subject of great interest partly due to their contribution in solving real-life problems that involve uncertainty. Bayesian networks are probabilistic graphical models that represent joint probability distributions concisely by factoring them into conditional probabilities based on independence assumptions, in order to perform inference more eﬃciently [1]. Further representational and computational advances have been made by exploiting causal independence [2], as well as contextual independence [3] and determinism [4] expressed in conditional probability tables (CPTs). In order to capture these independencies local to CPTs, Bayesian networks have been represented as weighted Boolean formulas [5, 6], reducing inference to Weighted Model Counting (WMC), or weighted #SAT [5]. By representing a Bayesian network as Boolean formula f in conjunctive normal form (CNF), it can be compiled into a more concise normal form, or language, that renders inference a polytime operation in the size of the representation [7]. A joint probability space with n Boolean variables has 2n interpretations. It is therefore necessary to be able to reason with sets of interpretations, requiring a symbolic representation [8]. Symbolic inference uniﬁes the work of probabilistic inference and the extensive research done in the ﬁeld of model checking, veriﬁcation and satisﬁability [9]. Ordered Binary Decision Diagrams (OBDDs) are based on Shannon decompositions and have been a very Preprint submitted to Elsevier July 3, 2021  inﬂuential symbolic representation that reduces compilation to the problem of ﬁnding the variable ordering resulting in the optimal factoring. We focus on the disadvantage of the approaches in recent work that encode a BN as an independent CNF f, motivated by the ability to use oﬀ-the-shelf SAT-solvers. While maintaining this ability, we exploit the knowledge that is lost during the encoding without requiring this independence. Our contributions are the following. We propose a weighted variant of OBDDs, called Weighted Positive Binary Decision Diagrams (WPBDDs), which are based on positive Shannon decompositions, allowing constraints in BNs to be represented more concisely. We use probabilities as symbolic edge weights, reducing the search space exponentially. An optimized compilation algorithm is introduced, inspired by the ﬁeld of Satisﬁability Modulo Theories (SMT), namely a lazy SMT-solver [10]. It provides the means to view constraints among variables in the encoding as background theory T which supports the SAT-solver, allowing constant time conditioning. We compile the conditional probability tables of a BN explicitly, but leave implicit the domain closure implied by the encoding. This approach allows us to remove by up to a third of the clauses in the encoding. A comparison is provided with the state-of-the-art CUDD (CU Decision Diagram [11]) and SDD (Sentential Decision Diagram [12]) compilers and we show that WPBDDs induce arithmetic circuits that are 60% reduced in size on average compared to a corresponding OBDD circuits at representing over 30 publicly available BNs. We show an inference speedup of over 2.6 times on average compared to Weighted Model Counting with OBDDs, and',\n",
       " '1303.7454': 'The capacity of the multiple input multiple output (MIMO) broadcast channel (BC) can be reached by non-linear precoding methods, namely dirty paper coding (DPC) [1]. However, linear precoding methods, like zero forcing (ZF) precoding, can still attain the channel capacity in a multiuser environment [2]–[4], while proven more realistic in terms of practical implementation. Linear precoding techniques, especially ZF, have been extensively investigated in [3], [5] and the references therein. In these cases, ZF precoding constitutes a simple precoder design solution. By inverting the channel, multiuser interferences are cancelled and the precoding design problem is reduced to a power allocation problem over new equivalent channels; hence a simple concave optimization problem [6] needs to be solved. To maximize the throughput (sum-rate, SR), the well known water-ﬁlling solution can be straightforwardly applied [7]. To maximize the minimum offered rate (i.e. the fairness problem), the problem is still convex and thus solvable [5]. The key assumption of all the above considerations however is the assumption of Gaussian signaling. The concept of constructive interference linear precoding, initially proposed in [8] for code division multiple access (CDMA) systems and then extended to apply for MIMO communications in [9], is based on the multiuser interference cancellation concept of channel inversion. An example of the concept is described in Fig. 1. The novelty of this precoder design lies in considering practical constellations and allowing users that add up to the intended user’s signal power to interfere. This is referred to as constructive interference (CI) and it can be exploited by acknowledging each users’ channel and modulated signal. The problem of power allocation in constructive interference zero forcing (CIZF) precoding techniques has not been studied in existing literature. Existing works on this topic only assumed CIZF precoding with equal power allocation for all users [9]. Fig. 1. The constructive interference (CI) concept over binary phase shift keying (BPSK) modulations: The k-th user’s transmit symbol is sk = +1. The i-th user’s symbol, si, multiplied by the cross-correlation between the k-th and the j-th user’s channels, ρkj (see Sec. II-B), is a vector that when added to sk will move the resulting vector further away from the decision threshold (0 for BPSK). Subsequently, not cancelling this user will beneﬁt the k-th user. On the other hand, the j-th user is still interfering thus needs to be cancelled by the precoding design. Another very important aspect of linear precoding is the user selection problem investigated in [3], [6]. ZF performance is increased when user channels are orthogonal to each other. Under the assumption of large random user sets, the probability of orthogonal users increases and with that the complexity of the user selection problem. Nevertheless, simple suboptimal algorithms in the existing literature provide substantial gains with affordable complexity. Based on existing methods, Yoo et al [2] proposed a low complexity, iterative user selection algorithm that allows ZF to achieve',\n",
       " '1708.00111': 'Sequence-to-sequence (seq2seq) models have been successfully used for many sequential decision tasks such as machine translation (Sutskever, Vinyals, and Le 2014; Bahdanau, Cho, and Bengio 2015), parsing (Dyer et al. 2016; Dyer et al. 2015), summarization (Rush, Chopra, and Weston 2015), dialog generation (Serban et al. 2015), and image captioning (Xu et al. 2015). Beam search is a desirable choice of test-time decoding algorithm for such models because it potentially avoids search errors made by simpler greedy methods. However, the typical approach to training neural sequence models is to use a locally normalized maximum likelihood objective (cross-entropy training) (Sutskever, Vinyals, and Le 2014). This objective does not directly reason about the behaviour of the ﬁnal decoding method. As a result, for cross-entropy trained models, beam decoding can sometimes yield reduced test performance when compared with greedy decoding (Koehn and Knowles 2017; Neubig 2017; Cho et al. 2014). These negative results are not unexpected. The training procedure was not search-aware: it was not able to consider the effect that changing the model’s scores might have on the ease of search while using a beam decoding, greedy decoding, or otherwise. We hypothesize that the under-performance of beam search in certain scenarios can be resolved by using a better designed training objective. Because beam search potentially offers more accurate search when compared to greedy decoding, we hope that appropriately trained models should be able to leverage beam search to improve performance. In order to train models that can more effectively make use of beam search, we propose a new training procedure that focuses on the ﬁnal loss metric (e.g. Hamming loss) evaluated on the output of beam search. While well-deﬁned and a valid training criterion, this “direct loss” objective is discontinuous and thus difﬁcult to optimize. Hence, in our approach, we form a sub-differentiable surrogate objective by introducing a novel continuous approximation of the beam search decoding procedure. In experiments, we show that optimizing this new training objective yields substantially better results on two sequence tasks (Named Entity Recognition and CCG Supertagging) when compared with both cross-entropy trained greedy decoding and cross-entropy trained beam decoding baselines. Several related methods, including reinforcement learning (Ranzato et al. 2016; Bahdanau et al. 2017), imitation learning (Daumé, Langford, and Marcu 2009; Ross, Gordon, and Bagnell 2011; Bengio et al. 2015), and discrete search based methods (Wiseman and Rush 2016; Andor et al. 2016; Daumé III and Marcu 2005; Gormley, Dredze, and Eisner 2015), have also been proposed to make training searchaware. These methods include approaches that forgo direct optimization of a global training objective, instead incorporating credit assignment for search errors by using methods like early updates (Collins and Roark 2004) that explicitly track the reachability of the gold target sequence during the search procedure. While addressing a related problem – credit assignment for search errors during training – in this paper, we propose',\n",
       " '1801.01803': 'A GE of Information (AoI) has been receiving increasing attention in the literature [2]–[25], particularly for applications that generate time-sensitive information such as position, command and control, or sensor data. An interesting feature of this performance metric is that it captures the freshness of the information from the perspective of the destination, in contrast to the long-established packet delay, that represents the freshness of the information with respect to individual packets. In particular, AoI measures the time that elapsed since the generation of the packet that was most recently delivered to the destination, while packet delay measures the time interval between the generation of a packet and its delivery. The two parameters that inﬂuence AoI are packet delay and packet inter-delivery time. In general, controlling only one is insufﬁcient for achieving good AoI performance. For example, consider an M/M/1 queue with a low arrival rate and a high service rate. In this setting, the queue is often empty, resulting in low packet delay. Nonetheless, the AoI can still be high, since infrequent packet arrivals result in outdated information at the destination. Table I provides a numerical example of an M/M/1 queue with ﬁxed service rate µ = 1 and a variable arrival rate λ. The ﬁrst and third rows represent a system with The authors are with the Massachusetts Institute of Technology and with the Middle East Technical University. (e-mail: kadota@mit.edu; sinhaa@mit.edu; uelif@metu.edu.tr; rsingh12@mit.edu; modiano@mit.edu) This paper was presented in part at the Allerton Conference in 2016 [1]. a high average AoI caused by high inter-delivery time and high packet delay, respectively. The second row shows the queue at the point of minimum average AoI [2]. A good AoI performance is achieved when packets with low delay are delivered regularly. It is important to emphasize the difference between delivering packets regularly and providing a minimum throughput. Figure 1 illustrates the case of two sequences of packet deliveries that have the same throughput but different delivery regularity. In general, a minimum throughput requirement can be fulﬁlled even if long periods with no delivery occur, as long as those are balanced by periods of consecutive deliveries. The problem of minimizing AoI was introduced in [2] and has been explored using different approaches. Queueing Theory is used in [2]–[9] for ﬁnding the optimal server utilization with respect to AoI. The authors in [10]–[13] consider the problem of optimizing the times in which packets are generated at the source in networks with energy-harvesting or maximum update frequency constraints. Link scheduling optimization with respect to AoI has been recently considered in [14]–[21]. Applications of AoI are studied in [22]–[25]. The problem of optimizing link scheduling decisions in broadcast wireless networks with respect to throughput and delivery times has been studied extensively in the literature. Throughput maximization of trafﬁc with strict packet delay constraints has been addressed',\n",
       " '1505.00880': 'One of the fundamental challenges of computer vision is to draw inferences about the three-dimensional (3D) world from two-dimensional (2D) images. Since one seldom has access to 3D object models, one must usually learn to recognize and reason about 3D objects based upon their 2D appearances from various viewpoints. Thus, computer vision researchers have typically developed object recognition algorithms from 2D features of 2D images, and used them to classify new 2D pictures of those objects. But what if one does have access to 3D models of each object of interest? In this case, one can directly train recognition algorithms on 3D features such as voxel occupancy or surface curvature. The possibility of building such classiﬁers of 3D shapes directly from 3D representations has recently emerged due to the introduction of large 3D shape repositories, such as 3D Warehouse, TurboSquid, and Shapeways. For example, when Wu et al. [37] introduced the ModelNet 3D shape database, they presented a classiﬁer for 3D shapes using a deep belief network architecture trained on voxel representations. While intuitively, it seems logical to build 3D shape classiﬁers directly from 3D models, in this paper we present a seemingly counterintuitive result – that by building classiﬁers of 3D shapes from 2D image renderings of those shapes, we can actually dramatically outperform the classiﬁers built directly on the 3D representations. In particular, a convolutional neural network (CNN) trained on a ﬁxed set of rendered views of a 3D shape and only provided with a single view at test time increases category recognition accuracy by a remarkable 8% (77% →85%) over the best models [37] trained on 3D representations. With more views provided at test time, its performance further increases. One reason for this result is the relative efﬁciency of the 2D versus the 3D representations. In particular, while a full resolution 3D representation contains all of the information about an object, in order to use a voxel-based representation in a deep network that can be trained with available samples and in a reasonable amount of time, it would appear that the resolution needs to be signiﬁcantly reduced. For example, 3D ShapeNets use a coarse representation of shape, a 30×30×30 grid of binary voxels. In contrast a single projection of the 3D model of the same input size corresponds to an image of 164×164 pixels, or slightly smaller if multiple projections are used. Indeed, there is an inherent trade-off between increasing the amount of explicit depth information (3D models) and increasing spatial resolution (projected 2D models). Another advantage of using 2D representations is that we can leverage (i) advances in image descriptors [22, 26] and (ii) massive image databases (such as ImageNet [9]) to pre-train our CNN architectures. Because images are ubiquitous and large labeled datasets are abundant, we can learn a good deal about generic features for 2D image categorization and then ﬁne-tune',\n",
       " '1802.07442': 'Truly autonomous artiﬁcial agents must be able to discover useful behaviors in complex environments without having humans present to constantly pre-specify tasks and rewards. This ability is beyond that of today’s most advanced autonomous robots. In contrast, human infants exhibit a wide range of interesting, apparently spontaneous, visuo-motor behaviors — including navigating their environment, seeking out and attending to novel objects, and engaging physically with these objects in novel and surprising ways [4, 9, 13, 15, 20, 21, 44]. In short, young children are excellent at playing — “scientists in the crib” [13] who create, intentionally, events that are new, informative, and exciting to them [9, 42]. Aside from being fun, play behaviors are an active learning process [40], driving selfsupervised learning of representations underlying sensory judgments and motor planning [4, 15, 24]. But how can we use these observations on infant play to improve artiﬁcial intelligence? AI theorists have long realized that playful behavior in the absence of rewards can be mathematically formalized via loss functions encoding intrinsic reward signals, in which an agent chooses actions that result in novel but predictable states that maximize its learning [38]. These ideas rely on a virtuous cycle in which the agent actively self-curricularizes as it pushes the boundaries of what its world-modelprediction systems can achieve. As world-modeling capacity improves, what used to be novel becomes old hat, and the cycle starts again. ∗Equal contribution Preprint. Work in progress. arXiv:1802.07442v2  [cs.LG]  30 Oct 2018  Here, we build on these ideas using the tools of deep reinforcement learning to create an artiﬁcial agent that learns to play. We construct a simulated physical environment inspired by infant play rooms, in which an agent can swivel its head, move around, and physically act on nearby visible objects (Fig. 1). Akin to challenging video game tasks [26], informative interactions in this environment are possible, but sparse unless actively sought by the agent. However, unlike most video game or constrained robotics environments, there is no extrinsic goal to constrain the agent’s action policy. The agent has to learn about its world, and what is interesting in it, for itself. Figure 1: 3D Physical Environment. The agent can move around, apply forces to visible objects in close proximity, and receive visual input. In this environment, we describe a neural network architecture with two interacting components, a world-model and a self-model, which are learned simultaneously. The world-model seeks to predict the consequences of agent’s actions, either through forward or inverse dynamics estimation. The self-model learns explicitly to predict the errors of the world-model. The agent then uses the self-model to choose actions that it believes will adversarially challenge the current state of its world-model. Our core result is the demonstration that this intrinsically-motived self-aware architecture stably engages in a virtuous reinforcement learning cycle, spontaneously discovering highly nontrivial cognitive behaviors — ﬁrst understanding and controlling self',\n",
       " '1801.04354': 'Deep learning has achieved remarkable results in the field of natural language processing (NLP), including sentiment analysis, relation extraction, and machine translation [17, 29, 30]. However, recent studies have shown that adding small modifications to test inputs can fool state-of-the-art deep classifiers, resulting in incorrect classifications [7, 28]. This phenomenon was first formulated as adding very small and often imperceptible perturbations on images, which could fool deep classifiers on image classification tasks. It naturally raises concerns about the robustness of deep learning systems, considering that they have become core components of many security-sensitive applications such as text-based spam detection. Formally, for a given classifier F and test sample x, recent literature defined such perturbations as vector ∆x and the resulting sample x′ as an adversarial sample[7]: x′ = x + ∆x, ∥∆x∥p < ϵ, x′ ∈X F(x) , F(x′) or F(x′) = t (1) Figure 1: Perspective API: A example of deep learning text classification applications, which is a black-box scenario Here we denote a machine learning classifier as F : X →Y, where X is the sample space, x ∈X denotes a single sample and Y describes the set of output classes. The strength of the adversary, ϵ, measures the permissible transformations. The choice of condition in Eq. (1) indicates two methods for finding adversarial examples: whether they are untargeted(F(x) , F(x′)) or targeted (F(x′) = t) [2]. The choice of ∆x is typically an Lp-norm distance metric. Recent studies [3, 7, 20, 28] used three norms L∞, L2 and L0. Formally for ∆x = x′ −x ∈Rd, the Lp norm is ∥∆x∥p = p v u t p Õ i=1 |x ′ i −xi |p (2) The L∞norm measures the maximum change in any dimension. This means an L∞adversary is limited by the maximum change it can make to each feature but can alter all the features by up to that maximum [7]. The L2 norm corresponds to the Euclidean distance between x and x′ [3]. This distance can still remain small when small changes are applied to many different features. An L0 adversary is limited by the number of feature variables it can alter [20]. A third parameter for categorizing recent methods, in addition to targeted/untargeted and ∆choices, is whether the assumption of an adversary is black-box or white box. An adversary may have various degrees of knowledge about the model it tries to fool, ranging from no information to complete information. In the black box setting, an adversary is only allowed to query the target classifier and does not know the details of learned models or the feature representations of inputs. Since the adversary does not know the feature set, it can only manipulate input samples by testing and observing a classification model’s outputs. In the white box setting, an adversary has access to the model, model parameters, and the feature set of inputs. Similar to the black',\n",
       " '1809.07941': 'Road detection is an important task that needs to be solved accurately and robustly in order to achieve higher automation levels. Knowing what regions of the road surface are available for driving is in fact a crucial prerequisite for carrying out safe trajectory planning and decision-making. Although some automated driving vehicles are already available on the market, the recent crash of a Tesla car controlled by its autopilot system highlighted that further research and testing are very much necessary. In that case, it was pointed out that a possible reason for the crash was that the autopilot system misinterpreted the trailer of a truck as free road due to unfavourable lighting conditions [1], [2]. Current approaches for road detection use either cameras or LIDAR sensors. Cameras can work at high frame-rate, and provide dense information over a long range under good illumination and fair weather. However, being passive sensors, they are strongly affected by the level of illumination. A passive sensor is able to receive a speciﬁc amount of energy from the environment, light waves in the case of cameras, ∗Corresponding author. Luca Caltagirone, Mauro Bellone, and Mattias Wahde are with the Adaptive Systems Research Group, Department of Mechanics and Maritime Sciences, Chalmers University of Technology, Gothenburg, Sweden. Lennart Svensson is with the Department of Electrical Engineering, also at Chalmers University of Technology. and transform it into a quantitative measure (image). Clearly, the process depends on the amplitude and frequency of the light waves, inﬂuencing the overall result, while a reliable system should be invariant with respect to changes in illumination [3]. LIDARs sense the environment by using their own emitted pulses of laser light and therefore they are only marginally affected by the external lighting conditions. Furthermore, they provide accurate distance measurements. However, they have a limited range, typically between 10 and 100 meters, and provide sparse data. Based on this description of beneﬁts and drawbacks of these two sensor types, it is easy to see that using both might provide an improved overall reliability. Inspired by this consideration, the work presented here investigates how LIDAR point clouds and camera images can be integrated for carrying out road segmentation. The choice to use a fully convolutional neural network (FCN) for LIDAR-camera fusion is motivated by the impressive success obtained by deep learning algorithms in recent years in the ﬁelds of computer vision and pattern recognition [4]. In summary, this work makes the following two main contributions: (i) A novel LIDAR-camera fusion FCN that outperforms established approaches found in the literature and achieves state-of-the-art performance on the KITTI road benchmark; (ii) a data set of visually challenging scenes extracted from KITTI driving sequences that can be used to further highlight the beneﬁts of combining LIDAR data and camera images for carrying out road segmentation. The remainder of the paper is structured as follows: Sect. II gives a brief overview of related approaches that deal with the problems of road detection',\n",
       " '1812.00602': 'P REDICTIVE policing is the use of analytical techniques to identify either likely places of future crime scenes or past crime perpetrators, by applying statistical predictions [29]. As a crime typically involves a perpetrator and a target and occurs at a certain place and time, techniques of predictive policing need to answer: a) who will commit a crime, b) who will be offended, c) what type of crime, d) in which location and e) at what time a new crime will take place. This work does not focus on the victim and the offender, but on the prediction of occurrence of a certain crime type per location and time using past data. The ultimate goal, in a policing context, is the selection of the top areas in the city for the prioritization of law enforcement resources per department. One of the most challenging issues of police departments is to have accurate crime forecasts to dynamically deploy patrols and other resources so as to improve deterring of crime occurrence and police response times. Routine activity theory [8] suggests that most crimes take place when three conditions are met: a motivated offender, a suitable victim and lack of victim protection. The rational choice theory [9], suggests that prospective criminal weights the gain of successfully committing the crime against the probability of being caught and makes a rational choice whether to actually commit the crime or not. Both theories agree that a crime takes place when a person willing to commit it has an opportunity to do so. As empirical studies P. Stalidis, T. Semertzidis and P. Daras are with the Information Technologies Institute, Centre for Research and Technology Hellas, Thessaloniki, Greece. Email: stalidis,theosem,daras@iti.gr Manuscript received 19 Sep. 2017; revised 22 Mar. 2018 in near repeat victimization [15, 19, 20, 3] have shown, these opportunities are not randomly distributed, but follow patterns in both space and time. Traditionally, police ofﬁcers use maps of an area and place a pin on the map for every reported incident. Studying these maps, they can detect these patterns and thus, to efﬁciently predict hotspots; A hotspot is deﬁned as the area with the higher possibility for a crime to occur, compared to the neighbouring areas. Simple mapping methods are not sufﬁcient to make use of these general phenomena as early indicators for predicting crimes but more complex methodologies, such as machine learning, are needed. Various machine learning methodologies like Random Forests [4], Naive Bayes [47] and Support Vector Machines (SVMs) [10] have been exploited in the literature both for predicting the number of crimes that will occur in an area and for hotspot prediction. The success of a machine learning analysis highly depends on the experience of the analyst to prepare the data and to hand-craft features that describe properly the problem in question. Deep learning is a machine learning approach where the algorithm can extract the features from the raw data, overcoming the limitations of other machine learning',\n",
       " '1710.09318': 'The load-coupling model (see, e.g., [1, 2] and [3]) is widely used when designing networks according to the long-term evolution (LTE) standard and has also attracted attention in the context of ﬁfth-generation (5G) networks. More speciﬁcally, the load-coupling model has been used in various optimization frameworks dealing with different aspects of network design including, but not limited to, data ofﬂoading [4], proportional fairness [5], energy optimization [6, 7], and load balancing [8]. The radio resource management (RRM) in future 5G networks is expected to be similar to the RRM in orthogonal frequency-division multiple access (OFDMA)-based networks such as LTE. Unfortunately many of the RRM problem This research was supported by Grant STA 864/9-1 from German Research Foundation (DFG). formulations, such as small-scale optimal assignment of timefrequency resource blocks (RBs) to users, have been shown to be NP-hard [9]. As a result, interference models that are able to capture the long-term behavior of OFDMA-like networks while giving rise to tractable problem formulations have been the focus of recent research. The aforementioned non-linear load-coupling model is such a network-layer model that considers long-term average RB consumption and it has been shown to be sufﬁciently accurate [2]. In this model, the cellload at a base station (BS) is the proportion of RBs scheduled to support a particular rate demand. Therefore, given some power budget that can be used for transmission, each BS needs to calculate the cell-load required to serve given rate demands. In [4], the authors presented an intuitive result showing that cell-load is monotonic in user rate demand and the nonlinear coupling between cells implies that increasing an arbitrary rate demand in the network increases the cell-load at each BS. Therefore before serving a higher rate demand, it is important for a BS to have a reliable estimation of the impact of this increase to the neighboring BSs in terms of cell-load and interference. This estimation can be used to make RRM and self-organizing-network (SON) algorithms more reliable and efﬁcient. The difﬁculty in performing such management tasks lies in the need for calculating the expected value of induced cell-load at BSs for given user rates. This is because such a computation typically uses iterative methods requiring a large amount of network information such as pathlosses, user rates etc. We provide a robust and optimal machine learning technique which allows BSs to approximate cell-load values induced for any given rate demand vector. Moreover, the complexity of the proposed method is low and the algorithm can be implemented in parallel at each BS. The contributions of this study are as follows. We ﬁrst study the feasible rate region and obtain some properties of the cell-load as a function of rate demand vector. The feasible rate region is deﬁned as the set of',\n",
       " '1802.00469': 'Single-particle cryo-electron microscopy (cryo-EM) aims to determine the structure of 3D specimens (macromolecules) from multiple 2D projections. In order to acquire these 2D projections, a solution containing the macromolecules is frozen in vitreous ice on carbon ﬁlm, thus creating a sample grid. An electron beam then passes through the ice and the macromolecules frozen within, creating 2D projections. Unfortunately, due to radiation damage only a small number of imaging electrons can be used in the creation of the micrograph. As a result, micrographs have a low signal-tonoise ratio (SNR). An elaboration on the noise model can be found in (Sigworth, 2004). Since micrographs typically have low SNR, each micrograph consists of regions of noise and regions of noisy 2D projections of the macromolecule. In addition to these, micrographs also contain regions of non-signiﬁcant information stemming from contaminants such as carbon ﬁlm. Different types of regions have different typical intensity values. The regions of the micrograph that contain only noise will typically have higher intensity values than other regions. In addition, regions containing a particle typically have higher variance than regions containing noise alone (Nicholson & Glaeser, 2001; van Heel, 1982). Due to this, two cues that can be used for projection image identiﬁcation are the mean and variance of the image. In order to determine the 3D structure at high resolution, many projection images are needed, often in the hundreds of thousands. Thus, the ﬁrst step towards 3D reconstruction of macromolecules consists of determining regions of the micrograph that contain a particle as opposed to regions that contain noise or contaminants. This is the particle picking step. A fully manual selection of hundreds of thousands of 2D projections is tedious and time-consuming. For this reason, semi-automatic and automatic particle picking is a much researched problem for which numerous frameworks have been suggested. Solutions to the particle picking problem include edge detection (Harauz & Fong-Lochovsky, 1989), deep learning (Ogura & Sato, 2004; Wang et al., 2016; Zhu et al., 2016), support vector machine classiﬁers (Aebel´aez et al., 2011), and template matching (Frank & Wagenknecht, 1983). Email addresses: aheimowitz@math.princeton.edu (Ayelet Heimowitz), janden@flatironinstitute.org (Joakim And´en), amits@math.princeton.edu (Amit Singer) Preprint submitted to Journal of Structural Biology August 7, 2018 arXiv:1802.00469v2  [cs.CV]  14 Jun 2018  (a) (b) (c) Figure 1: Result of our suggested framework. The left column contains micrographs. The middle column contains the output of the classiﬁer. The right column contains the picked particles. Top row contains a β-Galactosidase micrograph. Bottom row contains a KLH micrograph. Template matching is a popular approach to particle picking. The input to template matching schemes consists of a micrograph and images containing 2D templates to match. These templates can be, for example, generated from manually selected particle projections. The aim is to output the regions in the micrograph that contain the sought-after templates. The basic idea behind this',\n",
       " '1005.1524': 'A t ﬁrst Γ(L, G)-codes were introduced by V.D.Goppa [1] in 1970. These codes are a large and powerful class of error correcting codes. F.J. McWilliams and N.J. Sloane [2] deﬁned these codes as the most important class of alternant codes. It is known that there are Γ(L, G)-codes that reach the Gilbert-Varshamov bound and that many Γ(L, G)-codes are placed in the Table of the best known codes [3]. It is noted also that Goppa codes are interesting for postquantum cryptography. There are four basic types of Γ(L, G)-codes: cyclic, separable, cumulative, and irreducible Goppa codes. In this paper we describe new type of Γ(L, G)-codes that we call cumulative-separable Goppa codes. We are motivated to study this class of Goppa codes, because, as it will be shown below, there are its subclasses that have improved estimations on minimum distance and dimension and that there exist codes of these subclasses that have parameters better than those for codes from the Table of the best known codes [3]. This paper is organized as follows. In Section II we review brieﬂy the deﬁnitions that we will use in the paper. In Section III we describe subclasses of cumulative-separable Γ(L, G)-codes with improved estimations on the dimension and minimum distance. In Section IV the relations between codes from different subclasses of cumulative-separable codes are presented. In Sections V and VI theorems on estimations of the dimension and minimum distance of considered subclasses are presented. II. CLASS OF CUMULATIVE-SEPARABLE Γ(L, G)-CODES A. Cumulative Goppa codes Deﬁnition 1: [1] A Goppa code with G(x) = (x −α)t, where α ∈GF(qm) is called a cumulative code. It is well known [1], [2] that the cumulative code Γ({GF(qm) \\\\ {α}} , (x −α)t) is equivalent to a cumulative Γ({GF(qm) \\\\ {0}} , xt) , that, in its tern, is equivalent to a primitive BCH-code of length n = qm −1 with a parity check matrix The material in this paper was presented in part at the 9th International Conference on Finite Fields and their Applications,University College Dublin, July 13-17, 2009. S. Bezzateev and N. Shekhunova are with the Department of Information Systems and Security , Saint Petersburg State University of Airspace Instrumentation, Saint-Petersburg, Russia, e-mail: bsv@aanet.ru, sna@delfa.net H = \\uf8ee \\uf8ef\\uf8ef\\uf8f0 1 α−t α−2t . . . α−(n−1)t 1 α−(t−1) α−2(t−1) . . . α−(n−1)(t−1) . . . . . . . . . . . . 1 α−1 α−2 . . . α−(n−1) \\uf8f9 \\uf8fa\\uf8fa\\uf8fb. Lemma 1: A cumulative q-ary Goppa Γ(L, G)-code with L ⊂GF(qm) and G(x) = xq is equivalent to the Γ(L, G∗)- code with G∗(x) = xq−1 . Proof: Let us consider a parity check matrix H∗of the Γ(L, G∗)- code: H∗= \\uf8ee \\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8f0 1 αq−1 1 1 αq−1 2 . . . 1 αq−1 n α1 αq−1 1 α2 αq−1',\n",
       " '1808.10442': 'Big 2 (also known as deuces, big deuce and various other names) is a four player card game of Chinese origin which is played widely throughout East and South East Asia. The game begins with a standard deck of 52 playing cards being shuﬄed and dealt out so that each player starts with 13 cards. Players then take it in turns to either play a hand or pass with basic aim of being the ﬁrst player to be able to discard all of their cards (see section 2 for more details about the rules). In this work we introduce a virtual environment to simulate the game which is ideal for the application of multi-agent reinforcement learning algorithms. We then go on to train a deep neural network which learns how to play the game using only self-play reinforcement learning. This is an interesting environment to study because the most remarkable successes that have come from self-play reinforcement learning such as Alpha Go (Silver et al., 2016) and Alpha Zero (Silver et al., 2017) have been conﬁned to two-player games of perfect information (e.g. Go, Chess and Shogi). In contrast Big 2 is a four-player game of imperfect information where each player is not aware of the cards that are held by the other players and so does not have access to a full description of the game’s current state. In addition to this Alpha Zero supplements its training and ﬁnal decision making with a monte carlo tree search which requires the simulation of a large number of future game states in order to make a single decision whereas here we consider only training a neural network to make its decision using the current game state that it receives. This is also in contrast to the most successful Poker playing programs such as Libratus (Brown and Sandholm, 2017) and DeepStack (Moravˇc´ıc et al., 2017) which again require much more computationally intense calculations to perform at the level that they do (e.g. DeepStack uses a heuristic search method adapted to imperfect information games). 1 arXiv:1808.10442v1  [cs.LG]  30 Aug 2018  Charlesworth One approach which does directly apply deep self-play reinforcement learning to games of imperfect information is “neural ﬁctitious self-play” (Heinrich and Silver, 2016) where an attempt is made to learn a strategy which approximates a Nash equilibrium, although this has not been applied to any games with more than two players. Multi-agent environments in general pose an interesting challenge for reinforcement learning algorithms and many of the techniques which work well for single-agent environments cannot be readily adapted to the multi-agent domain (Lowe et al., 2017). Approaches such as Deep Q-Networks (Mnih et al., 2015) struggle because multi-agent environments are inherently non-stationary (due to the fact that the other agents are themselves improving with time) which prevents the straightforward use of experience replay that is necessary to stabilize the algorithm. Standard',\n",
       " '1705.08395': 'Deep generative models have gained widespread use as a tractable way to model high-dimensional data distributions. Recently introduced frameworks, such as generative adversarial networks (GANs) [2] and variational autoencoders (VAEs) [5], can map a noise distribution to the data space, producing realistic samples. Capturing these high-dimensional data distributions makes possible a variety of downstream tasks, e.g., semi-supervised learning, sampling, and reconstruction/denoising. These models are also amenable to conditional training, where a conditional input (e.g., class label, data from another modality) guides the sampling process [13, 18]. At test time, manually selected conditional inputs lead to samples from the corresponding conditional distribution. Assuming the distributions share some underlying structure, this vastly reduces the capacity required to model the distributions compared to modeling each conditional distribution in a separate network. However, the standard training regime for deep generative models assumes that training data is drawn i.i.d. from the distribution of interest. For example, in the setting where the dataset contains multiple classes (e.g., MNIST digits), data representing every class is used concurrently during training. In many real-world scenarios, data may actually arrive sequentially or only be available for a short time period. Notably, a number of potential applications of deep generative models encounter exactly this constraint. One reason for widespread interest in unsupervised learning is that vastly more unlabeled data is available than labeled data. In many cases, such as an agent exploring an environment and learning a visual representation via a camera feed or training a generative model of text from the Twitter ﬁrehose, it is unlikely to be practical to save all the data over the lifetime of the system. A (batched) online or streaming approach is preferable. Another area which has gained recent interest and which exhibits this constraint is private learning [1]. Learning a differentially private deep classiﬁer from many private datasets currently requires many rounds of communication with or queries to models trained locally on each dataset [15, 12]. While private learning of deep generative models is still an open research problem, a differentially private arXiv:1705.08395v1  [cs.LG]  23 May 2017  deep generative model would allow generation of synthetic data and good feature representations for downstream tasks, without the need for repeated communication. Given this model, it would be desirable to efﬁciently update it from private data sources in sequence without having to access previous data sources again. If we wish to update a trained generative model to capture a newly observed distribution, naively training the model solely on the new data will result in the previously learned distributions being forgotten (Figure 1). This is due to the general susceptibility of neural networks to catastrophic forgetting when trained on multiple tasks sequentially [11]. Instead, the standard training regime requires that we train on new and old data simultaneously. This approach is not very scalable as it requires that all previously observed data be stored, or synthetic data representative of previous observations be regenerated, for',\n",
       " '1705.07565': 'Intuitively, deep neural networks [1] can approximate predictive functions of arbitrary complexity well when they are of a huge amount of parameters, i.e., a lot of layers and neurons. In practice, the size of deep neural networks has been being tremendously increased, from LeNet-5 with less than 1M parameters [2] to VGG-16 with 133M parameters [3]. Such a large number of parameters not only make deep models memory intensive and computationally expensive, but also urge researchers to dig into redundancy of deep neural networks. On one hand, in neuroscience, recent studies point out that there are signiﬁcant redundant neurons in human brain, and memory may have relation with vanishment of speciﬁc synapses [4]. On the other hand, in machine learning, both theoretical analysis and empirical experiments have shown the evidence of redundancy in several deep models [5, 6]. Therefore, it is possible to compress deep neural networks without or with little loss in prediction by pruning parameters with carefully designed criteria. However, ﬁnding an optimal pruning solution is NP-hard because the search space for pruning is exponential in terms of parameter size. Recent work mainly focuses on developing efﬁcient algorithms to obtain a near-optimal pruning solution [7, 8, 9, 10, 11]. A common idea behind most exiting approaches is to select parameters for pruning based on certain criteria, such as increase in training error, magnitude of the parameter values, etc. As most of the existing pruning criteria are 31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA. arXiv:1705.07565v2  [cs.NE]  9 Nov 2017  designed heuristically, there is no guarantee that prediction performance of a deep neural network can be preserved after pruning. Therefore, a time-consuming retraining process is usually needed to boost the performance of the trimmed neural network. Instead of consuming efforts on a whole deep network, a layer-wise pruning method, Net-Trim, was proposed to learn sparse parameters by minimizing reconstructed error for each individual layer [6]. A theoretical analysis is provided that the overall performance drop of the deep network is bounded by the sum of reconstructed errors for each layer. In this way, the pruned deep network has a theoretical guarantee on its error. However, as Net-Trim adopts ℓ1-norm to induce sparsity for pruning, it fails to obtain high compression ratio compared with other methods [9, 11]. In this paper, we propose a new layer-wise pruning method for deep neural networks, aiming to achieve the following three goals: 1) For each layer, parameters can be highly compressed after pruning, while the reconstructed error is small. 2) There is a theoretical guarantee on the overall prediction performance of the pruned deep neural network in terms of reconstructed errors for each layer. 3) After the deep network is pruned, only a light retraining process is required to resume its original prediction performance. To achieve our ﬁrst goal, we borrow an idea from some classic pruning approaches for shallow neural networks, such as',\n",
       " '1707.03195': 'Convolutional neural networks (CNNs) have become a very popular method for medical image segmentation. In the ﬁeld of brain MRI segmentation, CNNs have been applied to tissue segmentation [20,13,14] and various brain abnormality segmentation tasks [5,8,3]. A relatively new approach for segmentation with CNNs is the use of dilated convolutions, where the weights of convolutional layers are sparsely distributed over a larger receptive ﬁeld without losing coverage on the input image [19,18]. Dilated CNNs are therefore an eﬀective approach to achieve a large receptive ﬁeld with a limited number of trainable weights and a limited number of convolutional layers, without the use of subsampling layers. Generative adversarial networks (GANs) provide a method to generate images that are diﬃcult to distinguish from real images [4,15,17]. To this end, GANs use a discriminator network that is optimised to discriminate real from generated images, which motivates the generator network to generate images arXiv:1707.03195v1  [cs.CV]  11 Jul 2017  2 P. Moeskops et al. that look real. A similar adversarial training approach has been used for domain adaptation, using a discriminator network that is trained to distinguish images from diﬀerent domains [2,7] and for improving image segmentations, using a discriminator network that is trained to distinguish manual from generated segmentations [11]. Recently, such a segmentation approach has also been applied in medical imaging for the segmentation of prostate cancer in MRI [9] and organs in chest X-rays [1]. In this paper we employ adversarial training to improve the performance of brain MRI segmentation in two sets of images using a fully convolutional and a dilated network architecture. 2 Materials and Methods 2.1 Data Adult subjects 35 T1-weighted MR brain images (15 training, 20 test) were acquired on a Siemens Vision 1.5T scanner at an age (µ ± σ) of 32.9 ± 19.2 years, as provided by the MICCAI 2012 challenge on multi-atlas labelling [10]. The images were segmented in six classes: white matter (WM), cortical grey matter (cGM), basal ganglia and thalami (BGT), cerebellum (CB), brain stem (BS), and lateral ventricular cerebrospinal ﬂuid (lvCSF). Elderly subjects 20 axial T1-weighted MR brain images (5 training, 15 test) were acquired on a Philips Achieva 3T scanner at an age (µ ± σ) of 70.5 ± 4.0 years, as provided by the MRBrainS13 challenge [12]. The images were segmented in seven classes: WM, cGM, BGT, CB, BS, lvCSF, and peripheral cerebrospinal ﬂuid (pCSF). Possible white matter lesions were included in the WM class. 2.2 Network architecture Two diﬀerent network architectures are used to evaluate the hypothesis that adversarial training can aid in improving segmentation performance: a fully convolutional network and a network with dilated convolutions. The outputs of these networks are input for a discriminator network, which distinguishes between generated and manual segmentations. The fully convolutional nature of both networks allows arbitrarily sized inputs during testing. Details of both segmentation networks are listed in Figure 1, left. Fully',\n",
       " '1204.5703': 'Convolutional low-density parity-check (LDPC) codes, or spatially-coupled (SC) LDPC codes, were introduced in [1] and shown to have excellent belief-propagation (BP) thresholds in [2], [3], [4]. Moreover, they have recently been observed to universally approach the capacity of various channels [4], [5], [6], [7], [8], [9], [10], [11]. The fundamental mechanism behind this is explained well in [12], where it is proven analytically for the BEC that the BP threshold of a particular SC ensemble converges to the maximum-a-posteriori (MAP) threshold of the underlying ensemble. This phenomenon is now called threshold saturation. A similar result was also observed independently in [13] and stated as a conjecture. The same result for general binary memoryless symmetric (BMS) channels was ﬁrst empirically observed [4], [5] and recently proven analytically [11]. The underlying principle behind threshold saturation appears to be very general and it has now been applied, with much success, to a variety of more general scenarios in information theory and coding. In [14], the beneﬁts of spatial coupling are described for K-satisﬁability, graph coloring, and the Curie-Weiss model in statistical physics. SC codes are shown to achieve the entire rate-equivocation region for the BEC wiretap channel in [6]. The authors observe in [7] This material is based upon work supported by the National Science Foundation (NSF) under Grants No. 0747470 and No. 0802124. Any opinions, ﬁndings, conclusions, and recommendations expressed in this material are those of the authors and do not necessarily reﬂect the views of these sponsors. that the phenomenon of threshold saturation extends to multiterminal problems (e.g., a noisy Slepian-Wolf problem) and can provide universality over unknown channel parameters. Threshold saturation has also been observed for the binaryadder channel [15], for intersymbol-interference channels [8], [9], [10], for message-passing decoding of code-division multiple access (CDMA) [16], [17], and for iterative hard-decision decoding of SC generalized LDPC codes [18]. For compressive sensing, SC measurement matrices were investigated ﬁrst with veriﬁcation-based reconstruction in [19], and then proved to achieve the information-theoretic limit in [20]. In many of these papers it is conjectured, either implicitly or explicitly, that threshold saturation occurs for the studied problem. A general proof of threshold saturation (especially one where only a few details must be veriﬁed for each system) would allow one to settle all of these conjectures simultaneously. In this paper, we provide such a proof for systems with scalar density-evolution (DE) equations. Our method is based on potential functions and was motivated mainly by the approach taken in [21]. It turns out that their approach is missing a few important elements and does not, as far as we know, lead to a general proof of threshold saturation. Still, it introduces the idea of a potential function deﬁned by an integral of the DE recursion and this is an important element in our approach. More recently, a continuum approach to DE is',\n",
       " '1406.7486': 'Scaling-up multiple-input-multiple-output (MIMO) systems, thus exploiting the spatial degreeof-freedom (DoF), plays a pivotal role in boosting the capacity of next generation wireless communication systems. In cellular systems, it is found desirable to deploy a large number of antennas at base stations (BSs) [1], resulting in what is referred to as the massive MIMO system. Such designs have several advantages, including signiﬁcant improvements of spectral efﬁciency and radiated energy efﬁciency [2], immunity to small-scale channel fading due to the channel hardening effect, simpliﬁcation of the media-access-control (MAC) layer design, etc. Striving to reap the dramatic throughput gain of massive MIMO systems, it is found that such capacity improvements rely heavily on the availability of channel state information at the transmitter (CSIT). Without CSIT, e.g., when the user channels are identically distributed and are i.i.d. (independent identically distributed) in time/frequency, the total DoF reduces to one [3].1 In practice, a pilot-assisted CSIT acquisition approach is widely adopted, where the BS ﬁrst broadcasts downlink channel training sequences, and then listens to the channel feedback from the users. This is the case for the frequency-division-duplex (FDD) system or the uncalibrated time-division-duplex (TDD) system.2 For the calibrated TDD system, the channel reciprocity is exploited to allow the BS to obtain the CSIT through uplink channel training. Assuming the channel coefﬁcients are i.i.d. for different users and BS antennas, the CSIT acquisition overhead, which leads to a dimensionality loss of the time-frequency resource, scales with the number of BS antennas for FDD systems, and the number of users for TDD systems, respectively. As we scale up the number of BS antennas, the overhead will become prohibitively large for the FDD system. Therefore, it is commonly considered that the TDD mode is the better, if not the only, choice for massive MIMO systems. Nonetheless, since currently deployed cellular systems are dominantly FDD, and many frequency bands are assigned explicitly for use in FDD, it is of great interest to design schemes that realize the massive MIMO gains with an FDD mode. Given the fact that the dimensionality loss due to CSIT acquisition overhead is devastating 1In such condition it has been shown that even when the CSIT is known within a mean-square error that does not decrease with SNR, the DoF collapses to one [4]. 2Since in practice TDD reciprocity is quite difﬁcult to obtain, which requires reciprocity calibration of the transmit and receive radio frequency chains. In fact, the only current system that uses MU-MIMO, which is 802.11ac, uses explicit polling of the users through downlink pilots, and explicit quantized closed-loop feedback from the users, even though it is a TDD system.  3 with closed-loop channel estimation in FDD and uncalibrated TDD systems, and that the system performance without CSIT is unacceptably poor, it is natural to pose the question whether there exists other information that can be',\n",
       " '1710.10772': 'Generative Adversarial Networks demonstrate state-of-the-art performance within the class of generative models [1]. The success of GAN is accomplished not only by algorithmic advance but also by the recent growth of computational capacity. For example, state-of-the-art generative adversarial models such as [2, 3] utilize enormous computational resource by constructing complex models with a large number of model parameters and train them on powerful Graphics Processing Units (GPUs). A critical problem that accompanies with such dependency on powerful computational system arises when deploying the large-scale generative frameworks on platforms with limited computational power (e.g. tablets, smartphones). For instance, mobile devices such as smartphones can only carry somewhat limited computational system due to its hardware design. Although unsupervised learning (especially generative adversarial learning) could improve the capability and functionality Fig. 1: Best viewed in color. Visualization of a three-way tensor layer. Given an input three-way tensor X ∈RI×J×K and three weight matrices U1 ∈ RL×I, U2 ∈RM×J and U3 ∈RN×K, the output is Y ∈RL×M×N. We call the resulting tensor Y after an activation a tensor layer and U1, U2 and U3 weight matrices. of mobile devices substantially, the trend of employing massive computational resource seems not proﬁting the usage of such generative framework for the general public. The necessity of such complex model is partially attributed to the multi-dimensionality of datasets. Natural datasets often possess multi-modal structure, and among a plethora of such available datasets, images are often the subject of generative learning frameworks [1, 2, 3]. As it becomes necessary to learn such high-dimensional dataset, models with a large number of parameters have been employed. Goodfellow et. al. adopt multilayer perceptron (MLP) to learn and classify such higher-dimensional datasets [1]. Although MLPs can represent rich classes of functions, the major drawback of them are, 1) the dense connection between layers requires a large number of parameters, leading to a limited applicability of the framework to common computational environment, and 2) the vectorization operation leads to the loss of rich inter-modal information of the datasets. In this paper, we propose a new generative framework with the purpose of reducing the number of model parameters while maintaining the quality of generated samples. Our framework is inspired by the recent works of applying tensor methods to machine learning models [4, 5]. For illustration, Novikov et al. proposed to use low-rank Tensor-Train (TT) approximations for weight parameters, where it shows that employing such tensor approximations will lead to the reduction of the space complexity of a model [4]. Although applying TT dearXiv:1710.10772v2  [cs.LG]  30 Mar 2018  composition to dense matrices demonstrates a large factor of compression rate [4], ﬁnding optimal TT-ranks still remains to be a difﬁcult problem. In our proposed framework, we compress the traditional afﬁne transformation using tensor algebra in order to reduce the number of parameters',\n",
       " '1801.01260': 'Recently human parsing (Liu et al. 2015) has been receiving increasing attention owning to its wide applications, such as person re-identiﬁcation (Zhao, Ouyang, and Wang 2014), people search (Li et al. 2017), fashion synthesis (Zhu et al. ). Existing human parsing algorithms can be divided into following two categories. The ﬁrst one is constrained huCopyright c⃝2018, Association for the Advancement of Artiﬁcial Intelligence (www.aaai.org). All rights reserved. GT\\xa0Labels: Images: Source\\xa0domains\\xa0with\\xa0plenty\\xa0of\\xa0labeled\\xa0data Pi l i Ad t ti Pixel‐wise\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0Adaptation Images: Images: Parsing\\xa0 Results: ages Parsing\\xa0 Results: ages Target\\xa0domain\\xa01:\\xa0canteen Target\\xa0domain\\xa02:\\xa0road Differences:\\xa0\\xa0\\xa0\\xa0illumination,\\xa0view\\xa0points,\\xa0images\\xa0scale,\\xa0resolution,\\xa0etc. , p , g , , Commonalities:\\xa0\\xa0spatial\\xa0priors,\\xa0relative\\xa0positions,\\xa0shapes\\xa0of\\xa0the\\xa0labels Figure 1: Cross-domain human parsing: the upper panel is the source domain with a large amount of training data, e.g., the LIP dataset; the lower panel shows the target domain, e.g, canteen and road, without any manual labeling. man parsing. More speciﬁcally, the clean images of wellposed persons are collected from some fashion sharing websites, e.g., Chictopia.com, for training and testing. Representative datasets include Fashionista (Yamaguchi et al. 2012) with 685 images, Colorful-Fashion dataset (Liu et al. 2014) with 2, 682 images and ATR dataset (Liang et al. 2015a) with 7, 700 dataset. Each image in these datasets contains only one person, with relatively simple poses (mostly standing), against relatively clean backgrounds. The human parsers trained in such strictly constrained scenario often fail when applied to images captured under the real-life, more complicated environments. The second category is unconstrained human parsing. Representative datasets include Pascal human part dataset (Chen et al. 2014b) with 3, 533 images and LIP dataset (Gong et al. 2017) with 50, 462 images. The images in these dataset present humans with varying clothing appearances, strong articulation, partial (self-) occlusions, truncation at image borders, diverse viewpoints and background clutters. Although they are closer to real environments than the constrained datasets, when applying the human parser trained on these unconstrained datasets to a real application scenario, such as shop, airport, the performance is still worse than the parser trained on that particular scenario even with much less training samples, due to domain shift on visual features. In this paper, we explore a new cross-domain human parsing problem: taking the unconstrained benchmark arXiv:1801.01260v2  [cs.CV]  8 Jan 2018  dataset with rich pixel-wise labeling as the source domain, how to obtain a satisfactory parser for a totally different target domain without any additional manual labeling? As shown in Figure 1, the source domain (shown in the upper panel of Figure 1) is a set of labeled data. The target domain training set (shown in the lower panel of Figure 1) is as a set of images without any annotations. We believe investigation on this challenging problem will push human parsing models toward',\n",
       " '1708.01155': 'Radiotherapy treatment planning requires a magnetic resonance (MR) volume for segmentation of tumor volume and organs at risk, as well as a spatially corresponding computed tomography (CT) volume for dose planning. Separate acquisition of these volumes is time-consuming, costly and a burden to the patient. Furthermore, voxel-wise spatial alignment between MR and CT images may be compromised, requiring accurate registration of MR and CT volumes. Hence, to circumvent separate CT acquisition, a range of methods have been proposed for MR-only radiotherapy treatment planning in which a substitute or synthetic CT image is derived from the available MR image [2]. Previously proposed methods have used convolutional neural networks (CNNs) for CT synthesis in the brain [4] and pelvic area [8]. These CNNs are trained by minimization of voxel-wise diﬀerences with respect to reference CT volumes that are rigidly aligned with the input MR images. However, slight voxel-wise misalignment of MR and CT images may lead to synthesis of blurred images. To address this, Nie et al. [9] proposed to combine the voxel-wise loss with an image-wise adversarial loss in a generative adversarial network (GAN) [3]. In this arXiv:1708.01155v1  [cs.CV]  3 Aug 2017  2 J.M. Wolterink et al. Fig. 1: Left When training with paired data, MR and CT slices that are simultaneously provided to the network correspond to the same patient at the same anatomical location. Right When training with unpaired data, MR and CT slices that are simultaneously provided to the network belong to diﬀerent patients at diﬀerent locations in the brain. GAN, the synthesis CNN competes with a discriminator CNN that aims to distinguish synthetic images from real CT images. The discriminator CNN provides feedback to the synthesis CNN based on the overall quality of the synthesized CT images. Although the GAN method by Nie et al. [9] addresses the issue of image misalignment by incorporating an image-wise loss, it still contains a voxel-wise loss component requiring a training set of paired MR and CT volumes. In practice, such a training set may be hard to obtain. Furthermore, given the scarcity of training data, it may be beneﬁcial to utilize additional MR or CT training volumes from patients who were scanned for diﬀerent purposes and who have not necessarily been imaged using both modalities. The use of unpaired MR and CT training data would relax many of the requirements of current deep learning-based CT synthesis systems (Fig. 1). Recently, methods have been proposed to train image-to-image translation CNNs with unpaired natural images, namely DualGAN [11] and CycleGAN [12]. Like the methods proposed in [4,8,9], these CNNs translate an image from one domain to another domain. Unlike these methods, the loss function during training depends solely on the overall quality of the synthesized image as determined by an adversarial discriminator network. To prevent the synthesis CNN from generating images that look real but bear little similarity to',\n",
       " '1701.04724': 'A powerful approach to managing massive datasets (big data) is based on network or graph representations of the datasets [1]–[4]. Examples of networked data are found in signal processing where signal samples can be arranged as a chain, in image processing with pixels arranged on a grid, in wireless sensor networks where measurements conform to sensor proximity [1]. Organising data using networks is also used in knowledge bases (graphs) whose items are linked by relations [5], [6]. Using network models is beneﬁcial from a computational and statistical perspective. Indeed, network models for data lend naturally to highly scalable learning algorithms in the form of message passing on the data network [7]. Moreover, the network structure allows to borrow statistical strength across different localized high-dimensional statistical models which are associated with individual data points (nodes) [2], [8]. Finally, network models provide a high level of ﬂexibility in order to cope with heterogeneous datasets composed of different data types (e.g., mixtures of audio, video and text data). In some applications, the network structure underlying the data is not known explicitly but has to be learned in a datadriven fashion. This task can be accomplished in a principled way by using probabilistic graphical models (PGM) [3], [9]. Within a PGM, we interpret data points as realizations of random variables. A particular type of PGM is based on representing the conditional independence relations between individual data points using a network structure (graph) [9], [10]. The problem of estimating the network structure of a PGM from observed data is known as graphical model selection (GMS). Many efﬁcient methods have been proposed for GMS for data which is modelled as sequences of i.i.d. realizations of some underlying random vector [11]–[13]. The extension of GMS from the i.i.d. setting to cope with correlations between vector samples using stationary process models has been studied in [14]–[18]. A robust GMS method which is able to cope with outliers is proposed in [19]. In this paper, we consider the extension of GMS to non-stationary time series data. As we will detail below, our approach includes GMS for stationary time series as a special case. It is of practical relevance for the usage of GMS methods to understand the fundamental requirements on the available data such that accurate GMS is possible. For data which can be modelled as i.i.d. realizations of a Gaussian random vector (Gaussian Markov random ﬁeld), the required sample size is well understood. A lower bound on the sample size has been obtained by [20], which does not place any computational constraints on the GMS method. Remarkably, this lower bound can be achieved by computationally tractable convex optimizaton methods [21] proving them as optimal in terms of sample size requirement. By adapting the informationtheoretic approach of [20], a lower bound on the sample size required for accurate GMS from data conforming to a stationary random process model is presented in [16]. Contribution. Our focus',\n",
       " '1809.04720': 'Teaching robots to perform challenging tasks has been an active topic of research. In particular, it has recently been demonstrated that reinforcement learning (RL) coupled with deep neural networks is able to learn policies (controllers) which can successfully perform tasks such as pick and fetch. Robots may be slow, dangerous, can damage themselves and they are expensive. When a robot is learning a task, it needs to be taken out of production. Learning policies using model-free deep RL typically requires many samples to explore the sequential decision making space. Model-free RL applied to tasks that involve complex dynamics, require even more samples to learn adequate policies compared to tasks involving (largely) linear dynamics. Directly learning on robots may thus be very costly. In order to reduce the time required for learning on a real robot, training can be performed in simulation environments. The learned policy is then transferred to the real world domain. Modern graphics cards and sophisticated physics engines enable the simulation of complex tasks. Learning with simulators has several advantages. The rendering and physics engines are capable of computing simulations faster than realtime. This helps to reduce overall training times. Recent deep reinforcement learning algorithms allow agents to learn in Mitsubishi Electric Research Laboratories (MERL), Cambridge, MA 02139, USA jeroen@merl.com parallel [1], which reduces training times. Furthermore, both appearance and physics can be controlled in simulation. For example the lighting condition, or the friction of an object can be changed, or the entire simulation can be halted to allow for computation of updates. Appearance, complex dynamics, and robot motor movements in the real world can only be simulated up to some approximation. Simulation to real world transfer thus requires ﬁne-tuning on real data. Furthermore, real setups involving various components, experience delays which are hard to determine exactly. For example, the delay introduced by the acquisition system, where some time has passed before the acquired image is available for processing by the algorithm. By randomization of the appearance, physics and system parameters during reinforcement learning on simulation data, robustiﬁed policies can be learned. This is analogous to training a deep convolutional neural network to classify objects regardless of the background in the input images. We found that robustiﬁed policies can greatly reduce the amount of time for ﬁne-tuning in transfer learning. Reducing the ﬁne-tuning time in transfer learning becomes especially important for tasks involving complex dynamics. We demonstrate our proposed approach on a challenging task of a robot learning to solve a marble maze game. The maze game is shown in Figure 1. The marbles are subject to static and rolling friction, acceleration, and collisions (with other marbles and with the maze geometry). A simulator simulates the physics of the marbles in the maze game, and renders the results to images. We learn to solve the game from scratch using deep reinforcement learning. A modiﬁed version of the deep reinforcement learning is used to learn directly on real robot hardware',\n",
       " '1804.08198': '1.1 Multilingual Machine Translation Neural machine translation (NMT) relies on word and sentence embeddings to encode the semantic information needed for translation. The standard attentional encoder-decoder models (Bahdanau et al., 2015) for bilingual NMT decompose naturally into separate encoder and decoder subnetworks for the source and target languages. This factorization has inspired various forms of multilingual NMT models that extended the original bilingual framework to handle more language pairs simultaneously. We refer to NMT models that accept sentences from one source language and produce outputs in one target language as ‘bilingual’. We contrast this with ‘multilingual’ NMT models, which support more than one source and/or target languages within the same model. The naive approach to multilingual machine translation would train a model for each language pair, which scales quadratically with the number ∗Equal contribution of languages in the corpus. Instead, by combining language-speciﬁc encoders and decoders in different ways, Dong et al. (2015), Zoph and Knight (2016), Luong et al. (2016), and Firat et al. (2016a) have explored the one source-tomany target, many source-to-one target, and many source-to-many target multilingual MT settings. The multi-way shared attention model (Firat et al., 2016a) is closest to our work, in that they consider the large-scale, many-to-many scenario with multiple encoders and decoders. It is also possible to adapt existing bilingual NMT models to the many-to-many case without changing the architecture at all. The universal encoder-decoder approach (Ha et al., 2016; Johnson et al., 2017) constructs a shared vocabulary for all languages in the dataset, and use just one encoder and decoder for multilingual translation. In addition, Johnson et al. (2017) introduce direct zero-shot translation, which refers to the task of translating between language pairs without parallel text or pivoting through an intermediate language like English. Direct zero-shot translation may yield lower BLEU scores than pivot-based approaches, but avoids doubling the latency and computational overhead (due to translating the source sentence twice,) which is a concern for large-scale, productionized MT systems. Nonetheless, both the multi-way shared attention model and the universal encoder-decoder model suffer from certain disadvantages. For the former, direct zero-shot translation was shown to be impossible in Firat et al. (2016b), and there is no indication that the model learns any kind of shared representation across languages. For the latter, the output vocabulary size is typically ﬁxed to the vocabulary size for a single target language (i.e. roughly 20,000 to 30,000 types), regardless of the number of languages in the corpus. Increasing the vocabulary size is costly, since the training arXiv:1804.08198v3  [cs.CL]  16 Oct 2018  and inference time scales linearly with the size of the decoder’s output layer. 1.2 Our Contributions In this work, we construct an explicit neural interlingua for multilingual NMT, which addresses some of',\n",
       " '1811.08048': 'Many natural language tasks require recognizing and reasoning with qualitative relationships. For example, we may read about temperatures rising (climate science), a drug dose being increased (medicine), or the supply of goods being reduced (economics), and want to reason about the effects. Qualitative story problems, of the kind found in elementary exams (e.g., Figure 1), form a natural example of many of these linguistic and reasoning challenges, and is the target of this work. Understanding and answering such questions is particularly challenging. Corpus-based methods perform poorly in this setting, as the questions ask about novel scenarios rather than facts that can be looked up. Similarly, word association Copyright c⃝2019, Association for the Advancement of Artiﬁcial Intelligence (www.aaai.org). All rights reserved. Qualitative Story Problem: Alan noticed that his toy car rolls further on a wood ﬂoor than on a thick carpet. This suggests that: (A) The carpet has more resistance (B) The ﬂoor has more resistance Solution: (A) The carpet has more resistance Identiﬁcation of worlds being compared: Question Interpretation (Logical Form): qrel(distance, higher, world1) → qrel(friction, higher, world2) ; qrel(friction, higher, world1)? Figure 1: An example problem from QUAREL and its logical form (LF), from which the answer can be inferred (Section 3). The problem is conceptualized as comparing two worlds which the semantic parser needs to identify and track. In the LF, qrel(p, higher|lower, w) denotes that p is higher/lower in world w (compared with the other world). Colors show approximate correspondence between the question and the LF. methods struggle, as a single word change (e.g., “more” to “less”) can ﬂip the answer. Rather, the task appears to require knowledge of the underlying qualitative relations (e.g., “more friction implies less speed”). Qualitative modeling (Forbus 1984; Weld and De Kleer 2013; Kuipers 1994) provides a means for encoding and reasoning about such relationships. Relationships are expressed in a natural, qualitative way (e.g., if X increases, then so will Y), rather than requiring numeric equations, and inference allows complex questions to be answered. However, the semantic parsing task of mapping real world questions into these models is formidable and presents unique challenges. These challenges must be solved if natural questions involving qualitative relationships are to be reliably answered. We make three contributions: (1) a simple and ﬂexible conceptual framework for formally representing these kinds of questions, in particular ones that express qualitative comparisons between two scenarios; (2) a challenging new dataset (QUAREL), including logical forms, exemplifyarXiv:1811.08048v1  [cs.CL]  20 Nov 2018  ing the parsing challenges; and (3) two novel models that extend type-constrained semantic parsing to address these challenges. Our ﬁrst model, QUASP+, addresses the problem of tracking different “worlds” in questions, resulting in signiﬁcantly higher scores than with off-the-shelf tools (Section 7.1). The second model, QUASP+ZERO, demonstrates zero-shot capability, i.e., the ability to handle new',\n",
       " '1703.08837': 'The extensive deployment of close-circuit television cameras in visual surveillance results in a vast quantity of visual data and necessitates inevitably automated data interpretation mechanisms. One of the most essential visual data processing tasks is to automatically re-identify individual person across non-overlapping camera views distributed at different physical locations, which is known as person re-identiﬁcation (re-id). However, person re-id by visual matching is inherently challenging due to the existence of many visually similar people and dramatic appearance changes of the same person arising from the great cross-camera variation in viewing conditions such as illumination, viewpoint, occlusions and background clutter [1] (Figure 1). In current person re-id literature, the best performers are discriminative learning based methods [2,3,4,5,6,7,8,9,10,11,12,13,14, • Ying-Cong Chen is with the School of Data and Computer Science, Sun Yat-sen University, Guangzhou 510275, China, with the Collaborative Innovation Center of High Performance Computing, National University of Defense Technology, Changsha 410073, China, and is also with Department of Computer Science and Engineering, The Chinese University of Hong Kong. E-mail: yingcong.ian.chen@gmail.com • Xiatian Zhu is with School of Data and Computer Science, Sun Yat-sen University, Guangzhou 510275, China; and also with School of Electronic Engineering and Computer Science, Queen Mary University of London, United Kingdom. E-mail: xiatian.zhu@qmul.ac.uk • Wei-Shi Zheng is with the School of Data and Computer Science, Sun Yat-sen University, Guangzhou 510275, China., and is also with the Key Laboratory of Machine Intelligence and Advanced Computing (Sun Yatsen University), Ministry of Education, China. E-mail: wszheng@ieee.org. • Jian-Huang Lai are with the School of Data and Computer Science, Sun Yat-sen University, Guangzhou 510275, China, and is also with Guangdong Province Key Laboratory of Information Security, P. R. China. E-mail: stsljh@mail.sysu.edu.cn. 15,16,17,18,19,20,21]. Their essential objective is to establish a reliable re-id matching model through learning identity discriminative information from the pairwise training data. Usually, this is achieved by either view-generic modelling (e.g., optimizing a common model for multiple camera views) [5,6,8,10,13,15] or view-speciﬁc modelling scheme (e.g., optimizing a separate model for each camera view) [16,17,18,19]. The former mainly focuses on the shared view-generic discriminative learning but does not explicitly take the individual view information (e.g., via camera view labels) into modelling. Given that person re-id inherently incurs dramatic appearance change across camera views due to the great difference in illumination, viewpoint or camera characteristics, the view-generic approach is inclined to be sub-optimal in quantifying the feature distortion caused by these variations in individual camera views. While the latter approach may enable to mitigate this problem by particularly considering view label information during modelling, most of these methods do not explicitly take into consideration the feature distribution alignment across camera views',\n",
       " '1712.05138': 'The recent prevalence of Internet-of-Things has spawned a plethora of real-time services that require timely data/update exchange [1]. In vehicular networks [2], [3], for example, vehicles need to share their status information (e.g., position, speed, acceleration) timely to ensure safety. For these scenarios, neither traditional delay nor traditional throughput is suitable [4]. To be speciﬁc, when delay is small, the received data may not always be fresh if the transmissions are very infrequent; when throughput is large, the received data may also be not fresh if the data undergo large queueing delay [5]– [7]. To convey the freshness of the received information, therefore, a new metric was proposed in [8], i.e., age of information (AoI) . AoI is deﬁned as the elapsed time since the generation of the latest received update [8], i.e., the age of the newest update at the receiver. Since AoI is closely related to queueing theory, it has been studied in various queueing systems, e.g., M/M/1, M/D/1 and D/M/1 [8], and under several serving disciplines, e.g., ﬁrst-come-ﬁrst-served (FCFS) [8], [9] and last-generateﬁrst-served (LGFS) [10]. The zero-wait policy where a new update is served immediately after the completion of previous update was also investigated in [11]. Moreover, the authors of [12] studied the average AoI of transmitting k-symbol updates over an erasure channel. Although all of these serving disciplines can ﬁnd many suitable applications, neither of them can be generally optimal. This has motivated many studies which minimize the AoI of the system by scheduling the transmission of updates. For example, the authors of [13] discussed some protocols in which any arriving updates seeing a busy server or more than one waiting updates would be discarded. The method of replacing the waiting updates with newly arriving updates was studied in [13] [14]. The AoI of energy harvesting powered systems has also attracted many attentions. Due to the randomness of the energy harvesting process, energy buffers are needed to store the harvested energy. To this end, the authors of [15], [16] investigated how buffer size affects the average AoI of the system; the optimal threshold of remaining energy to trigger a new update has been found in [17]. Moreover, AoI was also investigated in multi-source [18], multi-class [19], multi-hop [20] scenarios. In this paper, we consider the freshness of the uplink transmission from the slave node to the master node in a two-way data exchanging system, as shown in Fig. 1. We assume that only the master node has a constant energy supply. When the master node is not transmitting data, it transfers energy to the slave node using wireless power transfer [21]. Using the harvested energy, the slave node can then transmit its own data to the master node. Since the freshness and effectiveness of uplink transmission are jointly constrained by the information transmission capability of the uplink channel and',\n",
       " '1810.01218': 'A sequence is a list of elements arranged in a certain order. Prime numbers arranged in ascending order, for example, is a sequence [1]. The arrangements of nucleic acids in DNA polynucleotide chains are also sequences [2]. Discovering sequences with desired properties is an intellectual pursuit with important applications [1]. In particular, sequences are critical components in many information systems. For example, cellular code division multiple access (CDMA) systems make use of spread spectrum sequences to distinguish signals from different users [3]; pulse compression radar systems make use of probe pulses modulated by phase-coded sequences [4] to enable high-resolution detection of objects at a large distance. Sequences in information systems are commonly designed by algebraists and information theorists using mathematical tools such as ﬁnite ﬁled theory, algebraic number theory, and character theory. However, the design criterion for a good sequence may be complex and cannot be put into a clean mathematical expression for solution by the available mathematical tools. Faced with this problem, sequence designers may do two things: 1) Overlook the practical criterion and simplify the requirements to make the problems analytically tractable. In so doing, a disconnect between reality and theory may be created. 2) Introduce additional but artiﬁcial constraints absent in the original practical problem. In this case, the analytical solution is only valid for a subset of sequences of interest. For example, the protocol sequences in [5] are constructed by means of the Chinese Remainder Theorem (CRT) [6]; hence, the number of supported users is restricted to a prime number. Yet a third approach is to ﬁnd the desired sequences algorithmically. This approach rids us of the conﬁnes imposed by analytical mathematical tools. On the other hand, the issue becomes whether good sequences can be found within a reasonable time by algorithms. Certainly, to the extent that desired sequences can be found by a random search algorithm within a reasonable time, then the problem is solved. Most desired sequences, however, cannot be found so easily and algorithms with complexity polynomial in the length of the sequences are not available. Reinforcement Learning (RL) is an important branch of machine learning [7] known for its ability to derive solutions for Markov Decision Processes (MDPs) [8] through a learning process. A salient feature of RL is “learning from interactions”. Fig. 1 illustrates the framework  3 action 𝑎𝑡 reward 𝑅𝑠𝑇 state 𝑠𝑡 𝑠𝑡+1 Agent Environment Fig. 1. In episodic reinforcement learning, the agent-environment interactions are broken into sessions called episodes. Each episode starts anew from an initial state s0. The agent takes actions in successive discrete time steps t = 0, 1, 2, ..., T −1, resulting in the state of the environment traversing through states s0, s1, s2, ..., until a terminal state sT is reached, whereupon a reward R(sT ) is given. The next episode begins independently of how the previous episode ended [7]. of episodic RL1. In the framework, an agent interacts with an environment in a sequence of discrete time steps t = 0, 1',\n",
       " '1811.00416': 'Convolutional neural networks have been used in recent years to successfully learn regulatory patterns in genomic DNA [1, 4, 5]. Combinations of Transcription Factors (TFs) bind combinations of motifs in DNA sequence at non-coding regulatory elements to control gene expression. While the core sequence motifs of a subset of TFs are relatively well-known, the role of ﬂanking nucleotides that inﬂuence in vivo TF binding, as well as the combinatorial interactions with other TFs, remain largely uncharted. Deep learning models are appealing for this problem because of their ability to learn complex, hierarchical, predictive patterns directly from raw DNA sequence, thus removing the need to explicitly featurize the data (such as featurization using a database of known motifs). Convolutional Neural Networks (CNNs) in particular contain several hierarchical layers of pattern-matching units referred to as convolutional ﬁlters that are well suited to learning from DNA sequence. In these models, each convolutional ﬁlter in the ﬁrst layer learns a sequence pattern that is analogous to a position weight matrix (PWM). The ﬁlter is scanned (convolved) with the sequence to produce a score for the strength of the match at each position. Later convolutional layers operate on the scores from all ﬁlters in the previous layer, allowing the network to learn complex higher-order patterns. arXiv:1811.00416v5  [cs.LG]  30 Apr 2020  A barrier to the adoption of deep learning models for genomic applications is the difﬁculty in interpreting the models. While several methods such as Lanchantin et al. [5], Shrikumar et al. [8] and Sundararajan et al. [10] have been developed to assign importance scores to each base of an input sequence, methods for learning re-occurring patterns do not leverage importance scores and are largely limited to variations of visualizing the learned representations of individual CNN ﬁlters [5, 4, 1]. In practice, this poses an issue because CNNs learn highly distributed representations, meaning that the patterns found by individual convolutional neurons may not be very informative. In this technical note, we detail the methods behind version 0.5.6.5 of TF-MoDISco. TF-MoDISco is a method for identiﬁcation of high-quality, consolidated motifs using deep learning. The critical insight of TF-MoDISco is that the importance scores on the inputs are computed using information from all the neurons in the network; thus, by clustering segments of high importance in the inputs, it is possible to identify consolidated motifs learned by the deep learning model. The implementation is available at https://github.com/kundajelab/tfmodisco, and the release history is available at https://github. com/kundajelab/tfmodisco/releases. The main difference relative to version 0.4.2.2 (the version described in the previous technical note) is a modiﬁcation of how the null distribution is handled in Section 3.1. Examples applications of TF-MoDISco can be found in Shrikumar et al. [9] and Avsec et al. [2]. This technical note focuses only on providing a description of the methods. 2 Input to TF-MoDISco TF-MoDISco',\n",
       " '1711.01567': 'Automatic speech recognition (ASR) is becoming increasingly more integral in our day-to-day lives enabling virtual assistants and smart speakers like Siri, Google Now, Cortana, Amazon Echo, Google Home, Apple HomePod, Microsoft Invoke, Baidu Duer and many more. While recent breakthroughs have tremendously improved ASR performance [1, 2] these models still suffer considerable degradation from reasonable variations in reverberations, ambient noise, accents and Lombard reﬂexes that humans have little or no issue recognizing. Most of these problems can be mitigated by training the models on a large volume of data that exemplify these effects. However, in the case of non-stationary processes, such as accents, accurate data augmentation is most likely infeasible, and in general, collecting high quality datasets can be expensive and time-consuming. Past robust ASR literature has considered hand-engineered front-ends and data-driven approaches in an attempt to increase the value of relatively parsimonious data with desired effects [3, 4]. While these techniques are quite effective in their respective operating regimes, they do not generalize well to other modalities in practice due to the aforementioned reasons. Namely, it is difﬁcult to model anything beyond reverberation and background noise from the ﬁrst principles. Existing techniques ∗equal contribution. do not directly induce invariance for ASR or are not scalable. And, due to the sequential nature of speech, alignments are needed to compare two different utterances of the same text. In this work, we employ the generative adversarial network (GAN) framework [5] to increase the robustness of seq-to-seq models [6] in a scalable, end-to-end fashion. The encoder component is treated as the generator of GAN and is trained to produce indistinguishable embeddings between noisy and clean audio samples. Because no restricting assumptions are made, this new robust training approach can in theory learn to induce robustness without alignment or complicated inference pipeline and even where augmentation is not possible. We also experiment with encoder distance objective to explicitly restrict the embedding space and demonstrate that achieving invariance at the hidden representation level is a promising direction for robust ASR. The rest of the paper is organized as follows. Related work is documented in Section 2. Section 3 deﬁnes our notations and details the robust ASR GAN. Section 4 explains the experimental setup. Section 5 shows results on the Wall Street Journal (WSJ) dataset with simulated far-ﬁeld effects. Finishing thoughts are found in Section 6. 2. RELATED WORK A vast majority of work in robust ASR deals with reverberations and ambient noise; [3] provides an extensive survey in this effort. One of the most effective approaches in this variability is to devise a strong front-end such as the weighted prediction error (WPE) speech dereverberation [7, 8] and train the resulting neural network with realistic augmented data [9, 10]. A shift from more traditional signal processing techniques to more modern, data-driven methods was seen when the denoising autoencoder',\n",
       " '1807.01425': 'In recent years, deep reinforcement learning (Deep RL) has enjoyed success in many different applications, including playing Atari games [Mnih et al., 2013], controlling a humanoid robot to perform various manipulation tasks [Chebotar et al., 2017b; Chebotar et al., 2017a] and beating the world champion in Go [Silver et al., 2016]. The success and wide range of use cases of RL algorithms is partly due to the very general description of the problem that RL aims to solve, i.e., to learn autonomous behaviors given a high-level speciﬁcation of a task by interacting with the environment. Such highlevel speciﬁcation is provided by a reward function, which must be sufﬁciently descriptive as well as easy to optimize for an RL algorithm to learn efﬁciently. These requirements make the design of the reward function challenging in practice, creating a bottleneck for even a wider set of applications for RL algorithms. The problem of designing a reward function has been tackled in various ways. These include: i) learning the reward function from human demonstrations in the ﬁeld of inverse reinforcement learning (IRL) [Levine et al., 2011; Abbeel and Ng, 2004], ii) initializing the reinforcement learning process with demonstrations in imitation learning [Chebotar et al., 2017b; Kalakrishnan et al., 2012], and iii) creating reward shaping functions that aim to guide the RL process to high-reward regions [Chebotar et al., 2017a; Popov et al., 2017]. Even though all of these methods have shown promising solutions to the problem of reward function design, they present other signiﬁcant challenges such as the requirement of domain expertise or access to demonstration data. Ideally, one would like to learn from a simple sparse binary reward that indicates completion of the task. Such a reward signal is natural for many goal-oriented tasks. It allows signiﬁcant reduction of engineering effort, and in some cases can be used to learn very complicated skills from human feedback, where design of the reward function is very hard [Christiano et al., 2017]. Despite being attractive, such a reward function creates signiﬁcant difﬁculties for learning. This is due to the fact that it is very unlikely for an agent to generate the exact sequence of actions leading to solving the task from random exploration [Duan et al., 2016]. Recent efforts focus on learning from such sparse reward signals by constructing a curriculum from a continuous set of tasks [Held et al., 2017; Florensa et al., 2017]. These methods exploit the simple intuition that tasks initialized closer to the goal should be easier to solve. Proximity to the goal is deﬁned either explicitly [Held et al., 2017] or through the number of random actions needed to reach the state from the goal [Florensa et al., 2017]. Nevertheless, all of these methods have a common disadvantage: they are designed for either singlestart or single-goal scenarios. In this paper, we address the situa',\n",
       " '1807.11293': 'Convolutional neural networks (CNNs) have demonstrated to learn powerful visual representations from large amounts of tediously labeled training data [24]. However, since visual data is cheap to acquire but costly to label, there has recently been great interest in learning compelling features from unlabeled data. Without any annotations, self-supervision based on surrogate tasks, for which the target value can be obtained automatically, is commonly pursued [32, 28, 17, 3, 34, 10, 31, 35, 30, 39, 27, 9, 18, 45]. In colorization [27], for instance, the color information is stripped from an image and serves as the target value, which has to be recovered. Various surrogate tasks have been proposed, including predicting a sequence of basic motions [30], counting parts within regions [35] or embedding images into text topic spaces [39]. The key competence of visual understanding is to recognize structure in visual data. Thus, breaking the order of visual patterns and training a network to recover the structure provides a rich training signal. This general framework of permuting the input data and learning a feature representation, from which ⋆Indicates equal contribution arXiv:1807.11293v1  [cs.CV]  30 Jul 2018  2 U. B¨uchler, B. Brattoli, B. Ommer the inverse permutation (and thus the correct order) can be inferred, is a widely applicable strategy. It has been pursued on still images [34, 36, 10, 9, 11] by employing spatial shuﬄing of images (especially permuting jigsaws) and in videos [32, 28, 17, 6] by utilizing temporally shuﬄed sequences. Since spatial and temporal shuﬄing are both ordering tasks, which only diﬀer in the ordering dimension, they should be addressed jointly. We observe that there has been unused potential in self-supervision based on ordering: Previous work [28, 17, 34, 36, 6] has randomly selected the permutations used for training the CNN. However, can we not ﬁnd permutations that are of higher utility for improving a CNN representation than the random set? For instance, given a 3 × 3 jigsaw grid, shuﬄing two neighboring image patches, two patches in faraway corners, or shuﬄing all patches simultaneously will learn structure of diﬀerent granularity. Thus diverse permutations will aﬀect the CNN in a diﬀerent way. Moreover the eﬀect of the permutations on the CNN changes during training since the state of the network evolves. During learning we can examine the previous errors the network has made when recovering order and then identify a set of best suited permutations. Therefore, wrapped around the standard back-propagation training of the CNN, we have a reinforcement learning algorithm that acts by proposing permutations for the CNN training. To learn the function for proposing permutations we simultaneously train a policy and self-supervised network by utilizing the improvement over time of the CNN network as a reward signal. 2 Related Work We ﬁrst present previous work on self-supervised learning using one task or a combination of surrogate approaches. Then we introduce curriculum learning procedures and discuss meta-learning for deep neural network. Self-Supervised',\n",
       " '1811.01741': 'Building machines to mimic human brain’s abilities has drawn considerate attention from the recent progress in artiﬁcial intelligence (AI) (Lake 2014; Lake, Salakhutdinov, and Tenenbaum 2015; Graves et al. 2016; Baker et al. 2017). Founders of the modern computational science consider the possibility that machines would ultimately possess consciousness (Turing 1950), which is the ability to perceive events and objects as humans have (Van Gulick 2018). However, many of the current advances lie on the statistical pattern recognition paradigm, which treats learning as making good predictions by discovering patterns correlated to high value rewards (or low errors) directly from the environments (Lake et al. 2017). These approaches do not draw inspiration from human cognition aspects, i.e., learning and thinking like a person (Dehaene, Lau, and Kouider 2017), and are considered as model-free. At the early stage of learning in high-dimensional environments with sparse rewards, modelfree methods cannot ﬁnd an optimal learning direction due to the lack of reward signals, thus requiring large amounts of data to explore and learn a good policy. In contrast, humans can achieve comparable performances on a range of tasks with much less experiences. For ∗Equal contribution. example, a human player needs only two hours of practice before achieving reasonable performance on one Atari game and can quickly adapt to different games, while DQN needs several days’ of training using large amounts of computational resources (Mnih et al. 2015). Humans develop a mental model of the world from the most impoverished of visual stimuli (Heider and Simmel 1944), and use this world to make rapid decisions and take actions (Forrester 1971). To build truly human-like AI machines, we consider an engineering approach in the ﬁrst step, and focus on developing the world model to support explanation and understanding. One of the key ingredients for building this model is the cognitive capability of understanding the underlying physics and dynamics of the environment (Wellman and Gelman 1992). For example, in the Atari Pong game, the ball and paddles follow principles of persistence, continuity, cohesion and solidity (Bellemare et al. 2015). Through mental models of the world, humans can reconstruct a perceptual scene following these principles to support mental simulations that can predict the future movement of the objects (Spelke 1990). Equipped with a world model understanding these intuitive theories of physics, agents can simulate the real experiences and learn the structured properties of the environment. By exploiting the underlying dynamics learned by the model, we can reduce the dimension of the input and generalize features across states and actions in high-dimensional environments (Watter et al. 2015; Wahlstr¨om, Sch¨on, and Deisenroth 2015; Levine and Abbeel 2014). With one transition model, agents can attend to the dynamics of the states by modeling how the environment evolves with speciﬁc action. These approaches, regarded as model-based learning, have been investigated by several previous works (Sutton',\n",
       " '0712.3327': 'A broadcast channel with degraded message sets represents a scenario where a sender wishes to communicate a common message to all receivers, a ﬁrst private message to a ﬁrst subset of the receivers, a second private message to a second subset of the ﬁrst subset and so on. Such scenario can arise, for example, in video or music broadcasting over a wireless network to nested subsets of receivers at varying levels of quality. The common message represents the lowest quality version to be sent to all receivers, the ﬁrst private message represents the additional information needed for the ﬁrst subset of receivers to decode the second lowest quality version, and so on. What is the set of simultaneously achievable rates for communicating such degraded message sets over the network? This question was ﬁrst studied by K¨orner and Marton in 1977 [1]. They considered a general 2-receiver discrete-memoryless broadcast channel with sender X and receivers Y1 and Y2. A common message M0 ∈[1, 2nR0] is to be sent to both receivers and a private message M1 ∈[1, 2nR1] is to be sent only to receiver Y1. They showed that the capacity region is given by the set of all rate pairs (R0, R1) such that 1 R0 ≤min{I(U; Y1), I(U; Y2)}, (1) R1 ≤I(X; Y1|U), for some p(u, x). These rates are achieved using superposition coding [2]. The common message is represented by the auxiliary random variable U and the private message is superimposed to generate X. The main contribution of [1] is proving a strong converse using the technique of images-of-a-set [3]. Extending the K¨orner-Marton result to more than 2 receivers has remained open even for the simple case of 3 receivers Y1, Y2, Y3 with 2 degraded message sets, where a common message M0 is to be sent to all receivers and a private message M1 is to be sent only to receiver Y1. The straightforward extension of the K¨orner-Marton region to this case yields the achievable rate region consisting of the set of all rate pairs (R0, R1) such that R0 ≤min{I(U; Y1), I(U; Y2), I(U; Y3)}, (2) R1 ≤I(X; Y1|U), Chandra Nair was partly supported by the Direct Grant for research at the Chinese University of Hong Kong 1The K¨orner-Marton characterization does not include the second term inside the min in the ﬁrst inequality, I(U; Y1). Instead it includes the bound R1 + R2 ≤I(X; Y1). It can be easily shown that the two characterizations are equivalent.  2 for some p(u, x). Is this region optimal? In [4], it was shown that the above region (and its natural extension to k > 3 receivers) is optimal for a class of product discrete-memoryless and Gaussian broadcast channels, where each of the receivers who decode only the common message is a degraded version of the unique receiver that also decodes the private message',\n",
       " '1707.01183': 'Social media text differs from other conventional text in many ways. It is noisy in nature and requires comprehensive processing from a multilingual point of view. In social media communication, a multilingual speaker often uses more than one language. Therefore, the communication, inherently informal in nature, presents the scientiﬁc community with a challenging yet interesting problem. First of all, we need to understand the necessity of language switching. Is it motivational? Or is it circumstantial? Although mixing of languages was prevalent in verbal communication, it was the proliferation of social media which accelerated the use of multiple languages in a single written communication and this is motivated by both social and conversational needs [1]. Sometimes, the speaker is not competent in the language he is writing. The lack of vocabulary provokes him to use words from his native language as a substitute. On some other occasions, the need is purely social and is used by the writer to mark him as part of a large group. Automatic identiﬁcation of the code switching points is important as it helps to understand the frequency of code switching or code mixing and subsequent complexity of the text. Also, it would allow us to determine the language speciﬁc models which are better suited for the analysis of such text. It is also important to understand the arXiv:1707.01183v1  [cs.CL]  4 Jul 2017  2 Souvick Ghosh1, Satanu Ghosh2, and Dipankar Das3 differences between code switching and code mixing as both the terms are used interchangeably in the literature. In our work, the term ’CodeSwitching’ refers to intersentential language shifts while the term ’Code-Mixing’ refers to intra-sentential shifts of language. In the present work, we have used short utterances collected from Facebook pages and Twitter data for our analysis. As the dataset is purely based on Indian social media text, it is essential that we give a brief statistics about the degree of multilingualism in India. There are more than 20 ofﬁcially recognized languages in India. The number of Hindi speakers range from 14.5% to 24.5% of total population (source:Wikipedia1). Other languages are spoken by 10% or less out of the total population. English and Hindi are mostly used for ofﬁcial communication in India. Similarly, it has been also observed that the diversity of Indian languages and the necessity for faster and efﬁcient communication motivates the mixing of languages in Indian social media context. This brings us to one of the challenging problems, i.e. transliteration. Most of the time, the languages like Hindi or Bengali are not written using their native scripts - Devanagari for Hindi and Eastern Neo Brahmi script for Bengali. Instead, the users prefer using Roman script as it is more convenient with a regular keyboard. While analyzing a codemixed transliterated text, it is often useful to determine the complexity of the corpus. For any task on code-mixed corpora such as language identiﬁcation, part-of',\n",
       " '1803.08586': 'Global function optimization with stochastic (zeroth-order) query oracles is an important problem in optimization, machine learning and statistics. To optimize an unknown bounded function f : X ÞÑ R deﬁned on a known compact d-dimensional domain X Ď Rd, the data analyst makes n active queries x1, . . . , xn P X and observes yt “ fpxtq ` wt, wt i.i.d. „ Np0, 1q, 1 t “ 1, . . . , n. (1) 1The exact distribution of the independent noise variables εt is not important, and our results can be generalized to sub-Gaussian noise variables as well. 1  The queries x1, . . . , xt are active in the sense that the selection of xt can depend on the previous queries and their responses x1, y1, . . . , xt´1, yt´1. After n queries, an estimate pxn P X is produced that approximately minimizes the unknown function f. Such “active query” models are relevant in a broad range of (noisy) global optimization applications, for instance in hyper-parameter tuning of machine learning algorithms [43] and sequential design in material synthesis experiments where the goal is to maximize strengths of the produced materials [37, 44]. We refer the readers to Section 2.1 for a rigorous formulation of the active query model and contrast it with the classical passive query model. The error of the estimate pxn is measured by the difference of fppxnq and the global minimum of f: Lppxn; fq :“ fppxnq ´ f ˚ where f ˚ :“ inf xPX fpxq. (2) To simplify our presentation, throughout the paper we take the domain X to be the d-dimensional unit cube r0, 1sd, while our results can be easily generalized to other compact domains satisfying minimal regularity conditions. When f belongs to a smoothness class, say the Hölder class with exponent α, a straightforward global optimization method is to ﬁrst sample n points uniformly at random from X and then construct nonparametric estimates pfn of f using nonparametric regression methods such as (high-order) kernel smoothing or local polynomial regression [21, 49]. Classical analysis shows that the sup-norm reconstruction error } pfn ´ f}8 “ supxPX | pfnpxq ´ fpxq| can be upper bounded by rOPpn´α{p2α`dqq2. This global reconstruction guarantee then implies an rOPpn´α{p2α`dqq upper bound on Lppxn; fq by considering pxn P X such that pfnppxnq “ infxPX pfnpxq (such an pxn exists because X is closed and bounded). Formally, we have the following proposition (proved in the Appendix) that converts a global reconstruction guarantee into an upper bound on optimization error: Proposition 1. Suppose pfnppxnq “ infxPX pfnpxq. Then Lppxn; fq ď 2} pfn ´ f}8. Typically, fundamental limits on the optimal optimization error are understood through the lens of minimax analysis where the object of study is the (global) minimax risk: inf pxn sup fPF EfLppxn, fq, (3) where F is a certain smoothness function class such as the Hölder class. Although optimization appears to be easier than global reconstruction, we show in this paper that the n´α{p2α`dq rate is not improvable in the',\n",
       " '1708.03152': 'Human-computer conversation has long attracted attention in both academia and industry. Researchers have developed a variety of approaches, ranging from rule-based systems for task-oriented dialog (Ferguson et al., 1996; Graesser et al., 2005) to data-driven models for open-domain conversation (Ritter et al., 2011). A simple setting in the research of dialog systems is context-free, i.e., only a single utterance is considered during reply generation (Shang et al., 2015). Other studies leverage context information by concatenating several utterances (Sordoni et al., 2015) or building hierarchical models (Yao et al., 2015; Serban et al., 2016). The above approaches do not distinguish different speakers, and thus speaker information would be lost during conversation modeling. Speaker modeling is in fact important to dialog systems, and has been studied in traditional dialog research. However, existing methods are usually based on hand-crafted statistics and ad hoc to a certain application (Lin and Walker, 2011). Another research direction is speaker modeling in a multi-modal setting, e.g., acoustic and visual (Uthus and Aha, 2013), which is beyond the focus of this paper. Recently, neural networks have become a prevailing technique in both task-oriented and open-domain dialog systems. After single-turn and multi-turn dialog studies, a few researchers have realized the role of speakers in neural conversational models. Li et al. (2016) show that, with speaker identity information, a sequence-to-sequence neural dialog system tends to generate more coherent replies. In their approach, a speaker is modeled by a learned vector (also known as an embedding). Such method, unfortunately, requires massive conversational data for a particular speaker to train his/her embedding, and thus does not generalize to rare or unseen speakers. Ouchi and Tsuboi (2016) formalize a new task of addressee selection on online forums: by leveraging either the tem- ∗Corresponding author. poral or utterance information, they predict whom a post is talking to. While tempting for benchmarking speaker modeling, the task requires explicit speaker ID mentions, which occurs occasionally, and thus is restricted. In this paper, we propose a speaker classiﬁcation task that predicts the speaker of an utterance. It serves as a surrogate task for general speaker modeling, similar to next utterance classiﬁcation (Lowe et al., 2015, NUC) being a surrogate task for dialog generation. The speaker classiﬁcation task could also be useful in applications like speech diarization,1 where text understanding can improve speaker segmentation, identiﬁcation, etc. in speech processing (Li et al., 2009; Meng et al., 2017). We further propose a neural model that combines temporal and content information with interpolating or gating mechanisms. The observation is that, what a speaker has said (called content) provides non-trivial background information of the speaker. Meanwhile, the relative order of a speaker (e.g., the i-th latest speaker) is a strong bias: nearer speakers are more likely to speak again; we call it temporal information. We',\n",
       " '1808.07604': 'As music style (e.g., Jazz, Pop, and Rock) is one of the most frequently used labels for music, music style classiﬁcation is an important task for applications of music recommendation, music information retrieval, etc. There are several criteria related to the instrumentation and rhythmic structure of music that characterize a particular style. In real life, many pieces of music usually map to more than one style. Several methods have been proposed for automatic music style classiﬁcation (Qin and Ma, 2005; Zhou et al., 2006; Wang et al., 2009; Choi et al., 2017). Although these methods make some progress, they are limited in two aspects. First, their generalization ability partly suffers ∗Equal Contribution from the small quantity of available audio data. Due to the limitation of music copyright, it is difﬁcult to obtain all necessary audio materials to classify music styles. Second, for simpliﬁcation, most of the previous studies make a strong assumption that a piece of music has only one single style, which does not meet the practical needs. Different from the existing methods, this work focuses on review-driven multi-label music style classiﬁcation. The motivation of using reviews comes from the fact that, there is a lot of accessible user reviews on relevant websites. First, such reviews provide enough information for effectively identifying the style of music, as shown in Table 1. Second, compared with audio materials, reviews can be obtained much more easily. Taking practical needs into account, we do not follow the traditional single-label assumption. Instead, we categorize music items into ﬁne-grained styles and formulate this task as a multi-label classiﬁcation problem. For this task, we build a new dataset which contains over 7,000 samples. Each sample includes a music title, a set of human annotated styles, and associated reviews. An example is shown in Table 1. The major challenge of this task lies in the complicated correlations of music styles. For example, Soul Music1 contains elements of R&B and Jazz. These three labels can be used alone or in combination. Many multi-label classiﬁcation methods fail to capture this correlation, and may mistake the true label [Soul Music, R&B, Jazz] for the false label [R&B, Jazz]. If well learned, such relations are useful knowledge for improving the performance, e.g., increasing the probability of Soul 1Soul Music is a popular music genre that originated in the United States in the late 1950s and early 1960s. It contains elements of African-American Gospel Music, R&B and Jazz.  Music Title Mozart: The Great Piano Concertos, Vol.1 Styles Classical Music, Piano Music Reviews (1) I’ve been listening to classical music all the time. (2) Mozart is always good. There is a reason he is ranked in the top 3 of lists of greatest classical composers. (3) The sound of piano brings me peace and relaxation. (4) This volume of Mozart concertos',\n",
       " '1412.2196': 'Subspaces are the most commonly assumed structure for high dimensional data due to their simplicity and effectiveness. For example, motion (Tomasi and Kanade, 1992), face (Belhumeur et al., 1997; Belhumeur and Kriegman, 1998; Basri and Jacobs, 2003), and texture (Ma et al., 2007) data have been known to be well characterized by low dimensional subspaces. There has been a lot of effort on robustly recovering the underlying subspaces of data. The most widely adopted approach is Principal Component Analysis (PCA). Unfortunately, PCA is known to be fragile to large noises or outliers. So much work has been devoted to improving the robustness of PCA (Gnanadesikan and Kettenring, 1972; Huber, 2011; Fischler and Bolles, 1981; De La Torre and Black, 2  2003; Ke and Kanade, 2005), among which the Robust PCA (R-PCA) (Wright et al., 2009; Chandrasekaran et al., 2011; Cand`es et al., 2011) is probably the only one with theoretical guarantees. Cand`es et al. (2011); Chandrasekaran et al. (2011); Wright et al. (2009) proved that under certain conditions the ground truth subspace can be exactly recovered with an overwhelming probability. Later work (Hsu et al., 2011) gave a justiﬁcation of R-PCA in the case where the spatial pattern of the corruptions is deterministic. Although R-PCA has found wide applications, such as video denoising, background modeling, image alignment, photometric stereo, and texture representation (see e.g., Wright et al., 2009; De La Torre and Black, 2003; Ji et al., 2010; Peng et al., 2010; Zhang et al., 2012), it only aims at recovering a single subspace that spans the whole data. To identify ﬁner structure of data, the multiple subspaces recovery problem should be considered, which aims at clustering data according to the subspaces they lie in. This problem has attracted a lot of attention in recent years (Vidal, 2011). Rank minimization methods account for a large class of subspace clustering algorithms, where rank is connected to the dimensions of subspaces. Representative rank minimization based methods include Low Rank Representation (LRR) (Liu and Yan, 2011; Liu et al., 2013), Robust Low Rank Representation (R-LRR) (Wei and Lin, 2010; Vidal and Favaro, 2014) 1, Latent Low Rank Representation (LatLRR) (Liu et al., 2010; Zhang et al., 2013a) 1Note that Wei and Lin (2010) and Vidal and Favaro (2014) called R-LRR as Robust Shape Interaction (RSI) and Low Rank Subspace Clustering (LRSC), respectively. The two models are essentially the same, only differing in the optimization algorithms. In order to remind the readers that they are both robust versions of LRR by using a denoised dictionary, in this paper we call them Robust Low Rank Representation (R-LRR) instead. 3  and its robust version (R-LatLRR) (Zhang et al., 2014). Nowadays, subspace clustering algorithms, including these low rank methods, have been widely applied, e.g., to motion segmentation (Gear, 1998; Costeira and Kanade, 1998; Vidal and Hartley, 2004; Yan and Pollefeys, 2006; Rao et al., 2010), image segmentation (Yang et al., 2008',\n",
       " '1001.2190': 'Recently, generalized entropies have been studied from the mathematical point of view. The typical generalizations of Shannon entropy [2] are R´enyi entropy [3] and Tsallis entropy [4]. The R´enyi entropy and the Tsallis entropy are deﬁned by Rq(X) = 1 1 −q log n X j=1 xq j, (q ̸= 1, q > 0) and Sq(X) = n X j=1 xj −xq j q −1 , (q ̸= 1, q > 0) for a given information source X = {x1, · · · , xn} with the probability pj ≡Pr(X = xj). Both entropies recover Shannon entropy: S1(X) ≡− n X j=1 pj log pj in the limit q →1. The uniqueness theorem for the Tsallis entropy was ﬁrstly given in [5] and improved in [6]. Throughout this paper, a parametric extended entropy such as R´enyi entropy and Tsallis entropy and so on, is called by a generalized entropy. ∗E-mail:furuichi@chs.nihon-u.ac.jp 1  We note that the R´enyi entropy has the additivity: Rq(X × Y ) = Rq(X) + Rq(Y ) but the Tsallis entropy has the non-additivity: Sq(X × Y ) = Sq(X) + Sq(Y ) + (1 −q)Sq(X)Sq(Y ), (1) where X × Y means that X and Y are independent random variables. Therefore we have a deﬁnitive diﬀerence for these entropies, although we have the simple relation between them: Rq(X) = 1 1 −q log {1 + (1 −q)Sq(X)} , (q ̸= 1). The Tsallis entropy is rewritten by Sq(X) = − n X j=1 pq j lnq pj (2) where the q-logarithmic function is deﬁned by lnq x ≡x1−q −1 1 −q , (q ̸= 1), which uniformly converges to log x in the limit q →1. Since Shannon entropy can be regarded as the expectation value for each value −log pj, we may consider that the Tsallis entropy can be regarded as the q-expectation value for each value −lnq pj, as an anology to Shannon entropy. Where q-expectation value Eq is deﬁned by Eq(X) ≡ n X j=1 pq jxj. However, the q-expectation value Eq lacks the fundamental property such as E(1) = 1, so that it was considered to be inadequate to adopt as a generalized deﬁnition of the usual expectation value. Then the noremalized q-expectation value was introduced: E(nor) q (X) ≡ Pn j=1 pq jxj Pn i=1 pq i and by using this, the normalized Tsallis entropy was deﬁned by S(nor) q (X) ≡Sq(X) Pn j=1 pq j = − Pn j=1 pq j lnq pj Pn i=1 pq i , (q ̸= 1). We easily ﬁnd that we have the following non-additivity relation for the normalized Tsallis entropy: S(nor) q (X × Y ) = S(nor) q (X) + S(nor) q (Y ) + (q −1)S(nor) q (X)S(nor) q (Y ). (3) As for the details on the mathematical properties of the normalized Tsallis entropy, see [7] for example. The diﬀerence between two non-additivities Eq.(1) and Eq.(3) is the signature',\n",
       " '1603.07849': 'Nowadays web users are confronted with an overabundance of information caused by a constant increase in the volume of information that users can no longer absorb, process, or prioritize. As a result, the selection and use of information processed by users become particularly complex. This phenomenon presents the need to design a recommender system that best depicts the preferences of a user with regard to the most relevant information at possibly the shortest time [1], [2]. Recommender systems are tools whose purpose is to help users overcome information overload by selecting the most interesting information based on their preferences. In other words, they try to predict a user’s interest towards an item. The items to recommend are varied, ranging from movies to watch, books to read, podcast to listen to, or else. Conventional recommender systems have been successfully applied by e-commerce or social networking websites such as Amazon (www.amazon.com), Netﬂix (www.netﬂix.com), YouTube (www.youtube.com), and Facebook (www.facebook.com). Since then many recommender system algorithms and their variants have been proposed in literature, however, most of them were mainly accuracy-oriented algorithms that predict the rating of an item. In other words, these algorithms were focused on optimizing the accuracy of the rating of a predicted item. Although such recommender system algorithms are sufﬁcient in many applications, there are situations where they may not be enough because they do not take into account all facets of the user’s interests such as the desire to change. At this point the need to design a new paradigm of recommender systems arises considering important factors outside the optimization of the accuracy of the rating of predicted item. A multinomial probabilistic model for movie genre prediction is proposed in this paper as a response to the confronting challenge. Our model aims to predict a movie’s genre rather than to predict its rating. Technically, this approach is based on Bayesian reasoning and is enacted in two steps. In the ﬁrst step, the multinomial probabilistic model is applied to learn the movie’s likelihood of belonging to a particular genre using multinomial model. At the second step, the Bayesian probabilistic reasoning is applied for the prediction of the movie’s genres. This in turn completes the item’s genre given by experts and consequently can improve the recommendation. In the recent past, many recommender systems that consider factors other than the accuracy-oriented ones and their variants have been proposed in literature [3], [4], [5], [6]. To the best of our knowledge, our model predicting an item’s genre/s that complement the genres assigned by experts is a new attempt in the ﬁeld of recommender systems. The rest of the paper is organized as follows. Section 2 discusses the related work. Section 3 outlines the proposed algorithm. Section 4 contains the performance study. Finally in section 5, we summarize our work. II. RELATED WORK Tradition',\n",
       " '1804.06137': 'Twitter is one of the most popular micro-blogging platforms that has attracted over 300M daily users1 with over 500M 2 tweets sent every day. Tweet data has attracted NLP researchers because of the ease of access to large data-source of people expressing themselves online. Tweets are micro-texts comprising of emoticons, hashtags as well as location data, making them feature rich for performing various kinds of analysis. Tweets provide an interesting challenge as users tend to write grammatically incorrect and use informal and slang words. In domain of natural language processing, emotion recognition is the task of associating words, phrases or documents with emotions from predeﬁned using psychological models. The classiﬁcation of emotions has mainly been researched from 1https://www.statista.com/statistics/282087/number-ofmonthly-active-twitter-users/ 2http://www.internetlivestats.com/twitter-statistics/ two fundamental viewpoints. (Ekman, 1992) and (Plutchik, 2001) proposed that emotions are discrete with each emotion being a distinct entity. On the contrary, (Mehrabian, 1980) and (Russell, 1980) propose that emotions can be categorized into dimensional groupings. Affect in Tweets (Mohammad et al., 2018) - shared task in SemEval-2018 focuses on extracting affect from tweets conﬁrming to both variants of the emotion models, extracting valence (dimensional) and emotion (discrete). Previous version of the task (Mohammad and Bravo-Marquez, 2017) focused on estimating the emotion intensity in tweets. We participated in 4 sub-tasks of Affect in Tweets, all dealing with English tweets. The sub-tasks were: EI-oc: Ordinal classiﬁcation of emotion intensity of 4 different emotions (anger, joy, sadness, fear), EI-reg: to determine the intensity of emotions (anger, joy, sadness, fear) into a real-valued scale of 0-1, V-oc: Ordinal classiﬁcation of valence into one of 7 ordinal classes [-3, 3], V-reg: determine the intensity of valence on the scale of 0-1. Prior work in extracting Valence, Arousal, Dominance (VAD) from text primarily relied on using and extending lexicons (Bestgen and Vincze, 2012) (Turney et al., 2011). Recent advancements in deep learning have been applied in detecting sentiments from tweets (Tang et al., 2014), (Liu et al., 2012), (Mohammad et al., 2013). In this work, we use various state-of-the-art machine learning models and perform domain adaptation (Pan and Yang, 2010) from their source task to the target task. We use multi-view ensemble learning technique (Kumar and Minz, 2016) to produce the optimal feature-set partitioning for the classiﬁer. Finally, results from multiple such classiﬁers are stacked together to create an ensemble (Polikar, 2012). arXiv:1804.06137v1  [cs.CL]  17 Apr 2018  In this paper, we describe our approach and experiments to solve this problem. The rest of the paper is laid out as follows: Section 2 describes the system architecture, Section 3 reports results and inference from different experiments. Finally we conclude in Section 4 along with a discussion about future work. 2 System Description 2',\n",
       " '1806.07688': 'Deep Convolutional Neural Networks (CNNs) and their variants have emerged as the architecture of choice for computer vision. Deep networks have achieved state-of-the-art results in object class recognition [1], [2], [3], face recognition [4], semantic segmentation [5], pose estimation [6], and visual tracking [7] among other applications. While the initial focus has been on making CNNs deeper in order to achieve higher performance, recent work has been exploring leaner networks, such as DenseNet [8] as an alternative to ResNet [3], that are more efﬁcient yet perform just as well if not better than their larger counterparts. In its simplest form a CNN consists of a feature extraction convolutional network followed a linear classiﬁer, the head of the network. One beneﬁt of CNNs is that they are trained in an end to end manner, thus the maximum beneﬁt can be extracted from each stage. However, the features learned by CNNs can be further improved for robustness. A robust feature representation is one that minimizes differences between Fig. 1. Visualization of DEFRAG process of optimization along the gradient direction and then retraction on the Grassmann manifold. samples of the same class and maximizes differences between samples from different classes. In this work we present a method referred to as DEFRAG, inspired by Linear Discriminate Analysis (LDA) [9]. Our approach shapes the feature representation through a novel auxiliary loss function, (Section 3.1), and a orthogonalization step that involves retraction on a Grassmann manifold (Section 3.2) illustrated in Fig. 1. An auxiliary loss, Laux, is secondary metric that is added to the loss from the main training objective, Lclass, for the optimizer to minimize, as L = LClass + λauxLaux (1) Where λaux is a mixture parameter used to balance the impact of the auxiliary loss. In this work the main loss objective is the traditional categorical cross-entropy loss which learns to classify the samples, and a proposed new auxiliary loss function, the Silhouette Loss. Figure 3 illustrates the clustering characteristics of DEFRAG compared to other methods. The contributions of this paper are the following: (a) We introduce a new auxiliary loss functions based on the Silhouette clustering metric which encourages tight intra-class clustering and inter-class separation. (b) We propose an orthogonalization step which retracts the optimized feature projection arXiv:1806.07688v1  [cs.CV]  20 Jun 2018  matrix back on the Grassmann manifold. (c) We demonstrate how the DEFRAG method improves performance so that a small network matches or exceeds the performance of much bigger networks and achieves state of the art results on standard datasets. In the remainder of this paper, Section 2 provides background on auxiliary loss functions and other regularization methods used to train deep neural networks. Section 3 presents our proposed DEFRAG method and its theoretical justiﬁcations. Section 4 outlines our results and Section 5 offers concluding remarks. 2. BACKGROUND There are many variants of auxiliary loss functions',\n",
       " '1404.2520': 'The capacity region of the broadcast channel with M users (i.e. M receivers) is a well-known open problem. However, it is known that feedback can increase the capacity region for broadcast channels. Specially, Ozarow and Leung [1] proved for M = 2 that feedback can increase the capacity region of the additive white Gaussian broadcast channel (AWGN-BC) by cooperation between the users and the sender via feedback. Kramer [2] extended this coding scheme to the case of M ≥3. Later, Elia [3] showed for M = 2 that the achievable rate region obtained by Ozarow and Leung [1] can be enlarged by using robust control theory. Ardestanizadeh et al. [4] proposed a coding scheme based on LQG (Linear Quadratic Gaussian) control approach for the symmetric AWGN-BC with feedback, and showed that their LQG code can attain the same achievable rate region as the Elia scheme [3] for M = 2 and outperforms the Kramer code [2] for the symmetric AWGN-BC with feedback for M ≥3. The LQG code is derived based on a mapping from a feedback control problem to a linear code for the AWGN-BC with feedback. The achievable rate region is determined by the eigenvalues of the open-loop matrix of a linear system and the power constraint of channel input is related to the minimum power needed to stabilize the system using a feedback control signal. Recently, Amor et al. [5], [6] showed that the rate regions achieved by linear feedback coding schemes †The author is with National University of Singapore. ††The author is with The University of Tokyo. a) E-mail: lantruong@u.nus.edu b) E-mail: hirosuke@ieee.org DOI: 10.1587/trans.E0.??.1 over dual multi-antenna AWGN multi-access channels (MACs) and broadcast channels (BCs) with independent noises coincide, and the sum-rate achieved by the LQG code is optimal among all the linear-feedback coding schemes for the symmetric AWGN-BCs. This optimal sum-rate is called linear-feedback sum-capacity, and they showed for M = 2 that the linear-feedback sum-capacity of the scalar AWGN-BC with independent noises can be achieved by a simple rearrangement of Ozarow’s MAC coding scheme [7]. (Refer to Remark 7 in Section 5 for more details.) However, it is not shown for M ≥3 how to construct a coding scheme for AWGN-BCs with feedback by a rearrangement of a coding scheme for AWGN-MACs with feedback. Note that since Kramer’s MAC coding scheme [2], which is a generalization of Ozarow’s MAC coding scheme for M ≥3, uses complex modulation coeﬃcients, it is not easy to construct a BC coding scheme from Kramer’s MAC coding scheme even if we try to use a rearrangement similar to the one used in [6]. In a more general setting, Gaspar et al. [8], [9] proposed a coding scheme for the AWGN-BC with correlated',\n",
       " '1709.02349': 'Dialogue systems and conversational agents - including chatbots, personal assistants and voicecontrol interfaces - are becoming ubiquitous in modern society. Examples of these include personal assistants on mobile devices, technical support help over telephone lines, as well as online bots selling anything from fashion clothes and cosmetics to legal advice and self-help therapy. However, building intelligent conversational agents remains a major unsolved problem in artiﬁcial intelligence research. In 2016, Amazon.com Inc proposed an international university competition with the goal of building a socialbot: a spoken conversational agent capable of conversing coherently and engagingly with humans on popular topics, such as entertainment, fashion, politics, sports, and technology. The socialbot converses through natural language speech through Amazon’s Echo device (Stone & Soper 2014). This article describes the models, experiments and ﬁnal system (MILABOT) developed by our team at University of Montreal.3 Our main motivation for participating has been to help advance artiﬁcial intelligence research. To this end, the competition has provided a special opportunity for training and testing state-of-the-art machine learning algorithms with real users (also known as machine learning in the wild) in a relatively unconstrained setting. The ability to experiment with real users is unique in the artiﬁcial intelligence community, where the vast majority of work consists of experiments on ﬁxed datasets (e.g. labeled datasets) and software simulations (e.g. game engines). In addition, the computational resources, technical support and ﬁnancial support provided by Amazon has helped scale up our system and test the limits of state-of-the-art machine learning methods. Among other things, this support has enabled us to crowdsource 200, 000 labels on Amazon Mechanical Turk and to maintain over 32 dedicated Tesla K80 GPUs for running our live system. 1School of Computer Science, McGill University. 2CIFAR Fellow. 3Our team is called MILA Team, where MILA stands for the Montreal Institute for Learning Algorithms. arXiv:1709.02349v2  [cs.CL]  5 Nov 2017  Our socialbot is based on a large-scale ensemble system leveraging deep learning and reinforcement learning. We develop a new set of deep learning models for natural language retrieval and generation — including recurrent neural networks, sequence-to-sequence models and latent variable models — and evaluate them in the context of the competition. These models are combined into an ensemble, which generates a candidate set of dialogue responses. Further, we apply reinforcement learning — including value function and policy gradient methods — to train the system to select an appropriate response from the models in its ensemble. In particular, we propose a novel reinforcement learning procedure, based on estimating a Markov decision process. Training is carried out on crowdsourced data and on interactions recorded between real-world users and a preliminary version of the system. The trained systems yield substantial improvements in A/B testing experiments with real-world users. In the competition semi-ﬁnals, our best performing system reached an average user score of 3.15 on a scale 1 −5, with a minimal number of hand',\n",
       " '1812.02253': 'The past years have seen increased interest from the research community in the development of deep reading comprehension models, spurred by the release of datasets such as SQuAD. (Rajpurkar et al., 2016). For a majority of these datasets, the top performing models employ span prediction, selecting a span of tokens from the reference document that answers the question. Such models have been very successful; the best model on the SQuAD leaderboard approaches human performance (Yu et al., 2018). However, this strong performance may be deceptive. (Jia and Liang, 2017) show that inserting lexically similar adversarial sentences into the passages sharply reduces performance. One possible reason for this disparity is that standard span prediction is an easy task. The information required to evaluate whether a span is the correct answer is often located right next to the span. Masala et al. (2017) transform the SQuAD dataset into a sentence selection task where the ∗All authors contributed equally goal is to predict the sentence that contains the correct span. They achieve high accuracy on this task using simple heuristics that compare lexical similarity between the question and each sentence individually, without additional context. Selecting an answer from a list of candidate answers that are lexically dissimilar to the context makes it more challenging for models to retrieve the relevant information. For that reason, we focus on reading comprehension for answer selection. Another common weakness of reading comprehension datasets is that they consist of short paragraphs. This property also makes it easier to locate relevant information from the context. Realistic tasks require answering questions over longer documents. Building on (Clark and Gardner, 2017), we propose a weighted global normalization method to improve the performance of reading comprehension models for answer selection on long documents. First, we adapt global normalization to the multiple-choice setting by applying a reading comprehension model in parallel over ﬁxed length portions (chunks) of the document and normalizing the scores over all chunks. Global normalization encourages the model to produce low scores when it is not conﬁdent that the chunk it is considering contains the information to answer the question. Then we incorporate a weighting function to rescale the contribution of different chunks. In our work we use an Multilayer Perceptron over the scores and a TF-IDF heuristic as our weighting function, but more complex models are possible. We experiment on the answer selection task over story summaries from the recently released NarrativeQA (Koˇcisk`y et al., 2017) dataset. It provides an interesting and a challenging test bed for reading comprehension as the summaries are long, and the answers to questions often do not occur in the summaries. We adopt the three-way attention arXiv:1812.02253v2  [cs.CL]  25 Nov 2021  model (Wang, 2018), an adapted version of the BiDAF (Seo et al., 2016) span prediction model, in order to evaluate our method. We show that straightforward application of',\n",
       " '1508.00964': 'Compressive sensing (CS) [1], [2] is a technique to reconstruct sparse signals from compressed measurements. CS has received great attention due to its broad application areas including imaging, radar, and communication systems [3], [4]. The fundamental theory of CS guarantees to recover a high dimensional signal vector from linear measurements that are far fewer in number than the signal’s dimension, provided that the sparsity of the signal, i.e. number of nonzero elements, is smaller than a certain fraction of the number of measurements. Denoting the sparse signal vector and the compressive sensing matrix as x ∈RN and Φ ∈RM×N respectively, with M < N, the optimal sparse recovery solution can be theoretically obtained by solving the ℓ0-minimization problem min ∥x∥0 subject to y = Φx. (1) In practice, however, solving this problem is NP-hard [5] and computationally unfeasible for large signal dimension (N). Design of computationally efﬁcient sparse signal recovery algorithms have extensively studied in past works. Basis Pursuit (BP) [6]–[8] is a representative sparse signal recovery algorithm leveraging convex optimization. Relaxing the ℓ0minimization problem to a ℓ1-minimization problem, it has N. Lee is with Intel Labs, 2200 Mission College Blvd, Santa Clara, CA 95054, USA (e-mail:namyoon.lee@intel.com). This work was done when the author was with the University of Texas at Austin. been shown that the sparse signal recovery problem can be solved with stability and uniform guarantees using linear programming, but with polynomially bounded computation complexity. For example, an interior point method that solves the ℓ1-minimization problem has an associated computational complexity of O(M 2N 3) [9]. As a result, greedy algorithms are also popular because their complexity is lower than that of BP although stability and guarantees are challenging to prove [10], [15]–[19]. The underlying idea of greedy algorithms is to estimate the nonzero elements of a sparse vector iteratively. Orthogonal matching pursuit (OMP) is a well-known greedy algorithm [10]–[14], which estimates the coordinate of the non-zero element in signal x that has the maximum absolute correlation between the column vector in the sensing matrix and the residual vector in each iteration. By subtracting the contribution from the measurement vector y, the algorithm updates the entire support of x in an iterative manner. Although this algorithm is simple to implement, it is vulnerable to error propagation effect [10]–[16]. This is because the OMP algorithm is not capable of removing incorrectly estimated supports once those are added to the support set during the iterations, which leads to signiﬁcant performance degradation in the signal recovery. Several other advanced greedy algorithms have been proposed to overcome the error propagation effect, which include Stagewise Orthogonal Matching Pursuit (StOMP) [15], iterative hard thresholding (IHT) [16], generalized OMP (gOMP) [17], Compressive Sampling Matching Pursuit (CoSaMP) [18], and Subspace Pursuit (SP) [19]. The underlying principle of these advanced greedy algorithms is the selection of multiple support indices per itera',\n",
       " '1111.4555': 'Consider a distributed detection scenario where N sensors are connected by a generic network with intermittently failing links. The sensors perform consensus+innovations distributed detection; in other words, at each time k, each sensor i updates its local decision variable xi(k) by: 1) sensing and processing a new measurement to create an intermediate variable; and 2) weight averaging it with its neighbors’ intermediate decision variables. We showed in [1] that, when the sensor observations are Gaussian, the consensus+innovations distributed detector exhibits a phase transition. When the network connectivity is above a threshold, then the distributed detector is asymptotically optimal, i.e., asymptotically equivalent to the optimal centralized detector that collects the observations of all sensors. This paper establishes the asymptotic performance of distributed detection over random networks for generic, non-Gaussian sensor observations. We adopt as asymptotic performance measure the exponential decay rate of the Bayes error probability (error exponent). We show that phase transition behavior emerges with non-Gaussian observations and demonstrate how the optimality threshold is a function of the logmoment generating function of the sensors’ observations and of the number of sensors N. This reveals a very interesting interplay between the distribution of the sensor observations (e.g., Gaussian or Laplace) and the rate of diffusion (or connectivity) of the network (measured by a parameter | log r| ∈[0, ∞) deﬁned in Section II): for a network with the same connectivity, a distributed detector with say, Laplace observations distributions, may match the optimal asymptotic performance of the centralized detector, while the distributed detector for Gaussian observations may be suboptimal, even though the centralized detectors for the two distributions, Laplace and Gaussian, have the same optimal asymptotic performance. For distributed detection, we determine the range on the detection threshold γ for which each sensor achieves exponentially fast decay of the error probability (strictly positive error exponent), and we ﬁnd the optimal γ that maximizes the error exponent. Interestingly, above the critical (phase transition) value for the network connectivity | log r|, the optimal detector threshold is γ = 0, mimicking the (asymptotically) optimal threshold for the centralized detector. However, below the critical connectivity, we show by a numerical example that the optimal distributed detector threshold might be non zero. Brief review of the literature. Distributed detection has been extensively studied, in the context of parallel fusion architectures, e.g., [2], [3], [4], [5], [6], [7], [8], consensus-based detection [9], [10], [11], [12], and, more recently, consensus+innovations distributed inference, see, e.g., [13], [14], [15], [16], [17] for distributed estimation, and [18], [19], [20], [21], [22], [23], [24] for distributed detection. Different variants of consensus+innovations distributed detection algorithms have been proposed; we analyze here August 9, 2018 DRAFT  3 running consensus, the variant in [20]. Reference [20] considers asymptotic optimality of running consensus, but in a framework that is very different from ours. Reference [20] studies the asymptotic performance of the distributed detector where the means of the sensor observations under the two hypothesis become closer and',\n",
       " '1607.06583': \"Alzheimer’s Disease  Alzheimer’s disease is a neurological, irreversible, progressive brain disorder and multifaceted disease  that slowly destroys brain cells causing memory and thinking skills loss, and ultimately the ability to  carry out the simplest tasks. The cognitive decline caused by this disorder ultimately leads to dementia.  For instance, the disease begins with mild deterioration and gets progressively worse in a  neurodegenerative type of dementia. Diagnosing Alzheimer’s disease requires very careful medical   3    assessments such as patients’ history, Mini Mental State Examination (MMSE) and physical and  neurobiological exam. Structural imaging based on magnetic resonance is an integral part of the clinical  assessment of patients with suspected Alzheimer dementia. Atrophy of medial temporal structures is now  considered to be a valid diagnostic marker at the mild cognitive impairment stage. Structural imaging is  also included in diagnostic criteria for the most prevalent non-Alzheimer dementias, reflecting its value in  differential diagnosis. In addition, rates of whole-brain and hippocampal atrophy are sensitive markers of  neurodegeneration, and are increasingly used as outcome measures in trials of potentially diseasemodifying therapies [1]. Clinical diagnostic criteria are currently based on the clinical examination and  neuropsychological assessment, with the identification of dementia and then of the Alzheimer's phenotype  [2]. Development of an assistant tool or algorithm to classify structural MRI data and more importantly to  recognize brain disorder data from healthy subjects has been always clinicians ‘interests. Any machine  learning algorithm which is able to classify Alzheimer’s disease assists scientists and clinicians to  diagnose this brain disorder. In this work, the convolutional neural network (CNN) which is one of the  Deep Learning Network architecture is utilized in order to classify the Alzheimer’s brains and healthy  brains and to produce a trained and predictive model.  Deep Learning  Hierarchical or structured deep learning is a modern branch of machine learning that was inspired by  human brain. This technique has been developed based on complicated algorithms that model high-level  features and extract those abstractions from data by using similar neural network architecture but much  complicated. The neuroscientists discovered the “neocortex” which is a part of the cerebral cortex  concerned with sight and hearing in mammals, process sensory signals by propagating them through a  complex hierarchy over time. That was the main motivation to develop the deep machine learning  focusing on computational models for information representation that exhibit similar characteristics to  that of the neocortex [3] [4] [5]. Convolutional Neural Networks which are inspired by human visual  system are similar to classic neural networks. This architecture has been particularly designed based on   4    the explicit assumption that raw data are two-dimensional (images) that enables us to encode certain  properties and also to reduce the amount of hyper parameters. The CNN topology utilizes spatial  relationships to reduce the number of parameters which must be learned and thus improves upon general  feed-forward back propagation training. Equation 1 shows how Error is calculated in the back  propagation step where E is\",\n",
       " '1408.6824': 'Polar coding, introduced by Arıkan in [1], has attracted much attention for its ability to achieve capacity of binaryinput memoryless output-symmetric channels under a lowcomplexity decoding procedure (a successive cancellation, or SC decoder). The polar code construction has been extended in a number of ways including non-binary alphabets as well as asymmetric channels, source coding problems, and various multi-user scenarios. The original construction of polar codes depends on the communication channel for the transmission. At the same time, it is often desirable to have a coding scheme that attains capacity of channels irrespective of the structure of the transition probabilities. This feature, termed universal coding, has been recently studied in several works. One line of research was started in the works by Korada [2] who proved that polar codes constructed for a given communication channel V can support reliable transmission with SC decoding over a channel W that is a stochastically degraded version of V . Sutter and Renes [3] extended this result to channels that are “less noisy” with respect to the original channel. Similar results for universal source polarization were obtained earlier by Abbe [4]. These works assume that the receiver has full knowledge of the channel/source statistics. In a recent work Alsan [5] considered conditions for reliable communication with polar codes when both the encoder and decoder are designed for a channel different from the actual communication channel (“mismatched decoding”). Another line of works is concerned with the classical deﬁnition of universal coding, aiming to achieve compound capacity of a set of channels using modiﬁed polar codes. Along these lines, Hassani and Urbanke showed [6] that polar codes under SC decoding cannot achieve the compound capacity of a set of binary-input output-symmetric channels. In a later work [7] they proposed several modiﬁcations of the original polar coding scheme that achieve the compound capacity at the cost of increasing the decoding delay. A ∗Research supported in part by NSF grants CCF1217245 and CCF1217894. similar result was also established by S¸as¸o˘glu and Wang [8] (see also Mahdavifar et al. [9]). In this paper we address the universality problem for source coding with side information using polar codes, and use this scheme to attain the region of achievable rates in a joint source-channel coding problem proposed by Tuncel in [10]. The formal deﬁnition of the universal source coding problem with side information is given in Section II, where we also present our coding scheme. The scheme itself forms a modiﬁcation of the “chaining” idea from [7], adapted for the source coding problem. The block length optimization problem is analyzed in Sect. III. The second main result of this work relates to a joint source-channel coding problem over a broadcast channel. In Sect. V we design a polarcodes-based compression scheme to construct rate-optimal codes for this problem. As a preliminary result, in Section IV we analyze a generalized universal compression problem in which the decoders',\n",
       " '1704.02079': 'Locally repairable codes (LRCs) with unequal or multiple localities have been introduced by [1] and [2], where localities are different among symbols. This can be beneﬁcial in the scenarios where hot data symbols require faster repair or reduced download latency [1]. Both the results of [1] and [2] rely on their own restrictive conditions. In particular, [1] assumes the knowledge of the locality proﬁle instead of the conventional locality, i.e., the locality requirement. On the other hand, [2] assumes disjointness of local repair groups of different locality. It is natural to consider the extension of the r-locality to the (r, δ)-locality. This has been done in [3] by the authors in the locality proﬁle setting of [1]. Similarly, [4] extends the result of [2]. In this paper, we apply the techniques used in [3] to the problem setting of [4], and obtain some improved and additional results. The rest of the paper is organized as follows. In Section II, we review some important preliminaries. The problem setting of unequal and disjoint (r, δ)-localities is deﬁned in Section III. Section IV presents both the dimension and minimum distance upper bounds, and their tightness is shown by optimal code constructions in Section V. The concluding remarks are given in Section VI. II. PRELIMINARIES A. Notation We use the following notation. 1) For an integer i, [i] = {1, . . ., i}. 2) A vector of length n is denoted by v = (v1, . . . , vn). 3) A matrix of size k × n is denoted by G = (gi,j)i∈[k],j∈[n]. The authors are with the Institute of New Media and Communications, Department of Electrical and Computer Engineering, Seoul National University, Seoul, 08826, Korea (e-mail: bdkim@wspl.snu.ac.kr; junglee@snu.ac.kr). November 27, 2024 DRAFT  2 4) For sets A and B, A ⊔B denotes the disjoint union, i.e., A ∪B with further implication that A ∩B = ∅. 5) For a symbol index set T ⊂[n] of a code C of length n, C |T denotes the punctured code with support T , and G|T is the corresponding generator matrix. Furthermore, we deﬁne rankG(T ) = rank(G|T ). 6) For a symbol index set T ⊂[n] of a linear [n, k] code C constructed via polynomial evaluation on an extension ﬁeld Fqt, rankE(T ) denotes the rank of the evaluation points corresponding to C |T over the base ﬁeld Fq. B. Minimum Distance The minimum distance of linear codes is well known to be characterized by the following lemma [5, Lem. A.1], which is the basis of our minimum distance bounds. Lemma 1. For a symbol index set T ⊂[n] of a linear [n, k, d] code such that rankG(T ) ≤k −1, we have d ≤n −|T |, with equality if and only if T is of largest cardinality such that rankG(T ) = k −1. Below, we state a lemma (see also [6]) based on Lemma 1 that turns out to be more useful. Note that this',\n",
       " '1711.07956': 'This paper deals with generalizations of certain concepts from elementary signals and systems analysis, which we ﬁrst review. 1.1. Spectral analysis of linear, time-invariant systems. Linear, time-invariant (LTI) systems are ubiquitous in signal processing and control theory, and it is well known that the output of a continuous-time (CT) LTI system with input signal x(t) can be computed using the convolution integral y(t) = (x ∗h)(t) = Z ∞ τ=−∞ h(t −τ)x(τ) d τ, (1) where h(t) ∈L2(R) is the impulse response of the system. Such a system can equivalently be viewed as a linear operator H : L2(R) →L∞(R), where H(x)(t) = Z ∞ τ=−∞ h(t −τ)x(τ) d τ. (2) Because this linear operator involves a kernel function h(t −τ) that depends only on the diﬀerence t−τ, we refer to it as a Toeplitz operator.1 In this setting, the behavior of the Toeplitz operator can be naturally understood in the frequency domain: for an input signal x(t) with continuous-time Fourier transform (CTFT) bx(F) = Z ∞ t=−∞ x(t)e−j2πF t d t, ∀F ∈R, (3) 2010 Mathematics Subject Classiﬁcation. 47B35, 47N70, 94A12. Key words and phrases. Toeptliz operators, time-frequency analysis, subspace approximation, eigenvalue distribution. 1Our notion of Toeplitz operators follows from the deﬁnition of Toeplitz operators in [24, Section 7.2]. 1  the CTFT of the output signal y(t) will satisfy by(F) = bx(F)bh(F), where bh(F) denotes the CTFT of the impulse response h(t) and is also known as the frequency response of the system. The spectrum of the Toeplitz operator H also coincides with bh(F) [24, Section 7.2]. Note that the spectrum of a linear operator H, a generalization of the set of eigenvalues of a matrix, is the set of complex numbers λ such that H −λI (where I denotes the identity operator) is not invertible. Similar facts hold for discrete-time (DT) LTI systems, where the response to an input signal x[n] is given by the convolution y[n] = ∞ X m=−∞ h[n −m]x[m], (4) where h[n] ∈ℓ2(Z) is the impulse response of the DT system. Such a system can equivalently be viewed as a linear operator H : ℓ2(Z) →ℓ2(Z), which corresponds to multiplication of the input signal x ∈ℓ2(Z) by the bi-inﬁnite Toeplitz matrix H = \\uf8ee \\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8f0 ... ... ... ... ... ... h[0] h[−1] h[−2] ... ... h[1] h[0] h[−1] ... ... h[2] h[1] h[0] ... ... ... ... ... ... \\uf8f9 \\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fb . (5) We note that H[m, n] = h[m −n] for all m, n ∈Z. The behavior of this system can also be interpreted as multiplication in the discrete-time Fourier transform (DTFT) domain where the DTFT of the impulse response h[n] is deﬁned as: bh(f) = ∞ X n=−∞ h[n]e−j2πfn. (6) The spectrum of H also coincides with bh(f) [24]. 1.2. The eﬀects of time-limiting. Practical systems',\n",
       " '1811.03862': 'Multi-objective optimization (MOO) aims at minimizing m objectives simultaneously: min x∈X⊂Rd(f1(x), . . . , fm(x)). As these objectives are generally competing, the optimal trade-oﬀsolutions known as the Pareto optimal set PX are sought. These solutions are non-dominated: it is not possible to improve one objective without worsening another; ∀x∗∈PX , ∄z ∈X such that f(z) ≺f(x∗) where “≺” stands for Pareto domination. The image of PX in the objective space is called the Pareto front, PY = {f(x), x ∈PX }. The Ideal and the Nadir points bound the Pareto front and are deﬁned respectively as I = ( min y∈PYy1, . . . , min y∈PYym) and N = (max y∈PYy1, . . . , max y∈PYym). More theory and concepts in multi-objective optimization can be found in [41, 34]. This is the author’s version of the work. It is posted here for your personal use. Not for redistribution. The deﬁnitive Version of Record was published in Annals of Mathematics and Artiﬁcial Intelligence, volume 88, pp. 187-212 (2020), https://doi.org/10.1007/s10472-019-09644-8. 1 arXiv:1811.03862v5  [stat.ML]  19 Feb 2020  MOO algorithms aim at constructing the best approximation to PY, called the empirical Pareto front (or approximation front) c PY which is made of non-dominated observations. The construction is of course iterative. The contribution of the sampled points is measured by diﬀerent criteria, the ones based on the dominated hypervolume being state-of-the-art when searching for the entire Pareto front [53, 39, 5]. At the end of the search, c PY is delivered to a Decision Maker (DM) who will choose a solution. However, when dealing with expensive computer codes, only a few designs x can be evaluated. In Bayesian optimization, a surrogate for each objective, Yj(·), is ﬁrst ﬁtted to an initial Design of Experiments (DoE) evaluated at n locations, Dn j := {(x(1), fj(x(1))), . . . , (x(n), fj(x(n)))}, using Gaussian Processes (GP) [28]. Classically, to contain the computational complexity, the metamodels Yj(·) are assumed to be independent. In [43] dependent GPs have been considered without noticing signiﬁcant beneﬁts. Information given by Y(·) := (Y1(·), . . . , Ym(·))⊤is used to sequentially evaluate new promising inputs with the aim of reaching the Pareto front [31, 30, 14, 39, 44, 38]. It is now established, e.g. in [38], that the algorithms with embedded metamodels such as GPs call much more sparingly the objective functions than Multiobjective Evolutionary Algorithms without models do (typically NSGA-II, [12]). As the Pareto set takes up a large part of the design space when many objectives are considered, it may be impossible to compute an accurate approximation to it within the restricted computational budget. Moreover, it may be irrelevant to provide the whole Pareto set because it contains many uninteresting solutions from the DM’s point of view. In the current article, in addition to the GPs, we make use of an aspiration point [48]. This aspiration point can be implicitly deﬁned',\n",
       " '1809.10243': 'S KIN lesion analysis through image processing and machine learning techniques has attracted a lot of attention in the last decades [1]. With the advent of deep convolutional neural networks (CNNs) and different scientiﬁc competitions on this topic in the recent years [2], [3], numerous powerful computational methods have been emerged to solve different problems in this area. In general, the ﬁnal goal of using computer aided diagnosis (CAD) systems for skin lesion analysis is to automatically detect any abnormalities or skin diseases. The methods in the literature usually follow a certain analysis pipeline [4]: ﬁrst, lesion area in the image is detected (segmentation task) which secondly helps other computerized algorithms to extract discriminative feature (feature extraction M. Jahanifar and N. Zamani Tajeddin were with the Department of Biomedical Engineering, Tarbiat Modares University. M. Jahanifar is now with the Department of Research and Development, NRP company, Tehran, Iran (e-mails: {m.jahanifar,n.zamanitajeddin}@modares.ac.ir). N. Alemi Koohbanani and N. Rajpoot are with the Tissue Image Analytics (TIA) Lab at the Department of Computer Science, University of Warwick, UK (emails: {n.alemi-koohbanani,N.M.Rajpoot}@warwick.ac.uk). Ali Gooya is with the Department of Electronic and Electrical Engineering, University of Shefﬁeld, Shefﬁeld, England (e-mail: a.gooya@shefﬁeld.ac.uk) *These authors contributed equally to this work task) from the lesion, to ﬁnally decide about the type of skin lesions (classiﬁcation task). In this framework, precise segmentation of lesion boundary is a critical task which can lead to representative features to differentiate between normal and malignant lesions. Lesions attributes, also known as dermoscopic structures, are meaningful visual patterns in the skin lesion texture. Each of them represents a speciﬁc diagnostic symptom, and based on the lesion type and malignancy severity their appearance may change [5]. Some lesions may not contain any speciﬁc dermoscopic pattern while some may include textural pattern related to several attributes. There are different types of attributes deﬁned in dermatology. Five of the most clinically interesting attributes are pigment networks, globules/dot, Milia like cysts, negative networks, and streaks. In clinical practices, apart from the general and local appearance characteristics of the lesion, dermatologists look for these attributes to better decide about the lesion type and its malignancy level. Hence, CAD systems can also beneﬁt from the useful information that attributes deliver, to achieve a better automatic recognition performance. Although modern CNNs are able to extract relevant features from the raw dermoscopic images and classify them without the need of lesions or their attributes segmentation map [6], it has been shown that incorporating additional information can signiﬁcantly improve lesion classiﬁcation task [7], [8]. Yu et al. [7] showed that incorporating lesion mask can elevate lesion classiﬁcation and they achieved 1st rank in the ISIC2016: Melanoma Recognition challenge. Moreover, Gonzalez Diaz [8] proposed a lesion classiﬁcation framework that incorporates both lesion segmentation and attributes probability maps which was able to achieve state-of-the-art results using only one single model by',\n",
       " '1801.07243': 'Despite much recent success in natural language processing and dialogue research, communication between a human and a machine is still in its infancy. It is only recently that neural models have had sufﬁcient capacity and access to sufﬁciently large datasets that they appear to generate meaningful responses in a chit-chat setting. Still, conversing with such generic chit-chat models for even a short amount of time quickly exposes their weaknesses (Serban et al., 2016; Vinyals and Le, 2015). Common issues with chit-chat models include: (i) the lack of a consistent personality (Li et al., 2016a) as they are typically trained over many dialogs each with different speakers, (ii) the lack of an explicit long-term memory as they are typically trained to produce an utterance given only the recent dialogue history (Vinyals and Le, 2015); 1Work done while at Facebook AI Research. and (iii) a tendency to produce non-speciﬁc answers like “I don’t know” (Li et al., 2015). Those three problems combine to produce an unsatisfying overall experience for a human to engage with. We believe some of those problems are due to there being no good publicly available dataset for general chit-chat. Because of the low quality of current conversational models, and because of the difﬁculty in evaluating these models, chit-chat is often ignored as an end-application. Instead, the research community has focused on taskoriented communication, such as airline or restaurant booking (Bordes et al., 2016), or else singleturn information seeking, i.e. question answering (Rajpurkar et al., 2016). Despite the success of the latter, simpler, domain, it is well-known that a large quantity of human dialogue centers on socialization, personal interests and chit-chat (Dunbar et al., 1997). For example, less than 5% of posts on Twitter are questions, whereas around 80% are about personal emotional state, thoughts or activities, authored by so called “Meformers” (Naaman et al., 2010). In this work we make a step towards more engaging chit-chat dialogue agents by endowing them with a conﬁgurable, but persistent persona, encoded by multiple sentences of textual description, termed a proﬁle. This proﬁle can be stored in a memory-augmented neural network and then used to produce more personal, speciﬁc, consistent and engaging responses than a persona-free model, thus alleviating some of the common issues in chit-chat models. Using the same mechanism, any existing information about the persona of the dialogue partner can also be used in the same way. Our models are thus trained to both ask and answer questions about personal topics, and the resulting dialogue can be used to build a model of the persona of the speaking partner.  To support the training of such models, we present the PERSONA-CHAT dataset, a new dialogue dataset consisting of 162,064 utterances between crowdworkers who were randomly paired a',\n",
       " '1708.09401': 'FAILED',\n",
       " '1510.04455': 'There have been many attempts to quantify interactions between elements in a stochastic system. Information theory has played a pivotal role in this goal, leading to various measures of interactions such as multiinformation [1–3], transfer entropy [4], stochastic interaction [5, 6], and integrated information [7, 8]. In this study, we propose a uniﬁed theoretical framework for quantifying spatio-temporal interactions in a stochastic dynamical system based on information geometry [9], which is useful for elucidating various measures and their relations. In particular, we focus on the concept of integrated information and its related measures [5, 6, 10]. Utilizing the uniﬁed framework, we propose a novel measure of integrated information, called ‘geometric integrated information’ ΦG. The concept of integrated information was proposed by Tononi in Integrated Information Theory (IIT) [7, 8, 11]. Integrated information is designed for measuring the degree of causal interactions between parts of a system and the amount of information integrated in a system. IIT postulates that levels of consciousness correspond to the amount of integrated information in a system [7], and this has been supported by experiments conducted in various types of loss of consciousness [12–15]. Consider a joint probability distribution p(X, Y ) of the past states X and the present states Y of a system, where information about X is integrated and transmitted to Y . Further, consider another probability distribution q(X, Y ), whose degree of freedom is constrained in terms of the way information is transmitted from X to Y . More precisely, in q(X, Y ), some elements of X are disconnected from other elements of Y , prohibiting informaFIG. 1. Information geometric picture for minimizing the KL divergence between the full model p(X, Y ) and disconnected model q(X, Y ). tion transmission over the branches that connect them. We call the former p(X, Y ) a ‘full model’ and the latter q(X, Y ) a ‘disconnected model’. We propose to quantify the degree of interactions using the Kullback-Leibler (KL) divergence from the full to the disconnected model based on information geometry. A set of the disconnected model form a submanifold, MD, inside the entire manifold of the full model, MF . Given p(X, Y ), we search for the closest point q∗(X, Y ) to p(X, Y ) within the submanifold MD (Fig. 1). The closest point is the minimizer of the KL divergence between p(X, Y ) and q(X, Y ) and is found by projecting p(X, Y ) to the submanifold. The minimized KL divergence can then be interpreted as ‘information loss’ caused by disconnections of information transmission branches. This framework provides uniﬁed interpretations of var2 ious measures of interactions (Fig. 2) and oﬀers a way to quantify these measures in a hierarchical manner which clariﬁes the relationships between them. We show that mutual information between X and Y corresponds to information loss when all the time-lagged interactions between',\n",
       " '1811.10315': 'The problem of analytical calculations of characteristics for a given information channel is of great importance in the information theory due to the practically signiﬁcant applications of optical ﬁbers. These characteristics are as follows: the conditional probability density function (P[Y |X]), i.e., the probability to detect the output signal Y (t) if the transmitted input signal is X(t); the distribution of the output signal (Pout[Y ]); the distribution of the recovered input signal, the output (H[Y ]) and conditional (H[Y |X]) entropies, the mutual information (IPX = H[Y ] −H[Y |X]); the optimal input signal distribution; the channel capacity (C = maxPX[X] IPX[X]) and others. In our work we consider the problem of the signal propagation in a noisy information channel where the propagation is governed by the stochastic nonlinear Schr¨odinger equation (NLSE) with the additive white Gaussian noise for the case of small dispersion and the large signal-to-noise power ratio (SNR). We consider the complex signal ψ(z, t) which is related with the electric ﬁeld in the optical ﬁber as ⃗E(z, t) ∝⃗e0Re n ψ(z, t + z vg )eik0z−iω0to with ω0 = ω(k0) and vg = dω dk (k0) being the carrier frequency and the group velocity, correspondingly. The propagation of the signal ψ(z, t) is described by the NLSE with the additive white Gaussian noise, see [1, 2, 3, 4]: ∂zψ(z, t) + iβ∂2 t ψ(z, t) −iγ|ψ(z, t)|2ψ(z, t) = η(z, t) , (1)  here β is the second dispersion coeﬃcient, γ is the Kerr nonlinearity coeﬃcient, η(z, t) is the additive complex white noise with zero mean ⟨η(z, t)⟩η = 0 and correlation function ⟨η(z, t)¯η(z′, t′)⟩η = Qδ(z −z′)δ(t −t′) , (2) where bar means complex conjugation, Q is a power of the white Gaussian noise per unit length and per unit frequency interval. The input condition for the signal ψ(z, t) is ψ(z = 0, t) = X(t) and the output one is ψ(z = L, t) = Y (t), where Y (t) is determined both the input condition and the noise impact in Eq. (1). The frequency bandwidth W ′ of the noise η(z, t) is assumed to be much greater than the frequency bandwidth W of the input signal X(t): W ′ ≫W. There are diﬀerent approaches to analyze Eq. (1) and to ﬁnd informational channel characteristics, primarly, the conditional probability density function P[Y |X] that is one of the most important characteristics. The ﬁeld theory approach is based on the path-integral formulation of the quantity P[Y |X] [5, 6]. We have performed some estimations for the channel with the small dispersion parameter via this approach [7]. Now we proceed the small dispersion analysis of the Eq. (1) by exploiting the stochastic approximation of the noisy equation (1) within the detector averaging procedure. Firstly, we perform the linearization of the Eq. (1) using the fact',\n",
       " '1310.2632': 'In this work, we present a new algorithmic framework for the following generalized bilinear inference problem: estimate the matrices A=[amn]∈RM×N and X =[xnl]∈RN×L from a matrix observation Y ∈RM×L that is statistically coupled to their product, Z ≜AX. In doing so, we treat A and X as realizations of random matrices A and X with known separable pdfs (or pmfs in the case of discrete models), i.e., pA(A) = Y m Y n pamn(amn) (1) pX(X) = Y n Y l pxnl(xnl), (2) J. Parker is with the Sensors Directorate, Air Force Research Laboratory, Dayton, OH 45433, USA e-mail: jason.parker.13@us.af.mil. His work on this project has been supported by AFOSR Lab Task 11RY02COR. P. Schniter is with the Dept. ECE, The Ohio State University, 2015 Neil Ave., Columbus OH 43210, e-mail: schniter@ece.osu.edu, phone 614.247.6488, fax 614.292.7596. His work on this project has been supported by NSF grants IIP-0968910, CCF-1018368, CCF-1218754, and by DARPA/ONR grant N66001-10-1-4090. V. Cevher is with ´Ecole Polytechnique F´ed´erale de Lausanne. Email: volkan.cevher@epﬂ.ch. His work is supported in part by the European Commission under the grants MIRG-268398 and ERC Future Proof, and by the Swiss Science Foundation under the grants SNF 200021-132548, SNF 200021-146750 and SNF CRSII2-147633. Portions of this work were presented at the 2011 Workshop on Signal Processing with Adaptive Sparse Structured Representations [1], the 2012 Information Theory and Applications Workshop [2], and at the 2012 Asilomar Conference on Signals, Systems, and Computers [3]. and we likewise assume that the likelihood function of Z is known and separable, i.e., pY|Z(Y | Z) = Y m Y l pyml|zml(yml | zml). (3) Recently, various special cases of this problem have gained the intense interest of the research community, e.g., 1) Matrix Completion: In this problem, one observes a few (possibly noise-corrupted) entries of a low-rank matrix and the goal is to infer the missing entries. In our framework, Z = AX would represent the complete low-rank matrix (with tall A and wide X) and pyml|zml the observation mechanism, which would be (partially) informative about zml at the observed entries (m, l) ∈Ω and non-informative at the missing entries (m, l) /∈Ω. 2) Robust PCA: Here, the objective is to recover a lowrank matrix (or its principal components) observed in the presence of noise and sparse outliers. In our framework, Z = AX could again represent the low-rank matrix, and pyml|zml the noise-and-outlier-corrupted observation mechanism. Alternatively, X could also capture the outliers, as described in the sequel. 3) Dictionary Learning: Here, the objective is to learn a dictionary A for which there exists a sparse data representation X such that AX closely matches the observed data Y . In our framework, {pxnl} would be chosen to',\n",
       " '1810.09202': 'Cooperation is a widespread phenomenon in nature from viruses, bacteria, and social amoebae to insect societies, social animals, and humans (Melis & Semmann, 2010). Human exceeds all other species in terms of range and scale of cooperation. The development of human cooperation is facilitated by the underlying graph of human societies (Ohtsuki et al., 2006; Apicella et al., 2012), where the mutual interplay between humans is abstracted by their relations. It is crucially important to enable agents to learn to cooperate in multi-agent environments for many applications, e.g., autonomous driving (Shalev-Shwartz et al., 2016), trafﬁc light control (Wiering, 2000), smart grid control (Yang et al., 2018a), and multi-robot control (Matignon et al., 2012). Multiagent reinforcement learning (MARL) facilitated by communication (Sukhbaatar et al., 2016; Peng et al., 2017; Jiang & Lu, 2018), mean ﬁeld theory (Yang et al., 2018b), and causal inﬂuence (Jaques et al., 2019) have been exploited for multi-agent cooperation. However, communication among all agents (Sukhbaatar et al., 2016; Peng et al., 2017) makes it hard to extract valuable information for cooperation, while communication with only nearby agents (Jiang & Lu, 2018) may restrain the range of cooperation. MeanField (Yang et al., 2018b) captures the interplay of agents by mean action, but the mean action eliminates the difference among agents and thus incurs the loss of important information that could help cooperation. Causal inﬂuence (Jaques et al., 2019) is a measure of action inﬂuence, which is the policy change of an agent in the presence of an action of another agent. However, causal inﬂuence is not directly related to the reward of the environment and thus may not encourage cooperation. Unlike existing work, we consider the underlying graph of agents, which could potentially help understand agents’ mutual interplay and promote their cooperation as it does in human cooperation (Ohtsuki et al., 2006; Apicella et al., 2012). In this paper, we propose graph convolutional reinforcement learning, where the multi-agent environment is modeled as a graph. Each agent is a node, the encoding of local observation of agent is the feature of node, and there is an edge between a node and its each neighbor. We apply convolution to the graph of agents. By employing multi-head attention (Vaswani et al., 2017) as the convolution kernel, graph convolution is able to extract the relation representation between nodes and convolve the features from neighboring nodes just like a neuron in a convolutional neural network (CNN). Latent features extracted from gradually increased receptive ﬁelds are exploited to learn cooperative policies. Moreover, the relation representation is temporally regularized to help the agent develop consistent cooperative policy. ∗Work done at Peking University. †Correspondence to Zongqing Lu <zongqing.lu@pku.edu.cn>. 1 arXiv:1810.09202v5  [cs.LG]  11 Feb 2020  Published as a conference paper at ICLR 2020 Graph convolutional reinforcement learning, namely DGN, is instantiated based on deep Q network and trained end-to-end. DGN shares weights among all agents, making it easy to scale',\n",
       " '1405.0947': 'Distributed representations have become an increasingly important tool in machine learning. Such representations—typically continuous vectors learned in an unsupervised setting—can frequently be used in place of hand-crafted, and thus expensive, features. By providing a richer representation than what can be encoded in discrete settings, distributed representations have been successfully used in many areas. This includes AI and reinforcement learning (Mnih et al., 2013), image retrieval (Kiros et al., 2013), language modelling (Bengio et al., 2003), sentiment analysis (Socher et al., 2011; Hermann and Blunsom, 2013), framesemantic parsing (Hermann et al., 2014), and document classiﬁcation (Klementiev et al., 2012). In Natural Language Processing (NLP), the use of distributed representations is motivated by the idea that they could capture semantics and/or syntax, as well as encoding a continuous notion of similarity, thereby enabling information sharing between similar words and other units. The success of distributed approaches to a number of tasks, such as listed above, supports this notion and its implied beneﬁts (see also Turian et al. (2010) and Collobert and Weston (2008)). While most work employing distributed representations has focused on monolingual tasks, multilingual representations would also be useful for several NLP-related tasks. Such problems include document classiﬁcation, machine translation, and cross-lingual information retrieval, where multilingual data is frequently the norm. Furthermore, learning multilingual representations can also be useful for cross-lingual information transfer, that is exploiting resource-fortunate languages to generate supervised data in resource-poor ones. We propose a probabilistic model that simultaneously learns word alignments and bilingual distributed word representations. As opposed to previous work in this ﬁeld, which has relied on hard alignments or bilingual lexica (Klementiev et al., 2012; Mikolov et al., 2013), we marginalize out the alignments, thus capturing more bilingual semantic context. Further, this results in our distributed word alignment (DWA) model being the ﬁrst probabilistic account of bilingual word representations. This is desirable as it allows better reasoning about the derived representations and furthermore, makes the model suitable for inclusion in higher-level tasks such as machine translation. The contributions of this paper are as follows. We present a new probabilistic similarity measure which is based on an alignment model and prior language modeling work which learns and relates word representations across languages. Subsequently, we apply these embeddings to a standard document classiﬁcation task and show that they outperform the current published state of the art (Hermann and Blunsom, 2014b). As a by-product we develop a distributed version of FASTALIGN (Dyer et al., 2013), which performs on par with the original model, thereby demonstrating the efﬁcacy of the learned bilingual representations. 2 Background The IBM alignment models, introduced by Brown et al. (1993), form the basis of most statistical machine translation systems. In this paper we base our alignment model on FASTALIGN (FA), a variarXiv:1405.0947v1  [cs.CL]  5 May',\n",
       " '1607.03025': 'W ITH their increased popularity and their abundance in radio access networks, smartphones are becoming active parts of the system. While traditional cell phones were considered as mere terminals by the service providers, the increased computation power and storage capacity of smartphones are turning them into active components of the network. For example, to support a massive number of devices and further reduce latency, the notion of device-to-device (D2D) [1] communication has been proposed as a potential candidate for the next generation mobile radio system (5G) [2]. Similarly, multiple works investigate the use of smartphones are potential relays in the network. Lately, the notion of fog computing [3], [4] emerged as a new paradigm in radio access network in which not only the communication and computing resources of the mobile devices are exploited but also their storage capacity. Such paradigm shift allows not only to save the data center resources but also to have fast access to the ﬁles and thus to meet the ever increasing data rates and the Quality of Service (QoS) requirements [5]. As for all new notions, the deﬁnition of fog networking and computing is still ambiguous and does not make consensus in the literature, e.g., [6]–[8]. This paper Ahmed Douik is with the Department of Electrical Engineering, California Institute of Technology, Pasadena, CA 91125 USA (e-mail: ahmed.douik@caltech.edu). Sameh Sorour is with the Department of Electrical and Computer Engineering, University of Idaho, Moscow, ID 83844, USA (e-mail: samehsorour@uidaho.edu). considers fog computing from the storage perspective in which the cloud data centers disseminate ﬁles in the network for faster access. By exploiting the computation abilities of the intermittent nodes in the network, Network Coding (NC) has shown remarkable abilities in signiﬁcantly improving the network capacity and reducing the delay of wireless broadcast conﬁgurations [9]. For D2D systems in which devices exchange packets over a short range and possibly more reliable channels, NC is a suitable complementary solution [10] to provide reliable and secure data communications over ad-hoc networks such that Internet of Things (IoT) and wireless sensor networks. While random NC schemes require computationally expensive matrix inversion, Instantly Decodable Network Coding (IDNC) [11] is an important subclass of NC that is suitable for battery-powered D2D communications. IDNC provides an incredibly fast, or as it name indicates instantly, encoding and decoding through simple binary XOR operations which are particularly well adapted for the network of interest in this paper wherein devices are highly limited in terms of computation complexity. Besides, IDNC provides progressive decoding which is a fundamental feature that makes ﬁles ready-to-use from their reception instant. For its aforementioned beneﬁts, IDNC is employed in various settings [11]–[17]. Consider a D2D fog-radio access network (F-RAN) wherein a set of devices are required to store a set of ﬁles. Each device is connected to a subset of the cloud data centers and thus possesses a subset',\n",
       " '1901.00828': 'In some Internet of Things applications, it is envisaged that a very large number of objects send sporadic data via a wireless channel to a central collector. Such objects may be sensingenabled appliances, that are mass-produced and disseminated into the environment without any speciﬁc centralized control. For massive scalability and production costs reasons, the transmission protocol (including signaling and channel coding) shall be hard-wired and identical to all devices. This poses a new random access problem known as “unsourced massive random access”, where the goal of the receiver (data collector) consists of decoding the messages transmitted by a small number of active nodes on each transmission slot, whose identity is not known a priori, and such that these nodes make use of exactly the same channel codebook (or, more in general, the same transmission protocol). In this context, if senders want to identify themselves, they can include their ID into the information message itself. Therefore, the goal of the receiver is to decode the list of active user messages up to permutations. This new information theoretic problem has been posed by Polyanskiy in [1]. In Polyanskiy’s formulation, the number of users is comparable to the channel block length (e.g., imagine a city-wide IoT network with ∼106 sensors, each of which sends sporadic data using a codebook of block length ∼104). In this regime, under the classical notion of probability of error used in the information theoretic multiple access channel [3], no reliable communication is possible. Hence, Polyanskiy proposes the Per-User Probability of Error (PUPE), i.e., the average fraction of mis-decoded messages over the number of active users, as a more practically meaningful performance metric. In [1] the channel is modeled as a real adder with additive white Gaussian noise (AWGN), where the discretetime baseband signal received at the decoder is given by yt = X k∈Ka xt(mk) + zt, t = 1, . . . , n, (1) where Ka is the set of |Ka| = Ka active users in a population Ktot of |Ktot| = Ktot total users, xt(m) is the t-th symbol of the m-th codeword of a common codebook C ⊂Rn of cardinality 2nR, mk ∈[1 : 2nR] is the message transmitted by active user k ∈Ka, and zi ∼N(0, N0/2) is the real AWGN. For this channel, [1] established quite tight achievability and converse bounds to the minimum energy per bit over N0 (Eb/N0) necessary for reliable communication. The sporadic communication patterns and the very large number of potential users Ktot rule out most of the current network solutions, which are essentially “grant-based” random access. In such schemes, when a user wishes to send a data packet, it must ﬁrst access a dedicated Random Access Control Channel (RACCH), identify itself, and ask for a transmission resource. After being granted access, the user sends its message on the allocated dedicated resource (e.g., a combination of time-frequency slot and space beam, in modern MIMO-enabled space',\n",
       " '1801.00708': 'A UTONOMOUS vehicles need to perceive and understand their surroundings (such as road users, free space, and other road scene semantics) for decision making, path planning, etc. Since Nissan introduced the surround view camera system in 2007 on the Inﬁniti EX35, many Tier1s and OEMs are actively developing such technology. Besides Inﬁniti and Nissan, automakers such as BMW, Audi, Mercedes Benz, Lexus, and Toyota offer similar systems in their production vehicles. The system usually consists of four ﬁsheye cameras mounted around the vehicle to provide 360-degree surroundings, which helps eliminate all blind spots during critical and Manuscript received December 17, 2017; revised October 9, 2018, March 10, 2019, and July 18, 2019; accepted August 28, 2019. This work was supported in part by the National Natural Science Foundation of China under Grant U1764264 and Grant 61873165, in part by the Shanghai Automotive Industry Science and Technology Development Foundation under Grant 1733 and Grant 1807, and in part by the International Chair on Automated Driving of Ground Vehicle. The Associate Editor for this article was D. FernandezLlorca. (Corresponding author: Ming Yang.) L. Deng, M. Yang, T. Li, B. Hu, and C. Wang are with the Department of Automation, Shanghai Jiao Tong University, Shanghai, 200240, and also with the Key Laboratory of System Control and Information Processing, Ministry of Education of China, Shanghai, 200240, China (phone: +86-21-34204553; e-mail: mingyang@sjtu.edu.cn). H. Li is with SJTU-ParisTech Elite Institute of Technology and also with Department of Automation, Shanghai Jiao Tong University, Shanghai, 200240, China. Digital Object Identiﬁer 10.1109/TITS.2019.2939832 (a) Raw ﬁsheye image (b) Undistorted image Fig. 1. Illustration of image undistortion. The center of the undistorted image is clear, but the boundaries of the image are very blurred. And some information is lost during transferring the pixels of the raw ﬁsheye image into the undistorted image. Fig. 2. Illustration of CNN based semantic segmentation on raw surround view images. Surround view cameras consist of four ﬁsheye cameras mounted on each side of the vehicle. Cameras in different directions capture images with different image composition. precise maneuvers. Based on the surround view cameras, this paper explores the 360-degree road scene understanding. Thanks to the methodology of Convolutional Neural Network (CNN) based semantic segmentation, in recent years, road scene understanding has achieved huge progress using narrow-angle or even wide-angle conventional cameras [1]. Conventional cameras follow well the pinhole camera model: all straight lines in the real world are projected as straight lines in the image. However, images captured by ﬁsheye cameras have strong distortions. As distortions bring difﬁculties in image processing, ﬁsheye images are usually undistorted before use [2], [3]. However, image undistortion hurts image quality (especially at image boundaries) [4] and leads to information loss. An example of image undistortion is shown in Fig. 1. We consider that the segmented results on raw ﬁsheye images can be used as an information source for other tasks. For',\n",
       " '1703.00377': 'Boosting (Freund and Schapire, 1995) is a popular method that leverages simple learning models (e.g., decision stumps) to generate powerful learners. Boosting has been used to great eﬀect and trump other learning algorithms in a variety of applications. In computer vision, boosting was made popular by the seminal ViolaJones Cascade (Viola and Jones, 2001) and is still used Proceedings of the 20th International Conference on Artiﬁcial Intelligence and Statistics (AISTATS) 2017, Fort Lauderdale, Florida, USA. JMLR: W&CP volume 54. Copyright 2017 by the author(s). to generate state-of-the-art results in pedestrian detection (Nam et al., 2014; Yang et al., 2015; Zhu and Peng, 2016). Boosting has also found success in domains ranging from document relevance ranking (Chapelle et al., 2011) and transportation (Zhang and Haghani, 2015) to medical inference (Atkinson et al., 2012). Finally, boosting yields an anytime property at test time, which allows it to work with varying computation budgets (Grubb and Bagnell, 2012) for use in real-time applications such as controls and robotics. The advent of large-scale data-sets has driven the need for adapting boosting from the traditional batch setting, where the optimization is done over the whole dataset, to the online setting where the weak learners (models) can be updated with streaming data. In fact, online boosting has received tremendous attention so far. For classiﬁcation, (Chen et al., 2012; Oza and Russell, 2001; Beygelzimer et al., 2015b) proposed online boosting algorithms along with theoretical justiﬁcations. Recent work by Beygelzimer et al. (2015a), addressed the regression task through the introduction of Online Gradient Boosting (OGB). We build upon on the developments in (Beygelzimer et al., 2015a) to devise a new set of algorithms presented below. In this work, we develop streaming boosting algorithms for regression with strong theoretical guarantees under stochastic setting, where at each round the data are i.i.d sampled from some unknown ﬁxed distribution. In particular, our algorithms are streaming extension to the classic gradient boosting (Friedman, 2001), where weak predictors are trained in a stage-wise fashion to approximate the functional gradient of the loss with respect to the previous ensemble prediction, a procedure that is shown by Mason et al. (2000) to be functional gradient descent of the loss in the space of predictors. Since the weak learners cannot match the gradients of the loss exactly, we measure the error of approximation by redeﬁning of edge of online weak learners (Beygelzimer et al., 2015b) for online regression setting. Assuming a non-trivial edge can be achieved by each deployed weak online learner, we develop algorithms to handle smooth or non-smooth loss functions, and theoarXiv:1703.00377v1  [cs.LG]  1 Mar 2017  Gradient Boosting on Stochastic Data Streams retically analyze the convergence rates of our streaming boosting algorithms. Our ﬁrst algorithm targets strongly convex and smooth loss functions and achieves exponential decay on the average regret with respect to',\n",
       " '1612.01189': 'The rapidly growing video-on-demand (VoD) streaming trafﬁc in cellular networks has created signiﬁcant challenges for cellular operators due to the scarce radio resources in the radio access network (RAN) and the limited capacity of the backhaul links [1]. To meet the stringent VoD streaming requirements in 5G cellular networks, wireless caching has been proposed in the literature [2]–[6]. In particular, caching has been exploited as a physical layer mechanism to facilitate trafﬁc ofﬂoading on the backhaul, capacity enhancement and latency reduction in the RAN, and energy savings in the network. Meanwhile, due to the broadcast nature of wireless transmission, VoD streaming data is vulnerable to potential eavesdroppers such as non-paying subscribers and malicious attackers. Secure video streaming schemes providing both video data protection and streaming quality of service (QoS) guarantee are thus preferred. Secure data delivery is not considered in cached-enabled transmission until recently [7]–[9]. The existing works [7]–[9] are motivated by the coded caching scheme proposed in [10]. Speciﬁcally, each user has a local cache to prestore parts of popular video content. By properly encoding (e.g. via network coding) the cached and the delivered contents, coded multicast delivery opportunities are enabled to achieve high delivery rates The work of D. W. K. Ng was supported by the Australian Research Council (ARC) Linkage Project LP 160100708. The work of R. Schober was supported by the Alexander von Humboldt Professorship Program. in serving various user requests [10]. In [7], a coded caching scheme is proposed to guarantee information delivery secrecy when eavesdroppers passively decipher the video data over the multicast link. For secrecy purpose, the cached and the delivered contents are encoded using random secret keys and secure coded multicast delivery is enabled based on Shannon’s one-time pad method. However, secure sharing of the secret keys can incur signiﬁcant system overheads because the size of the secret keys should be large enough to keep the video ﬁle secret from the eavesdroppers. The coded caching scheme is extended to deviceto-device (D2D) networks in [8], where a sophisticated key generation and encryption scheme is investigated. Moreover, a secure delivery scheme, which prevents the eavesdroppers from obtaining the number of coded packets required for successful video ﬁle recovery, was proposed for cache-enabled heterogeneous small cell networks in [9]. On the other hand, secure transmission has been thoroughly investigated for cellular networks. In particular, physical layer security (PLS) exploiting multi-input multi-output (MIMO) techniques has signiﬁcant advantages over one-time pad based methods [11]–[13]. For example, PLS techniques can opportunistically exploit the inherent randomness of wireless channels to enhance communication secrecy without using secret keys. In an Nt × Nr MIMO wiretap channel with full channel state information (CSI), information-theoretic studies have revealed that the secure degrees of freedom (s.d.o.f.)1 enabled by multiple antennas are given by min([Nt−Ne]+, Nr) [11], [12], where Ne is the number of eavesdropping',\n",
       " '1402.5836': 'FAILED',\n",
       " '1803.08910': 'Stance detection is one of the subproblems in sentiment analysis (opinion mining) [Pang and Lee 2008] and is a considerably recent research area. In stance detection, the position of an author of a piece of text is explored for a particular target (an entity, event, idea etc.) which may be explicitly stated in the text or not. The stance output is usually expected from the set: {Favor, Against, Neither} [Mohammad et al. 2016b] while in the sentiment analysis task, the output is usually one of Positive, Negative, or Neutral and usually no sentiment target is considered. In this paper, we present our SVM-based stance detection approaches on sports-related tweets1. The main contributions of this study are presented below: • Three diﬀerent versions of a tweet data set in Turkish annotated with stance information are presented. The corresponding annotations are made publicly available for research purposes. The second and third versions of the data set are described in the current paper for the ﬁrst time. They are the extended versions of a previously proposed data set [Küçük 2017b] and the extended versions have been annotated by two annotators as opposed to the initial version which was annotated by a single annotator. Additionally, the number of tweets in the ﬁnal version of the data set is more than 1.5 times the number of tweets in the initial version. The tweets in the data sets are about two popular football clubs which are, hence, the stance targets. To the best of our knowledge, 1A preliminary version of this paper has been presented in [Küçük 2017b]. The current study also includes our previous experiments published as a preprint in [Küçük 2017a]. Authors’ addresses: D. Küçük, Electrical Power Technologies Department, TÜBİTAK Energy Institute, Ankara, Turkey; F. Can, Bilkent Information Retrieval Group, Computer Engineering Department, Bilkent University, Ankara, Turkey. © 2018 Copyright held by the authors. 1  2 D. Küçük and F. Can the data sets are the ﬁrst stance-annotated resources for Turkish, two of which are annotated by two native speakers, and they constitute the ﬁrst sport-related stance-annotated resources in general. • We provide the results of our experiments based on SVM classiﬁers (one for each target) on the data set versions using features based on unigrams, bigrams, hashtags, external links, and emoticons. Named entities in tweets are also considered as features for stance classiﬁcation and the results of the related experiments are provided as well. These experiments form plausible baselines with which future work on stance detection can be compared. The rest of the paper is organized as follows: In Section 2, a review of the literature on stance detection is provided. In Section 3, we describe three diﬀerent versions of our tweet data set annotated with the stance target and stance information. Section 4 includes the details of our SVM-based stance classiﬁers and their evaluation results with discussions. Future research topics based on the current study are provided in Section 5. Finally, Section 6 concludes',\n",
       " 'cs/0008004': 'Grammatical relationships (GRs), which include arguments (e.g., subject and object) and modiﬁers, form an important level of natural language processing. GRs in the sentence Yesterday, my cat ate the food in the bowl. include ate having the subject my cat, the object the food and the time modiﬁer Yesterday, and the food having the location modiﬁer in (the bowl). However, diﬀerent sets of GRs are useful for diﬀerent purposes. For example, Ferro et al. (1999) is interested in semantic interpretation, and needs to diﬀerentiate between time, location and other modiﬁers. The SPARKLE project (Carroll et al., 1997), on the other hand, ∗This paper reports on work performed at the MITRE Corporation under the support of the MITRE Sponsored Research Program. Marc Vilain, Lynette Hirschman and Warren Greiﬀhave helped make this work happen. Christine Doran and John Henderson provided helpful editing. Copyright c⃝2000 The MITRE Corporation. All rights reserved. does not diﬀerentiate between these types of modiﬁers. As has been mentioned by John Carroll (personal communication), this is ﬁne for information retrieval. Also, having less diﬀerentiation of the modiﬁers can make it easier to ﬁnd them (Ferro et al., 1999). Unless the desired set of GRs matches the set already annotated in some large training corpus (e.g., the Buchholz et al. (1999) GR ﬁnder used the GRs annotated in the Penn Treebank (Marcus et al., 1993)), one will have to either manually write rules to ﬁnd the GRs or annotate a training corpus for the desired set. Manually writing rules is expensive, as is annotating a large corpus. We have performed experiments on learning to ﬁnd GRs with just a small annotated training set. Our starting point is the work described in Ferro et al. (1999), which used a fairly small training set. This paper reports on a comparison between the transformation-based error-driven learner described in Ferro et al. (1999) and the memory-based learner for GRs described in Buchholz et al. (1999) on ﬁnding GRs to verbs1 by retraining the memory-based learner with the data used in Ferro et al. (1999). We ﬁnd that the transformation versus memory-based diﬀerence only seems to cause a small diﬀerence in the results. Most of the result diﬀerences seem to instead be caused by diﬀerences in the representations and information used by the learners. An example is that diﬀerent GR length measures are used. In English, one measure seems better for recovering simple argument GRs, while another measure seems better for modiﬁer GRs. We also ﬁnd that partitioning the data sometimes helps memory-based learn1That is, GRs that have a verb as the relation target. For example, in Cats eat., there is a “subject” relation that has eat as the target and Cats as the source.  ing. 2 Diﬀerences Between the Two Systems Ferro et al. (1999) and Buchholz et al. (1999) both describe learning systems to ﬁnd GRs. The former (TR',\n",
       " '1710.04234': 'In the typical supervised regression setting, we are given set of learning examples, each associated with a real-valued output. The goal is to learn a predictor that accurately estimates the outputs, given new examples. This fundamental problem has been extensively studied and has given rise to algorithms such as Support Vector Regression (Basak et al., 2007). A similar, but far less studied, problem is that of interval regression, where each learning example is associated with an interval (yi, yi), indicating a range of acceptable output values, and the expected predictions are real numbers. Interval-valued outputs arise naturally in ﬁelds such as computational biology and survival analysis. In the latter setting, one is interested in predicting the time until some adverse event, such as death, occurs. The available information is often limited, giving rise to outputs that are said to be either un-censored (−∞< yi = yi < ∞), left-censored (−∞= yi < yi < ∞), right-censored (−∞< yi < yi = ∞), or interval-censored (−∞< yi < yi < ∞) (Klein and Moeschberger, 2005). For instance, right censored data occurs when all that is known is that an individual is still alive after a period of time. Another recent example is from the ﬁeld of genomics, where interval regression was used to learn a penalty function for changepoint detection in DNA copy number and ChIP-seq data (Rigaill et al., 2013). Despite the ubiquity of this type of problem, there are surprisingly few existing algorithms that have been designed to learn from such outputs, and most are linear models. Decision tree algorithms have been proposed in the 1980s with the pioneering work of Breiman et al. (1984) and Quinlan (1986). Such algorithms rely on a simple framework, where trees are grown by recursive partitioning of leaves, each time maximizing some task-speciﬁc criterion. Advantages of these algorithms include the ability to learn non-linear models from both numerical and categorical data of various scales, and having a relatively low training time complexity. In this work, we extend the work of Breiman et al. (1984) to learning non-linear interval regression tree models. 31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA. arXiv:1710.04234v2  [stat.ML]  27 Oct 2017  1.1 Contributions and organization Our ﬁrst contribution is Section 3, in which we propose a new decision tree algorithm for interval regression. We propose to partition leaves using a margin-based hinge loss, which yields a sequence of convex optimization problems. Our second contribution is Section 4, in which we propose a dynamic programming algorithm that computes the optimal solution to all of these problems in log-linear time. In Section 5 we show that our algorithm achieves state-of-the-art prediction accuracy in several real and simulated data sets. In Section 6 we discuss the signiﬁcance of our contributions and propose possible future research directions. An implementation is available at https://git.io/mmit. 2 Related work The bulk of related work comes from the ﬁeld of survival analysis. Linear models for censored outputs',\n",
       " '1710.00478': 'Person re-identiﬁcation (ReID) is an important and challenging task in computer vision. It has many applications in surveilance video, such as person tracking across multiple cameras and person searching in a large gallery etc. However, some issues make the task difﬁcult such as large variations in poses, viewpoints, illumination, background environments and occlusion. And the similarity of appearances among different persons also increases the difﬁculty. Some traditional ReID approaches focus on low-level features such as colors, shapes and local descriptors [8, 10]. With the development of deep learning, the convolutional neural network (CNN) is commonly used for feature representation [26, 38, 5]. The CNN based methods can present high-level features and thus improve the performance of person ReID. In supervised learning, current methods can be divided into representation learning and metric learning in terms of the target loss. For the representation learning, ReID is considered as a veriﬁcation or identiﬁcation problem. For instance, in [57], the authors make the comparison between the veriﬁcation baseline and the identiﬁcation baseline: (1) For the former, two images are judged whether they belong to the same person. (2) For the latter, the method treats each identity as a category, and then minimizes the softmax loss. In some improved work, Lin et al. combined the veriﬁcation loss with attributes loss [19], while Matsukawa et al. combined the identiﬁcaCNN … … input features distance matrix max(dp) min(dn) Figure 1. Framework of our method. Input data are designed to be groups of identities. Distace matrix of features extracted by CNN is calculated. The minimum of negative pair distances and the maximum of positive pair distances are sent to the loss function. tion loss with attributes loss [26]. Representation learning based methods have prominent advantages, having reasonable performance and being easily trained and reproducible. But those methods do not care about the similarity of different pairs, leading it difﬁcult to distinguish between pairs of same persons and different persons. To mitigate that problem, different distance losses, such as contrastive loss [38], triplet loss [21], improved triplet loss [5], quadruplet loss [3], etc. are proposed. And [12] also proposes hard batch by sampling hard image pairs. These methods can directly evaluate the similarity of two input images according to their embedding features. Although these distance losses are sensitive to image pairs, which increases the training difﬁculty, they can generally get better performance than representation learning based methods. In this paper, we propose a novel metric learning loss with hard sample mining called margin smaple mining loss (MSML). It can minimize the distance of positive pairs while maximizing the distance of negative pairs in feature embedding space. For original triplet or quadruplet loss, the pairs are randomly sampled. In our method, we put each K images of P persons into a batch, and then calculate an N × N distance matrix where N = K × P denotes the 1 arXiv:1710.00478v3  [cs.CV]  7 Oct 2017  batch size. Then, we choose the maximum distance of pos',\n",
       " 'cs/0610079': 'In the classic problem of multiterminal source coding, M (M ≥2) correlated general sources have to be compressed separately from each other in a lossy fashion, i.e., with respect to a ﬁdelity criterion, and then decoded by the common decoder which has access to a side information source that is correlated with the sources to be compressed. This situation is illustrated in Fig. 1, and it is also called distributed source coding. The well-known   Encoder 1  Encoder 2  Encoder m          Decoder  n S n M X 2 n X 1 n X 1 n Y 2 n Y n M Y 1 R 2 R m R Figure 1: Separate compression of M correlated general sources with side information at the decoder Slepian-Wolf coding problem and the Wyner-Ziv coding problem can be regarded as two special cases of this situation. These two special cases were solved in 1970’s for stationary memoryless sources [1, 2], and later extended to the case of general sources [3,4]. However, for this general problem, no conclusive results are available to date. Even for the special case that the sources are memoryless and stationary and the distortion measure is additive, 1This work was supported in part by the Natural Science Foundation of China under Grant NSFC-60472079 and by the Chinese Specialized Research Fund for the Doctoral Program of Higher Education under Grant 2004-0335099. only inner and outer bounds are derived in [5,6], etc. Recently, in [7], we adopt an information-spectrum approach to solve this open problem for general sources with maximum distortion criterions under ﬁxed-length coding and a general formula for the rate-distortion region is obtained. Though the formula in [7] is incomputable in general and can not be used to obtain the single letter rate-distortion region for correlated memoryless sources, it does provide a very general suﬃcient condition, which includes many previous results (e.g. in [4,5]) as its special cases. In this paper, we goes further to investigate the problem with average distortion criterions under ﬁxed-length coding. Since the covering lemma for a Markov chain plays an important role in the proofs of these kinds of problems, we established an enhanced covering lemma in Section II, which is the main contribution of this paper. Then in Section III, we investigate the distributed source coding problem of two correlated general sources with one average distortion criterion under ﬁxed-length coding. II. Covering Lemma In this section, we will prove a covering lemma in a very general form. For comparison, the original covering lemma in [4] is ﬁrst shown below. Lemma 1 (Lemma 1 in [4]) Let U n, V n and W n be random variables which take values in ﬁnite sets Un, Vn and Wn, respectively, and satisfy a Markov condition PUnV nW n = PW nV nPUn|V n for each n. Now let {Ψn}∞ n=1 be a',\n",
       " '1807.11632': 'Recent speaker-dependent speech synthesis systems can generate high-quality reading speech indistinguishable from natural human speech when their training data is recorded in a quality-controlled condition and have sufﬁcient amount of data [1]. The speech synthesis community is currently trying to solve more challenging problems. A good example is multi-speaker speech synthesis and its adaptation [2, 3, 4, 5]. Here multi-speaker synthesis means generating synthetic speech of multiple known speakers included in a training dataset using a common model, and adaptation means adapting the speaker-independent common model to unseen speakers and generating their speech. This speakeradaptive speech synthesis systems are expected to opens possibilities for a wide range of new applications for speech synthesis such as a customizable, user-speciﬁc voice interface and voice preservation for people with medical conditions involving voice losses. However, training the multi-speaker This work was partially supported by MEXT KAKENHI Grants (16H06302, 17H04687, 18H04120, and 18H04112). synthesis models and adapting them to unseen speakers are still challenging problems, and resulting models are far from perfect, especially when less than ideal datasets are used [6]. Most adaptation methods for neural network models can be described as either (a) ﬁne-tuning a set of or all of parameters of speaker-independent network so it explains unseen speaker’s data better or (b) factorizing a neural network into speaker-speciﬁc and common parts and estimating the speaker-speciﬁc components for the unseen speaker’s data. The speaker-speciﬁc components may be composed by input codes (e.g. one-hot vector) [7], embedding vectors obtained externally (e.g. i-vector) [8], or latent variables (e.g. variational auto-encoder) [3, 9, 10]. Of course any of those speaker-speciﬁc components may be jointly optimized with the common parts (e.g. [7, 10, 11]). Although there are a lot of variants on multi-speaker modeling and adaptation, most approaches for augmenting the speaker-speciﬁc components into a neural network are equivalent to adapting a bias term of each hidden layer and this bias term is typically constant across all frames of all utterances. Although Wu et al. [12] and Nachmachi et al. [13] proposed frame-dependent components, these components are still bias adaptation and their underlying frameworks and concepts have mathematical similarities. In this paper we ﬁrst systematically overview the common concepts of neural-network based speaker-adaptive models and show that these approaches can be represented in a uniﬁed framework. Further, we introduce a scaling code as an extended speaker-adaptive transformation. As its name indicates, this code introduces an additional scaling operation as an approximation to adaptation of weight matrices unlike the conventional deep neural network (DNN) adaptation approaches. Section 2 details relevant work. Section 3 describes our factorized speaker adaptation based on scaling and bias codes. Section 4 explains our experiments and shows both objective and subjective results. We conclude our work and describe the',\n",
       " '0810.3442': 'Computational modelling is becoming more and more important tool to study langauge evolution [1, 2, 3, 4, 5]. The central assumption of such an approach is that language is a complex adaptive system that emerges from local interactions between its users, and evolves and complexiﬁes according to biological-like principles of evolution and self-organization [6, 7, 8]. This is by no means the only possibility since a number of researches claims that language does not have the adaptive values and is merely a byproduct of having a large and complex brain or of some other skills [9, 10]. Recently, however, adaptationists got a strong support from Pinker and Bloom, who in their inﬂuential paper [11] argued that linguistic abilities require complex and costly adaptations (e.g., large brain, longer infancy period, descended larynx) and the language origin can be explained only by means of natural selection theory. Since language was invented only in one lineage, and is therefore unique to human species, its appearance has the same status as the origin of genetic code or the eukaryotic cell. The emergence of language was thus listed as one of the major transition in the evolution of life on Earth [12] and it is certainly interesting to ask which factor is responsible for it. Some claims were made that most likely it was the combination of selective evolutionary pressure and unique context that lead to the emergence of human language [13]. Language has also lead to the novel inheritance system [14] and opened up the possibility for cumulative cultural evolution and creation of complex society [15] with collaboration of large non-kin groups [16]. While our willingness to share information with relatives is rather easy to reconcile with darwinian evolution (kin-selection [17]), linguistic interactions with non-kin individuals are harder to understand. Indeed, since speaking is costly (it takes time, energy and sometimes might expose a speaker to the predators), and listening is not, such a situation seems to favour selﬁsh individuals that would only listen but would not speak. Moreover, in the case of the conﬂict of interests the emerging communication system would be prone to misinformation or lying. A possible resolution of these problems is based on reciprocal altruism [18]. However, there is a growing evidence that cooperation and altruistic behaviour between humans are very complex and typically cannot be explained using standard reciprocal altruism arguments [16]. As an alternative explanation Dessalles[19] suggests that honest information is given freely because it is profitable - it is a way of competing for status within a group. In this context, an interesting computer simulations were made by Hurford[20]. He considered agents engaged in communicative tasks (one speaker and one hearer) and their abilities evolved with the genetic algorithm that was set to prefer either communicative or interpretative success. Only in the former case the emerging language was similar to natural languages where synonymy was rare and homonymy tolerated. When interpretative success',\n",
       " '1806.01267': 'Reinforcement learning (RL) [30] enables an agent to learn the desired behavior required to accomplish a given objective, such that the expected return or reward for the agent is maximized over time. Typically, a scalar reward signal is used to guide the agent’s behavior so that the agent learns a control policy that maximizes the cumulative scalar reward over trajectories. This type of learning is referred to as model-free RL if the agent does not have an apriori model or knowledge of the dynamics of the environment it is acting in. Some notable breakthroughs among the many recent research efforts that incorporate deep models are the deep Q-network (DQN) [17], which approximated a Q-value function used as a deep neural network and trained agents to play Atari games with discrete control, the deep deterministic policy gradient (DDPG) [15], which successfully applied deep RL for continuous control agents, and the trust region policy optimization (TRPO) [27], which formulated a method for optimizing control policies with guaranteed monotonic improvement. *This work originated while working at IBM Research In most RL methods, it is critical to choose a well-designed reward function to successfully ensure that the agent learns a good action policy for performing the task. Moreover, there are cases in which the reward function is very sparse or may not be directly available. Humans can often imitate the behavior of their instructors and estimate which actions or environmental states are good for the eventual accomplishment of a task without being provided with a continual reward. For example, young adults initially learn how to write letters by imitating demonstrations provided by their teachers or other adults (experts). Further skills get developed on the basis of exploration around this initial grounding provided by the demonstrations. Taking inspiration from such scenarios, various methods have been proposed, which are collectively known as imitation learning [8, 9] or learning from demonstration [26]. Inverse reinforcement learning [1, 19, 35], behavior cloning [25], and curiosity-based exploration [23] are also examples of research in this field. Typically, in all these formulations, expert demonstrations are provided as input. The majority of such prior work assumes that the demonstrations contain both states and actions {(si 0,ai 0), ..., (si t ,ai t )} and that these can be used to solve the problem of having only a sparse reward or a complete lack thereof. However, there are many cases in realworld environments in which such detailed action information is not readily available. For example, a typical schoolteacher does not tell students the exact amount of force to apply to each of their fingers while they are learning how to write. As such, in this work, as our primary contribution, we propose a reinforcement learning method in which the agent learns an internal predictive model that is trained on the external environment from state-only trajectories by expert demonstrations. This model is not trained on both the state and',\n",
       " '1805.08493': 'O BJECTIVE image quality assessment (IQA) is a fundamental problem in computer vision and plays an important role in monitoring image quality degradations, optimizing image processing systems and improving video encoding algorithms. Therefore, it is of great signiﬁcance to build an accurate IQA model. In the literature, some fullreference image quality assessment (FR-IQA) methods [1]– [7] which attempt to build a model simulating human visual system (HVS) can achieve good performance. For example, FSIM [2] predicts a single quality score from a generative similarity map (as shown in Fig. 1(b)). According to our analysis, two reasons bring FR-IQA methods into success. One reason is that it can access to reference image content and take the reference information by comparison. Meanwhile, this way of comparison is similar with the behavior of human vision and makes it easy to judge the image quality by FR-IQA methods [8]. The other reason is that hand-crafted features carefully designed by FR-IQA are closely related to some HVS methods properties. The difference of features on corresponding positions between reference and distorted images can well measure the distortion degree. On the other hand, some NR-IQA methods [9]–[12] which rely on natural scene statistics do not obtain the same satisfying performance. As a result, the accuracies of most FR-IQA methods are better than those of NR-IQA when the performance is objectively evaluated. (a) (b) (c) (d) Fig. 1. Examples of predicted quality maps: (a) is a distorted image; (b) is a similarity map from FSIM; (c) is a patch-based quality map from BIECON [13]; (d) is a pixel-based quality map predicted from our proposed model. Based on these analysis, it is difﬁcult for NR-IQA methods to build a model to imitate the behavior of HVS under the case of lacking reference information. Recently, researchers have started to harness the power of convolutional neural networks (CNNs) to learn discriminative features for various distortions types [14]–[17]. We name these methods DeepIQA. Most previous Deep-IQA methods just consider CNN as a complicated regression function or a feature extractor, but are unaware of the importance of generating intermediate quality maps which represent the perceptual impact of image quality degradations. This training process of Deep-IQA seems not to have an explicit perceptual meaning and is always a black box for researchers. But what interests us is that BIECON [13] proposed an idea that training a CNN to replicate a conventional FR-IQA such as SSIM [1] or FSIM [2]. However, the method estimates each local patch score and patch-wise scores are pooled to an overall quality score. In essence, it visualizes a score patch map which contains spatial distribution information and the map does not reﬂect the distorted image in pixel level, as shown in Fig. 1(c). But we consider that the distortion value of each pixel is affected by its neighboring pixels and should not be exactly the same in the same patch. The simple patch-based scheme is not enough',\n",
       " '1506.02897': 'Despite a long history of research, human pose estimation in videos remains a very challenging task in computer vision. Compared to still image pose estimation, the temporal component of videos provides an additional (and important) cue for recognition, as strong dependencies of pose positions exist between temporally close video frames. In this work we propose a new approach for using optical ﬂow for part localisation in deep Convolutional Networks (ConvNets), and demonstrate its performance for human pose estimation in videos. The key insight is that, since for localisation the prediction targets are positions in the image space (e.g. (x, y) coordinates of joints), one can use dense optical ﬂow vectors to warp predicted positions onto a target image. In particular, we show that when regressing a heatmap of positions (in our application for human joints), the heatmaps from neighbouring frames can be warped and aligned using optical ﬂow, effectively propagating position conﬁdences temporally, as illustrated in Fig 1. We also propose a deeper architecture that has additional convolutional layers beyond the initial heatmaps to enable learning an implicit spatial model of human layout. These layers are able to learn dependencies between human body parts. We show that these ‘spatial fusion’ layers remove pose estimation failures that are kinematically impossible. Related work. Traditional methods for pose estimation have often used pictorial structure models [2, 8, 10, 27, 39], which optimise a conﬁguration of parts as a function of local image evidence for a part, and a prior for the relative positions of parts in the human kinematic chain. An alternative approach uses poselets [1, 13]. More recent work has tackled pose estimation holistically: initially with Random Forests on depth data [12, 29, 31, 34] and RGB [3, 4, 24], and most recently with convolutional neural networks. The power of ConvNets has been demonstrated in a wide variety of vision tasks – object classiﬁcation and detection [11, 21, 28, 40], face recognition [32], text recognition [15, 16], video action recognition [20, 30] and many more [7, 22, 25]. For pose estimation, there were early examples of using ConvNets for pose comparisons [33]. More recently, [37] used an AlexNet-like ConvNet to directly regress joint coordinates, with a cascade of ConvNet regressors to improve accuracy over a single pose regressor network. Chen and Yuille [5] combine a parts-based model with ConvNets (by using a ConvNet to learn conditional probabilities for the presence of parts and their spatial relationship with image patches). In a series of papers, Tompson, Jain et al. developed ConvNet architectures to directly regress heatmaps for each joint, with subsequent layers to add an Markov Random Field (MRF)-based spatial model [17, 36], and a pose reﬁnement model [35] (based on a Siamese network with shared weights) upon a rougher pose estimator ConvNet. 1 arXiv:1506.02897v2  [cs.CV]  8 Nov 2015  conv1 SpatialNet Input ... ... t t+n t-n ... ... conv9 1x1x7 Pose heatmaps Warped heatmaps Optical',\n",
       " '1704.00623': 'T HE idea behind Massive MIMO is to equip base stations (BS) in wireless networks with large arrays of phasecoherently cooperating antennas. The use of such arrays facilitates spatial multiplexing of many user equipments (UEs) in the same time-frequency resource, and yields a coherent beamforming gain that translates directly into reduced interference and improved cell-edge coverage. The original Massive MIMO concept [1]–[4] assumes timedivision duplexing (TDD) and exploits reciprocity for the acquisition of channel state information (CSI) at the BS. UEs send pilots on the uplink (UL); all UE-to-BS channels are estimated, and each antenna has its own RF electronics. The concept has, since its introduction a decade ago [1], [3], matured signiﬁcantly: rigorous information-theoretic analyses are available [2], ﬁeld-trials have demonstrated its performance in high-mobility scenarios [5]–[7], and circuit prototypes have shown the true practicality of implementations [8]. Concurrently, motivated by spectrum regulation issues, there is signiﬁcant interest in developing frequency-division duplexing (FDD) versions of Massive MIMO [9]–[13]. There is also interest in hybrid beamforming architectures that rely on This work was supported by the Seventh Framework Programme (FP7) of the European Union under grant agreement no. 619086 (MAMMOET), ELLIIT—an Excellence Center at Link¨oping-Lund in Information Technology, the Swedish Research Council (VR), and the Swedish Foundation for Strategic Research (SSF). Jose Flordelis, Fredrik Rusek, Fredrik Tufvesson, and Ove Edfors are with the Department of Electrical and Information Technology, Lund University, SE-221 00 Lund, Sweden (e-mail: jose.ﬂordelis@eit.lth.se; fredrik.rusek@eit.lth.se; fredrik.tufvesson@eit.lth.se; ove.edfors@eit.lth.se). E. G. Larsson is with the Department of Electrical Engineering (ISY), Link¨oping University, SE-581 83 Link¨oping, Sweden (e-mail: erik.g.larsson@liu.se). the use of analog phase shifters and signal combiners [14]– [17], somewhat reminiscent of phased-arrays implementations of radar. With hybrid beamforming, the number of actual antennas may substantially exceed the number of RF chains. FDD operation and hybrid beamforming solutions both bring the same difﬁculty – albeit for different reasons: signiﬁcant assumptions on the structure of propagation must be made for the techniques to work efﬁciently. Speciﬁcally: • FDD operation requires CSI feedback from the UEs to the BS. Efﬁcient encoding of this CSI is only possible if side information on the propagation is exploited. The resulting techniques are often called “grid-of-beams”, and have similarities to existing forms of multiuser (MU) MIMO in LTE [18]. • Hybrid-beamforming architectures inherently rely on beamforming into predetermined spatial directions, as deﬁned by the angle-of-arrival or angle-of-departure, seen from the array. Such directions only have a well-deﬁned operational meaning when the propagation environment offers strong direct or specular paths [19]. There has been a long-standing debate on the relative performance between reciprocity-based (TDD) Massive MIMO and that of solutions based on grid-of-beams or hybridbeamforming architectures. The matter',\n",
       " '1704.01975': 'Due to the large and continuously growing volume of textual data, automated text classiﬁcation methods have taken an increasing interest of research community. Although many eﬀorts have been proposed in this direction, it remains as an open problem. The arrival of massive data sources, like micro-blogging platforms, introduces new challenges where many of the prior techniques failed. Among the new challenges are: the volume and noisy nature of the data, the shortness of the texts that implies little context, the informal style also plagued of misspellings and lexical errors, among others. These new data sources have made popular tasks such as sentiment analysis and user proﬁling. The sentiment analysis problem consists in determining the polarity of a given text, which can be a global polarity (about the whole text) or about a particular subject or entity. The user proﬁling task consists in, given a text, predicting some facts about the author, like her/his demographic information (e.g., gender, age, language or region). Such is the importance of these problems that in the research community several international competitions have been carried out in recent years. For example SemEval1, TASS2 and SENTIPOLC3 are challenges for sentiment classiﬁers for Twitter data in English, Spanish, and Italian languages, respectively. PAN4 also opens calls for author proﬁling systems for English, Spanish and German languages. These problems are closely related to traditional text classiﬁcation applications such as topic classiﬁcation (e.g, classifying a news-like text into sports, politics, or economy), authorship attribution (e.g., identifying the author of a given text) and spam detection. Usually, each of aforementioned problems is treated in a particular way, i.e., a method is proposed to solve adequately one classiﬁcation task. Traditionally, this approach cannot generalize to other related task, and, consequently, the methods are dependent on the problem; however, it is worth to mention that this specialization produces a lot of insight about the problem’s domain. Conversely, in this contribution, we proposed a framework to create a text classiﬁer regardless of both the domain and the language and based only a training set of labeled examples. The idea of creating a text classiﬁer almost independent of the language and domain is not novel, in fact, in our previous work [1], we introduced a combinatorial framework for sentiment analysis. There, aspects of language were considered such as stopwords and tokenizers with special attention to lexical structures for negations. Also, particularities of the domain like emoticons and emojis are considered. The presented manuscript is a generalization and formalization of our previous work; this allows us to simplify the entire framework to work independently of both the language and the particular task, and empower the use of more sophisticated text treatments whenever it is possible and 1http://alt.qcri.org/semeval2017/ 2http://www.sepln.org/workshops/tass/2016/tass2016.php 3http://www.di.unito.it/ tutreeb/sentipolc-evalita16/ 4http://pan.webis.de/ 2  necessary. As stated above, we tackle the',\n",
       " '1512.06429': '2 1.1 Overview of results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 1.2 Organization and notation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 2 Examples and properties of the FI-curves 6 3 Diagonal bound for Gaussian channels 7 4 Diagonal bound for general additive noise 10 5 Minimum mean square error and near-Gaussianness 13 6 Horizontal bound for Gaussian channels 16 7 Deconvolution results for total variation 19 8 Horizontal bound for general additive noise 22 9 Inﬁnite-dimensional case 24 A Alternative version of Lemma 5 25 B L´evy concentration function near zero 26 1 Introduction Strong data-processing inequalities (SDPIs) quantify the decrease of mutual information under the action of a noisy channel. Such inequalities have apparently been ﬁrst discovered by Ahlswede and G´acs in a landmark paper [AG76]. Among the work predating [AG76] and extending it we mention [Dob56,Sar62,CIR+93]. Notable connections include topics ranging from existence and uniqueness of Gibbs measures and log-Sobolev inequalities to performance limits of noisy circuits. We refer the reader to the introduction in [PW16] and the recent monographs [Rag14,RS+13] for more detailed discussions of applications and extensions. For a ﬁxed channel PY |X : X →Y, let PY |X ◦P be the distribution on Y induced by the pushforward of the distribution P. One approach to strong data processing seeks to ﬁnd the contraction coeﬃcients ηf ≜ sup P,Q:P ̸=Q Df \\x00PY |X ◦P∥PY |X ◦Q \\x01 Df(P∥Q) , (1) where the Df(P∥Q) ≜EQ[f(dP dQ)] is an f-divergence of Csisz´ar [Csi67]. When the divergence Df is the KL-divergence and total variation,1 we denote the coeﬃcient ηf as ηKL and ηTV, respectively. For discrete channels, [AG76] showed that strict contraction for KL-divergence is equivalent to strict contraction in terms of total variation (ηKL < 1 ⇔ηTV < 1), and ηKL < 1 if an only if the bipartite graph describing the channel, determined by the edges \\x08 (x, y) | PY |X(y|x) > 0 \\t , 1The total variation between two distributions P and Q is dTV(P, Q) ≜supE |P[E] −Q[E]|. 2  is connected. Having ηKL < 1 implies reduction in the usual data-processing inequality for mutual information [CK81, Exercise III.2.12], [AGKN13]: ∀W →X →Y : I(W; Y ) ≤ηKL · I(W; X) . (2) We refer to inequalities of the form (2) as linear SDPIs. When PY |X is an additive white Gaussian noise channel, i.e. Y = X + Z with Z ∼N(0, 1), it has been shown [PW16] that restricting the maximization in (1) to distributions with a bounded second moment (or any moment) still leads to no-contraction, giving ηKL = ηTV = 1 for AWGN. Nevertheless, the contraction does indeed take place, except not multiplicatively. The region \\x08 (dTV(P, Q), dTV(P ∗PZ, Q ∗PZ)) : E(P +Q)/2[X2] ≤γ \\t , has been explicitly determined in [PW16], where ∗denotes convolution. The boundary of this region, dubbed the Dobrushin curve of the channel, turned out to be strictly bounded away from the diagonal',\n",
       " '1812.09449': 'N AMED Entity Recognition (NER) aims to recognize mentions of rigid designators from text belonging to predeﬁned semantic types such as person, location, organization etc [1]. NER not only acts as a standalone tool for information extraction (IE), but also plays an essential role in a variety of natural language processing (NLP) applications such as text understanding [2], [3], information retrieval [4], [5], automatic text summarization [6], question answering [7], machine translation [8], and knowledge base construction [9] etc. Evolution of NER. The term “Named Entity” (NE) was ﬁrst used at the sixth Message Understanding Conference (MUC-6) [10], as the task of identifying names of organizations, people and geographic locations in text, as well as currency, time and percentage expressions. Since MUC6 there has been increasing interest in NER, and various scientiﬁc events (e.g., CoNLL03 [11], ACE [12], IREX [13], and TREC Entity Track [14]) devote much effort to this topic. Regarding the problem deﬁnition, Petasis et al. [15] restricted the deﬁnition of named entities: “A NE is a proper noun, serving as a name for something or someone”. This restriction is justiﬁed by the signiﬁcant percentage of proper nouns present in a corpus. Nadeau and Sekine [1] claimed that the word “Named” restricted the task to only • J. Li is with the Inception Institute of Artiﬁcial Intelligence, United Arab Emirates. This work was done when the author was with Nanyang Technological University, Singapore. E-mail: jli030@e.ntu.edu.sg. • A. Sun is with School of Computer Science and Engineering, Nanyang Technological University, Singapore. E-mail: axsun@ntu.edu.sg. • J. Han is with SAP, Singapore. E-mail: ray.han@sap.com. • C. Li is with School of Cyber Science and Engineering, Wuhan University, China. E-mail:cllee@whu.edu.cn. Accepted in IEEE TKDE. those entities for which one or many rigid designators stands for the referent. Rigid designator, deﬁned in [16], include proper names and natural kind terms like biological species and substances. Despite the various deﬁnitions of NEs, researchers have reached common consensus on the types of NEs to recognize. We generally divide NEs into two categories: generic NEs (e.g., person and location) and domain-speciﬁc NEs (e.g., proteins, enzymes, and genes). In this paper, we mainly focus on generic NEs in English language. We do not claim this article to be exhaustive or representative of all NER works on all languages. As to the techniques applied in NER, there are four main streams: 1) Rule-based approaches, which do not need annotated data as they rely on hand-crafted rules; 2) Unsupervised learning approaches, which rely on unsupervised algorithms without hand-labeled training examples; 3) Feature-based supervised learning approaches, which rely on supervised learning algorithms with careful feature engineering; 4) Deep-learning based approaches, which automatically discover representations needed for the classiﬁcation and/or detection from raw input in an end-toend manner. We brief 1), 2) and 3), and review 4) in detail. Motivations for conducting this survey. In recent years',\n",
       " '1705.00002': 'The signiﬁcant developments in the ﬁeld of sparse models during the last decades lead to the opening of the new research and application ﬁelds. One of the ﬁrst application for sparse modelling is the linear regression problem where l0 and l1-norm regularisation is considered. The latter has the advantage that a regulariser term is convex, while it has not so obvious sparse interpretation [1]. Sparse modelling is further developed in the ﬁeld of signal processing in compressive sensing [2], where the main idea is to minimise the number of measurements of the signal without loss of the decoding accuracy. Compressive sensing concerns the two main problems: selecting the optimal design matrix and solving ill-posed regression, that arises in the original signal decoding from the measurements [3]. The idea of sparse Bayesian modelling is mentioned in [4]. This imposes the sparsity-inducing Laplace prior on the data, but does not give the inference for the whole distribution, only a maximum aposteriori probability estimate. The full inference to this model is provided in [5], using the Expectation Propagation (EP) technique. Another work is [6], where the prior is modiﬁed to the hierarchical Gauss-Gamma distribution. These models are used as a basis for Bayesian compressive sensing in [7] and [8]. The recent monograph [9] presents the sparse modelling application for image and video processing. One of the essential problems in video processing is foreground detection which is mostly solved by background subtraction. Background subtraction aims to distinguish foreground (moving objects) from background (static ones). Sparseness is natural for the background subtraction problem as the foreground objects occupy the small regions on a frame. Background subtraction hence represents a natural application area for sparse modelling. The idea to apply compressive sensing for background subtraction is originally proposed in [10] and developed in [11]. In contrast to these works in this paper we focus on the sparse Bayesian methods for background subtraction and the comprehensive comparison of these methods with the conventional compressive sensing one. The contribution of this paper is in applying the Bayesian compressive sensing approach for the background subtraction problem. As far as the authors know, this approach for moving object detection has not been considered yet. Also several algorithms are overviewed and compared to evaluate their applicability in different situations. This paper is organised as follows. In Section II the proposed model is explained. The experimental results are represented in Section III. Section IV concludes the paper and discusses the future work. II. FRAMEWORK Assume that we have a static camera and we can acquire a frame B ∈Rn1×n2 from the camera that is referenced as the background. The video from the camera consists of the sequential frames Vk ∈Rn1×n2, k ∈{1, . . . , K}. The aim is to estimate the mask of the foreground objects in these frames. A. Video preprocessing We convert the source video frames to greyscale. The background frame B is converted to a vector b ∈Rn, the video frames Vk',\n",
       " '1602.05307': \"Entity typing is an important task in text analysis. Assigning types (e.g., person, location, organization) to mentions of entities in documents enables eﬀective structured analysis of unstructured text corpora. The extracted type information can be used in a wide range of ways (e.g., serving as primitives for information extraction [23] and knowledge base (KB) completion [4], and assisting question answering [6]). Traditional entity typing systems [22, 18] focus on ∗Equal contribution. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and the full citation on the ﬁrst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission and/or a fee. Copyright 20XX ACM X-XXXXX-XX-X/XX/XX ...$15.00. ID Sentence  S1 S2 S3 ...   Republican presidential candidate Donald Trump     spoke during a campaign event in Rock Hill.   Donald Trump's company has threatened to withhold    up to $1 billion of investment if the U.K. government     decides to ban his entry into the country.   In Trump’s TV reality show, “The Apprentice”, 16    people competed for a job. ... Text Corpus Entity: Donald Trump Knowledge Bases Noisy Training Examples Distant Supervision Candidate Type Set  (Sub-tree) root product person location organiz ation ... ... politician artist business man ... ... ... author actor singer ... Target Type  Hierarchy Mention: “Donald Trump”; Context: S1; Candidate Types: {person, politician,  businessman, artist, actor} Mention: “Donald Trump”; Context: S2; Candidate Types: {person, politician,  businessman, artist, actor} Mention: “Trump”; Context: S3; Candidate Types: {person, politician,  businessman, artist, actor} 1 2 3 ... ... Figure 1: Current systems may ﬁnd Donald Trump mentioned in sentences S1-S3 and assign the same types to all (listed within braces), when only some types are correct for context (blue). a small set of coarse types (typically fewer than 10). Recent studies [34, 14, 35] work on a much larger set of ﬁne-grained types which form a tree-structured hierarchy (e.g., actor as a subtype of artist, and artist is a subtype of person, as in blue region of Fig. 1). While types are usually deﬁned to be mutually exclusive within a coarse type set (e.g., by assuming a mention cannot be both person and location), ﬁnegrained typing allows one mention to have multiple types, which together constitute one type-path (not necessarily ending in a leaf node) in the given type hierarchy, depending on the local context (e.g., sentence). Consider the example in Fig. 1, “Trump” could be labeled as {person, artist, actor} in S3 (TV show). But he could also be labeled as {person, politician} in S1 or {person, businessman} in S2. A major challenge in ﬁne-grained typing is the absence of human-annotated data. The process of manually labeling a training set with large numbers of ﬁne\",\n",
       " '1502.03167': 'Deep learning has dramatically advanced the state of the art in vision, speech, and many other areas. Stochastic gradient descent (SGD) has proved to be an effective way of training deep networks, and SGD variants such as momentum (Sutskever et al., 2013) and Adagrad (Duchi et al., 2011) have been used to achieve state of the art performance. SGD optimizes the parameters Θ of the network, so as to minimize the loss Θ = arg min Θ 1 N N X i=1 ℓ(xi, Θ) where x1...N is the training data set. With SGD, the training proceeds in steps, and at each step we consider a minibatch x1...m of size m. The mini-batch is used to approximate the gradient of the loss function with respect to the parameters, by computing 1 m ∂ℓ(xi, Θ) ∂Θ . Using mini-batches of examples, as opposed to one example at a time, is helpful in several ways. First, the gradient of the loss over a mini-batch is an estimate of the gradient over the training set, whose quality improves as the batch size increases. Second, computation over a batch can be much more efﬁcient than m computations for individual examples, due to the parallelism afforded by the modern computing platforms. While stochastic gradient is simple and effective, it requires careful tuning of the model hyper-parameters, speciﬁcally the learning rate used in optimization, as well as the initial values for the model parameters. The training is complicated by the fact that the inputs to each layer are affected by the parameters of all preceding layers – so that small changes to the network parameters amplify as the network becomes deeper. The change in the distributions of layers’ inputs presents a problem because the layers need to continuously adapt to the new distribution. When the input distribution to a learning system changes, it is said to experience covariate shift (Shimodaira, 2000). This is typically handled via domain adaptation (Jiang, 2008). However, the notion of covariate shift can be extended beyond the learning system as a whole, to apply to its parts, such as a sub-network or a layer. Consider a network computing ℓ= F2(F1(u, Θ1), Θ2) where F1 and F2 are arbitrary transformations, and the parameters Θ1, Θ2 are to be learned so as to minimize the loss ℓ. Learning Θ2 can be viewed as if the inputs x = F1(u, Θ1) are fed into the sub-network ℓ= F2(x, Θ2). For example, a gradient descent step Θ2 ←Θ2 −α m m X i=1 ∂F2(xi, Θ2) ∂Θ2 (for batch size m and learning rate α) is exactly equivalent to that for a stand-alone network F2 with input x. Therefore, the input distribution properties that make training more efﬁcient – such as having the same distribution between the training and test data – apply to training the sub-network as well. As such it is',\n",
       " '1702.06230': 'The past few years have seen a renaissance of sorts for neural network models in AI and machine learning. Driven in part by hardware advances in the GPUs that accelerate their training, the ﬁrst breakthroughs came in 2012 when convolutional architectures were able to achieve record performance on image classiﬁcation [Krizhevsky et al., 2012] [Cirean et al., 2012]. Today the technique is known as Deep Learning due to its use of many layers that build up increasingly abstract representations from raw inputs. In this paper we focus not on vision but on game-playing. As far back as the early 90’s, neural networks were used to reach expert-level play on Backgammon [Tesauro, 1995]. More recently, there have been breakthroughs on learning to play various video games [Mnih et al., 2013]. Even the ancient board game Go, which for long has thwarted attempts by AI researchers to build human-level programs, fell to a combination of neural networks and Monte-Carlo Tree Search [Silver et al., 2016]. 2 The SSBM Environment We focus on Super Smash Bros. Melee (SSBM), a fast-paced multi-player ﬁghting game released in 2001 for the Nintendo Gamecube. SSBM has steadily grown in popularity over its 15-year history, and today sports an active tournament and professional scene. The metagame is constantly evolving as new mechanics are discovered and reﬁned and top players push each other to ever greater levels of skill. From an RL standpoint, the SSBM environment poses several challenges - large and only partially observable state, complex transition dynamics, and delayed rewards. There is also a great deal of diversity in the environment, with 26 unique characters and a multitude of different stages. The partial observability comes from the limits of human reaction time along with several frames of built-in input delay, which forces players to anticipate their opponent’s actions ahead of time. Furthermore, being a multi-player game adds an entirely new dimension of complexity - success is no longer a single, absolute measure given by the environment, but instead must be deﬁned relative to a variable, unpredictable adversary. Figure 1: The Battleﬁeld Stage 2.1 State, Action, Reward Many previous applications of deep RL to video games have used raw pixels as observations. Partly for pragmatic reasons, we instead use features read from the game’s memory on each frame, consisting of each player’s position, velocity, and action state, along with several other values. This alarXiv:1702.06230v3  [cs.LG]  8 May 2017  lows us to focus purely on the RL challenge of playing SSBM rather than the perception. In any case, the game features are readily inferred from the pixels; as deep networks are known to perform quite well on vision tasks, we have good reason to believe that pixel-based models would perform similarly. Pixel-based networks would also be better able to deal with projectiles, which we do not currently know how to',\n",
       " '1812.00797': 'Quantization of signals of interest is an integral part of all modern digital signal processing applications such as sensing, communication, and inference. In an ideal hardware implementation of a quantization system, a high-resolution analogto-digital converter (ADC) with b-bit resolution and sampling frequency of fs samples the original analog signal and maps the obtained samples into a discrete state space of size 2bfs. Generally, a large number of bits is required to obtain an accurate digital representation of the analog signal. In such a case, the quantization process has negligible impact on the performance of algorithms which were typically developed on the assumptions of inﬁnite precision samples, and thus, the highresolution (in terms of amplitude) quantization process can be directly modeled as an additive noise source. However, a crucial obstacle with modern ADCs is that their power consumption, manufacturing cost, and chip area grows exponentially with their resolution b [1–3]. ⋆Corresponding author (e-mail: skhoba2@uic.edu). This work was supported in part by U.S. National Science Foundation Grants CCF-1704401 and ECCS-1809225. The required high sampling data rate of ADCs used in next generataion communications systems is another obstacle that must be tackled in such applications. For instance, the promising millimeter wave (mmWave) multiple-input multiple output (MIMO) communication technology requires a very large bandwidth, and the corresponding sampling rate of the ADCs must increase accordingly. However, manufacturing ADCs with high-resolution (e.g., more than 8 bits) and high sampling rate are extremely costly and may not be available. Moreover, in other applications such as spectral sensing and cognitive radio, which require extremely high sampling rates, the cumulative cost and power consumption of using high-resolution and extremely fast ADCs are typically prohibitive and impractical. Hence, when signals across a wide frequency band are of interest, a fundamental trade-off between sampling rate, amplitude quantization precision, cost, and power consumption is encountered. An immediate solution to such challenges is to use low-resolution, and specifically one-bit, ADCs. The use of one-bit signed measurements, and more speciﬁcally one-bit ADCs, allows for an extremely high sampling rate at a low cost and low power consumption. From a sampling viewpoint, the most extreme case of quantization is to use only one bit per sample. More precisely, one-bit sampling can be seen as a process through which we repeatedly compare the amplitude of a signal (at each sample) to some reference threshold level and use only one bit to convey whether the signal amplitude resides above or below that threshold. Due to its appealing sampling properties, the problem of recovering a signal from its one-bit measurements has attracted a great deal of interest over the past few years [4–8]. Therefore, it is vital to develop algorithms that can deal with low-resolution samples for different applications. The ﬁelds of machine learning (ML',\n",
       " '1508.01880': 'We derive the capacity region of the semideterministic discrete memoryless broadcast channel (SD-BC) with partial message side-information (P-MSI) (Theorem 2). In this setting each receiver knows part of the message intended for the other receiver already before the transmission begins. Our capacity result generalizes that of [1, 2] for the SDBC without MSI. The capacity region of the general BC with full MSI (F-MSI), where each receiver knows the entire message intended for the other receiver, was established in [3, 4]. The work of Kramer and Shamai [4] also considers P-MSI and establishes the capacity region of the BC with P-MSI and degraded message sets. The three-receiver BC with P-MSI is studied in [5]. Independently of our work, Asadi, Ong, and Johnson proposed a coding scheme for general two-receiver BCs with P-MSI [6]. One can show that—for a judicious choice of the auxiliary random variables—their scheme achieves the capacity region of the SD-BC. Their work does not, however, provide a converse.1 Generally speaking, P-MSI reduces the eﬀect of self-interference on the BC and hence enables more eﬃcient communication (see, e.g., [4]). More speciﬁcally, in the current paper we show that on the SD-BC P-MSI aﬀects the capacity region as follows: • P-MSI at the deterministic receiver can increase capacity if, and only if, one of the following two holds: 1) also the stochastic receiver has P-MSI; or 2) the encoder conveys also a common message (Remark 1). • P-MSI at the stochastic receiver can increase capacity (Remark 2); and this holds irrespective of whether or not the deterministic receiver has P-MSI or the encoder conveys a common message. To establish these ﬁndings we use our capacity result for the SD-BC with P-MSI. Of particular interest to us is the latter ﬁnding, which we shall use to design a feedback code for the SD-BC with or without P-MSI that can improve over the channel’s no-feedback capacity. Feedback on the BC was ﬁrst studied in [10], where it is shown that even perfect feedback does not increase the capacity region of the physically-degraded BC [10]. It 1Somewhat similar to P-MSI is decoder cooperation on the BC, which allows the decoders to exchange information via ﬁnite-capacity links. The capacity region of the SD-BC with one-sided cooperation via a link from the deterministic to the stochastic receiver is established in [7]. In fact, as it is shown in [7], this network is operationally equivalent to a class of relay-broadcast channels whose capacity region is established in [8]. The physically-degraded BC with parallel conferencing and the BC with conferencing and degraded message sets are studied in [9]. 2  was later proved that feedback can, however, increase the capacity region of several BCs that are not physically degraded [11, 12, 13, 14, 15, 16]; and achievable rate regions for the BC with feedback were established in [12, 13, 14, 15, 16]. An intuition for the gain',\n",
       " '1506.08891': 'Tables are primarily used to present data such as the results of statistical analysis, experimental records, attributes of items, etc. The grid structure of the table – columns and rows – allows a reader to easily interpret and compare different items. Due to the advantages, tables have been widely adopted in many different articles such as web pages, academic publications, online manuals. Computer scientists who conduct research on information extraction take delight in engaging with tables that occur in those electronic documents, as they are the natural sources to feed and populate relational databases. Some formats of the electronic documents are machinereadable, such as HTML, XML and even TEX. These formats derive from SGML (Standard Generalized Markup Language) and inherit the basic principle that the language pins a pair of speciﬁc tags to mark a snippet of text. For example, HTML ﬁles use ⟨table⟩as the start and ⟨/table⟩ as the end, to indicate the region of a table. AI programs can easily recognize expected regions with the help of tags, and extract the information that we want with pre-deﬁned actions. However, it is tedious for our human beings to read the markup language, because we are sensitive to the layouts of documents, and focus more on the contents. Therefore, the Portable Document Format (PDF) was designed as a ﬁle format to represent a document independent of the platform it displays, and to preserve the layouts both on screen and in print. These strengths draw much attention from the online publishing. So far, many academic papers and manuals have adopted PDF as the standard format. Unfortunately, we meet Waterloo when detecting the region of tables within PDF ﬁles, due to the lack of structural information. To the best of our knowledge, the latest off-theshelf software, Apache PDFBox1, could only provide the coordinates (x, y) and the font style of each character in a PDF document. As table region detection is the fundamental and signiﬁcant step for further information extraction from PDF ﬁles, fruitful approaches have been proposed in recent decades. However, they either simply design heuristic rules based on pre-deﬁned layouts, or adopt supervised learning techniques fed by few annotated corpora from restricted domains. For instance, ICDAR 2013 set up a competition about table detection and structure recognition within 67 annotated PDF documents posted by U.S. and E.U. governments, where each document is accompanied by a XML ﬁle to indicate the location of tables. When we further apply these methods to some free access digital academic archives, such as IEEE Xplore and Springer Link, the variety of layouts and explosive amount of unannotated data expose the urgent demand on unsupervised or semi-supervised frameworks. By means of these frameworks, we do not have to spend much labor on annotation, but can leverage large-scale unlabeled PDF ﬁles. To the best of our knowledge, Klampﬂet al. [1] have recently proposed unsupervised table recognition methods applied on digital scientiﬁc articles. However, their work was',\n",
       " '1708.05221': 'Annually in the United State alone 24,000 adult and 4,830 children will be diagnosed as new cases of brain cancer. A lot of people have died due to brain tumor, multiple sclerosis, ischemic stroke and Alzheimer diseases 1. Medical imaging is an important tool for brain diseases diagnosis in case of surgical or chemical planning. Magnetic Resonance Imaging (MRI) can provide rich information for premedication and surgery medication, which is extremely helpful for evaluating the treatment and lesion progress. However the raw data extracted from MR images is hard to be directly applied for diagnosis due to the large amount of the data. An accurate brain lesion detection and classiﬁcation algorithm based on MR images might be able to improve the prediction accuracy and eﬃciency, that enables a better treatment planning and optimize the diagnostic progress. 1 http://www.cancer.net/cancer-types/brain-tumor/statistics arXiv:1708.05221v1  [cs.CV]  17 Aug 2017  2 Convolutional Neural Networs for Lesions Detection in Brain MRI As mentioned by Menze et al. [5], the number of clinical study for automatic brain lesion detection has grown signiﬁcantly in the last several decades. Some brain lesions such as ischemic strokes, or even tumors can appear with diﬀerent shapes, inappropriate sizes and unpredictable locations within the brain. Furthermore, diﬀerent types of MRI machines with speciﬁc acquisition protocols may provide MR images with a wide variety of gray scale representations on the same lesion cells. Recent research has shown strong ability of Convolutional Neural Network (CNN) for learning hierarchical representation of image data without requiring any eﬀort to design handcrafted features [15,21,10]. This technology became very popular in computer vision society for image classiﬁcation [14,12], object detection [22,8,18], medical image classiﬁcation [17,7] and segmentation[19,6]. As mentioned by LeCun et al. in [15]: diﬀerent layers of a network are capable of diﬀerent levels of abstraction, and capture diﬀerent amount of structures from the patterns present in the image. In this work we investigate the applicability of CNN for brain lesions detection. Our goal is to perform localization and classiﬁcation of single as well as multiple anatomic regions in volumetric clinical images from various image modalities. To this end we propose a novel framework based on CNN with l2norm unit. A detailed evaluation on parameter variations and network architectures has been provided. We show that l2-norm operation unit is robust to the error variations in the classiﬁcation task and is able to improve the prediction result. We conducted experiments on a number of brain MRI datasets, which demonstrate the excellent generalization ability of our approach. The contribution of this work can be summarized as following: – We propose a robust solution for brain lesions classiﬁcation. We achieved promising results on four diﬀerent brain diseases (The overall accuracy is over 95%). – We applied multiple MRI modalities as network input, and this improved the dice coeﬃcient up to 30% on ISLES',\n",
       " '1703.00035': 'Currently, 3D imaging of moving objects is limited by the time it takes to acquire a single image. The slower an imaging modality is, the more likely motion induced artefacts will occur within and between individual slices of a 3D volume. Very fast imaging modalities like Computed Tomography are not always applicable because of harmful ionising radiation, and ultrasound often suﬀers from poor image quality. Thus, Magnetic Resonance Imaging (MRI) is usually the modality of choice when; large ﬁelds of view, high anatomical detail, and noninvasive imaging is required. MRI is often applied to image involuntary moving objects such as the beating heart and examination of the fetus in-utero. Motion compensation for cardiac imagining can be achieved through ECG gating. However, fetal targets do not provide options for gated or tracked image acquisition to compensate for motion. Thus motion compensation is performed during post-processing of oversampled input spaces, usually involving the acquisition arXiv:1703.00035v3  [cs.CV]  23 Sep 2017  2 S. McDonagh et al. of orthogonally oriented stacks of slices [8]. Oversampling with high resolution (HR) slices causes long scan times, which is uncomfortable and risky for patients like pregnant women. This limits the possible number of scan sequences during examination. However, improving image resolution is key to improving accuracy, understanding of anatomy and assessment of organ size and morphology. Imaging at lower resolution increases acquisition speed, thus partly mitigating the likelihood for motion between individual slices but at the cost of missing structural detail that could render the scan inappropriate for diagnostic purposes. Due to signal-to-noise ratio (SNR) limitations, the acquired slices are usually also thick compared to the in-plane resolution and thus negatively inﬂuence the visualization of anatomy in 3D. Na¨ıve up-sampling of fast but low resolution (LR) images is undesirable for the clinical practice, since results lack information. Information content cannot be increased by simply increasing the number of pixels with linear interpolation methods. Therefore, optimization-based super-resolution (SR) methods have been explored to generate rich volumetric information from oversampled input spaces. However, these methods are highly dependant on the quality and amount of input samples and depend on the choice of the objective function. Recent work, e.g. [4], on example-based SR has focused on incorporating additional prior image knowledge, and, in particular, deep neural networks have been employed to solve the single-image SR (SISR) problem. However, the majority of recent contributions typically place strong emphasis on natural images and therefore lack domain speciﬁc high-frequency detail prior knowledge [1]. Contribution: We present a novel approach to SISR in the context of motion compensation when using fast to acquire, low resolution volumes. Taking inspiration from recent investigation of network based SR for MRI modalities [15], we propose a network architecture with convolutional and transposed-convolutional layers and hypothesize that such a deep network architecture can be tailored to context sensitive applications, such as motion',\n",
       " '1312.6064': 'Quantum error correcting codes have been introduced as an alternative to classical codes for use in quantum communication channels. Since the landmark papers [6] and [7], this ﬁeld of research has grown rapidly. Classical codes have been used to construct good quantum codes [1]. Recently, Lisonek and Singh [5] gave a variant of Construction X that produces binary stabilizer quantum codes from arbitrary linear codes. In their construction, the requirement on the duality of the linear codes was relaxed. In this paper, we extend their work on construction X to obtain quantum error-correcting codes over ﬁnite ﬁelds of order p2 where p is a prime number. We apply our results to the dual of Hermitian repeated root cyclic codes to generate new quantum error-correcting codes. The remainder of the paper is organized as follows. In Section 2, we present our main result on the extension of the quantum construction X. Section 3 characterizes the generator polynomial of the Hermitian dual of a repeated root cyclic code. We also give the structure of cyclic codes of length 3ps over Fp2 as well as the structure of the dual codes. Our interest in this class of codes comes from the importance of relaxing the condition (n, p) = 1, which allows us to consider codes other than the simple root codes. 2 Extending Construction X for Fp Let Fp denote the ﬁnite ﬁeld with p elements and F⋆ p = Fp\\\\{0}. For x ∈Fp2 we denote the conjugate of x by x = xp. Let ⟨x, y⟩= Pn i=1 xiyi be the Hermitian inner product. Then the norm of x is deﬁned as ||x|| = ⟨x, x⟩= Pn i=1 xp+1, and the trace of x as Tr(x) = x+ x. Both the trace and norm are mappings from Fp2 to Fp. The following lemmas will be used later. 1  Lemma 1. Let S be a subspace of Fn p2 such that there exist x, y with ⟨x, y⟩̸= 0. Then for all k ∈Fp, there exists z ∈S with ||z|| = k. Proof. This is a non-constructive proof of the existence of the required element z. With the assumption on x and y, let g(c) = ||cx + y|| = (cx + y)p+1 be a polynomial of degree p + 1 in c. We claim that as c ranges over the elements of Fp2, the rhs will range over all elements of Fp. Assume now that there exists some k ∈Fp2 such that ∀c ∈Fp2, g(c) ̸= k. For each i ∈Fp\\\\k, let Si = {c ∈Fp2; g(c) = i}. Since the polynomial g has degree p+1, g can have at most p+1 roots in any ﬁeld. Then |Si| ≤p+1, as the polynomial g(c)−i can have at most p+1 roots, and the Si partition the set Fp2. Then |Fp2| = p2 ≤P i∈Fp\\\\k |Si| ≤(p+1)(p−1) = p2−1, which is a contradiction. Hence the result follows. Lemma 2. Let D be a subspace',\n",
       " '1511.06241': 'Deep neural networks require massive amounts of data to be trained. In large-scale datasets, supervised methods have been successfully trained over the past few years due to the advances in parallel computing (Simonyan & Zisserman, 2014; Szegedy et al., 2014). Popular datasets such as ImageNet (Deng et al., 2009) contain more than a million labeled samples, and even larger datasets are already sought after by researchers in the ﬁeld. Further pushing the boundaries, video datasets are becoming increasingly important in the context of deep neural networks for event recognition tasks. In all such cases, labeling is necessary so that a supervised training algorithm can be used. However, the task of labeling data is quite expensive and time-consuming, requiring tedious work. For example, several hundreds of hours were spent to create ImageNet, and thousand of hours may be needed to annotate even the most simple video dataset (Russakovsky et al., 2015). To circumvent this problem, the research community recognizes that a large breakthrough lies in the use of unlabeled data, which is freely available in abundant quantities. Over the last few decades, extensive research has been dedicated to learning feature hierarchies for deep learning in the context of image understanding. Examples include unsupervised, supervised, and semi-supervised learning. Such deep learning techniques use hierarchy of layers, which use “ﬁlters” to extract multiple input features and “connections” to combine extracted features together into inputs for the next layer. In earlier studies in the ﬁeld, unsupervised pre-training was required for training deep networks by supervised learning methods. Recent advances in Convolutional Neural Networks (ConvNets) combined with abundant amounts of labeled data have shown great promises in object recognition tasks to remedy this issue (Krizhevsky et al., 2012). On the other hand, unsupervised learning algorithms, such as k-means clustering, also increased the number of parameters in the network and achieved state-of-the-art results when labeled data are limited. Although unsupervised learning techniques using k-means algorithm were commonly used to train ﬁlters in several studies (Coates & Ng, 2011b; Bo et al., 2013), the network encoding structures present many similarities with ConvNets, such as the use of convolution and pooling in each layer. The main differences between ConvNets and unsupervised learning techniques based on k-means applied to image recognition are the number of layers (depth) and the number of ﬁlters (width) at 1 arXiv:1511.06241v2  [cs.LG]  16 Feb 2016  Workshop track - ICLR 2016 each layer, and the connections among layers. ConvNets improve accuracy by increasing network depth and width. Recent studies show that, signiﬁcant performance of ConvNets was a result of the increased depth (Zeiler & Fergus, 2014). By contrast, unsupervised learning algorithms for deep networks were not able to scale to the same depth as conventional ConvNets. Therefore, recent unsupervised studies use large network width and two-to-three layers with diminishing returns (Coates & Ng, 2011b). In this work, we demonstrate that learning the connections between the layers of deep neural networks plays a crucial role',\n",
       " '1606.02467': 'Accurate video segmentation is an important step in many high-level computer vision tasks. It can provide for example window proposals for object detection [12,26] or action tubes for action recognition [14,13]. One of the key challenges in video segmentation is on handling the large amount of data. Traditionally, methods either build upon some ﬁne-grained image segmentation [2] or supervoxel [32] method [11,10,21,22,34] or they consist in the grouping of priorly computed point trajectories (e.g. [24,19]) and transform them in a postprocessing step into dense segmentations [23]. The latter is well suited for motion segmentation applications, but has general issues with segmenting non-moving, or only slightly moving, objects. Indeed, image segmentation into small segments forms the basis for many high-level video segmentation methods like [10,22,34]. A key question when employing such preprocessing is the error it introduces. While state-of-the-art image segmentation methods [2,18,3] oﬀer highly precise boundary localization, they usually suﬀer from low temporal consistency, i.e.,the superpixel shapes and sizes can change drastically from one frame to the next. This causes ﬂickering eﬀects in high-level segmentation methods. In this paper, we present a low-level video segmentation method that aims at producing spatio-temporal superpixels with high temporal consistency in a arXiv:1606.02467v1  [cs.CV]  8 Jun 2016  2 M. Keuper and T. Brox Fig. 1. Results of the proposed hierarchical video segmentation method for frame 4, 14 and 24 of the ballet sequence from VSB100 [11]. The segmentation is displayed in a hot color map. Note that corresponding contours have exactly the same value. Segmentations at diﬀerent thresholds in this contour map are segmentations of the spatio-temporal volume. bottom-up way. To this aim, we employ an aﬃnity measure, that has recently been proposed for image segmentation [18]. While other, learning-based methods such as [3] slightly outperform [18] on the image segmentation task, they can hardly be transferred to video data because their boundary detection requires training data that is currently not available for videos. However, in [18], boundary probabilities are learned in an unsupervised way from local image statistics, which can be transferred to video data. To generate hierarchical segmentations, we build upon an established method for low-level image segmentation [2] and make it applicable to video data. More speciﬁcally, we build an aﬃnity matrix according to [18] for each entire video over space and time. Solving for the eigenvectors and eigenvalues of the resulting aﬃnity matrices would require an enormous amount of computational resources. Instead, we show that solving the eigensystem for small temporal windows is suﬃcient and even produces results superior to those computed on the full system. To generate spatio-temporal segmentations from these eigenvectors according to what has been proposed in [2] for images, we need to generate small spatio-temporal segments from the eigenvectors. We do so by extending the oriented watershed transform',\n",
       " '1410.5557': 'FAILED',\n",
       " '1901.09532': 'Electricity management is classically performed by anticipating demand and adjusting accordingly production. The development of smart grids, and in particular the installation of smart meters (see Yan et al., 2013; Mallet et al., 2014), come with new opportunities: getting new sources of information, offering new services. For example, demand-side management (also called demand-side response; see Albadi & El-Saadany, 2007; Siano, 2014 for an overview) consists of reducing or increasing consumption of electricity users when needed, typically reducing at peak times and encouraging consumption of off-peak times. This is good to adjust to intermittency of renewable energies and is made possi1EDF R&D, Palaiseau, France 2Laboratoire de math´ematiques d’Orsay, Universit´e Paris-Sud, CNRS, Universit´e Paris-Saclay, Orsay, France 3INRIA - D´epartement d’Informatique de l’´Ecole Normale Sup´erieure, PSL Research University, Paris, France. Correspondence to: Margaux Br´eg`ere <margaux.bregere@edf.fr>. Proceedings of the 36 th International Conference on Machine Learning, Long Beach, California, PMLR 97, 2019. Copyright 2019 by the author(s). ble by the development of energy storage devices such as batteries or even electric vehicles (see Fischer et al., 2015; Kikusato et al., 2019); the storages at hand can take place at a convenient moment for the electricity provider. We will consider such a demand-side management system, based on price incentives sent to users via their smart meters. We propose here to adapt contextual bandit algorithms to that end, which are already used in online advertising. Other such systems were based on different heuristics (Shareef et al., 2018; Wang et al., 2015). The structure of our contribution is to ﬁrst provide a modeling of this management system, in Section 2. It relies on making the mean consumption as close as possible to a moving target by sequentially picking price allocations. The literature discussion of the main ingredient of our algorithms, contextual bandit theory, is postponed till Section 2.4. Then, our main results are stated and discussed in Section 3: we control our cumulative loss through a T 2/3 regret bound with respect to the best constant price allocation. A reﬁnement as far as convergence rates are concerned is offered in Section 4. A section with simulations based on a real data set concludes the paper: Section 5. For the sake of length, most of the proofs are provided in the supplementary material. Notation. Without further indications, ∥x∥denotes the Euclidean norm of a vector x. For the other norms, there will be a subscript: e.g., the supremum norm of x is is denoted by ∥x∥∞. 2. Setting and Model Our setting consists of a modeling of electricity consumption and of an aim—tracking a target consumption. Both rely on price levels sent out to the customers. 2.1. Modeling of the Electricity Consumption We consider a large population of customers of some electricity provider and assume it homogeneous, which is not an uncommon',\n",
       " '1812.02288': 'Anomaly detection is a problem of great practical signiﬁcance across a range of real-world settings, including cyber-security [1], manufacturing [2], fraud detection, and medical imaging [3]. Fundamentally, anomaly detection methods need to model the patterns in normal data to identify atypical samples. Although anomaly detection is a wellstudied problem [3]–[5], developing effective methods for complex and high-dimensional data remains a challenge. Generative Adversarial Networks (GANs) [6] are a powerful modeling framework for high-dimensional data that could address this challenge. Standard GANs consist of two competing networks, a generator G and discriminator D. G models the data by learning a mapping from latent random variables z (drawn from Gaussian or uniform distributions) to the data space, while D learns to distinguish between real data and samples generated by G. GANs have been empirically successful as a model for natural images [7], [8] and are increasingly being used in speech [9] and medical Proceedings of the 20th IEEE International Conference on Data Mining, Singapore, 2018. All code and hyperparameters can be found at https: //github.com/houssamzenati/Adversarially-Learned-Anomaly-Detection imaging applications. For example, [10] proposes a method that uses a standard GAN for anomaly detection on eye images. However, at test time, the method requires solving an optimization problem for each example to ﬁnd a latent z such that G(z) yields a visually similar image that is also on the image manifold modeled by G; this z is then used to compute an anomaly score for the example. The need to solve an optimization problem for every test example makes this method impractical on large datasets or for real-time applications. In this work, we propose a GAN-based anomaly detection method that is not only effective, but also efﬁcient at test time. Speciﬁcally, our method utilizes a class of GANs that simultaneously learn an encoder network during training [11], [12], thus enabling faster and more efﬁcient inference at test time than [10]. In addition, we incorporate recent techniques to further improve the encoder network [13] and stabilize GAN training [14], and show through ablation studies that these techniques also improve performance on the anomaly detection task. Experiments on a range of highdimensional tabular and image data demonstrate the efﬁciency and effectiveness of our approach. II. RELATED WORK Anomaly detection has been extensively studied, as surveyed in [3]–[5]. As such, here we give a brief overview and refer the reader to these reviews for a more in-depth discussion. A major class of classic anomaly detection methods are distance-based, using distances to nearest neighbors or clusters in the data to assess if data is anomalous. Such methods rely on having an appropriate distance metric for the data. One-class classiﬁcation approaches trained only on normal data such as one-class SVMs [15] are also widely used; these methods learn a classiﬁcation boundary around the normal data. A third class of methods uses ﬁdelity of reconstruction [5',\n",
       " '1811.00613': 'All datasets have biases. Baselines should capture these regularities so that outperforming them indicates a model is actually solving a task. In multimodal domains, bias can occur in any subset of the modalities. To address this, we argue it is not sufﬁcient for researchers to provide random or majority class baselines; instead we recommend presenting results for unimodal models. We investigate visual navigation and question answering tasks, where agents move through simulated environments using egocentric (ﬁrst person) vision. We ﬁnd that unimodal ablations (e.g., language only) in these seemingly multimodal tasks can outperform corresponding full models (§4.1). This work extends observations made in both the Computer Vision (Goyal et al., 2018; Cirik et al., 2018) and Natural Language (Mudrakarta et al., 2018; Glockner et al., 2018; Poliak et al., 2018; Gururangan et al., 2018; Kaushik and Lipton, 2018) communities that complex models often perform well by ﬁtting to simple, unintended correlations in the data, bypassing the complex grounding and reasoning that experimenters hoped was necessary for their tasks. F L R U D E F L R U D E F L R U D E F L R U D E t1 t2 t3 t4 Actions: Forward, turn Left & Right, tilt Up & Down, End Figure 1: Navigating without vision leads to sensible navigation trajectories in response to commands like “walk past the bar and turn right”. At t3, “forward” is unavailable as the agent would collide with the wall. We ablate models from three recent papers: (1) navigation (Figure 1) using images of real homes paired with crowdsourced language descriptions (Anderson et al., 2018); and (2, 3) navigation and egocentric question answering (Gordon et al., 2018; Das et al., 2018a) in simulation with synthetic questions. We ﬁnd that unimodal ablations often outperform the baselines that accompany these tasks. Recommendation for Best Practices: Our ﬁndings show that in the new space of visual navigation and egocentric QA, all modalities, even an agent’s action history, are strongly informative. Therefore, while many papers ablate either language or vision, new results should ablate both. Such baselines expose possible gains from unimodal biases in multimodal datasets irrespective of training and architecture details. 2 Ablation Evaluation Framework In the visual navigation and egocentric question answering tasks, at each timestep an agent receives an observation and produces an action. Actions can move the agent to a new location or heading arXiv:1811.00613v3  [cs.CL]  11 Mar 2019  forward turn left turn right tilt up i forward turn left turn right tilt up tilt down end start Conditional Marginal .36 .44 .43 .54 .54 .393 .255 .257 .22 .22 .16 .071 .012 .012 .001 .00 .00 .00 .00 .00 .00 .00 .02 .02 .01 .01 .01 .01 Figure 2: P(act = col|prev = row) and marginal action distributions in Matterport training. Peaked distributions enable agents to memorize simple rules like not turning left immediately',\n",
       " '1802.03499': 'Deep learning has achieved large successes in many domains of science, business and government for many years because it can provide a kind of end-to-end approach for machine learning and requires very little engineering by hand (LeCun et al., 2015). However, the deep model requires large amount of annotated data for tuning its millions of parameters. Building a large training set for deep learning is sometimes extremely expensive and not acceptable, which hinder deep learning to be applied in more domains. Human can learn a novel concept from just one or few examples (Fei-Fei et al., 2006; Lake et al., 2015a). Can deep *Equal contribution 1College of computer science and engineering,Chongqing University of Technology, Chongqing, China 2College of Computer and Information Science,Chongqing Normal University, Chongqing, China 3School of Software Engineering,Chongqing University, Chongqing, China. Correspondence to: Chuanyun Xu <33677670@QQ.COM>. model learn a new concept from a small training data, and it don’t fall into overﬁtting? This is an opening and challenging question of machine learning. Most of traditional deep learning approaches try to learn functions that map each high-dimensional sample to lower-dimensional space with the least average training error. In nature, they learn some common and global representations from training data for detecting or classifying patterns in the input(LeCun et al., 2015). It is difﬁcult to draw the representation features from a small training set because the distribution of training data might not be identical with the test set. When the training data are sparse and diverse, it becomes more difﬁcult. This is inconsistent with the human beings cognitive behaviors that human can more easily distinguish two completely different kinds of objects, such as a car and an apple. So, we can propose a hypothesis that in the lower cognitive level, human recognizes the objects in a speciﬁc context by contrasting the objects in the context or in her/his memory instead of drawing universal representations for building a global mapping function. Based on the key insights, the paper introduced the Local Contrast Learning (LCL) approach for deep learning. LCL makes use of two key ideas from the human cognitive behavior: (a) Local context:Cognition always base on a local context, and only depends on the local context. Local context consists of a set of objects drawn from the objects in global context for cognition. If the context cannot provide enough information for cognition, the new local context must be built by gathering new information or recalling new memories. To human being, the local context must be a small scenario only with a few target objects. The number of the targets are usually less than seven(Miller, 1967). (b) Contrast:In order to identify an object, the recognition is iteratively executed by contrasting the object and each contrastive object in the local context, and the contrast results of the different contrastive objects are compared again among them',\n",
       " '1804.00775': 'There has been a signiﬁcant progress in the study of visual question answering (VQA) over a short period of time since its introduction, showing rapid boost of performance for common benchmark datasets. This progress has been mainly brought about by two lines of research, the development of better attention mechanisms and the improvement in fusion of features extracted from an input image and question. Since introduced by Bahdanau et al. [3], attention has been playing an important role in solutions of various problems of artiﬁcial intelligence ranging from tasks using single modality (e.g., language, speech, and vision) to multimodal tasks. For VQA, attention on image regions generated from the input question was ﬁrst introduced [32] and then several extensions have been proposed [21, 35, 5]. Meanwhile, researchers have proposed several methods for feature fusion [6, 16, 36], where the aim is to obtain better fused representation of image and question pairs. These studies updated the state-of-the-art for common benchmark datasets at the time of each publication. We observe that these two lines of research have been independently conducted so far. This is particularly the case with the studies of feature fusion methods, where attention is considered to be optional, even though the best performance is achieved with it. However, we think that they are rather two different approaches towards the same goal. In particular, we argue that a better attention mechanism leads to a better fused representation of image-question pairs. Motivated by this, we propose a novel co-attention mechanism for improved fusion of visual and language representations. Given representations of an image and a question, it ﬁrst generates an attention map on image regions for each question word and an attention map on question words for each image region. It then performs computation of attended features, concatenation of multimodal representations, and their transformation by a single layer network with ReLU and a residual connection. These computations are encapsulated into a composite network that we call dense co-attention layer, since it considers every interaction between any image region and any question word. The layer has fully symmetric architecture between the two modalities, and can be stacked to form a hierarchy that enables multi-step interactions between the image-question pair. Starting from initial representations of an input image and question, each dense co-attention layer in the layer stack updates the representations, which are inputted to the next layer. Its ﬁnal output are then fed to a layer for answer prediction. We use additional attention mechanisms in the initial feature extraction as well as the answer prediction layer. We call the entire network including all these components the dense coattention network (DCN). We show the effectiveness of DCNs by several experimental results; they achieve the new state-of-the-art for VQA 1.0 and 2.0 datasets. arXiv:1804.00775v2  [cs.CV]  1 Dec 2018  2',\n",
       " '1701.05013': 'Chronic obstructive pulmonary disease (COPD) is characterized by chronic inﬂammation of the lung airways and emphysema, i.e., degradation of lung tissue [1]. Emphysema can be visually assessed in vivo using chest computed tomography (CT) scans, however, to overcome limitations of visual assessment, automatic quantiﬁcation of emphysema has been explored [2], [3], [4], [5], [6]. Several of these methods rely on supervised learning and require manually annotated regions of interest (ROIs) [2], [3], [4], while other approaches V. Cheplygina was with the Biomedical Imaging Group Rotterdam, Departments of Medical Informatics and Radiology of the Erasmus MC - University Medical Center Rotterdam, Rotterdam, The Netherlands when this work was performed. She is now with the Medical Image Analysis group, Eindhoven University of Technology. E-mail: v.cheplygina@tue.nl I. Pino Pe˜na is with the Department of Health Science and Technology, Aalborg University, Aalborg, Denmark. J. H. Pedersen is with the Department of Thoracic Surgery, Rigshospitalet, University of Copenhagen, Copenhagen, Denmark. D. A. Lynch is with the Department of Radiology, National Jewish Health, Denver, Colorado, United States of America. L. Sørensen and M. de Bruijne are with the Image Section, Department of Computer Science, University of Copenhagen, Copenhagen, Denmark. M. de Bruijne is also with the Biomedical Imaging Group Rotterdam, Departments of Medical Informatics and Radiology of the Erasmus MC - University Medical Center Rotterdam, Rotterdam, Netherlands. E-mail: marleen.debruijne@erasmusmc.nl using multiple instance learning (MIL) only require patientlevel labels indicating overall disease status [5], [6]. In this work we address this weakly-supervised classiﬁcation setting, i.e., the scans are only labeled as belonging to a COPD or nonCOPD subject, and no information on ROI level is available. categorization The problem can be seen as a categorization (assign scan to a COPD or non-COPD category) problem or as a detection (detect whether COPD is present in the scan) problem; to be consistent with machine learning terminology we refer to this problem as “classiﬁcation”. Although we do not focus on quantiﬁcation (quantifying the grade of COPD in the scan), we discuss how our classiﬁcation method can be adapted for this purpose. A challenge for classiﬁcation of COPD in practice is that the training data may not be representative of the test data, i.e. the distributions of the training and the test data are different. This can happen if the data originates from different domains, such as different subject groups, scanners, or scanning protocols. One approach to overcome this problem is to search for features that are robust to such variability. For example, in a multi-cohort study with different CT scanners [4], the authors compare intensity distribution features to local binary pattern (LBP) texture features, and suggest that intensity might be more effective in multi-scanner situations. Another way to explicitly address the differences in the distributions of the training and test data is called transfer learning [7] or domain adaptation. thesedifferences These differences can be caused by different marginal distributions p(x',\n",
       " '1705.02627': 'C OMPLEX systems are ubiquitous; biological, social, transportation networks are examples that we face them on a daily basis. Managing and controlling such systems require learning from data observed and measured at possibly distinct points of the systems. Extracted Data have several intrinsic features: they contain various forms of attributes which are noisy and incomplete; they are massive and usually generated distributively across the networks. Effective and efﬁcient utilization of available resources plays an important role in learning, managing, and controlling of such complex systems. Through a distributed and joint communication-computation design, this paper aims at presenting important machine learning instances where improvement in performance compared to conventional methods can be analytically and experimentally justiﬁed. Many frameworks are developed to handle complex and distributed datasets efﬁciently. Hadoop Distributed File Systems (HDFS) [1], Google File System (GFS) [2] are examples of distributed storage systems. MapReduce [3] and Spark [4] are well known frameworks for distributed data processing systems. These platforms can be used to implement machine learning algorithms naturally [5]. Distributed processing and storage systems are designed to be universal by separating computation and communication tasks. The aim of communication is to exchange information between distributed machines efﬁciently, whereas the aim of computation is to run a distributed algorithm with the given communication platform. However, communication can be adjusted and modiﬁed based on the problem at hand achieving superior results. A new trend in research • M. Tavassolipour, S. A. Motahari, and M. T. Manzuri Shalmani are with the Department of Computer Engineering, Sharif University of Technology, Tehran, Iran. is started to design distributed and joint communicationcomputation optimal systems [6]. In this paper, we present some important machine learning instances in distributed settings and determine analytically and experimentally how one can obtain the optimal trade-off between performance and communication cost. The problem that we focus on is learning of Gaussian Processes (GPs) which are fundamental models applicable to many machine learning tasks. We propose efﬁcient methods for GP learning and analyze the performance and communication cost of the proposed methods. Although GPs can be used for both classiﬁcation and regression, we only consider regression in presented applications and experiments. However, the proposed methods are also applicable to other learning models such as distributed manifold learning, KNN-based algorithms, etc. There exist abundant studies related to distributed learning. Here, we address a few of them which we have found closest to the setting considered in this paper. From information theoretic point of view, distributed statistical inference is addressed by Ahlswede [7], Amari and Han [8], [9], [10]. In their settings, data are assumed to be distributed between two machines and through minimal communication, it is desired to test a hypothesis or estimate a parameter optimally. They used the method of types [11] to obtain some useful error and communication bounds on several problems. A survey by Han et. al. [8] summarizes all early studies in that direction',\n",
       " '1809.04624': 'With image processing and learning approaches rapidly evolving, the ability to make sense of what is going on in a single picture is improving in both scalability and accuracy. However, restoring the visual quality of images acquired from participating media such as underwater environments remains a signiﬁcant challenge for most of the image processing techniques. After all, underwater images are crucial in many critical applications, such as biological research, maintenance of marine vessels, and studies of submerged archaeological sites that cannot be removed from the water. Despite remarkable advances in restoring underwater images with learning methods like Convolutional Neural Networks (CNN), the number of images and the quality of the ground truth data used in training limits these methods. In underwater environments, the light is scattered and absorbed when traveling its way to the camera. As a consequence, objects distant from the camera appear dimmer, with low contrast and color distortion. The ground truth of an underwater image is then another image of the same scene but immersed in a non-participating media without scattering and absorption. Building datasets with high quality and a large number of images is hard or infeasible, in most cases it is difﬁcult to acquire images of an underwater scene in a non-participating media, e.g., images taken from under the sea. Hence, the ability to work with a small number of images or with simulated underwater images plays a key role in restoring the visual quality of underwater images. In this work, we propose a new learning approach for restoring the visual quality of underwater images. Our approach aims at restoring the images by working with simulation data and not demanding a large amount of real data. A set of image quality metrics guides the optimization process toward the restored image. The experiments showed that our approach outperforms other methods qualitatively and quantitatively when considering the quality metric UCIQE [1]. Related Work. Early works on image restoration relied on image processing techniques, which focused mostly on enhancing the contrast level of the scene [2, 3, 4]. In the past decade, the methods based on physical models have emerged as effective approaches to predict the original scene radiance [5, 6, 7, 8, 9, 10]. A typical approach is the Dark Channel Prior (DCP) [8]. The DCP calculation takes the minimum value per channel at each pixel of an image. Mostly applied to outdoor haze-free images, the idea is that at least one of the intensity values from all color channels tends to zero. Because the assumption of the dark channel might not hold in underwater scenes, Drews et al. [9] presented the Underwater Dark Channel Prior (UDCP). The authors used only the blue and green channels since the red channel is dramatically absorbed in underwater. The UDCP achieved better results than those obtained by using the DCP. More recently, learning techniques have shown promising results when used for enhancing the',\n",
       " '1810.05237': 'Text-to-SQL task is one of the most important subtask of semantic parsing in natural language processing (NLP). It maps natural language sentences to corresponding SQL queries. In recent years, some state-of-the-art methods with Seq2Seq encoder-decoder architectures are able to obtain more than 80% exact matching accuracy on some complex text-to-SQL benchmarks such as ATIS and GeoQuery. These models seem to have already solved most problems in this area. 1Code available at https://github.com/taoyds/syntaxsql avg salary dept_name NONE SELECT ROOT HAVING GROUP > dept_name What are the name and lowest instructor salary of the departments with average salary greater than the overall average? Complex input sentence: Database: instructor Table 1 department Table 2 ...... Table n Columns ID name department_name salary .... name building budget  ....... primary\\xa0key foreign\\xa0key Correct SQL  translation: SELECT\\xa0min(salary),\\xa0department_name FROM\\xa0instructor\\xa0 GROUP\\xa0BY\\xa0department_name HAVING\\xa0avg(T1.salary)\\xa0>\\xa0 \\xa0\\xa0\\xa0\\xa0\\xa0(SELECT\\xa0avg(salary)\\xa0FROM\\xa0instructor) Our tree-based SQL generation:  ROOT SELECT salary avg min none salary Figure 1: To address the complex text-to-SQL generation task, SyntaxSQLNet employs a tree-based SQL generator. For example, our model can systematically generate a nested query as illustrated above. However, as (Finegan-Dollak et al., 2018) show, because of the problematic task deﬁnition in the traditional datasets, most of these models just learn to match semantic parsing results, rather than truly learn to understand the meanings of inputs and generalize to new programs and databases. More speciﬁcally, most existing complex text-toSQL datasets have less than 500 SQL labels. They are expanded by paraphrasing 4-10 questions for each SQL query. Under the standard train and test split (Zettlemoyer and Collins, 2005), most queries in the test set also appear in the train set. The WikiSQL dataset recently developed arXiv:1810.05237v2  [cs.CL]  25 Oct 2018  by (Zhong et al., 2017) is much larger and does use different databases for training and testing, but it only contains very simple SQL queries and database schemas. To address those issues in the current semantic parsing datasets, Yu et al. (2018b) have developed a large-scale human labeled text-to-SQL dataset consisting of 10,181 questions, 5,693 unique complex SQL queries, and 200 databases with multiple tables. They split the dataset into train/dev/test by databases, deﬁning a new complex and crossdomain text-to-SQL task that requires models to generalize well to both new SQL queries and databases. The task cannot be solved easily without truly understanding the semantic meanings of the input questions. In this paper, we propose SyntaxSQLNet, a SQL speciﬁc syntax tree network to address the Spider task. Speciﬁcally, to generate complex SQL queries with multiple clauses, selections and sub-queries, we develop a syntax tree-based decoder with SQL generation path history. To make our model learn to generalize to new databases with new tables and columns, we also develop a table-aware',\n",
       " '1811.02545': 'D ATA AUGMENTATION techniques like image cropping, ﬂipping, and jittering play a critical role in improving the performance of deep neural networks on visual recognition tasks like image classiﬁcation [1], [2], object detection [3], [4], and semantic segmentation [5]. Most existing techniques are designed to reduce overﬁtting during training by artiﬁcially creating more training samples. In this paper, we introduce a new general-purpose data augmentation technique called ‘Hide-and-Seek’ which is complementary to existing data augmentation techniques and is beneﬁcial for various visual recognition tasks. The key idea is simple: randomly hide patches from each image during training so that the model needs to seek the relevant visual content from what remains. Figure 1 (bottom row) demonstrates the intuition for the task of image classiﬁcation: if we randomly remove some patches from the image then there is a possibility that the dog’s face, which is the most discriminative part, will not be visible to the model. In this case, the model must seek other relevant parts like the tail and legs in order to do well on the classiﬁcation task. By randomly hiding different patches in each training epoch, the model sees different parts of the image and is forced to focus on multiple relevant parts of the object beyond just the most discriminative one. Importantly, the random hiding of patches need only be applied during training. During testing, the full image can be shown to the network. However, this means that the input data distribution will be different during training versus training, which can be problematic for generalization. We demonstrate that setting the hidden pixels’ value to be the training data mean can allow the two distributions to match, • K. K. Singh, A. Sarmasi, G. Pradeep and Y. J. Lee are with the Department of Computer Science, University of California, Davis, CA, 95616. H. Yu is with Zhejiang University, China. E-mail: krsingh@ucdavis.edu Full image Randomly hidden patches Fig. 1. Main idea. (Top row) A deep network tends to focus on the most discriminative parts of an image (e.g., face of the dog) for classiﬁcation. (Bottom row) By hiding image patches randomly, we can force the network to focus on other relevant object parts in order to correctly classify the image as ‘dog’. and provide a theoretical justiﬁcation. As the network sees partially hidden objects during training, it becomes robust to occlusion. This is the key property that makes Hide-and-Seek different from standard data augmentation techniques like random cropping and ﬂipping, and its advantage is particularly notable for the task of weakly-supervised localization. Weakly-supervised learning is important because it requires less detailed annotations compared to fully-supervised learning, and therefore has the potential to use the vast weakly-annotated visual data available on the Web. For example, weakly-supervised object detectors and segmentation models can be trained using only image-level labels (‘dog’ or ‘no dog’) without any object location annotations [6], [7], [8',\n",
       " '1804.10752': 'Experts have shown signiﬁcant interest in the area of sequenceto-sequence modeling with attention [1, 2, 3, 4] on ASR tasks in recent years. Sequence-to-sequence attention-based models integrate separate acoustic, pronunciation and language models of a conventional ASR system into a single neural network [5] and do not make the conditional independence assumptions as in standard hidden Markov based model [6]. Sequence-to-sequence attention-based models are commonly comprised of an encoder, which consists of multiple recurrent neural network (RNN) layers that model the acoustics, and a decoder, which consists of one or more RNN layers that predict the output sub-word sequence. An attention layer acts as the interface between the encoder and the decoder: it selects frames in the encoder representation that the decoder should attend to in order to predict the next sub-word unit [5]. However, RNNs maintain a hidden state of the entire past that prevents parallel computation within a sequence. In order to reduce sequential computation, the model architecture of the Transformer has been proposed in [7]. This model architecture eschews recurrence and instead relies entirely on an attention mechanism The research work is supported by the National Key Research and Development Program of China under Grant No. 2016YFB1001404. to draw global dependencies between input and output, which allows for signiﬁcantly more parallelization and achieves a new single-model state-of-the-art BLEU on NMT tasks [7]. Since the outstanding performance of the Transformer, this paper focuses on it as the basic architecture of sequence-to-sequence attention-based model on Mandarin Chinese ASR tasks. Recently various modeling units of sequence-to-sequence attention-based models have been studied on English ASR tasks, such as graphemes, CI-phonemes, context-dependent phonemes and word piece models [1, 5, 8]. However, few related works have been explored by sequence-to-sequence attention-based models on Mandarin Chinese ASR tasks. As we know, Mandarin Chinese is a syllable-based language and syllables are their logical unit of pronunciation. These syllables have a ﬁxed number (around 1400 pinyins with tones are used in this work) and each written character corresponds to a syllable. In addition, syllables are a longer linguistic unit, which reduces the difﬁculty of syllable choices in the decoder by sequence-tosequence attention-based models. Moreover, syllables have the advantage of avoiding out-of-vocabulary (OOV) problem. Due to these advantages of syllables, we are concerned with syllables as the modeling unit in this paper and investigate a comparison between CI-phoneme based model and syllable based model with the Transformer on Mandarin Chinese ASR tasks. Moreover, Since we investigate the comparison between CI-phonemes and syllables, these CI-phoneme sequences or syllable sequences from the Transformer have to be converted into word sequences for the performance comparison in terms of CER. The conversion from CI-phoneme sequences or syllable sequences to word sequences can be regarded as a sequenceto-sequence',\n",
       " '1809.04185': 'In the past few years, the most popular representation learning frameworks are dictionary learning and deep learning. Dictionary learning aims at learning a set of atoms such that a given feature can be well approximated by a sparse linear combination of these atoms, while deep learnFigure 1: Multiple local coordinates and “fake” anchor points. Suppose that we want to encode the input signal yi∈Rm in order to ﬁnd the nonlinear function deﬁned on it, for instance with three local coordinates in the same space Rm. In fact, yi relies on the manifold that can be described by the 3rd local coordinate, but unfortunately, we do not have enough atoms (anchor points) on the 3rd manifold close to it. Therefore, some nearby atoms (“fake” anchor points) from the 1st or 2nd local coordinate will “kidnap” yi, overlooking in this way the true coordinate (3rd), where yi really resides. This happens due to the small numbers of training samples and/or a large variety of signals, arriving at overﬁtting even though the learned model ﬁts the training samples well. ing methods focus on extracting semantic features via a deep network. So far most studies in dictionary learning employ a shallow (single layer) architecture, e.g., currently popular dictionary learning techniques are K-SVD [1], Discriminative K-SVD (D-KSVD) [57] and Label Consistent K-SVD (LC-KSVD) [20] which decompose the training data into a dense basis and sparse coefﬁcients. In addition, both Local Coordinate Coding (LCC) [55, 54] and arXiv:1809.04185v2  [cs.CV]  25 Dec 2018  Figure 2: The pipeline of the Deep Micro-Dictionary Learning and Coding Network (DDLCN). The idea of DDLCN comes from the architectures of CNNs, while the difference from CNNs is that the convolutional layers in CNNs are replaced by our compound dictionary learning and coding layers. its fast implementation algorithm [43] are traditional dictionary learning methods. LCC and Locality Constrained Coding (LLC) [43] are based on the empirical observation that the sparse representations tend to be “local”. In other words, nonzero coefﬁcients are often assigned to the atoms nearby to the encoded signal y. However, LLC has a major disadvantage: to achieve higher approximation, one has to use a large number of so-called “anchor points” to make a better linear approximation of the signal. Since LLC is a local linear approximation of a complex signal yi, for a nonlinear function on yi the local linear approximation may not necessarily be optimal. It means that the anchor points need to provide higher approximation power, allowing some of them to not necessary be “real” local anchors on the manifold where yi resides. In this context, our goal is to equip anchors with more descriptive power for better approximating yi in order to ﬁnally make more accurate inferences from it. An illustrative example is shown in Figure 1. Recent work [40] has shown that deeper architectures can be built from dictionary learning. Chun et al. [8] present a Block Proximal Gradient method using a Majorizer for',\n",
       " 'cs/0605006': 'In this correspondence, we study the classic problem in multiterminal rate-distortion theory, i.e., multiterminal source coding problem. In this problem, M (M ≥2) correlated general sources have to be compressed separately from each other in a lossy fashion, i.e., with respect to a ﬁdelity criterion, and then decoded by the common decoder which has access to a side information source that is correlated with the sources to be compressed. This situation is illustrated in Fig. 1, and it is also called distributed source coding. The well-known Slepian-Wolf coding problem and the Wyner-Ziv coding problem can be   Encoder 1  Encoder 2  Encoder m          Decoder n S n M X 2 n X 1 n X 1 n Y 2 n Y n M Y 1 R 2 R m R Fig. 1. Separate compression of M correlated general sources with side information at the decoder regarded as two special cases of this situation. These two special cases were solved in 1970’s for stationary memoryless sources [1], [2], and later extended to the case of general sources [3], [4]. However, for this general problem, no conclusive results are available to date. Even for the special case that the sources are memoryless and stationary and the distortion measure is additive, only inner and outer bounds are derived in [5], [6], etc. In this correspondence, we adopt an information-spectrum approach to solve this open problem for general sources under maximum distortion criterions. We obtain the rate-distortion region for correlated general sources, which is the main contribution of this correspondence. The rest of this correspondence is organized as follows. In Section II, we ﬁrst brieﬂy introduce required notations and deﬁnitions in information-spectrum methods [7], and then formally state the multiterminal source coding problem. In Section III, the main theorem concerning the rate-distortion region is presented and discussed. All the proofs are ﬁnally given in Section IV. II. NOTATIONS AND DEFINITIONS A general source X with alphabet X is characterize by an inﬁnite sequence {Xn = (X(n) 1 , X(n) 2 , · · · , X(n) n )}∞ n=1  SUBMITTED TO IEEE TRANSACTIONS ON INFORMATION THEORY FOR PEER REVIEW (APRIL 28, 2006) 2 of n-dimensional random variables Xn taking values in the n-th Cartesian product X n, and in this correspondence, all the alphabets are assumed to be ﬁnite. Speciﬁcally, for M (M ≥2) correlated general sources, each general source Xm (1 ≤m ≤M) with alphabet Xm is an inﬁnite sequence denoted by {Xn m = (X(n) m,1, X(n) m,2, · · · , X(n) m,n)}∞ n=1, and the whole group of correlated general sources is denoted by (Xm)m∈IM, where IM denotes the set {1, 2, · · ·, M}. Analogously, any part of (Xm)m∈IM is denoted by (Xm)m∈A, where A ⊆IM. In most situations, A is also assumed to be an ordered set, hence (Xm)m∈A is virtually a vector. Similar notations apply to any related quantities or functions',\n",
       " '1803.02392': 'In the past few years the use of emojis in social media has increased exponentially, changing the way we communicate. The combination of visual and textual content poses new challenges for information systems which need not only to deal with the semantics of text but also that of images. Recent work (Barbieri et al., 2017) has shown that textual information can be used to predict emojis associated to text. In this paper we show that in the current context of multimodal communication where texts and images are combined in social networks, visual information should be combined with texts in order to obtain more accurate emojiprediction models. We explore the use of emojis in the social media platform Instagram. We put forward a multimodal approach to predict the emojis associated to an Instagram post, given its picture and text1. Our task and experimental framework are similar to (Barbieri et al., 2017), however, we use different data (Instagram instead of Twitter) and, in addition, we rely on images to improve the selection of the most likely emojis to associate to a post. We show that a multimodal approach (textual and visual content of the posts) increases the emoji prediction accuracy compared to the one that only uses textual information. This suggests that textual and visual content embed different but complementary features of the use of emojis. In general, an effective approach to predict the emoji to be associated to a piece of content may help to improve natural language processing tasks (Novak et al., 2015), such as information retrieval, generation of emoji-enriched social media content, suggestion of emojis when writing text messages or sharing pictures online. Given that emojis may also mislead humans (Miller et al., 2017), the automated prediction of emojis may help to achieve better language understanding. As a consequence, by modeling the semantics of emojis, we can improve highly-subjective tasks like sentiment analysis, emotion recognition and irony detection (Felbo et al., 2017). 2 Dataset and Task Dataset: We gathered Instagram posts published between July 2016 and October 2016, and geolocalized in the United States of America. We considered only posts that contained a photo together with the related user description of at least 4 words and exactly one emoji. Moreover, as done by Barbieri et al. (2017), we considered only the posts which include one and only one of the 20 most frequent emojis (the 1In this paper we only utilize the ﬁrst comment issued by the user who posted the picture. arXiv:1803.02392v2  [cs.CL]  17 Apr 2018  most frequent emojis are shown in Table 3). Our dataset is composed of 299,809 posts, each containing a picture, the text associated to it and only one emoji. In the experiments we also considered the subsets of the 10 (238,646 posts) and 5 most frequent emojis (184,044 posts) (similarly to the approach followed by Barbieri',\n",
       " '1810.10875': 'Distributed computing platforms are the current method of choice for the implementation of many computational tasks, such as learning algorithms [1]. A standard distributed computing framework is Map-Shufﬂe-Reduce. Under this protocol, nodes ﬁrst “map” the assigned data to some Intermediate Values (IVs) through the computation of given functions; then, IVs are ”shufﬂed” among the nodes; and ﬁnally nodes produce their ﬁnal result by “reducing” the relevant IVs. An important performance bottleneck for these systems is the communication load caused by the shufﬂing of IVs among the participating computing nodes [2]–[5]. It was recently observed that the communication load can be reduced if the computations carried out at the nodes in the Map phase have some degree of redundancy, in the sense that IVs computed at a node are also computed at other nodes. In the original works [2]–[5], nodes are connected by noiseless multicast channels. The availability of redundant IVs is leveraged to create coded multicasting opportunities, whereby the signal multicast by one node provides useful information for a number arXiv:1810.10875v2  [cs.IT]  26 Oct 2018  2 of other nodes that is proportional to the computing redundancy. A signiﬁcant number of follow-up works has offered various reﬁnements of this idea [6]–[9]. While the approaches reviewed above leverage the availability of redundant IVs at the receiver end of a multicast link, an alternative solution arises when the computing nodes are connected over a shared wireless channel. This scenario may be of interest, for instance, for distributed computing platforms in Internet-of-Things applications. On a wireless channel, the presence of common IVs can be leveraged to create cooperative transmission opportunities. Based on this idea, reference [10] proposed a cooperative Zero-Forcing (ZF) precoding strategy. This approach was shown to outperform coded multicasting in the presence of full-duplex nodes and under the assumption that perfect Channel State Information (CSI) is available to design the precoding matrices. In this paper, a novel scheme based on superposition coding is proposed that is demonstrated to outperform both coded multicasting and cooperative transmission under the assumption that imperfect, or outdated, CSI is available for precoding design. As in [10], analysis is carried out by focusing on a high-Signal-to-Noise Ratio (SNR) measure of the inter-node communication load in the Shufﬂe phase. The proposed approach reduces to coded multicasting [5] when CSI is completely unreliable and to cooperative ZF precoding [10] when CSI is perfect. This work contributes to a recent line of work that has demonstrated the advantages of superposition coding in the absence of perfect CSI [11], [12]. The rest of the paper is organized as follows. Section 2 describes the system model and the performance criterion. In Section 3, we review and analyze the two reference schemes studied in [5] and [10]. Section 4 presents the proposed superposition coding-based scheme, and Section 5 presents some results and discussion. Notation: For any integer P and J, we deﬁne the set [P] .= {1',\n",
       " '1502.00743': 'One typical vision problem usually comprises several subproblems, which tend to be tackled jointly to achieve superior capability. In this paper, we focus on a general joint task learning framework based on deep neural networks, and demonstrate its effectiveness and efﬁciency on generic (i.e., category-independent) object extraction. Generally speaking, two sequential subtasks are comprised in object extraction: rapidly localizing the objects-of-interest from images and further generating segmentation masks based on the localizations. Despite acknowledged progresses, previous approaches often tackle these two tasks independently, and most of them applied sliding windows over all image locations and scales [17, 22], which could limit their performances. Recently, several works [33, 18, 5] utilized the interdependencies of object localization and segmentation, and showed promising results. For example, Yang et al. [33] introduced a joint framework for object segmentations, in which the segmentation beneﬁts from the object detectors and the object detections are in consistent with the underlying segmentation of the ∗Corresponding author is Liang Lin (E-mail: linliang@ieee.org). This work was supported by the National Natural Science Foundation of China (no.61173082), the Hi-Tech Research and Development Program of China (no.2012AA011504), Guangdong Science and Technology Program (no. 2012B031500006), Special Project on Integration of Industry, Educationand Research of Guangdong (no.2012B091000101), and Fundamental Research Funds for the Central Universities (no.14lgjc11). 1 arXiv:1502.00743v1  [cs.CV]  3 Feb 2015  image. However, these methods still rely on the exhaustively searching to localize objects. On the other hand, deep learning methods have achieved superior capabilities in classiﬁcation [21, 19, 23] and representation learning [4], and they also demonstrate good potentials on several complex vision tasks [29, 30, 20, 25]. Motivated by these works, we build a deep learning architecture to jointly solve the two subtasks in object extraction, in which each task (either object localization or object segmentation) is tackled by a multi-layer convolutional neural network. Speciﬁcally, the ﬁrst network (i.e., localization network) directly predicts the positions and scales of salient objects from raw images, upon which the second network (i.e., segmentation network) generates the pixelwise object masks. (a) (b) Groundtruth Mask Segmentation Results Groundtruth Mask Segmentation Results Figure 1: Motivation of introducing latent variables in object extraction. Treating predicted object localizations (the dashed red boxes) as the inputs for segmentation may lead to unsatisfactory segmentation results, and we can make improvements by enlarging or shrinking the localizations (the solid blue boxes) with the latent variables. Two examples are shown in (a) and (b), respectively. Rather than being simply stacked up, the two networks are collaboratively integrated with latent variables to boost performance. In general, the two networks optimized for different tasks might have inconsistent interests. For example, the object localizations predicted by the ﬁrst network probably indicate incomplete object (foreground) regions or include a lot of backgrounds, which may lead to unsatisfactory pixelwise segmentation. This observation is well illustrated in Fig. 1, where we can obtain better segmentation results',\n",
       " '1506.03662': 'We consider a general problem that is pervasive in machine learning, namely optimization of an empirical or regularized convex risk function. Given a convex loss l and a µ-strongly convex regularizer Ω, one aims at ﬁnding a parameter vector w which minimizes the (empirical) expectation: w∗= argmin w f(w), f(w) = 1 n n X i=1 fi(w), fi(w) := l(w, (xi, yi)) + Ω(w) . (1) We assume throughout that each fi has L-Lipschitz-continuous gradients. Steepest descent can ﬁnd the minimizer w∗, but requires repeated computations of full gradients f ′(w), which becomes prohibitive for massive data sets. Stochastic gradient descent (SGD) is a popular alternative, in particular in the context of large-scale learning [2, 10]. SGD updates only involve f ′ i(w) for an index i chosen uniformly at random, providing an unbiased gradient estimate, since Ef ′ i(w) = f ′(w). It is a surprising recent ﬁnding [11, 5, 9, 6] that the ﬁnite sum structure of f allows for signiﬁcantly faster convergence in expectation. Instead of the standard O(1/t) rate of SGD for strongly-convex functions, it is possible to obtain linear convergence with geometric rates. While SGD requires asymptotically vanishing learning rates, often chosen to be O(1/t) [7], these more recent methods introduce corrections that ensure convergence for constant learning rates. Based on the work mentioned above, the contributions of our paper are as follows: First, we deﬁne a family of variance reducing SGD algorithms, called memorization algorithms, which includes SAGA and SVRG as special cases, and develop a unifying analysis technique for it. Second, we 1 arXiv:1506.03662v4  [cs.LG]  26 Feb 2016  show geometric rates for all step sizes γ < 1 4L, including a universal (µ-independent) step size choice, providing the ﬁrst µ-adaptive convergence proof for SVRG. Third, based on the above analysis, we present new insights into the trade-offs between freshness and biasedness of the corrections computed from previous stochastic gradients. Fourth, we propose a new class of algorithms that resolves this trade-off by computing corrections based on stochastic gradients at neighboring points. We experimentally show its beneﬁts in the regime of learning with a small number of epochs. 2 Memorization Algorithms 2.1 Algorithms Variance Reduced SGD Given an optimization problem as in (1), we investigate a class of stochastic gradient descent algorithms that generates an iterate sequence wt (t ≥0) with updates taking the form: w+ = w −γgi(w), gi(w) = f ′ i(w) −¯αi with ¯αi := αi −¯α, (2) where ¯α := 1 n Pn j=1 αj. Here w is the current and w+ the new parameter vector, γ is the step size, and i is an index selected uniformly at random. ¯αi are variance correction terms such that E¯αi = 0, which guarantees unbiasedness Egi(w) = f ′(w). The aim is to deﬁne updates of asymptotically vanishing variance, i.e. gi(w) →0 as w →w∗, which requires ¯αi →f ′ i',\n",
       " '1808.03314': 'Since the original 1997 LSTM paper [21], numerous theoretical and experimental works have been published on the subject of this type of an RNN, many of them reporting on the astounding results achieved across a wide variety of application domains where data is sequential. The impact of the LSTM network has been notable in language modeling, speech-to-text transcription, machine translation, and other applications [31]. Inspired by the impressive benchmarks reported in the literature, some readers in academic and industrial settings decide to learn about the Long Short-Term Memory network (henceforth, “the LSTM network”) in order to gauge its applicability to their own research or practical use-case. All major open source machine learning frameworks offer efficient, production-ready implementations of a number of RNN and LSTM network architectures. Naturally, some practitioners, even if new to the RNN/LSTM systems, take advantage of this access and cost-effectiveness and proceed straight to development and experimentation. Others seek to understand every aspect of the operation of this elegant and effective system in greater depth. The advantage of this lengthier path is that it affords an opportunity to build a certain degree of intuition that can prove beneficial during all phases of the process of incorporating an open source module to suit the needs of their research effort or a business application, preparing the dataset, troubleshooting, and tuning. In a common scenario, this undertaking balloons into reading numerous papers, blog posts, and implementation guides in search of an “A through Z” understanding of the key principles and functions of the system, only to find out that, unfortunately, most of the resources leave one or more of the key questions about the basics unanswered. For example, the Recurrent Neural Network (RNN), which is the general class of a neural network that is the predecessor to and includes the LSTM network as a special case, is routinely simply stated without precedent, and unrolling is presented without justification. Moreover, the training equations are often omitted altogether, leaving the reader puzzled and searching for more resources, while having to reconcile disparate notation used therein. Even the most oft-cited and celebrated primers to date have fallen short of providing a comprehensive introduction. The combination of descriptions and colorful diagrams alone is not actionable, if the architecture description is incomplete, or if important components and formulas are absent, or if certain core concepts are left unexplained. As of the timeframe of this writing, a single self-contained primer that provides a clear and concise explanation of the Vanilla LSTM computational cell with well-labeled and logically composed schematics that go hand-in-hand with the formulas is still 1The nickname “Vanilla LSTM” symbolizes this model’s flexibility and generality [17]. 1 arXiv:1808.03314v10  [cs.LG]  31 Jul 2023  lacking. The present work is motivated by the conviction that a unifying reference, conveying the basic theory underlying the RNN and the LSTM network, will benefit the Machine Learning (ML) community. The present article is an',\n",
       " '1406.6959': 'Entropy and related information measures arise in information theory, statistics, machine learning, biology, neuroscience, image processing, linguistics, secrecy, ecology, physics, and ﬁnance, among other ﬁelds. Numerous inferential tasks rely on data driven procedures to estimate these quantities (see, e.g. [1]–[6]). We focus on two concrete and well-motivated examples of information measures, namely the Shannon entropy [7] H(P) ≜ S X i=1 −pi ln pi, (1) and the power sum Fα(P), α > 0: Fα(P) ≜ S X i=1 pα i , α > 0. (2) The power sum Fα(P) functional often emerges in various operational problems [8]. It also has connections to the R´enyi entropy [9] Hα(P) via the formula Hα(P) = ln Fα(P ) 1−α . Consider estimating the Shannon entropy H(P) based on n i.i.d. samples following unknown discrete distribution P with unknown alphabet size S. This problem has a rich history with extensive study in various ﬁelds ranging from information theory, statistics, neuroscience, physics, psychology, medicine, etc. We refer the reader to [10] for a review. One of the most widely used estimators for this purpose is the Maximum Likelihood Estimator (MLE), which is simply the empirical entropy. The empirical entropy is an instantiation of the plugin principle in functional estimation, where a point estimate of the parameter (distribution P in this case) is used to construct an estimator for a functional of the parameter via the plug-in approach. The idea of using the MLE for estimating information measures of interest (in this case entropy), is not only intuitive, but has sound justiﬁcation: asymptotic efﬁciency. The beautiful theory of H´ajek and Le Cam [11]–[13] shows that, as the number of observed samples grows without bound while the ﬁnite parameter dimension (e.g., alphabet size) remains ﬁxed, the MLE performs optimally in estimating any differentiable functional when the statistical model complies with the benign LAN (Local Asymptotic Normality) condition [13]. Thus, for ﬁnite dimensional problems, the problems  2 of parameter and functional estimation are well understood in an asymptotic sense, and the MLE appears to be not only natural but also theoretically justiﬁed. But does it make sense to employ the MLE to estimate the entropy in most practical applications? As it turns out, while asymptotically optimal in entropy estimation, the MLE is by no means sacrosanct in many real applications, especially in regimes where the alphabet size is comparable to, or even larger than the number of observations. It was shown that the MLE for entropy is strictly sub-optimal in the large alphabet regime [14], [15]. Therefore, classical asymptotic theory does not satisfactorily address high dimensional settings, which are becoming increasingly important in the modern era of high dimensional statistics. There has been a wave of recent research activities focusing on analyzing existing approaches of functional estimation, as well as proposing new estimators that are provably near optimal in the large alphabet regime. Paninski [14] showed that the MLE',\n",
       " '1804.06609': 'One appeal of the phrase-based statistical approach to machine translation (Koehn et al., 2003) was that it provided control over system output. For example, it was relatively easy to incorporate domain-speciﬁc dictionaries, or to force a translation choice for certain words. These kinds of interventions were useful in a range of settings, including interactive machine translation or domain adaptation. In the new paradigm of neural machine translation (NMT), these kinds of manual interventions are much more difﬁcult, and a lot of time has been spent investigating how to restore them (cf. Arthur et al. (2016)). At the same time, NMT has also provided new capabilities. One interesting recent innovation is 1https://awslabs.github.io/sockeye/ inference.html#lexical-constraints No one has the intention of building a wall. “errichten” Niemand hat die Absicht, eine Mauer zu bauen.\\u2028 “No one has the intention, a wall to build.” Niemand hat die Absicht, eine Mauer zu errichten.\\u2028 “No one has the intention, a wall to construct.” “Keiner” “Keiner”\\u2028 \"errichten” Keiner hat die Absicht, eine Mauer zu bauen.\\u2028 “No one has the intention, a wall to build.” Keiner hat die Absicht, eine Mauer zu errichten.\\u2028 “No one has the intention, a wall to construct.” Figure 1: An example translating from English to German. The ﬁrst translation is unconstrained, whereas the remaining ones have one or two constraints imposed. A word-for-word translation of the German output has been provided for the convenience of nonGerman speaking readers. lexically constrained decoding, a modiﬁcation to beam search that allows the user to specify words and phrases that must appear in the system output (Figure 1). Two algorithms have been proposed for this: grid beam search (Hokamp and Liu, 2017, GBS) and constrained beam search (Anderson et al., 2017, CBS). These papers showed that these algorithms do a good job automatically placing constraints and improving results in tasks such as simulated post-editing, domain adaptation, and caption generation. A downside to these algorithms is their runtime complexity: linear (GBS) or exponential (CBS) in the number of constraints. Neither paper reported decoding speeds, but the complexities alone suggest a large penalty in runtime. Beyond this, other factors of these approaches (a variable sized beam, ﬁnite-state machinery) change the decoding procedure such that it is difﬁcult to integrate with other operations known to increase throughput, like batch decoding. We propose and evaluate a new algorithm, dynamic beam allocation (DBA), that is constant in the number of provided constraints (Table 1). Our arXiv:1804.06609v2  [cs.CL]  9 Nov 2018  work complexity Anderson et al. (2017) O(Nk2C) Hokamp and Liu (2017) O(NkC) This work O(Nk) Table 1: Complexity of decoding (sentence length N, beam size k, and constraint count C) with target-side constraints under various approaches. algorithm works by grouping together hypotheses that have met the same number of constraints into banks (similar in spirit to the grouping of hypotheses into stacks for phrase-based decoding (Koehn',\n",
       " '1602.01921': 'R ECENTLY, a convolutional neural network (CNN) [1], inspired by a mammalian visual cortex, showed a remarkably better object image recognition performance than conventional vision recognition schemes which employ elaborately hand-coded visual features. A CNN trained with 1 million visual images from ImageNet [2] was able to classify hundreds of object images with an error rate of 6.67% [3], and demonstrated near-human performance [4]. However, CNNs lack the capacity for temporal information processing. As a consequence, CNNs are less effective in handling video image patterns than static images. To address this shortcoming, a number of action recognition models have been developed. Typical deep learning models H. Lee is with the Department of Electrical Engineering, Korea Institute of Science and Technology, Daejeon 305-701, Republic of Korea, e-mail: (haanvidlee@gmail.com). M. Jung is with the Department of Electrical Engineering, Korea Institute of Science and Technology, Daejeon 305-701, Republic of Korea, e-mail: (minju5436@gmail.com). J. Tani is with the Department of Electrical Engineering, Korea Institute of Science and Technology, Daejeon 305-701, Republic of Korea, and also with the Okinawa Institute of Science and Technology, Okinawa 904-0412, Japan, e-mail: (tani1216jp@gmail.com). for action recognition are 3D convolutional neural networks (3D-CNNs) [5], long-term recurrent convolutional networks (LRCNs) [6], and two-stream convolutional networks [7]. The 3D-CNN extracts spatio-temporal features of videos through convolutions in the temporal and spatial domains in a ﬁxed window [5]. The LRCN is a two-stage model that ﬁrst extracts spatial features in its CNN stage and then extracts temporal features from its long-short term memory (LSTM) [8] stage [8]. And the two-stream convolutional network has one CNN stream for an RGB input, and the other CNN stream for an input of stacked optical ﬂows. The two streams are joined at the end to make a categorical output [7]. Although the 3D-CNN, LRCN, and two-stream convolutional network perform well, some of their dynamics are not consistent with neuroscientiﬁc evidences. One important piece of evidence in mammals is that the size of the spatio-temporal receptive ﬁeld of each cell is increased as the level goes higher [9], [10]. And a principle from cybernetics era, so-called the downward causation [11], [12] suggests that a spatio-temporal hierarchy can be naturally developed in human brains by taking advantage of macroscopic constraints genetically assigned to them. The evidence and principle suggest that a deep learning model for action recognition should form a hierarchy by assignment of spatio-temporal constraints. And the model should extract spatial and temporal features simultaneously in their hierarchy. But the representative action recognition models lack such properties. The current study is an extension of the prior study using so-called the multiple spatio-temporal scales neural network (MSTNN) [13]. The neural activity in the MSTNN is governed by both spatial and temporal constraints by means of local connectivity of convolutional layers and time',\n",
       " '1609.09869': 'Models of sequence data such as hidden Markov models (HMMs) and recurrent neural networks (RNNs) are widely used in machine translation, speech recognition, and computational biology. Linear and non-linear Gaussian state space models (GSSMs, Fig. 1) are used in applications including robotic planning and missile tracking. However, despite huge progress over the last decade, efﬁcient learning of non-linear models from complex high dimensional time-series remains a major challenge. Our paper proposes a uniﬁed learning algorithm for a broad class of GSSMs, and we introduce an inference procedure that scales easily to high dimensional data, compiling approximate (and where feasible, exact) inference into the parameters of a neural network. In engineering and control, the parametric form of the GSSM model is often known, with typically a few speciﬁc parameters that need to be ﬁt to data. The most commonly used approaches for these types of learning and inference problems are often computationally demanding, e.g. dual extended Kalman ﬁlter (Wan and Nelson 1996), expectation maximization (Briegel and Tresp 1999; Ghahramani and Roweis 1999) or particle ﬁlters (Schön, Wills, and Ninness 2011). Our compiled inference algorithm can easily deal with high-dimensions both in the observed Copyright c⃝2017, Association for the Advancement of Artiﬁcial Intelligence (www.aaai.org). All rights reserved. and the latent spaces, without compromising the quality of inference and learning. When the parametric form of the model is unknown, we propose learning deep Markov models (DMM), a class of generative models where classic linear emission and transition distributions are replaced with complex multi-layer perceptrons (MLPs). These are GSSMs that retain the Markovian structure of HMMs, but leverage the representational power of deep neural networks to model complex high dimensional data. If one augments a DMM model such as the one presented in Fig. 1 with edges from the observations xt to the latent states of the following time step zt+1, then the DMM can be seen to be similar to, though more restrictive than, stochastic RNNs (Bayer and Osendorfer 2014) and variational RNNs (Chung et al. 2015). Our learning algorithm performs stochastic gradient ascent on a variational lower bound of the likelihood. Instead of introducing variational parameters for each data point, we compile the inference procedure at the same time as learning the generative model. This idea was originally used in the wake-sleep algorithm for unsupervised learning (Hinton et al. 1995), and has since led to state-of-the-art results for unsupervised learning of deep generative models (Kingma and Welling 2014; Mnih and Gregor 2014; Rezende, Mohamed, and Wierstra 2014). Speciﬁcally, we introduce a new family of structured inference networks, parameterized by recurrent neural networks, and evaluate their effectiveness in three scenarios: (1) when the generative model is known and ﬁxed, (2) in parameter estimation when the functional form of the model is known and (3) for learning deep Markov models. By looking at the structure of the true',\n",
       " '1612.07360': 'Neural saliency methods have recently emerged as an effective mechanism for top-down task-driven visual search [4, 31]. They can efﬁciently extract saliency heatmaps given a high-level semantic input, e.g., highlighting regions corresponding to an object category, without any per-pixel supervision at training time. They can also explain the internal representations learned by CNNs [19, 30]. However, suppose we wanted to search a visual scene for salient elements described by a natural language sentence (Fig. 1(a)), or, given the description of an action, localize the most salient temporal and spatial regions corresponding to the subject, verb and other components (Fig. 1(b)). Classiﬁcation-based saliency methods are insufﬁcient for such language-driven tasks as they are limited to isolated object labels and cannot handle textual queries. (a) Input: A man in a jacket is standing at the slot machine ... 1 2 m −1 m woman cutting piece meat (b) Input: A woman is cutting a piece of meat Figure 1: Top-down Caption-Guided Visual Saliency approach that generates, for each word in a sentence, (a) spatial saliency in image and (b) spatiotemporal saliency in videos. For the video, we show temporally most important frames corresponding to the words at the bottom (arrows show positions of frames in the video) and spatial heatmaps indicating salient regions for these words. Deep image and video captioning models [6, 23, 24, 28] excel at learning representations that translate visual input into language potentially discovering a mapping between visual concepts and words. However, despite the good captioning performance, they can be very hard to understand and are often criticized for being highly non-transparent “black boxes.” They hardly provide any clear insight of the mapping learned internally between the image and the produced words. Consider for example, the video shown in Fig. 1(b). Which region in the model is used to predict arXiv:1612.07360v2  [cs.CV]  12 Apr 2017  words like “woman” or “meat” in the generated caption? Is the word “woman” generated because the model recognized the woman in the video, or merely because the language model predicts that “A woman” is a likely way to start a sentence? Can the model learn to localize visual concepts corresponding to words while training only on weak annotations in the form of image or video-level captions? Can it localize words both in space and in time? In this work, we address these questions by proposing a Caption-Guided Visual Saliency method that leverages deep captioning models to generate top-down saliency for both images and videos. Our approach is based on an encoderdecoder captioning model, and can produce spatial or spatiotemporal heatmaps for either a given input caption or a caption predicted by our model (Fig. 1). In addition to facilitating visual search, this allows us to expose the inner workings of deep captioning models and provide much needed intuition of what these models are actually learning. This, in',\n",
       " '1703.04247': 'The prediction of click-through rate (CTR) is critical in recommender system, where the task is to estimate the probability a user will click on a recommended item. In many recommender systems the goal is to maximize the number of clicks, and so the items returned to a user can be ranked by estimated CTR; while in other application scenarios such as online advertising it is also important to improve revenue, and so the ranking strategy can be adjusted as CTR×bid across all candidates, where “bid” is the beneﬁt the system receives if the item is clicked by a user. In either case, it is clear that the key is in estimating CTR correctly. It is important for CTR prediction to learn implicit feature interactions behind user click behaviors. By our study in a mainstream apps market, we found that people often download apps for food delivery at meal-time, suggesting that the (order-2) interaction between app category and time-stamp ∗This work is done when Huifeng Guo worked as intern at Noah’s Ark Research Lab, Huawei. †Corresponding Author. Figure 1: Wide & deep architecture of DeepFM. The wide and deep component share the same input raw feature vector, which enables DeepFM to learn lowand high-order feature interactions simultaneously from the input raw features. can be used as a signal for CTR. As a second observation, male teenagers like shooting games and RPG games, which means that the (order-3) interaction of app category, user gender and age is another signal for CTR. In general, such interactions of features behind user click behaviors can be highly sophisticated, where both lowand high-order feature interactions should play important roles. According to the insights of the Wide & Deep model [Cheng et al., 2016] from google, considering lowand high-order feature interactions simultaneously brings additional improvement over the cases of considering either alone. The key challenge is in effectively modeling feature interactions. Some feature interactions can be easily understood, thus can be designed by experts (like the instances above). However, most other feature interactions are hidden in data and difﬁcult to identify a priori (for instance, the classic association rule “diaper and beer” is mined from data, instead of discovering by experts), which can only be captured automatically by machine learning. Even for easy-to-understand interactions, it seems unlikely for experts to model them exhaustively, especially when the number of features is large. Despite their simplicity, generalized linear models, such as FTRL [McMahan et al., 2013], have shown decent performance in practice. However, a linear model lacks the ability to learn feature interactions, and a common practice is to manually include pairwise feature interactions in its feature vector. Such a method is hard to generalize to model high-order feature interactions or those never or rarely appear in the training data [Rendle, 2010]. Factorization Machines arXiv:1703',\n",
       " '1901.02220': 'Triggered by the availability of vast amounts of training data and drastic improvements in computing power, deep neural networks have become state-of-the-art technology for a wide range of practical machine learning tasks such as image classiﬁcation [1], handwritten digit recognition [2], speech recognition [3], or game intelligence [4]. For an in-depth overview, we refer to the survey paper [5] and the recent book [6]. A neural network effectively implements a mapping approximating a function that is learned based on a given set of input-output value pairs, typically through the backpropagation algorithm [7]. Characterizing the fundamental limits of approximation through neural networks shows what is possible if no constraints are imposed on the learning algorithm and on the amount of training data [8]. D. Elbr¨achter is with the Department of Mathematics, University of Vienna, Austria (e-mail: dennis.elbraechter@univie.ac.at). D. Perekrestenko and H. B¨olcskei are with the Chair for Mathematical Information Science, ETH Zurich, Switzerland (e-mail: pdmytro@mins.ee.ethz.ch, hboelcskei@ethz.ch). P. Grohs is with the Department of Mathematics and the Research Platform DataScience@UniVienna, University of Vienna, Austria (e-mail: philipp.grohs@univie.ac.at). D. Elbr¨achter was supported through the FWF projects P 30148 and I 3403 as well as the WWTF project ICT19-041. arXiv:1901.02220v4  [cs.LG]  12 Mar 2021  The theory of function approximation through neural networks has a long history dating back to the work by McCulloch and Pitts [9] and the seminal paper by Kolmogorov [10], who showed, when interpreted in neural network parlance, that any continuous function of n variables can be represented exactly through a 2-layer neural network of width 2n + 1. However, the nonlinearities in Kolmogorov’s neural network are highly nonsmooth and the outer nonlinearities, i.e., those in the output layer, depend on the function to be represented. In modern neural network theory, one is usually interested in networks with nonlinearities that are independent of the function to be realized and exhibit, in addition, certain smoothness properties. Signiﬁcant progress in understanding the approximation capabilities of such networks has been made in [11], [12], where it was shown that single-hiddenlayer neural networks can approximate continuous functions on bounded domains arbitrarily well, provided that the activation function satisﬁes certain (mild) conditions and the number of nodes is allowed to grow arbitrarily large. In practice one is, however, often interested in approximating functions from a given function class C determined by the application at hand. It is therefore natural to ask how the complexity of a neural network approximating every function in C to within a prescribed accuracy depends on the complexity of C (and on the desired approximation accuracy). The recently developed Kolmogorov-Donoho rate-distortion theory for neural networks [13] formalizes this question by relating the complexity of C—in terms of the number of bits needed to describe any element in C to within',\n",
       " '1210.0100': 'I N recent times, different diversity schemes have marked an important impact in the arena of wireless communication systems. The main reason behind this is that these different diversity schemes allow for multiple transmission and/or reception paths for the same signal [1]. The optimal diversity combining scheme is the maximal ratio combining (MRC) diversity scheme where all the diversity branches are processed to obtain the best possible signal-to-noise ratio (SNR) [1]– [3]. This results into extensive occurrence of the statistical distribution of the sum of squared envelopes of faded signals in several wireless communication systems [4]. Additionally, wireless communications are driven by a complicated phenomenon known as radio-wave propagation that is characterized by various effects such as fading, shadowing and path-loss. The statistical behavior of these effects is described by different models depending on the nature of the communication environment. Various distributions have several applications in wireless communication engineering problems and one of those that we focus on is a communication system employing MRC diversity scheme undergoing η-µ1 distribution i.e. the study of MRC diversity combining Imran Shaﬁque Ansari, Ferkan Yilmaz and Mohamed-Slim Alouini are with the Computer, Electrical, and Mathematical Sciences and Engineering (CEMSE) Division at King Abdullah University of Science and Technology (KAUST), Al-Khawarizmi Applied Math. Building (Bldg. #1), Thuwal 239556900, Makkah Province, Kingdom of Saudi Arabia (e-mail: {imran.ansari, ferkan.yilmaz, slim.alouini}@kaust.edu.sa). 1In this work, both the Formats are considered and hence the results presented herein are applicable to both the Formats. receiver operating over η-µ fading channels [5], where the statistics of the sum of squared η-µ random variates (RVs) are required. Moreover, the performance analysis of such wireless communication systems usually requires complicated and tedious tasks related to statistics as explained in detail in [6]. For instance, it is worth sharing here that the probability density function (PDF) and cumulative distribution function (CDF) of the sum of L independent but not necessarily identical (i.n.i.d.) Gamma RVs have been investigated in [7] using the results presented in [8] to address the performance of MRC diversity receivers over Nakagami-m fading channels. Similarly, in [9]– [11], the authors have independently presented a closed-form expression for the PDF of the sum of independent Gamma variates with arbitrary fading parameters. Recently, the η-µ fading distribution that includes the Nakagami-m and the Hoyt distribution as its special cases, has been proposed as a more ﬂexible model for practical fading radio channels [12] and free-space optical (FSO) communication systems. Additionally, the η-µ model has been found suitable for modeling small scale fading phenomenon in non-line-of-sight mobile communication channels [12]. Nonhomogeneous physical characteristics of the environment have been taken into consideration in the mathematical modeling of this channel that sometimes best ﬁts to the practical scenario and experimental data [13]. The η-µ distribution ﬁts well to experimental',\n",
       " '1709.02016': 'With the advent of Web 2.0 and ubiquitous adoption of low-cost and highresolution digital cameras, users upload and share images on a daily basis. This trend of public image distribution and access to user-friendly editing software such as Photoshop and GIMP has made image forgery a serious issue. Splicing is one of the most common types of image forgery. It manipulates images by copying a region from one image (i.e., the donor image) and pasting it onto another image (i.e., the host image). Forgers often use splicing to give a false impression that there is an additional object present in the image, or to remove an object from the image. 1 arXiv:1709.02016v1  [cs.CV]  6 Sep 2017  Figure 1: An image splicing example [32]: (a) the spliced image showing John Kerry and Jane Fonda together at an anti-Vietnam war rally, (b) an authentic image of Kerry, and (c) an authentic image of Fonda. Image splicing can be potentially used in generating false propaganda for political purposes. For example, during the 2004 US Presidential election campaign, an image that showed John Kerry and Jane Fonda speaking together at an anti-Vietnam war protest was released and circulated. It was discovered later that this was a spliced image, and was created for political purposes. Fig. 1 shows the spliced image, along with the two original authentic images that were used to create the spliced image [32]. Some additional splicing examples obtained from four datasets are shown in Fig. 2. Many of the current splicing detection algorithms only deduce whether a given image has been spliced and do not attempt to localize the spliced area. Relatively few algorithms attempt to tackle the splicing localization problem, which refers to the problem of determining which pixels in an image have been manipulated as a result of a splicing operation. A brief review of existing splicing localization techniques will be given in Sec. 2. In this paper, we present an eﬀective solution to the splicing localization problem based on a fully convolutional network (FCN). The base network architecture is the FCN VGG-16 architecture with skip connections, but we incorporate several modiﬁcations, including batch normalization layers and class 2  weighting. We ﬁrst evaluated a single-task FCN (SFCN) trained only on the surface label or ground truth mask, which classiﬁes each pixel in a spliced image as spliced or authentic. Although the SFCN is shown to provide superior performance over existing techniques, it still provides a coarse localization output in certain cases. Thus, we next propose the use of a multi-task FCN (MFCN) that utilizes two output branches for multi-task learning. One branch is used to learn the surface label, while the other branch is used to learn the edge or boundary of the spliced region. It is shown that by simultaneously training on the surface and edge labels, we can achieve ﬁner localization of the spliced region, as compared to',\n",
       " '1808.07048': 'Neural machine translation (Kalchbrenner and Blunsom, 2013; Sutskever et al., 2014; Bahdanau et al., 2015) has become the de-facto standard in machine translation, outperforming earlier phrasebased approaches in many data settings and shared translation tasks (Luong and Manning, 2015; Sennrich et al., 2016; Cromieres et al., 2016). Some recent results suggest that neural machine translation “approaches the accuracy achieved by average bilingual human translators [on some test sets]” (Wu et al., 2016), or even that its “translation quality is at human parity when compared to professional human translators” (Hassan et al., 2018). Claims of human parity in machine translation are certainly extraordinary, and require extraordinary evidence.1 Laudably, Hassan et al. (2018) have 1The term “parity” may raise the expectation that there is evidence for equivalence, but the term is used in the deﬁnition of “there [being] no statistical signiﬁcance between [two outputs] for a test set of candidate translations” by Hassan et al. (2018). Still, we consider this ﬁnding noteworthy given the strong evaluation setup. released their data publicly to allow external validation of their claims. Their claims are further strengthened by the fact that they follow best practices in human machine translation evaluation, using evaluation protocols and tools that are also used at the yearly Conference on Machine Translation (WMT) (Bojar et al., 2017), and take great care in guarding against some confounds such as test set selection and rater inconsistency. However, the implications of a statistical tie between two machine translation systems in a shared translation task are less severe than that of a statistical tie between a machine translation system and a professional human translator, so we consider the results worthy of further scrutiny. We perform an independent evaluation of the professional translation and best machine translation system that were found to be of equal quality by Hassan et al. (2018). Our main interest lies in the evaluation protocol, and we empirically investigate if the lack of document-level context could explain the inability of human raters to ﬁnd a quality difference between human and machine translations. We test the following hypothesis: A professional translator who is asked to rank the quality of two candidate translations on the document level will prefer a professional human translation over a machine translation. Note that our hypothesis is slightly different from that tested by Hassan et al. (2018), which could be phrased as follows: A bilingual crowd worker who is asked to directly assess the quality of candidate translations on the sentence level will prefer a professional human translation over a machine translation.  As such, our evaluation is not a direct replication of that by Hassan et al. (2018), and a failure to reproduce their ﬁndings does not imply an error on either our or their part. Rather, we hope to indirectly assess the accuracy of different evaluation protocols. Our underlying assumption is that professional human translation',\n",
       " '1705.07972': 'A UTOMATED ﬁngerprint identiﬁcation systems (AFIS) have become increasingly ubiquitous over the last ﬁfty years. With origins in the forensics community in the early 1900s, ﬁngerprints have continued to serve as valuable links to individuals due to their proven uniqueness, permanence, universality, and collectability [1]. More recently, ﬁngerprint recognition systems have exploded into a plethora of niche areas such as mobile device security, healthcare access, ﬁnancial systems, and government institutions [1]. As ﬁngerprints continue to become a key to access society’s conﬁdential data, social beneﬁts, networks, and buildings, the need to know and quantify ﬁngerprint recognition accuracy is paramount. As such, controlled, repeatable evaluations of the various components of ﬁngerprint recognition systems must be performed. While past end-to-end evaluations such as FpVTE 2012 [2] have provided us with baseline statistics on the performance of state-of-the-art ﬁngerprint recognition systems, much work remains to be done in developing rigorous evaluations of the reader1 subcomponent of ﬁnger- • J. J. Engelsma and A. K. Jain are with the Department of Computer Science and Engineering, Michigan State University, East Lansing, MI, 48824 E-mail: {engelsm7, jain}@cse.msu.edu • S. S. Arora was with the Department of Computer Science and Engineering, Michigan State University. He is now with the Risk and Authentication Products organization at Visa Inc., Foster City, CA 94404 Email: sunarora@visa.com • N. G. Paulter Jr. is with the National Institute of Standards and Technology (NIST), Gaithersburg, Maryland 20899 Email: paulter@nist.gov 1. A distinction is made between ﬁngerprint reader and ﬁngerprint sensor. Fingerprint reader refers to the entire device and process, which captures your physical ﬁngerprint and converts it into a digital image. The sensor is a subcomponent of the reader which converts, through a variety of means (capacitive, frustrated total internal reﬂection), the physical ﬁngerprint to an electrical signal. Fig. 1: A Universal 3D Fingerprint Target fabricated in (a) can be imaged by a variety of popular ﬁngerprint readers (contact-optical, contactlessoptical, and capacitive) shown in (b). The sensed images of the 3D ﬁngerprint target in (a) are shown in (c). This demonstrates that our targets are appropriate for ﬁngerprint reader interoperability evaluation studies. Similarity scores for each sensed ﬁngerprint image (with the 2D mapped target image) are displayed below each ﬁngerprint image in (c). Veriﬁnger 6.3 SDK was used for generating similarity scores. The score threshold at 0.01 % FAR is 33. print recognition systems. Previous attempts to evaluate the ﬁngerprint reader component have been predominantly undertaken by the FBI and constitute the Appendix F and PIV standards [17]. The Appendix F standard is comparatively stringent, requires pristine image capture, and is designed to facilitate evalarXiv:1705.07972v1  [cs.CV]  22 May 2017  2 Fig. 2: High ﬁdelity, wearable, 3D ﬁngerprint targets. (a) 3D ﬁngerprint target printed using TangoBlackPlus FLX980 [3], (b) 3D ﬁngerprint target printed using TangoPlus FLX 930 [4], (c) 3D ﬁngerprint target printed using TangoBlackPlus FLX980 and then sputter coated',\n",
       " '1306.1031': 'FAILED',\n",
       " '1802.06398': 'Singular value decomposition (SVD) [24] is a well-established and useful tool with a wide range of applications in various domains of information retrieval, natural language processing, and data analysis. The first SVD-based collaborative filtering (CF) models were proposed in the late 90’s early 00’s and were successfully adapted to a wide range of tasks [10, 28, 43]. It has also anticipated active research devoted to alternative matrix factorization (MF) techniques [30]. However, despite the development of many sophisticated and accurate methods, the simplest SVD-based approach called PureSVD ∗Also with Institute of Numerical Mathematics, Russian Academy of Sciences. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. RecSys ’19, September 16–20, 2019, Copenhagen, Denmark © 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-6243-6/19/09...$15.00 https://doi.org/10.1145/3298689.3347055 was later shown to outperform other algorithms in standard top-n recommendation tasks [18]. PureSVD offers a unique set of practical advantages, such as global convergence with deterministic output, lightweight hyperparameter tuning via simple rank truncation, an analytical expression for instant online recommendations (see Section 3.3), scalable modifications based on randomized algorithms [26]. It has highly optimized implementations in many programming languages based on BLAS and LAPACK routines and is included in many modern machine learning libraries and frameworks, some of which allow to handle nearly billion-scale problems1. However, like any other conventional collaborative filtering technique, PureSVD relies solely on the knowledge about user preferences expressed in the form of ratings, likes, purchases or other types of feedback, either explicit or implicit. On the other hand, a user’s choice may be influenced by intrinsic properties of items. For example, users may prefer products of a particular category/brand or products with certain characteristics. Similarly, additional knowledge about users, such as demographic information or occupation, may also help to explain their choice. These influencing factors are typically assumed to be well represented by the model’s latent features. However, in situations when users interact with a small number of items from a large assortment (e.g., in online stores), it may become difficult to build reliable models from the observed behavior without considering side information. This additional knowledge may also help in the extreme cold start [21] case, when preference data for some items and/or users are',\n",
       " '1412.7024': 'The training of deep neural networks is very often limited by hardware. Lots of previous works address the best exploitation of general-purpose hardware, typically CPU clusters (Dean et al., 2012) and GPUs (Coates et al., 2009; Krizhevsky et al., 2012a). Faster implementations usually lead to state of the art results (Dean et al., 2012; Krizhevsky et al., 2012a). Actually, such approaches always consist in adapting the algorithm to best exploit state of the art general-purpose hardware. Nevertheless, some dedicated deep learning hardware is appearing as well. FPGA and ASIC implementations claim a better power efﬁciency than general-purpose hardware (Kim et al., 2009; Farabet et al., 2011; Pham et al., 2012; Chen et al., 2014a;b). In contrast with general-purpose hardware, dedicated hardware such as ASIC and FPGA enables to build the hardware from the algorithm. Hardware is mainly made out of memories and arithmetic operators. Multipliers are the most space and power-hungry arithmetic operators of the digital implementation of deep neural networks. The objective of this article is to assess the possibility to reduce the precision of the multipliers for deep learning: • We train deep neural networks with low precision multipliers and high precision accumulators (Section 2). • We carry out experiments with three distinct formats: 1. Floating point (Section 3) 2. Fixed point (Section 4) 3. Dynamic ﬁxed point, which we think is a good compromise between ﬂoating and ﬁxed points (Section 5) • We use a higher precision for the parameters during the updates than during the forward and backward propagations (Section 6). • Maxout networks (Goodfellow et al., 2013a) are a set of state-of-the-art neural networks (Section 7). We train Maxout networks with slightly less capacity than Goodfellow et al. (2013a) on three benchmark datasets: MNIST, CIFAR-10 and SVHN (Section 8). 1 arXiv:1412.7024v5  [cs.LG]  23 Sep 2015  Accepted as a workshop contribution at ICLR 2015 • For each of the three datasets and for each of the three formats, we assess the impact of the precision of the multiplications on the ﬁnal error of the training. We ﬁnd that very low precision multiplications are sufﬁcient not just for running trained networks but also for training them (Section 9). We made our code available 1. 2 MULTIPLIER-ACCUMULATORS Multiplier (bits) Accumulator (bits) Adaptive Logic Modules (ALMs) 32 32 504 16 32 138 16 16 128 Table 1: Cost of a ﬁxed point multiplier-accumulator on a Stratix V Altera FPGA. Algorithm 1 Forward propagation with low precision multipliers. for all layers do Reduce the precision of the parameters and the inputs Apply convolution or dot product (with high precision accumulations) Reduce the precision of the weighted sums Apply activation functions end for Reduce the precision of the outputs Applying a deep neural network (DNN) mainly consists in convolutions and matrix multiplications. The key arithmetic operation of DNNs is thus the multiply-accumulate operation. Artiﬁcial neurons are basically multiplier-accumulators computing weighted sums of their inputs. The cost of',\n",
       " '1803.03474': '2 2. Single Shot TextSpotter by Joint Detection and Recognition 4 2.1. Text-Alignment Layer . . . . . . . . . . . 5 Appearing in Proc. IEEE Conf. Computer Vision and Pattern Recognition, 2018. The ﬁrst two authors contribute equally. C. Shen is the corresponding author (e-mail: chunhua.shen@adelaide.edu.au). 2.2. Word Recognition with Character Attention . . . . . . . . . . . . . . . . . . . . 6 2.2.1 Attention Mechanism . . . . . . 6 2.2.2 Attention Alignment and Enhancement . . . . . . . . . . . . 7 2.3. Training Strategy . . . . . . . . . . . . . 8 3. Experiments 8 3.1. Evaluation Protocols . . . . . . . . . . . 8 3.2. Text-alignment vs. RoI Pooling . . . . . 9 3.3. Character Attention . . . . . . . . . . . . 9 3.4. Joint Training vs. Separate Models . . . 10 3.5. Proposed Method vs. State-of-the-art Methods . . . . . . . . . . . . . . . . . . 10 arXiv:1803.03474v3  [cs.CV]  23 Mar 2018  1. Introduction The goal of text spotting is to map an input natural image into a set of character sequences or word transcripts and corresponding location. It has attracted increasing attention in the vision community, due to its numerous potential applications. It has made rapid progress riding on the wave of recent deep learning technologies, as substantiated by recent works [3, 4, 2, 5, 6, 7, 8, 9, 10, 11]. However, text spotting in the wild still remains an open problem, since text instances often exhibit vast diversity in font, scale and orientation with various illumination aﬀects, which often come with a highly complicated background. Past works in text spotting often consider it as two individual tasks: text detection and word recognition, which are implemented sequentially. The goal of text detection is to precisely localize all text instances (e.g., words) in a natural image, and then a recognition model is processed repeatedly through all detected regions for recognizing corresponding text transcripts. Recent approaches for text detection are mainly extended from general object detectors (such as Faster R-CNN [12] and SSD [13]) by directly regressing a bounding box for each text instance, or from semantic segmentation methods (e.g., Fully Convolutional Networks (FCN) [14]) by predicting a text/nontext probability at each pixel. With careful model design and development, these approaches can be customized properly towards this highly domain-speciﬁc task, and achieve the state-of-the-art performance [4, 6, 7, 8, 9, 15]. The word recognition can be cast into a sequence labeling problem where convolutional recurrent models have been developed recently [9, 16]. Some of them were further incorporated with an attention mechanism for improving the performance [17, 18]. However, training two tasks separately does not exploit the full potential of convolutional networks, where the convolutional features are not shared. It is natural for us to make a more reliable decision if we clearly understand or recognize the meaning of a word and all characters within it. Besides, it is also possible to introduce a number of heuristic rules and hyper-parameters that are costly to tune, making the whole system highly complicated. Recent Mask R-CNN',\n",
       " '1805.10604': 'Visual Data, in the form of images, videos and live streams, has been growing at an unprecedented rate in the last few years. While this massive amount data is a blessing for Data Science, as it helps in improving the predictive accuracy, it is also a curse since humans are unable to consume this large amount of data. Moreover, today, machine-generated videos (via Drones, Dash-cams, Body-cams, Surveillance cameras etc.) are being generated at a rate higher than what we as humans can process. Among machine-generated videos, surveillance videos are one of the largest contributors to this growth. Surveillance cameras are deployed in several verticals, including oﬃce facilities, road intersections ⋆Equal Contribution arXiv:1805.10604v2  [cs.CV]  27 Jun 2018  2 Pratik Dubal et al. for traﬃc monitoring, ATMs and Banks, Hospitals, Manufacturing Facilities, Industrial Plants, Construction Sites, Educational Institutions, Retail stores and Malls, Hotels and Restaurants etc. Each of these verticals have their own unique video analytics applications. In most scenarios, video analytics is used for security purposes (detecting loitering and intrusion, asset tampering, suspicious activity or object detection). In other scenarios, video analytics is used for process compliance, e.g. if an event in a manufacturing plant has happened on time, or whether it was done as desired. In retail scenarios and hotels, the information from video analytics is used for getting insights in customer pattern (e.g. heatmap, ﬂow-map, counts, dwell-times etc.) While all these applications sound very diﬀerent, the analytics building blocks are the same. Fig. 1. End-to-End process for analytics Figure 1 demonstrates the process clearly. The analytics engine consists of several building blocks, including object detection, tracking, face and human detection, human and face subattribute recognition, vehicle detection and vehicle sub-attribute recognition etc. The information from the analytics engine is then passed on to a business logic layer, which applies rules based on the analytics output. For example, using human detection (localizing where a human is in the video frame) if a human enters a demarcated area, it sends out a real-time alert. Similarly, by tracking the paths of the human in the video, we can compute the heat-map and ﬂow-map of human movement. The following sections outline the advancement of deep learning in computer vision, followed by the recent advances and challenges of video analytics for surveillance applications. Finally, we outline the main contributions of this paper. 1.1 Advancement of Deep Learning in Computer Vision Current approaches to all but a few Computer Vision tasks involve the use of Deep Convolutional Neural Networks (CNNs). CNNs generated a lot of interest after the successful performance of AlexNet [15] in the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) 2012 competition [29]. Following its triumph, there was an upsurge in the number of deep CNN models that were being used across the Computer Vision community. The winner of ILSVRC 2014 was the even deeper GoogLeNet, which was the',\n",
       " '1803.10470': 'In this perspective we will first very briefly review how \\u200bdeep learning (DL) has helped us                                 to study visual object recognition in the primate brain (see Kriegeskorte, 2015; Yamins                           & DiCarlo, 2016 for more thorough reviews). The successful application of DL in vision                             leads to the question whether these models could help us to also gain insights into other                                 aspects of human cognition. It is presently unclear whether DL can lead to improved                            understanding of other cognitive processes beyond vision. In the main part of the paper                             we ask whether DL could also help us to understand the emergence of higher cognitive                               functions such as Theory of Mind.     Marrying biology and AI: The success story in vision  DL as a model for primate vision    Visual object recognition in primates is mediated by a hierarchy of transformations along                        the occipitotemporal cortex (\\u200bDiCarlo et al., 2012\\u200b). Intriguingly, it has been shown that                          these transformations are quite similar to the hierarchy of transformations learned by                         deep neural networks (DNN) trained to recognize objects on natural images. Several                         pieces of work have demonstrated a direct correspondence between the hierarchy of                        the human visual areas and the layers of the DNNs (Gülcu 2015, Seibert, 2016, Cichy                               et al., 2016; Eickenberg 2016; Kuzovkin et al., 2018).     While DL has offered an algorithmic model for (feedforward) visual object recognition in                          brains, these developments do not provide a full understanding of biological vision (Cox,                          2014; Kriegeskorte, 2015; VanRullen, 2017). Most importantly, in biological vision at                       least part of the processing is done by feedback connections (Roelfsema, 2006),                         although the exact computational role of feedback is less clear (See Bastos et al, 2012                              for one particular view). The DL networks commonly used in machine vision are                           feedforward, although there is a recent trend towards incorporating feedback (e.g. Wen                       et al., 2018). Also, it is important to note that the DL networks still explain only a part of                                    the variability of the neural responses happening in real brains. Hence, the present-day                           DL networks cannot be seen as the ultimate model of biological visual processing (e.g.                             Kriegeskorte, 2015; Rajalingham et al, 2018). Nevertheless, the work with DL has                            illuminated how relatively simple transformations applied throughout a hierarchy of                     processing stages can be associated with successful object recognition.  What has made DL successful for investigating biological vision?    The recent developments in DL have been made possible by increased computational                         power, refinements to the algorithms, and availability of large data-sets necessary for                         training DL networks (LeCun et al., 2015). Beyond these factors there are several                           specific aspects to consider that have enabled DL to be helpful for investigating                           biological vision. There are three aspects to highlight: 1) Appropriate training data:                         DNNs are a good model for biological object recognition as they are trained on datasets                              that are directly relevant for biological vision: natural images (i.e. Imagenet (Deng et al.,                             2009)); 2) A training objective that is similar to biological vision: Machine vision has the                             straightforward goal to accurately recognize',\n",
       " '1805.10973': 'Deep learning have brought about breakthroughs in processing image, video, speech and audio (LeCun et al., 2015). The ﬁeld of natural language processing has been also interested in deep learning, e.g., sentence classiﬁcation (Kim, 2014; Iyyer et al., 2015), language modeling (Bengio et al., 2003; Mikolov et al., 2013), machine translation (Sutskever et al., 2014; Bahdanau et al., 2014; Wu et al., 2016), and question answering (Hermann et al., 2015). Naturally, bridging images and texts by deep learning has been follow1https://github.com/tkim-snu/GLACNet ing (Belz et al., 2018) such as image captioning (Vinyals et al., 2015; Xu et al., 2015; Karpathy and Fei-Fei, 2017), visual question answering (Antol et al., 2015; Kim et al., 2016), and image generation from caption (Reed et al., 2016; Zhang et al., 2017). The task of multi-image cued story generation is one of interesting visual-linguistic challenges to generate story of multiple coherent sentences from a given sequence of images. The main difﬁculty is how to generate image-speciﬁc sentences within the context of overall images. Additionally, it is harder than object recognition or image captioning since it needs ﬁne-grained object recognition and context understanding in the images. Recently, visual storytelling dataset (VIST) was released for the task of multi-image cued story generation, which is composed of ﬁve-sentence stories, descriptions and the corresponding sequences of ﬁve images (Huang et al., 2016). Here we propose a deep learning network model that generates visual stories by combining globallocal (glocal) attention and context cascading mechanisms. To focus on the image-speciﬁc appropriateness of them, we develop two levels of attention, i.e., overall encoding level (global) and image feature level (local). In the image sequence encoders, the global context of the storyline is encoded using bi-directional LSTMs on features of ﬁve images, we give attention on the context (global attention). Additionally, we give local attention to image features directly. Then both of them are combined and sent to RNN-based sentence generators. While standard attention conﬁguration needs a large number of parameters, we implement them in a very simple way via hard connections from the outputs of encoders or image features onto the sentence generators. To improve further the coherency of the generated stories, we design to convey the last hidden vector in the senarXiv:1805.10973v3  [cs.CL]  13 Feb 2019  tence generator to the next sentence generator as an initial hidden vector. This paper is organized as follows. Section 2 presents related works to positioning. In Section 3 we show brieﬂy dataset, section 4 explains the proposed models. Section 5 shows their experimental results. Finally, section 6 draws the conclusion. 2 Related Work Text Comprehension As similar works without visual cues, there are text comprehension tasks such as bAbI tasks (Weston et al., 2015), SQuAD (Rajpurkar et al., 2016) and Story Cloze Test (Mostafazadeh et al',\n",
       " '1808.01462': 'FAILED',\n",
       " '1608.02902': \"Recovery of a vector based on noisy linear measurements is the classical problem of linear regression, and is arguably the most basic problem in statistical inference. A variant, the “errors-in-variables” model [LR14], allows for errors in the measurement matrix, but mainly in the form of additive or multiplicative noise [LW12]. In this paper, we study a form of errorsin-variables in which the measurement matrix is perturbed by an unknown permutation of its rows. More concretely, we study an observation model of the form y = Π∗Ax∗+ w, (1) where x∗∈Rd is an unknown vector, A ∈Rn×d is a measurement (or design) matrix, Π∗is an unknown n × n permutation matrix, and w ∈Rn is observation noise. We refer to the setting where w = 0 as the noiseless case. As with linear regression, there are two settings of interest, corresponding to whether the design matrix is (i) deterministic (the ﬁxed design case), or (ii) random (the random design case). There are also two complementary problems of interest – recovery of the unknown Π∗, and recovery of the unknown x∗. In this paper, we focus on the former problem; the latter problem is also known as unlabelled sensing [UHV15]. The observation model (1) is frequently encountered in scenarios where there is uncertainty in the order in which measurements are taken. An illustrative example is that of sampling in the presence of jitter [Bal62], in which the uncertainty about the instants at which measurements are taken results in an unknown permutation of the measurements. A similar synchronization issue occurs in timing and molecular channels [RMS12]. Here, identical molecular tokens are received at the receptor at diﬀerent times, and their signatures are 1 arXiv:1608.02902v1  [math.ST]  9 Aug 2016    3D'object Unknown'linear'transformation 2D'image 0 B @ p1 q1 r1 ... ... ... pn qn rn 1 C A 0 @ x11 x12 x21 x22 x31 x32 1 A ⇧ 0 B @ u1 u2 ... ... un vn 1 C A = ⇥ Figure 1. Example of pose and correspondence estimation. The camera introduces an unknown linear transformation corresponding to the pose. The unknown permututation represents the correspondence between points, which is shown in the picture via coloured shapes, and needs to be estimated. indistinguishable. The vectors of transmitted and received times correspond to the signal and the observations, repectively, where the latter is some permuted version of the former with additive noise. Another such scenario arises in multi-target tracking problems [PG06]. For example, SLAM tracking [TL08] is a classical problem in robotics where the environment in which measurements are made is unknown, and part of the problem is to infer relative permutations between measurements. Archaeological measurements [Rob51] also suﬀer from an inherent lack of ordering, which makes inference of chronology hard. Another compelling example of such an observation model is in data anonymization, in which the order, or “labels”, of measurements are intentionally deleted to preserve privacy. The inverse problem of data de-anonymization [NS08] is to infer these\",\n",
       " '1511.01065': 'The electric power grid has undergone unprecedented changes over the past few years. The traditional, hierarchical and centralized electric grid has transformed into a large-scale, decentralized, and “smart” grid [1]–[4]. Such a smart grid is expected to encompass a mix of devices, as shown in Fig. 1, that include distributed renewable energy sources, electric vehicles (EVs), and storage units that can be actively controlled and operated via a reliable, two-way communication infrastructure [1]. The effective operation of such a heterogeneous and decentralized system is expected to change the way in which energy is produced and delivered to consumers. One key byproduct of the smart grid evolution is an ability to deliver innovative energy management services to consumers [1]–[4]. Here, energy management refers to the processes using which energy is generated, managed, and delivered to consumers in the grid. For instance, demand-side management (DSM) and demand response mechanisms will be an integral part of the smart grid. The primary goal of such programs is to dynamically shape and manage the supply and demand on the grid in order to maintain a desirable load over various timescales. Indeed, the design of optimized DSM and demand response protocols and associated pricing schemes has led to signiﬁcant research in this area in recent years [5]– [37]. This research is supported by the U.S. National Science Foundation under Grants CNS-1446621, ECCS-1549894, ECCS-1549900, and ECCS-1549881. Dr. Saad was a corresponding author. Fig. 1. A future smart grid with a heterogeneous mix of storage units, EVs, renewable sources, and other consumer-owned equipment. Moreover, in the smart grid, consumers will be able to individually own energy production units, such as solar panels, as well as storage devices in the form of EVs or small batteries. This can potentially transform every smart grid consumer into an independent energy production and storage source. Consequently, the possibility of energy trading between such well-equipped consumers will undoubtedly become a reality in the next few years. Indeed, many recent works, such as in [8], [38]–[66], have investigated the various challenges of such large-scale energy exchange, which include the development of optimized market mechanisms, the management of the grid operation, and the optimized exploitation of available consumer-owned storage and energy production units. Realizing this vision of a distributed, sustainable, and consumer-centric smart grid will naturally face many challenges. On the one hand, although DSM programs (and related ideas) have been theoretically shown to yield important technological beneﬁts to the grid, their wide-spread deployment still remains insipid [67]–[73]. On the other hand, the impact of energy trading on the smart grid operation and the realistic assumption that every consumer can become a producer of energy is still not well-understood. In addition, how to maximize the amount of energy that stems from renewable sources is yet another important challenge. Last but not least, the design of efﬁcient dynamic pricing mechanisms that go hand',\n",
       " '1803.09203': 'Automated vehicles have the potential to reduce traffic  accidents and improve traffic efficiency. A number of  automakers, high-tech companies, and research agencies are  dedicating their efforts to implement and demonstrate  partially or highly automated features in modern vehicles,  such as the AI-enabled computational platforms for  autonomous driving from NVIDIA [1], the Autopilot from  Tesla [2], and ‘Drive Me’ project by Volvo [3]. Fully  autonomous vehicles, e.g. Google self-driving car (WAYMO)  [4], are also being tested and may be deployed in the near  future.   Different levels of automated functions designed for  freeways or expressways are well developed and some of  them are being or will be introduced in the market soon, such  as Level 2 functions (e.g. adaptive cruise control plus lane  keeping, etc.) by various automakers. One example is the  Super Cruise by General Motors [5]. However, the  implementation of autonomous on-ramp merging still  presents considerable challenges. One big challenge is that  intelligent vehicle agent should take the long-term impacts  into consideration when it decides on its current control  action (the “long term” in the study is defined to be the  completion of a merge process while at any point along the  merging maneuver there is a “current” action). In other words,  the actions such as accelerating, decelerating, or steering that  the ego vehicle takes at the current moment may affect the  success or failure of the merge mission. Another challenge is  that the merging maneuver is not only based on the merging  vehicle’s own dynamic state, but dependent on its  surrounding vehicles whose actions may be cooperative (e.g.  decelerating or changing lane to yield to the merging vehicle)  or adversarial (e.g. speeding up to deter the merging vehicle).    The merging process can be handled at relative ease in  most cases by experienced human drivers but the algorithms  for automated execution of the merge maneuver in a  consistently smooth, safe, and reliable manner can become  complex. Most previous studies solve the merging problem  by assuming some specific rules. For example, Marinescu et  al. [6] proposed a slot-based merging algorithm by defining a         2  slot’s occupancy status (e.g. free or occupied) based on the  information of the mainline vehicles’ speed, position, and  behavior of acceleration or deceleration. Chen et al. [7]  applied a gap acceptance theory and defined some driving  rules to model the decision-making process of the on-ramp  merge behavior on urban expressways. These rule-based  models  are  conceptually  comprehensible  but  are  pragmatically vulnerable due to their inability to adapt to  unforeseen situations in the real world.  Reinforcement learning, a machine learning algorithm  which trains itself continually through trials and errors [8],  has the potential to allow the vehicle agent to learn how to  drive under different or previously unencountered situations  by training it to build up its pattern recognition capabilities.  Reinforcement learning is different from standard supervised  learning techniques, which need ground truth as input and  output pairs. A reinforcement learning agent learns from',\n",
       " '1805.00249': 'Automatic event extraction is a fundamental task of information extraction. Event detection, which aims to identify event triggers of speciﬁc types, is a key step of event extraction. For example, from the sentence “Henry was injured, and then passed away soon”, an event detection system should detect an “Injure” event triggered by “injured”, and a “Die” event triggered by “passed away”. Recently, neural network methods, which transform event detection into a word-wise classiﬁcation paradigm, have achieved signiﬁcant progress in event detection (Nguyen and Grishman, 2015; Die 这家/ 公司/ 并购/ 了/ 多家/ 公司/ 。 Injure Transfer_Ownership Merge_Organization The  injured solider died. 那个/ 受/ 了/ 伤/ 的/ 士兵/ 不治/ 身亡/ 。 The company acquired and merged with a number of companies. (a) (b) Figure 1: Examples of word-trigger mismatch. Slashes in the ﬁgure indicate word boundaries. Chen et al., 2015b; Ghaeini et al., 2016). For instance, a model will detect events in sentence ”Henry was injured” by successively classifying its three words into NIL, NIL and Injure. By automatically extracting features from raw texts, these methods rely little on prior knowledge and achieved promising results. Unfortunately, word-wise event detection models suffer from the word-trigger mismatch problem, because a number of triggers do not exactly match with a word. Speciﬁcally, a trigger can be part of a word or cross multiple words, which is impossible to detect using word-wise models. This problem is more severe in languages without natural word delimiters such as Chinese. Figure 1 (a) shows several examples of part-of-word triggers, where two characters in one word “¿\\t”(acquire and merge) trigger two different events: a “Merge Org” event triggered by “¿”(merge) and a “Transfer Ownership” event triggered by “\\t” (acquire). Figure 1 (b) shows a multi-word trigger, where three words “É”(is), “ ” and “ú”(injured) trigger an Injure event together. Table 1 shows the statistics of different types of word-trigger match on two standard datasets. We can see that word-trigger mismatch is crucial for Chinese event detection since nearly 25% of triggers in RichERE and 15% of them in ACE2005 dataset don’t exactly match with a word. To resolve the word-trigger mismatch problem, arXiv:1805.00249v1  [cs.CL]  1 May 2018  Match Type Rich ERE ACE2005 Exact Match 75.52% 85.39% Part of Word 19.55% 11.67% Cross words 4.93% 2.94% Table 1: Percentages of different types of matches between words and triggers. this paper proposes Nugget Proposal Networks (NPNs), which identify triggers by modeling character compositional structures of trigger nuggets regardless of word boundaries. Given a sentence, NPNs regard characters as basic detecting units and are able to 1) directly propose the entire potential trigger nugget at each character by exploiting inner compositional structure of triggers; 2) effectively categorize proposed triggers by learning semantic representation from both characters and words. For example, at character “ú”(injured) in Figure 1 (b), NPNs are not only capable to detect',\n",
       " '1102.2787': 'A multi-way channel is a scenario where users communicate with each other in both directions. The smallest multi-way communication model is the two way channel [1] where 2 nodes communicate with each other, and each has a message to deliver to the other node. In this sense, each node is a source and a destination at the same time. The two-way channel can be extended into a bi-directional relay channel by including a relay in the model. In the bidirectional relay channel, two nodes communicate with each other via a relay. This setup was introduced in [2] where relaying protocols were analyzed. In [3], further relaying protocols were proposed, and their achievable rate regions were compared to previous work. Achievable schemes for this setup using decode-and-forward and compress-and-forward were studied in [4] where rate regions were given and capacity was characterized within half a bit for the Gaussian setting. The capacity region of the two-way relay channel was also characterized within a constant gap in [5]. These results were The work of A. Chaaban and A. Sezgin is supported by the German Research Foundation, Deutsche Forschungsgemeinschaft (DFG), Germany, under grant SE 1697/3. The work of A. S. Avestimehr is partly supported by NSF CAREER award 0953117. also extended to the larger network consisting of two pair of nodes in addition to the relay. The approximate capacity of the two-pair bi-directional relay network was obtained in [6] and [7]. If more than two nodes want to communicate via a relay in a bi-directional manner, we get the multi-way relay channel. The multi-way relay channel was studied in [8], where upper and lower bounds for the capacity of the Gaussian multi-way relay channel were given. In their setup, G¨und¨uz et al. divided users into several clusters, where each user in a cluster has a single message intended to all other users in the same cluster. All users communicate simultaneously via a relay. A similar setup was considered in [9], where all users belong to the same cluster and all channel gains are equal. The authors of [9] obtained the sum-capacity of this Gaussian setup with more than 2 users. In this paper, we consider a Gaussian 3-way relay channel, with a slight difference from the aforementioned multi-way relay channel. In our 3-way channel, 3 users communicate with each other simultaneously via a relay. However, each user has 2 independent messages, each of which is intended to one of the other users. Thus each node wants to broadcast 2 messages to the other nodes, and wants to decode 2 other messages. A MIMO variant of this model was considered in [10], where a transmission scheme was proposed, and its corresponding achievable degrees of freedom were calculated. It was referred to as the “Y-channel”. We consider the single antenna Gaussian case, where all nodes are full-duplex, and derive upper',\n",
       " '1503.07455': 'Transmitting messages with perfect secrecy using physical layer techniques was ﬁrst studied in [1] on a physically degraded discrete memoryless wiretap channel model. Later, this work was extended to more general broadcast channel in [2] and Gaussian channel in [3], respectively. Wireless transmissions, being broadcast in nature, can be easily eavesdropped and hence require special attention to design modern secure wireless networks. Secrecy rate and capacity of pointto-point multi-antenna wiretap channels have been reported in the literature by several authors, e.g., [4]–[7]. In the above works, the transceiver operates in half-duplex mode, i.e., either it transmits or receives at any given time instant. On the other hand, full-duplex operation gives the advantage of simultaneous transmission and reception of messages [8]. But loopback self-interference and imperfect channel state information (CSI) are limitations. Full-duplex communication without secrecy constraint has been investigated by many authors, e.g., [9]–[12]. Full-duplex communication with secrecy constraint has been investigated in [13]–[15], where the achievable secrecy rate region of two-way (i.e., fullduplex) Gaussian and discrete memoryless wiretap channels have been characterized. In the above works, CSI in all the links are assumed to be perfect. In this paper, we consider the achievable sum secrecy rate in MISO full-duplex wiretap channel in the presence of a passive eavesdropper and imperfect CSI. The users participating in full-duplex communication have multiple transmit antennas, and single receive antenna each. The eavesdropper is assumed to have single receive antenna. The norm of the CSI errors in all the links are assumed to be bounded in their respective absolute values. In addition to a message signal, each user transmits a jamming signal in order to improve the secrecy rates. The users operate under individual power constraints. For this scenario, we obtain the achievable perfect secrecy rate region by maximizing the worst case sum secrecy rate. We also obtain the corresponding transmit covariance matrices associated with the message signals and the jamming signals. Numerical results that illustrate the impact of imperfect CSI on the achievable secrecy rate region are presented. We also minimize the total transmit power (sum of the transmit powers of users 1 and 2) with imperfect CSI subject to receive signal-to-interference-plusnoise ratio (SINR) constraints at the users and eavesdropper, and individual transmit power constraints of the users. The rest of the paper is organized as follows. The system model is given in Sec. II. Secrecy rate for perfect CSI is presented in Sec. III. Secrecy rate with imperfect CSI is studied in Sec. IV. Results and discussions are presented in Sec. V. Conclusions are presented in Sec. VI. Notations : A ∈CN1×N2 implies that A is a complex matrix of dimension N1 × N2. A ⪰0 and A ≻0 imply that A is a positive semideﬁnite matrix and positive deﬁnite matrix, respectively. Identity matrix is denoted by I. [.]∗ denotes complex conjugate transpose operation. E[.] denotes expectation',\n",
       " '1810.09302': 'Capturing sentence semantics plays a critical role in  biomedical and clinical text mining research. Traditional  methods that rely on bag-of-words may not model such  information accurately due to natural language ambiguity. For  instance, different sentences can be used to describe similar  findings (e.g., ‘It has recently been shown that Craf is essential  for Kras G12D-induced NSCLC.’ versus ‘It has recently  become evident that Craf is essential for the onset of Krasdriven non-small cell lung cancer.’[1]. In response,  embedding-based approaches have shown promising results  recently as the semantic is represented by high dimensional  vectors regardless whether the same set of words are used.  Such vector-based representations are commonly learnt from  large text corpora [2, 3] have becoming increasingly important   in today’s text mining research, especially when used as input  in advanced deep learning (DL) techniques [4, 5].  Representative sentence embeddings are doc2vec [6],  Universal Sentence Encoder [7], and sent2vec [8]. However,  to the best of our knowledge, there is no publicly available  sentence embeddings in biomedicine and clinical domains, in  spite of many related use cases and sentence-based  applications, such as finding relevant sentences for  information retrieval [1, 9], clinical sentence similarity [10],  biomedical sentence classification [11], or biomedical  question answering [12]. As a result, researchers would need  either train sentence embeddings on their own from scratch (a  data and time-intensive process, together with selection of best  model parameters), derive them from individual word  embeddings (loss of information about the entire sentence), or  use pretrained sentence embeddings from the general domain  (may suffer from the out-of-domain issue). Due to these  problems, suboptimal performance may be obtained.    To facilitate text mining research in biomedicine, we  propose BioSentVec, a pre-trained sentence embeddings for  readily generating sentence vectors given any arbitrary  sentences as inputs. Specifically, BioSentVec is created by  applying sent2vec, an advanced unsupervised model, to both  biological and clinical texts at a large scale. BioSentVec is  evaluated on two independent tasks: sentence similarity and  multi-label text classification, and is compared to the current  state-of-the-art methods.  II.  METHODS AND MATERIALS  To maximize the robustness and generalizability of  BioSentVec on different text genres in biomedicine and  clinical domains, BioSentVec embeddings are trained using  both PubMed and the clinical notes from MIMIC-III Clinical  Database [13]. Collectively, they consist of over 30 million  documents, ~223 million sentences, and ~5 billion tokens.  Table I summarizes the detailed statistics of the corpora.  Both PubMed and MIMIC-III texts were sentence-split  and tokenized using NLTK [14]. We then trained BioSentVec  using sent2vec [8]. It adapts the Continuous Bag-of-Words  model - known for training word embeddings – at the sentence  level, and extends the model by using n-grams of sentences.  By far, it achieves the state-of-the-art performance in a range  of text mining tasks in the general domain [8]. Based on a set  of experiments with different parameter settings (the vector  dimension, window size and negative',\n",
       " '1805.00743': 'Given the broadcast nature of wireless communication, it is well known that messages transmitted to an intended receiver can also be heard by eavesdroppers in the vicinity, thereby compromising the much needed conﬁdentiality feature. A standard technique to circumvent this problem is to employ crypto-primitives at the higher-layer between the transmitter and the receiver, e.g., symmetric-key encryption or publickey encryption methods [1]. With symmetric-key techniques being favored for application in low-cost wireless devices, the communicating parties need to posses a pre-shared secret-key to execute the crypto-primitives. While a plethora of cryptotechniques are well known for key-exchange mechanisms, the Parts of this work are in the proceedings of IEEE International Symposium on Personal Indoor and Mobile Radio Communications 2019 (PIMRC 2019) held at Istanbul, Turkey, and IEEE International Conference on Signal Processing and Communications 2018 (SPCOM 2018) held at Bangalore, India. This work was supported by the Indigenous 5G Test Bed project from the Department of Telecommunications, Ministry of Communications, New Delhi, India. concept of physical-layer key generation techniques has also received traction in the wireless community as the communicating nodes can harvest shared-keys just by witnessing the randomness in their channel realizations [2]-[17]. In the context of physical-layer key generation, the wireless channel realizations are referred to as the Common Source of Randomness (CSR). While a number of contributions have been reported under physical-layer two-user key generation, its generalization to a network comprising more than two nodes have also been studied, under the framework of Group Secret-Key (GSK) generation techniques [18]-[27]. In such a framework, more than two nodes generate a common secretkey by observing the temporal variation of their wireless channels so that these secret-keys can be used to keep their group messages conﬁdential when implementing broadcast and relaying strategies among the group members. Typical applications of GSK generation for broadcast, relaying and multi-cast communication include Device-to-Device communication in ad hoc networks, e.g., vehicular networks [17] and mobile networks. node-1 node-2 node-3 Eve h1E h3E h2E h12 h23 h13 Fig. 1. Network model with three wireless nodes, which intend to generate a GSK in the presence of the passive eavesdropper, referred to as Eve. All the channels in the network are assumed to be statistically independent. First, the three nodes share a common source of randomness, and then synthesize a group secret-key using a group consensus algorithm. Physical-layer GSK generation techniques can be broadly classiﬁed into two types: (i) pair-wise key based generation, wherein pairs of users in the network synthesize secret-keys using their wireless links, and subsequently distribute a GSK by using their pair-wise keys at the digital level [18], [19], [21], and (ii) GSK generation, wherein multiple nodes in the network ﬁrst exchange a CSR, and then generate a GSK after executing a group consensus algorithm [20], [22]. While the',\n",
       " '1409.7779': 'Wireless energy transfer (WET) has drawn signiﬁcant interests recently due to its great potential to provide cost-effective and reliable power supplies for energy-constrained wireless networks [1]. One enabling technique of WET for long-range applications (say up to tens of meters) is via radio-frequency (RF) or microwave prorogation, where dedicated energy-bearing signals are transmitted from the energy transmitter (ET) for the energy receiver (ER) to harvest the RF energy (see e.g. [2] and references therein). To overcome the signiﬁcant power attenuation over distance, employing multiple antennas at the ET and advanced beamforming techniques to efﬁciently direct wireless energy to the destined ER, termed energy beamforming, is an essential technique for WET [3]. Similar to the emerging massive multiple-input multiple-output (MIMO) enabled wireless communications (see e.g. [4] and references therein), by equipping a very large number of antennas at the ET, enormous energy beamforming gain can be achieved; hence, the end-to-end energy transfer efﬁciency can be greatly enhanced. arXiv:1409.7779v2  [cs.IT]  3 Oct 2014  2 On the other hand, for MIMO WET in a wide-band regime over frequency-selective channels, the frequencydiversity gain can also be exploited to further enhance the energy transfer efﬁciency, by transmitting more power over the sub-band with higher channel gain. WET in single-antenna or single-input single-output (SISO) frequencyselective channels has been studied in [5]–[7] under the more general setup of simultaneous wireless information and power transfer (SWIPT), where perfect channel state information (CSI) is assumed at the transmitter. In practice, both the energy-beamforming and frequency-diversity gains in MIMO WET over frequency-selective channels can be achieved, but crucially depend on the available CSI at the ET, which needs to be practically obtained at the cost of additional time and energy consumed. Similar to wireless communication, a direct approach to obtain CSI is by sending pilot signals from the ET to the ERs, each of which estimates the corresponding channel and then sends the estimated channel back to the ET via a feedback channel [8], [9]. However, since the training overhead increases with the number of antennas M at the ET, this method is not suitable when M is large. In [10], a new channel-learning design to cater for the practical RF energy harvesting circuitry at the ER has been proposed. However, the training overhead still increases quickly with M, and can be prohibitive for large M. In [11], by exploiting channel reciprocity between the forward (from the ET to the ER) and reverse (from the ER to the ET) links, we have proposed an alternative channel-learning scheme for WET based on the reverse-link training, which is more efﬁcient since the training overhead becomes independent of M. However, the proposed design in [11] applies only for narrowband ﬂat-fading channels instead of the more complex broadband frequency-selective fading channels, which motivates this work. In this paper, we consider a MISO point',\n",
       " '0908.0898': 'A. Background In their seminal work [1] Gupta and Kumar have shown that the randomly located nodes can achieve at most a rate that scales like 1 √n, as the number of nodes n →∞, under an interference-limited channel model. However, the proposed multi-hop scheme of [1] only achieves a scaling of 1 √n log n per node. This gap was recently closed in [2], where the authors proposed a highway based multi-hop forwarding protocol that achieves 1 √n rate per source-destination pair in random networks. In this approach, a set of connected highways, which span the network both horizontally and vertically, are constructed. Then, each source-destination pair communicates via a time-division strategy, where the source ﬁrst transmits its message to the closest horizontal highway. Then, the message is transported in multi-hop fashion to the appropriate vertical highway, which carries the message as close to the destination as possible. Finally, the message is delivered to the destination node from the vertical highway. The existence of highways, which satisfy certain desirable properties, is established by borrowing tools from percolation theory. Contrary to this multi-hop approach, a single-hop scheme called as ergodic interference alignment [3] (see also [4], [5]) is recently employed in [6] and, with arbitrary node placement and arbitrary trafﬁc pattern, the unicast and multicast capacity regions of dense networks are characterized (up to a factor of log n) under the Gaussian fading channel model. These line of works assumed an interference-limited channel model, where the interference is considered as noise (the focus of this work as well). Contrary to this model, [7] considered Gaussian fading channel model and proposed hierarchical cooperation schemes that can increase the per-node rate. This approach is further improved in the follow-up works (see, e.g., [8], [9], and references therein). The broadcast nature of the wireless communication makes it susceptible to eavesdropping. This motivates considering secrecy as a quality of service (QoS) constraint that must be accounted for in the network design. State of the art cryptographic approaches can be broadly classiﬁed into public-key and private-key protocols. Public-key cryptography assumes that the eavesdropper(s) has limited computational power, whereas the decryption requires a signiﬁcant complexity without the knowledge of the key [10]. Private-key approaches, on the other hand, assume that a random key is shared in private between the legitimate transmitter and receiver. This key is used to secure the transmitted information from potential eavesdropper(s). One of the earliest examples of private-key cryptography is the Vernam’s one time pad scheme [11], where the transmitter sends the XOR of the message bits and key bits. The legitimate receiver can decode the messages by XORing the shared key with the received sequence. In [12], Shannon showed that this scheme achieves perfect secrecy if and only if the two nodes share a key of the',\n",
       " '1810.10656': 'Human ability to answer a question related to an image is remarkable in several ways. Given a single image, a large number of diﬀerent questions can be answered about it. Answering these questions may require the detection and analysis of subtle, non-salient cues. Prior information and data obtained through experience are also incorporated into the process, to enable answering the question, which may be highly complex. The answering process itself is open to reasoning, allowing for example elaborations on the answer, or explaining how it was reached. In the last few years, the problem of image question-answering by a machine was addressed by many studies (Teney, Anderson, He, & Hengel, 2017a; Pandhre 1 arXiv:1810.10656v1  [cs.CV]  25 Oct 2018  Vatashsky & Ullman & Sodhani, 2017; Wu, Teney, Wang, Shen, Dick, & Hengel, 2016a; Kaﬂe & Kanan, 2016), mostly by treating the problem as an end-to-end multi-class training problem. In these methods, image representation is based on the last convolutional layer of a pre-trained Convolutional Neural Network (CNN) (Hochreiter & Schmidhuber, 1997). It is fused with the question features (mostly represented using a Recurrent Neural Network (RNN), e.g. LSTM (LeCun, Bottou, Bengio, & Haﬀner, 1998)) to generate embedded features that are used to predict the answer from common answers of a training set. Though current existing methods show statistical success on the trained datasets (e.g. VQA (Antol, Agrawal, Lu, Mitchell, Batra, Zitnick, & Parikh, 2015), VQA v2 (Goyal, Khot, Summers-Stay, Batra, & Parikh, 2017), CLEVR (Johnson, Hariharan, van der Maaten, FeiFei, Zitnick, & Girshick, 2017a)), they do so by exploiting biases of the questions and the speciﬁc datasets (Xu, Chen, Liu, Rohrbach, Darell, & Song, 2017; Agrawal, Batra, & Parikh, 2016). The human abilities and understanding mentioned above are missing from these methods. Casting the problem into an end-to-end multi-class problem, makes it practically impossible to obtain “human like” understanding of the question and the answering process itself, a process that for humans can be broken into meaningful pieces, which are used to provide elaborations and analysis of the answer. An Additional characteristic of the human answering process is the use of modular independent structures, where novel detection abilities may be integrated in the process. For example, learning to identify a new object class allows integrating this object into a variety of questions without requiring an additional training procedure. Finally, the question may guide the answering procedure to focus on speciﬁc and subtle details that may be lost in a general features extraction. Such abilities are missing from current machine answering algorithms In the approach described below, we develop a framework that proceeds along the following steps. It generates a meaningful representation of the question, maps the question representation into a corresponding answering procedure, and applies the answering procedure to the image. The answering process is determined by the question itself and the details of its composition. Our scheme includes a representation of the query’s meaning, in which the query is broken into its components',\n",
       " '1309.4111': 'Our lives are embedded in networks–social, biological, communication, etc.– and many researchers wish to analyze these networks to gain a deeper understanding of the underlying mechanisms. Some types of underlying mechanisms generate communities (aka clusters or modularities) in the network. As machine learners, our aim is not merely to devise algorithms for community detection, but also to study the algorithm’s estimation properties, to understand if and when we can make justiﬁable inferences from the estimated communities to the underlying mechanisms. Spectral clustering is a fast and popular technique for ﬁnding communities in networks. Several previous authors have studied the estimation properties of spectral clustering under various statistical network models (McSherry [3], Dasgupta et al. [4], Coja-Oghlan and Lanka [5], Ames and Vavasis [6], Rohe et al. [7], Sussman et al. [8] and Chaudhuri et al. [1]). Recently, Chaudhuri et al. [1] and Amini et al. [2] proposed two inspired ways of artiﬁcially inﬂating the node degrees in ways that provide statistical regularization to spectral clustering. This paper examines the statistical estimation performance of regularized spectral clustering under the Degree-Corrected Stochastic Blockmodel (DC-SBM), an extension of the Stochastic Blockmodel (SBM) that allows for heterogeneous degrees (Holland and Leinhardt [9], Karrer and Newman [10]). The SBM and the DC-SBM are closely related to the planted partition model and the extended planted partition model, respectively. We extend the previous results in the following ways: (a) In contrast to previous studies, this paper studies the regularization step with a canonical version of spectral clustering that uses k-means. The results do not require any assumptions on the minimum expected node degree; instead, there is a threshold demonstrating that higher degree nodes are easier to cluster. This threshold is a function of the leverage scores that have proven essential in other contexts, for both graph algorithms and network data analysis (see Mahoney [11] and references therein). These are the ﬁrst results that relate leverage scores to the statistical performance of spectral clustering. Research of TQ is supported by NSF Grant DMS-0906818 and NIH Grant EY09946. Research of KR is supported by grants from WARF and NSF grant DMS-1309998. 1 arXiv:1309.4111v1  [stat.ML]  16 Sep 2013  (b) This paper provides more guidance for data analytic issues than previous approaches. First, the results suggest an appropriate range for the regularization parameter. Second, our analysis gives a (statistical) model-based explanation for the “star-shaped” ﬁgure that often appears in empirical eigenvectors. This demonstrates how projecting the rows of the eigenvector matrix onto the unit sphere (an algorithmic step proposed by Ng et al. [12]) removes the ancillary eﬀects of heterogeneous degrees under the DC-SBM. Our results highlight when this step may be unwise. Preliminaries: Throughout, we study undirected and unweighted graphs or networks. Deﬁne a graph as G(E, V ), where V = {v1, v2, . . . , vN} is the vertex or node set and E is the edge set. We will refer to',\n",
       " '1602.00749': 'Recognition of human actions from RGB-D (Red, Green, Blue and Depth) data has attracted increasing attention in computer vision in recent years due to the advantages of depth information over conventional RGB video, e.g. being insensitive to illumination changes and reliable to estimate body silhouette and skeleton [14]. Since the ﬁrst work of such a type [10] reported in 2010, many methods [16, 24, 2, 12] have been proposed based on speciﬁc hand-crafted feature descriptors extracted from depth and/or skeleton data and many benchmark datasets were created for evaluating algorithms. With the recent development of deep learning, a few methods [18, 19, 3] have been developed based on Convolutional Neural Networks (Con- ∗Both authors contributed equally to this work †Corresponding author vNets) or Recurrent Neural Network (RNN). However, in most cases, either deeply learned or hand-crafted features have been employed. Little study was reported on the advantages of using both features simultaneously. This paper presents a novel framework that combines deeply learned features from the depth modality through ConvNets and the hand-crafted features extracted from skeleton modality. The framework overcomes the weakness of ConvNets being sensitive to global translation, rotation and scaling and leverages the strength of skeleton based features, e.g. Histogram of Oriented Displacement (HOD) [7], being invariant to scale, speed and clutter of background. In particular, depth and skeleton data are ﬁrstly augmented for deep learning and making the recognition insensitive to view variance. Secondly, depth sequences are segmented using the hand-crafted features based on joints motion histogram to exploit the local temporal information. All training segments are clustered using an Inﬁnite Gaussian Mixture Model (IGMM) through Bayesian estimation and labelled for training Convolutional Neural Networks (ConvNets) on the depth maps. Thus, a depth sequence can be reliably encoded into a sequence of segment labels. Finally, the sequence of labels is fed into a joint Hidden Markov Model and Support Vector Machine (HMM-SVM) classiﬁer to explore the global temporal information for ﬁnal recognition. The proposed framework has demonstrated a novel way in effectively exploring the spatial-temporal (both local and global) information for action recognition and has a number of advantages compared to conventional discriminative methods in which temporal information is often either ignored or weekly encoded into a descriptor and to generative methods in which temporal information tends to be overemphasized, especially when the training data is not sufﬁcient. Firstly, the use of skeleton data to segment video sequences into segments makes each segment have consistent and similar movement and, to some extent, be semantically meaningful (though this is not the intention of this paper) since skeletons are relatively high-level information 1  extracted from depth maps and each part of the skeleton has semantics. Secondly, the ConvNets trained over DMMs of depth maps provides a reliable sequence of labels by considering both spatial and local temporal information encoded into the DMMs. Thirdly, the use of HMM on the sequences',\n",
       " '1709.05522': 'Automatic Speech Recognition(ASR) has been an active research topic for several decades. Most state-of-the-art ASR systems beneﬁt from powerful statistical models, such as Gaussian Mixture Models(GMM), Hidden Markov Models(HMM) and Deep Neural Networks(DNN) [1]. These statistical frameworks often require a large amount of high quality data. Luckily, along with the wide adoption of smart phones, and the emerging market of various smart devices, real user data are generated world-wide and everyday, hence collecting data becomes easier than ever before. Combined with sufﬁcient amount of real data and supervised-training, statistical approach achieves great success all over the speech industry [2]. However, for legal and commercial reasons, most companies are not willing to share their data with the public: large industrial datasets are often inaccessible for academic community, which leads to a divergence between research and industry. On one hand, researchers are interested in fundamental problems such as designing new model structures or beating over-ﬁtting under limited data. Such innovations and tricks in academic papers sometimes are proven to be not effective when the dataset gets much larger, different scales of ∗The authors performed the work while off duty. data lead to different stories. On the other hand, industrial developers are more concerned about building products and infrastructures that can quickly accumulate real user data, then feedback collected data into simple algorithms such as logistic regression and deep learning. In ASR community, open-slr project is established to alleviate this problem1. For English ASR, industrial-sized datasets such as Ted-Lium [3] and LibriSpeech [4] offer open platforms, for both researchers and industrial developers, to experiment and to compare system performances. Unfortunately, for Chinese ASR, the only open-source corpus is THCHS30, released by Tsinghua University, containing 50 speakers, and around 30 hours mandarin speech data [5]. Generally speaking, Mandarin ASR systems based on small dataset like THCHS30 are not expected to perform well. In this paper, we present AISHELL-1 corpus. To authors’ limited knowledge, AISHELL-1 is by far the largest opensource Mandarin ASR corpus. It is released by Beijing ShellShell Company2, containing 400 speakers and over 170 hours of Mandarin speech data. More importantly, it is publicly available and is under Apache 2.0 license. This paper is organized as below. Section 2 presents the recording procedure, including audio capturing devices and environments. Section 3 describes the preparation of the related resources, including transcriptions and lexicon. Section 4 explains the ﬁnal structure of released corpus resources. In Section 5, a ”drop-in and run” Kaldi recipe is provided as a Mandarin ASR system baseline. 2. CORPUS PROFILE AISHELL-1 is a subset of the AISHELL-ASR0009 corpus, which is a 500 hours multi-channel mandarin speech corpus designed for various speech/speaker processing tasks. Speech utterances are recorded via there categories of devices in parallel: 1. Microphone: a high ﬁdelity AT2035 microphone with a',\n",
       " '1901.01365': 'Reinforcement learning (RL) has been successfully applied to a variety of tasks, including board games (Silver et al., 2016), robotic manipulation tasks (Levine et al., 2016), and video games (Mnih et al., 2015). Hierarchical reinforcement learning (HRL) is a type of RL that leverages the hierarchical structure of a given task by learning a hierarchical policy (Sutton et al., 1999; Dietterich, 2000). Past studies in this ﬁeld have shown that HRL can solve challenging tasks in the video game domain (Vezhnevets et al., 2017; Bacon et al., 2017) and robotic manipulation (Daniel et al., 2016; Osa et al., 2018b). In HRL, lower-level policies, which are often referred to as option policies, learn different behavior/control patterns, and the upper-level policy, which is often referred to as the gating policy, learns to select option policies. Recent studies have developed HRL methods using deep learning (Goodfellow et al., 2016) and have shown that HRL can yield impressive performance for complex tasks (Bacon et al., 2017; Frans et al., 2018; Vezhnevets et al., 2017; Haarnoja et al., 2018a). However, identifying the hierarchical policy structure that yields efﬁcient learning is not a trivial task, since the problem involves learning a sufﬁcient variety of types of behavior to solve a given task. In this study, we present an HRL method via the mutual information (MI) maximization with advantage-weighted importance, which we refer to as adInfoHRL. We formulate the problem of learning a latent variable in a hierarchical policy as one of learning discrete and interpretable repre1 arXiv:1901.01365v2  [cs.LG]  7 Mar 2019  Published as a conference paper at ICLR 2019 sentations of states and actions. Ideally, each option policy should be located at separate modes of the advantage function. To estimate the latent variable that corresponds to modes of the advantage function, we introduce advantage-weighted importance weights. Our approach can be considered to divide the state-action space based on an information maximization criterion, and it learns option policies corresponding to each region of the state-action space. We derive adInfoHRL as an HRL method based on deterministic option policies that are trained based on an extension of the deterministic policy gradient (Silver et al., 2014; Fujimoto et al., 2018). The contributions of this paper are twofold: 1. We propose the learning of a latent variable of a hierarchical policy as a discrete and hidden representation of the state-action space. To learn option policies that correspond to the modes of the advantage function, we introduce advantage-weighted importance. 2. We propose an HRL method, where the option policies are optimized based on the deterministic policy gradient and the gating policy selects the option that maximizes the expected return. The experimental results show that our proposed method adInfoHRL can learn a diversity of options on continuous control tasks. Moreover, our approach can improve the performance of TD3 on such tasks as the Walker2d and Ant tasks in OpenAI Gym with MuJoco simulator. 2 BACKGROUND In',\n",
       " '1110.4613': 'We consider the discrete memoryless wiretap channel shown in Fig. 1. The capacity region of this channel is characterized by the rate, R, between the legitimate users Alice and Bob, and the equivocation, Re, at the eavesdropper Eve. Wyner [1] characterized the rate-equivocation region when the received signal at Eve is a degraded version of the signal received at Bob. Csisz´ar and K¨orner [2] characterized the rate-equivocation region for general, not necessarily degraded, wiretap channels. Csisz´ar and K¨orner’s characterization involves two auxiliary random variables: U, for rate splitting, and V , for channel preﬁxing. Evaluation of capacity regions involving auxiliary random variables is generally diﬃcult, and it is desirable to determine cases where the auxiliary random variables are either not needed or their optimal selection is simpliﬁed. For the wiretap channel, under certain conditions, it is known that the use of one or both of these auxiliary random variables is unnecessary. For instance, if the wiretap channel is degraded, neither rate splitting nor channel preﬁxing is necessary, i.e., the selection U = φ and V = X is optimal, for the entire rate-equivocation region [1]. In fact, the same conclusion holds if the wiretap channel is less noisy [2, Theorem 3]. For general wiretap channels, for the purposes of characterizing the secrecy capacity, i.e., the largest equivocation, rate splitting is unnecessary, i.e., U = φ is optimal [2]; further, if the wiretap channel is more capable, then channel preﬁxing as well is unnecessary, i.e., U = φ and V = X are optimal [2]. In this paper, we explore speciﬁc classes of wiretap channels for which calculation of the optimal rate splitting and/or channel preﬁxing parameters is simpler. The inclusion relations among the classes of wiretap channels considered in this paper are shown in Fig. 2. First, we show that if the wiretap channel is more capable, then channel preﬁxing is unnecessary; that is, the rate-equivocation region can be characterized by rate splitting, i.e., V = X is optimal and the boundary of the rate-equivocation region can be traced with optimal (U, X) only. Conversely, we prove under a mild condition that, if the channel is not more capable, then channel preﬁxing is strictly necessary, i.e., V ̸= X is strictly needed. Next, we study the class of cyclic shift symmetric wiretap channels. We explicitly determine the optimal selection of U and V that achieve the boundary of the rate-equivocation region. In particular, optimal U and V are expressed in terms of the cyclic shifts of the solution of an auxiliary optimization problem that involves only one auxiliary random variable. This is a considerable reduction in the computation requirement for the calculation of (the boundary of) the rate-equivocation region. We provide the cardinality bound on this single auxiliary random variable appearing in the optimization problem. Then, we formulate the problem as a constrained optimization problem. We provide a suﬃcient condition under which rate splitting is unnecessary',\n",
       " '1806.05666': 'A signiﬁcant fraction of videos on the Internet contain people moving [18] and the literature suggests that optical ﬂow plays an important role in understanding human action [25, 39]. Several action recognition datasets [28, 39] contain human motion as a major component. The 2D motion of humans in video, or human ﬂow, is an important feature that provides a building block for systems that can understand and interact with humans. Human ﬂow is useful for various applications including analyzing pedestrians in road sequences, motioncontrolled gaming, activity recognition, human pose estimation system, etc. Despite this, optical ﬂow has previously been treated as a generic, low-level, vision problem. Given the importance of people, and the value of optical ﬂow in understanding them, we develop a ﬂow algorithm that is speciﬁcally tailored to humans and their motion. Such motions are non-trivial since humans are complex, articulated, objects that vary in shape, size and appearance. They move quickly, self occlude, and adopt a wide range of poses. Our goal is to obtain more accurate 2D motion estimates for human bodies by training a ﬂow algorithm speciﬁcally for human movement. To do so, we create a large and realistic dataset of humans moving in virtual worlds with ground truth optical ﬂow (Fig. 1(a)). We *This work was done by JR while at MPI. c⃝2018. The copyright of this document resides with its authors. It may be distributed unchanged freely in print or electronic forms. arXiv:1806.05666v2  [cs.CV]  22 Jul 2018  2 RANJAN, ROMERO, BLACK: LEARNING HUMAN OPTICAL FLOW (a) Our dataset (b) Results on synthetic scenes (c) Results on real world scenes Figure 1: (a) We simulate human motion in virtual world creating an extensive dataset with images (top row) and ﬂow ﬁelds (bottom row); color coding from [2]. (b) We train an existing deep network for human motion estimation and show that it performs better when trained on our dataset and (c) generalizes to human motions in real world scenes. train a neural network based on SPyNet [35] using this dataset and show that it outperforms state of the art optical ﬂow on the test sequences of this dataset (Fig. 1(b)). Furthermore we show that it generalizes to real video sequences (Fig. 1(c)). Here we also extend SPyNet, making it end-to-end trainable. Several datasets and benchmarks [2, 5, 17] have been established to drive the progress in optical ﬂow. We argue that these datasets are insufﬁcient for the task of human motion estimation and, despite its importance no attention has been paid to datasets and algorithms for human ﬂow. One of the main reasons is that dense human motion is extremely difﬁcult to capture accurately in real scenes. Without ground truth, there has been little work focused speciﬁcally on estimating human optical ﬂow. To advance research on this problem, the community needs a dataset tailored to human ﬂow. A key observation is that recent work has shown that optical ﬂow methods trained',\n",
       " '1505.01858': 'The research on future mobile broadband networks, referred to as the ﬁfth generation (5G), has started in the past few years. In particular, stringent key performance indicators (KPIs) and tight requirements have been introduced in order to handle higher mobile data volumes, reduce latency, increase connectivity and at the same time increase energy efﬁciency (EE) [1], [2]. The current network and infrastructure cannot cope with 5G requirements—fundamental changes are needed to handle future non-homogeneous networks as well as new trends in user behavior such as high quality video streaming and future applications like augmented reality. 5G technology is supposed to evolve existing networks and at the same time integrate new dedicated solutions to meet the KPIs [2]. The new key concepts for 5G include massive MIMO (multipleinput multiple-output), ultra dense networks (UDN), device-todevice (D2D) communications, and huge number of connected devices, known as machine-type communications (MTC). The potential gains and properties of these different solutions have been studied individually, but the practical gains when they coexist and share network resources are not very clear so far. In this paper, we study the coexistence of two main concepts, namely massive MIMO and D2D communication. Massive MIMO is a type of multiuser MIMO (MU-MIMO) technology where the base station (BS) uses an array with hundreds of active antennas to serve tens of users on the same time/frequency resources by coherent precoding [3], [4]. Massive MIMO techniques are particularly known to be very spectral efﬁcient, in the sense of delivering sum rates [5]. This comes at the price of more hardware, but the solution is still likely to be energy efﬁcient [6], [7]. On the other hand, in a D2D communication, user devices can communicate directly with each other and the user plane data is not sent through the BS [8]. D2D users either share the resources with cellular networks (overlay approach) or reuse the same spectrum (underlay approach). D2D communication is used for close proximity applications and can bring tremendous gains in terms of ofﬂoading core networks and achieving higher data rates with less transmission energy. We consider two network performance metrics in this work: The average sum rate (ASR) in bit/s and the EE deﬁned as the number of bits transmitted per Joule of energy consumed by the transmitted signals and the transceiver hardware. It is well known that these metrics depend on the network infrastructure, radio interface, and underlying system assumptions [7], [9], [10]. The motivation behind our work is to study how the additional degrees of freedom resulting from high number of antennas in the BS can affect the ASR and EE of a multi-tier network where a D2D tier is bypassing the BS. We focus on the downlink since majority of the payload data and network energy consumption are coupled to the downlink [9]. We assume that each D2D pair is transmitting simultaneously with the BS in an underlay fashion. In addition, we assume that the communication mode',\n",
       " '1807.00392': 'Artiﬁcial Neural Network methods are quickly becoming ubiquitous in society, spurred by advances in image, signal, and natural language processing. This pervasiveness leads to a new need for considering the fairness of such networks from many perspectives, including: how they are used, who can access them and their training data, and potential biases in the model itself. There are many reasons for desiring fair classiﬁcation algorithms. These include legal mandates to be non-discriminative, ensuring a moral or ethical goal, or for use as evidence in legal proceedings (Romei & Ruggieri, 2014). Despite the long-standing need and interest in this problem, there are few methods available today for training fair networks. When we say that a network is fair, we mean fair with respect to a protected attribute ap, such as age or gender. Our desire is that a model’s predicted label ˆy given a feature vector x is invariant to changes in ap. An initial reaction may be to simply remove ap from the feature vector x. While intuitive, this “fairness through unawareness” does not remove the correlations with ap that exist in the data, and so the result will still produce a biased model (Pedreshi et al., 2008). For this reason we need to devise approaches that explicitly remove the presence of ap from the model’s predictions. 1Booz Allen Hamilton 2University of Maryland, Baltimore County. Correspondence to: Edward Raff <raff_edward@bah.com>. Proceedings of the 5 th Workshop on Fairness, Accountability and Transparency in Machine Learning, Stockholm, Sweden, 2018. Copyright 2018 by the author(s). We do so in this work by introducing a new method to train fair neural networks. Our approach, termed Gradient Reversal Against Discrimination (GRAD), makes use of a network which simultaneously attempts to predict the target class y and protected attribute ap. The key is that the gradients resulting from predictions of ap are reversed before being used for weight updates. The result is a network which is capable of learning to predict the target class but effectively inhibited from being able to predict the protected attribute. GRAD displays competitive accuracy and improved fairness when compared to prior approaches. GRAD’s advantage comes from increased simplicity compared to prior approaches, making it easier to apply and applicable to a wider class of networks. Prior works in this space are limited to one attribute (but see Zafar et al., 2017) and require the introduction of multiple hyper-parameters. These parameters must be cross-validated, making the approaches challenging to use. Further, our approach can be used to augment any current model architecture, where others have been limited to auto-encoding style architectures. 2. Gradient Reversal Against Discrimination We now present our new approach to developing neural networks that are fair with respect to some protected attribute. We call it Gradient Reversal Against Discrimination (GRAD), and is inspired by recent work in transfer learning. Notably, Ganin et al. (2016) introduced the',\n",
       " '1812.10179': 'FAILED',\n",
       " '1611.01423': 'Combining abstract, symbolic reasoning with continuous neural reasoning is a grand challenge of representation learning. This is particularly important while dealing with exponentially large domains such as source code and logical expressions. Symbolic notation allows us to abstractly represent a large set of states that may be perceptually very different. Although symbolic reasoning is very powerful, it also tends to be hard. For example, problems such as the satisﬁablity of boolean expressions and automated formal proofs tend to be NP-hard or worse. This raises the exciting opportunity of using pattern recognition within symbolic reasoning, that is, to learn patterns from datasets of symbolic expressions that approximately represent semantic relationWork started when M. Allamanis was at Edinburgh. This work was done while P. Kohli was at Microsoft. 1Microsoft Research, Cambridge, UK 2University of Edinburgh, UK 3DeepMind, London, UK 4The Alan Turing Institute, London, UK. Correspondence to: Miltiadis Allamanis <t-mialla@microsoft.com>. Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017 by the author(s). ships. However, apart from some notable exceptions (Alemi et al., 2016; Loos et al., 2017; Zaremba et al., 2014), this area has received relatively little attention in machine learning. In this work, we explore the direction of learning continuous semantic representations of symbolic expressions. The goal is for expressions with similar semantics to have similar continuous representations, even if their syntactic representation is very different. Such representations have the potential to allow a new class of symbolic reasoning methods based on heuristics that depend on the continuous representations, for example, by guiding a search procedure in a symbolic solver based on a distance metric in the continuous space. In this paper, we make a ﬁrst essential step of addressing the problem of learning continuous semantic representations (SEMVECs) for symbolic expressions. Our aim is, given access to a training set of pairs of expressions for which semantic equivalence is known, to assign continuous vectors to symbolic expressions in such a way that semantically equivalent, but syntactically diverse expressions are assigned to identical (or highly similar) continuous vectors. This is an important but hard problem; learning composable SEMVECs of symbolic expressions requires that we learn about the semantics of symbolic elements and operators and how they map to the continuous representation space, thus encapsulating implicit knowledge about symbolic semantics and its recursive abstractive nature. As we show in our evaluation, relatively simple logical and polynomial expressions present signiﬁcant challenges and their semantics cannot be sufﬁciently represented by existing neural network architectures. Our work in similar in spirit to the work of Zaremba et al. (2014), who focus on learning expression representations to aid the search for computationally efﬁcient identities. They use recursive neural networks (TREENN)1 (Socher et al., 2012) for modeling homogenous, single-variable polynomial expressions. While they present impressive results, we ﬁnd that the TREENN model fails when applied to more complex symbolic polynomial',\n",
       " '1706.02888': 'Generic visual object tracking is the computer vision problem of estimating the trajectory of a target throughout an image sequence, given only the initial target location. Visual tracking is useful in numerous applications, including autonomous driving, smart surveillance systems and intelligent robotics. The problem is challenging due to large variations in appearance of the target and background, as well as challenging situations involving motion blur, target deformation, inand out-of-plane rotations, and fast motion. To tackle the problem of visual tracking, several paradigms exist in literature [13]. Among diﬀerent paradigms, approaches based on the Discriminative Correlation Filters (DCF) based framework have achieved superior results, evident from recent the Visual Object Tracking (VOT) challenge results [14][13]. This improvement in performance, both in terms of precision and robustness, is largely attributed to the use of powerful multi-dimensional features such as HOG, Colornames, and deep features [5][20][10], as well as sophisticated learning models [8][9]. Despite the improvement in tracking performance, the aforementioned stateof-the-art DCF based approaches employ a single rigid model of the target. However, this reliance on a single rigid model is insuﬃcient in situations involving rotations and deformable targets. In such complex situations, the rigid ﬁlters fail to capture information of the target parts that move relative to eachother. arXiv:1706.02888v1  [cs.CV]  9 Jun 2017  2 J. Johnander, M. Danelljan, F.S. Khan, M. Felsberg Fig. 1. Example tracking results of our deformable correlation ﬁlter approach on three challenging sequences. The circles mark sub-ﬁlter locations and the green box is the predicted target location. The red boxes (in the middle and lower rows) show the baseline predictions. The sub-ﬁlter locations deform according to the appearance changes of the target in the presence of deformations. This desired information can be retained by integrating deformability in the DCF ﬁlters. Several recent works aim at introducing part-based information into the DCF framework [18][16][19]. These approaches introduce an explicit component to integrate the part-based information in the learning. Diﬀerent to these approaches, we investigate a deformable DCF model, which can be learned in uniﬁed fashion. In many real-world situations, such as a running human or a rotating box, diﬀerent regions of the target deform relative to each other. Ideally, such information should be integrated in the learning formulation by allowing the regions of the appearance model to deform accordingly. This ﬂexibility in the tracking model reduces the need of highly invariant features, thereby increasing the discriminative power of the model. However, increasing the ﬂexibility and complexity of the model introduces the risk of over-ﬁtting and complex inference mechanisms, which degrades the robustness of the tracker. In this paper, we therefore advocate a uniﬁed formulation, where the deformable ﬁlter is learned by optimizing a single joint objective function. Additionally, this uniﬁed strategy enables the careful incorporation of regularization models to tackle the risk of over-ﬁtting. Contribution We propose a',\n",
       " '1211.7012': 'FAILED',\n",
       " '0902.2917': 'T O overcome the reduction of channel capacity caused by fading, Telatar [1], Foschini and Gans [2] described in the late 90s the potential gain of switching to multiple input multiple output (MIMO) systems. These results triggered many advances mostly concentrated on the coding aspects for transmitting antennas, e.g. Alamouti [3] and Tarokh et al. [4] for Space-Time Block Codes (STBC) and also Tarokh et al. [5] for Space-Time Trellis Codes. Zhang and Fitz [6], [7] were the ﬁrst to apply the idea of STC to CPM by constructing trellis codes. In [8], Silvester et al. derived a diagonal block ST-code which enables non-coherent detection. In [9], Bokolamulla and Aulin described a concatenation approach to the construction of STC for CPM. A condition for optimal coding gain while sustaining full diversity was also recently derived by Zaji´c and St¨uber [10]. Inspired by orthogonal design codes, Wang and Xia introduced in [11] the ﬁrst orthogonal STC for two transmitting antennas and full response CPM and later in [12] for partial response. Their approach was extended in [13] to construct a pseudo-orthogonal ST-coded CPM for four antennas. To avoid the structural limitation of orthogonal design, we proposed in [14], [15] a STC CPM scheme based on L2-orthogonality for two antennas. Sufﬁcient conditions for L2 orthogonality were described, L2-orthogonal codes were introduced and the simulation results displayed good performance and full rate. Here, motivated by this results, we extend our previous work and generalize these conditions for three transmitting antennas. The main result of the three transmit antennas case, is that it can, unlike the codes based on orthogonal design, achieve full diversity with a full rate code: 1) the full rate property is one of the main advantage of using the L2 norm criterion, instead of merely extending the classical Tarokh [4] orthogonal design to the CPM case. Indeed, in the classical orthogonal design approach, which is based on optimal decoding for linear modulations, the criterion is expressed as the orthogonality between matrices of elements, each of these elements being a deﬁnite integral (usually the output of a matched ﬁlter). On the contrary, in the L2 design approach M. Hesse, L. Deneire and J. Lebrun are with the Lab. I3S, CNRS / University of Nice, Sophia Antipolis, France; e-mail: {hesse,deneire,lebrun}@i3s.unice.fr; The work of M. Hesse is supported by the EU by a Marie-Curie Fellowship (EST-SIGNAL program: http://est-signal.i3s.unice.fr) under contract No MEST-CT-2005-021175.  used for non-linear modulations, the product in Eq. (8) is a deﬁnite integral itself, the integrand being the product of two signals. This allows more degrees of freedom and enables the full rate property. 2) the full diversity property can be proved in a similar way to the classical case [7], with the help of the extensions proposed by Zaji´c and St¨uber [10]. Furthermore, it should be pointed out that the proposed',\n",
       " '1706.10198': '1 1 Basics of Random Access - ALOHA and Slotted ALOHA 7 1.1 ALOHA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8 1.2 Slotted ALOHA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10 1.3 Considerations on ALOHA and Slotted ALOHA . . . . . . . . . . . . . . . . . 11 1.4 Other Fundamental Protocols in Random Access . . . . . . . . . . . . . . . . . 13 2 Preliminaries 19 2.1 The Scenario . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19 2.2 Time Diversity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20 2.3 Channel Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20 2.4 Successive Interference Cancellation . . . . . . . . . . . . . . . . . . . . . . . . 22 2.5 Decoding Conditions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 i  ii CONTENTS 3 The Role of Interference Cancellation in Random Access Protocols 25 3.1 Recent Random Access Protocols . . . . . . . . . . . . . . . . . . . . . . . . . . 25 3.1.1 Slot Synchronous Random Access . . . . . . . . . . . . . . . . . . . . . 26 3.1.2 Asynchronous Random Access . . . . . . . . . . . . . . . . . . . . . . . 30 3.1.3 Tree-Splitting Algorithms . . . . . . . . . . . . . . . . . . . . . . . . . . 36 3.1.4 Random Access Without Feedback . . . . . . . . . . . . . . . . . . . . . 45 3.2 Applicable Scenarios . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49 3.3 Open Questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51 3.4 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52 4 Asynchronous RA with Time Diversity and Combining: ECRA 55 4.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56 4.2 System Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56 4.2.1 Modeling of the Decoding Process . . . . . . . . . . . . . . . . . . . . . 58 4.2.2 Enhanced Contention Resolution ALOHA Decoding Algorithm . . . . 59 4.2.3 Summary and Comments . . . . . . . . . . . . . . . . . . . . . . . . . . 62 4.3 Packet Loss Rate Analysis at Low Channel Load . . . . . . . . . . . . . . . . . 63 4.3.1 Packet Loss Rate Approximation . . . . . . . . . . . . . . . . . . . . . . 64 4.3.2 Vulnerable Period Duration for Asynchronous RA with FEC . . . . . . 65 4.3.3 Vulnerable Period Duration for Asynchronous RA with MRC and d = 2 66 4.4 Performance Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67 4.4.1 Numerical Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69 4.5 Detection, Combining and Decoding - A Two-Phase Procedure . . . . . . . . . 75 4.5.1 Detection and Decoding . . . . . . . . . . . . . . . . . . . . . . . . . . . 76 4.5.2 Hypothesis Testing, Interference-Aware Rule . . . . . . . . . . . . . . . 79 4.6 Two-Phase Procedure Numerical Results . . . . . . . . . . . . . . . . . . . . . 80 4.6.1 ROC Comparison . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80 4.6.2 ECRA Detection and Replicas Coupling Performance . . . . . . . . . . 80 4.6.3 Spectral Efﬁciency . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 81 4.7 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83 5 Layer 3 Throughput and PLR Analysis for Advanced RA 85 5.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 86 5.2 System Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 86 5.3 L3 Throughput and Packet Loss Rate Analysis . . . . . . . . . . . . . . . . . . 87  CONTENTS iii 5.3.1 Asynchronous RA Protocols . . . . . . . . . . . . . . . . . . . . . . . . . 87 5.3.2 Slot Synchronous RA Protocols . . . . . . . . . . . . . . . . . . . . . . . 88 5.4 Numerical Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 91 5.4.1 Asynchronous and Slot Synchronous RA Layer 3 Performance Comparison . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 92 5.4.2 Slot Synchronous Layer 2 and Layer 3 Comparison . . . . . . . . . . . 95 5.4.3 Layer 3 Slot Synchronous Bounds . . . . . . . . . . . . . . . . . . . . . 96 5.5 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 98 6 IRSA over the Rayleigh Block Fading Channel 101 6.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101 6.2 System Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 102 6.2.1 Access Protocol . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 102 6.2.2 Received Power and Fading Models . . . . . . . . . . . . . . . . . . . . 103 6.2.3 Graph Representation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103 6.2.4 Receiver Operation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105 6.3 Decoding Probabilities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107 6.4 Density Evolution Analysis and Decoding Threshold Deﬁnition . . . . . . . . 108 6.5 Numerical Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 111 6.6 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 112 7 Random Access with Multiple Receivers 115 7.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115 7.2 System Model and Preliminaries . . . . . . . . . . . . . . . . . . . . . . . . . . 116 7.2.1 Notation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118 7.3 Uplink Performance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119 7.3.1 Uplink Throughput . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119 7.3.2 Packet Loss Probability . . . . . . . . . . . . . . . . . . . . . . . . . . . 125 7.4 An Achievable',\n",
       " '1807.10589': 'As deep neural networks have gained popularity in many scientiﬁc disciplines and technological applications, there is a growing interest in understanding the representations they learn and the computations they perform. One approach towards achieving such understanding is to visualize the features that activate the neurons in a network. There is a growing body of work that seeks to visualize features by synthesizing images which maximally drive hidden layer units. While this approach can give us a rough intuition about a unit’s selectivity, it provides only a very incomplete picture of its computation. In addition to characterizing feature detectors by the stimulus that elicits the largest response, it is important to identify the nuisance parameters to which the neuron is invariant. As hidden layers build up response invariances gradually with depth, it is not the image arXiv:1807.10589v1  [cs.CV]  27 Jul 2018  2 SA Cadena, MA Weis, LA Gatys. M Bethge, AS Ecker that most strongly drives a unit that is the most telling about this unit’s function, but instead the set of images that elicit a strong response. While some previous work has visualized multiple ‘facets’ of neurons’ selectivity, these eﬀorts focused mostly on the highest layers of the network and relied on initialization or random sampling strategies to create multiple images for each unit. However, as we show in the present paper, these approaches underestimate the true diversity of the selectivity of even relatively low-level units. Additionally, these approaches have not oﬀered insights about how the representations of diﬀerent networks trained on the same task compare. Our contributions are the following: 1. Motivated by the phase invariance of complex cells in the early visual system of the brain, we show why visualizing invariance is as important as visualizing selectivity for understanding the computations of even low-level units. 2. We develop a non-parametric approach to map the manifold of highlyactivating inputs as exhaustively as possible. 3. We show that even relatively low-level units exhibit a remarkable degree of invariance in VGG-19 [28], which is not revealed by ﬁnding highly activating stimuli from multiple optimization runs with random initializations. 4. We ﬁnd that in low to intermediate layers of VGG-19, at least two types of invariances emerge: tolerance to local diﬀeomorphic transformations tuned to speciﬁc features, and phase invariance, where units respond well to periodic texture patterns and are insensitive to their phase. We additionally oﬀer a way to quantify these invariances. 5. In contrast, we ﬁnd that low to intermediate layers of a network with skip connections (ResNet-50 [11]) that was trained on the same task as VGG19 exhibit far less phase invariance, revealing representational diﬀerences between these two networks. 6. We showcase our visualization approach on a CNN trained to predict responses to natural images in primary visual cortex of the primate brain. We provide the code to replicate our results. 1 2 Related work One way to',\n",
       " '1410.1784': 'Online learning methods based on stochastic approximation theory [21] have been a promising research direction to tackle the learning problems of the so-called Big Data era [1, 10, 12]. Stochastic gradient descent (SGD) is probably the best known example of this kind of techniques, used to solve a wide range of learning problems [9]. This algorithm and other versions [29] are usually employed to train discriminative models such as logistic regression or SVM [10]. There also are some successful examples of the use of SGD for discriminative training of probabilistic generative models, as is the case of deep belief networks [19]. However, this learning algorithm cannot be used directly for the discriminative training of general generative models. One of the main reasons is that statistical estimation or risk minimization problems of generative models involve the solution of an optimization problem with a large number of normalization constraints [26], i.e. those which guarantee that the optimized parameter set deﬁnes a valid probabilistic model. Although successful solutions to this problem have been proposed [16, 22, 26, 32], they are based on adhoc methods which cannot be easily extended to other statistical models, and hardly scale to large data sets. Stochastic approximation theory [21] has also been used for maximum likelihood estimation (MLE) of probabilistic generative models with latent variables, as is the case of the online EM algorithm [13, 30]. This method provides efﬁcient MLE estimation for a broad class of statistical models (i.e. exponential family models) by sequentially updating the so-called expectation parameters. The advantage of this approach is that the resulting iterative optimization algorithm is fairly simple and amenable, as it does not involve any normalization constraints. In this paper we show that the derivation of Sato’s online EM [30] can be extended for the discriminative learning of generative models by introducing a novel interpretation of this algorithm as a natural gradient algorithm [3]. The resulting algorithm, called stochastic discriminative EM (sdEM), is an online-EM-type algorithm that can train generative probabilistic models belonging to the exponential family using a wide range of discriminative loss functions, such as the negative conditional log-likelihood or the Hinge loss. In opposite to other discriminative learning approaches [26], models trained by sdEM can deal with missing data and latent variables in a principled way either when being learned or when making predictions, because at any moment they always deﬁne a joint probability distribution. sdEM could be used for learning using large scale data sets due to its stochastic approximation nature and, as we will show, because it allows to compute the natural gradient of the loss function with no extra cost [3]. Moreover, if allowed by the generative model and the discriminative loss  function, the presented algorithm could potentially be used interchangeably for classiﬁcation or regression or any other prediction task. But in this',\n",
       " '1705.02949': 'O BJECT tracking has emerged as a rigorous research topic due to increased demand of intelligent surveillance systems. But not only for surveillance, object detection and tracking are widely used in event classiﬁcation, behavior understanding, crowd ﬂow estimation, human-computer interaction and so on. Considerable progress is achieved in This work was a part of collaborative research between Indian Statistical Institute and University of Dayton. Kumar S. Ray is with Indian Statistical Institute, 203 B.T.Road, Kolkata108, India (e-mail: ksray@ isical.ac.in). Vijayan K. Asari is with University of Dayton, 300 Collage park, Dayton, OH 45469-0232, USA (e-mail: vasari1@udayton.edu). Soma Chakraborty is with Indian Statistical Institute, 203 B.T.Road, Kolkata-108, India (e-mail: soma.gchakraborty@gmail.com). object tracking during the present decade and many benchmark algorithms have been established on object tracking [3], [4], behavior understanding [18] etc. Still it remains a challenging problem due to the complexities in a video sequence like noise, unpredictable motion of objects, partial or full occlusion, illumination variation, background variation etc. When a video is captured by moving camera (hand-held or installed on a vehicle or on a rotating surface), both background and foreground features change their position in each frame. Thus, separation of background and foreground becomes highly complicated task as foreground extraction using traditional background subtraction or frame differencing does not apply for such videos. So far, some works have been reported to detect track object/s successfully in moving background. Most of the algorithms extract foreground by computing global motion and compensating it by processing feature points [19], [20], [21], [11], [31], [22], [32], [12], [23], [13], [5], [33]. In our work, we have proposed a direct foreground extraction method by analyzing an input video spatio-temporally. In this approach, neither we need any apriori knowledge about the scene nor we take any assumption about the objects in the scene. The intuition behind the proposed method is that; rate of change of foreground region in consecutive frames is greater than the rate of change of background region, as motion in background region is only perceivable due to the translation or transformation of camera. But for foreground region, velocity of the region itself and the speed of camera are integrated. So, variation in foreground is more prominent than variation in background. If a block of few (say, ’n’ number of) consecutive frames are analyzed at a time, then only signiﬁcant spatial and temporal changes can be easily extracted suppressing the background variation. We have analyzed each spatio-temporal block of an input image sequence using a three-dimensional Gabor ﬁlter bank. Spatio-temporal blobs are then generated by applying selective average approach on the output of 3D Gabor ﬁlter bank. These blobs are either the whole moving object or parts of a moving object. So, Kruskal’s Minimum Spanning Tree (KMST) is employed to merge the discrete blob-parts of an object. Then the object is represented by',\n",
       " '1709.00616': 'Arabic word segmentation has shown to signiﬁcantly improve output quality in NLP tasks such as machine translation (Habash and Sadat, 2006; Almahairi et al., 2016), part-of-speech tagging (Diab et al., 2004; Habash and Rambow, 2005), and information retrieval (M. Aljlayl and Grossman, 2002). A considerable amount of research has therefore been spent on Arabic morphological segmentation in the past two decades, ranging from rule-based analyzers (Beesley, 1996) to state-of-the-art statistical segmenters (Pasha et al., 2014; Abdelali et al., 2016; Khalifa et al., 2016). Morphological segmentation splits words into morphemes. For example, ‘‘wktAbnA” “A\\tJK.A\\x10J»ð” (gloss: and our book) is decomposed into its stem and afﬁxes as: “w+ ktAb +nA” “A\\tK+ H. A\\x10J» +ð”. Despite the gains obtained from using morphological segmentation, there are several caveats to using these tools. Firstly, they make the training pipeline cumbersome, as they come with complicated pre-processing (and additional postprocessing in the case of English-to-Arabic translation (El Kholy and Habash, 2012)). More importantly, these tools are dialectand domain-speciﬁc. A segmenter trained for modern standard Arabic (MSA) performs signiﬁcantly worse on dialectal Arabic (Habash et al., 2013), or when it is applied to a new domain. In this work, we explore whether we can avoid the language-dependent pre/post-processing components and learn segmentation directly from the training data being used for a given task. We investigate data-driven alternatives to morphological segmentation using i) unsupervised sub-word units obtained using byte-pair encoding (Sennrich et al., 2016), ii) purely character-based segmentation (Ling et al., 2015), and iii) a convolutional neural network over characters (Kim et al., 2016). We evaluate these techniques on the tasks of machine translation (MT) and part-of-speech (POS) tagging and compare them against morphological segmenters MADAMIRA (Pasha et al., 2014) and Farasa (Abdelali et al., 2016). On the MT task, byte-pair encoding (BPE) performs the best among the three methods, achieving very similar performance to morphological segmentation in the Arabic-to-English direction and slightly worse in the other direction. Character-based methods, in comparison, perform better on the task of POS tagging, reaching an accuracy of 95.9%, only 1.3% worse than morphological segmentation. We also analyze the effect of segmentation granularity of Arabic on the quality of MT. We observed that a neural MT (NMT) system is sensitive to source/target token ratio and performs best when this ratio is close to or greater than 1. arXiv:1709.00616v1  [cs.CL]  2 Sep 2017  2 Segmentation Approaches We experimented with three data-driven segmentation schemes: i) morphological segmentation, ii) sub-word segmentation based on BPE, and iii) two variants of character-based segmentation. We ﬁrst map each source word to its corresponding segments (depending on the segmentation scheme), embed all segments of a word in vector space and feed',\n",
       " '1410.5107': 'Interference channels (IC) have been extensively studied in the past years due to their practical relevance. The capacity of even the simple two-user case is still open in general. For the Gaussian noise IC progress has been made by focusing on the degrees-of-freedom (DoF), or scaling of the sum-capacity with signal-noise-ratio (SNR) as SNR grows to inﬁnity. A signaling scheme, known as interference alignment [1], has been shown to achieve 1/2 the interference-free capacity for each user for almost all channel realizations, regardless of the number of users, in single antenna systems. This showed the surprising result that ICs are not intrinsically interference limited. Multiple-input-multiple-output (MIMO) techniques are widely used in practical wireless communication systems as a means to increase the spectral efﬁciency. The complete characterization of the DoF of a general multiuser MIMO IC has been elusive so far. The case where every node has the same number of antennas was solved in [1], where it was shown that MIMO operations are not needed to achieve the optimal DoF. The question whether the same remains true in asymmetric MIMO IC has been answered in some special cases only. In [2] Jafar and Fakhereddin fully characterized the DoF of the 2-user MIMO IC with arbitrary number of antennas at each node. Their result has served as a fundamental outer bound for the K-user MIMO IC where each transmitter has M antennas, each receiver has N antennas, and M ̸= N, indicated as the (M × N)K IC [3], [4], [5], [6], [7], [8]. The idea is to partition both the set of transmitters and the set of receivers into two groups, let the users in each group perfectly cooperate and thus outer bound the performance of the original IC by that of the so obtained 2-(super)user IC. For the (M × N)K IC, MIMO operations are needed in order to attain the optimal DoF; however it was observed that, except for some values of M/N, either M or N can be reduced without affecting the DoF [3], [5]. For this (M × N)K model, both the achievability and converse proofs relied on the the symmetry of antennas across users and it is not a priori clear how to generalize them to settings that lack this symmetry. The case where K MIMO users share the same channel and each node can have different number of antennas has not received so much attention as of yet, to the best of our knowledge. The reason may lie in the fact that known bounds for “almost symmetric” ICs do not seem to be tight in the general case. In this work we study the class of general asymmetric MIMO ICs with square direct link channel matrices, that is, each transmitter and its corresponding receiver have the same number of antennas, but different transmitter-receiver pairs can have different number of antennas. Although this setting is not fully general',\n",
       " '1810.07278': 'FAILED',\n",
       " '1812.00312': 'Imagine you are visiting a large grocery store that you have never been to before. You see the dairy items on the left shelf and the seasoning corner ahead of you. Everything you see is new, yet you are still able to orient yourself and effortlessly navigate in the environment. Humans have developed the capability of building what is called a cognitive map—a mental representation to perceive, store, and recall relative location by learning semantic and geometric information [44]. Such cognitive map is (a) CNN features (b) ECO features Figure 1. CNN vs ECO feature embeddings of six different semantic categories from three grocery stores using PCA. ECO representation is well-aligned, robust to geometry and adaptable across different stores, while CNN representation is noisy and nondiscriminative. both robust and reconﬁgurable: it provides a sense of direction and distance in the semantic world. Humans can readily construct a new representation by reconﬁguring their past memories1. For instance, you can localize yourself in a new store despite the fact it has a new spatial layout and visual 1Such ability has been called the GPS of the brain and the hippocampus is known to be responsible to construct the cognitive map [30]. 1 arXiv:1812.00312v1  [cs.CV]  2 Dec 2018  patterns. We can do this, without accurate spatial information or photographic memory (e.g., exact item label, spatial arrangement of items, etc.). The ability to build such a cognitive map from (current and past) structured and semantically rich data, will enable intelligent systems, such as mobile robots, to explore and navigate uncharted spaces. Inspired by the cognitive map, in this paper, we present a new representation, called ECO (Egocentric COgnitive Map), built from a ﬁrst person video. ECO has the following properties: (1) Reconﬁgurability: the cognitive map is constructed sequentially via temporal saccade movements related to the retinal structure of human eyes, i.e., the representation of each region in the ﬁeld of view is reconstructed by parts. We design the map by assembling visual semantic data and use the spatial layout of the new scene as a geometric constraint; (2) Robustness: analogous to the human ability of mental re-scaling [5], visual semantics need to be stabilized using 3D geometric representations (e.g., vanishing point, gravity, and spatial layout) [25, 31]. Further, as the visual scene around the camera is distorted with respect to an egocentric coordinate (e.g., a farther object appears smaller [26]) this results in distinctive representations for the same object; (3) Adaptability: albeit sharing similar layout and visual patterns, different scenes never look the same, e.g., other people in the scene, illumination, and item arrangements make such scene quite unique. To build a generalizable cognitive map, the representation needs to be transformable, so that it can be adapted to a new scene without explicitly specifying scene correspondences. Existing visual localization frameworks in computer vision [4, 9, 12, 14',\n",
       " '1811.12064': 'Feature selection is also known as variable or attribute selection. It is the selection of a subset of relevant attributes in our data that are most relevant to our predictive modeling problem. It has been $Fully documented templates are available in the elsarticle package on CTAN. Preprint submitted to Elsevier December 4, 2018 arXiv:1811.12064v3  [stat.ML]  3 Dec 2018  an active and fruitful ﬁeld of research and development for decades in statistical learning. It has proven to be eﬀective and useful in both theory and practice for many reasons: enhanced learning eﬃciency and increasing predictive accuracy (see Mitra et al. (2002)), model simpliﬁcation to ease its interpretation and improve performance (see Almuallim and Dietterich (1994), Koller and Sahami (1996) and Blum and Langley (1997)), shorter training time (see Mitra et al. (2002)), curse of dimensionality avoidance, enhanced generalization with reduced overﬁtting, implied variance reduction. Both Hastie et al. (2009) and Guyon and Elisseeﬀ(2003) are nice references to get an overview of various methods to tackle features selections. The approaches followed varies. Brieﬂy speaking, the methods can be sorted into three main categories: Filter method, Wrapper methods and Embedded methods. We developed these three categories in the following section. 1.1 Features selection methods 1.1.1 Filter methods Filter type methods select variables regardless of the model. These methods suppress the least interesting variables by using ranking techniques as a criteria to select the variables. Once the ranking is done, a threshold is determined in order to select features above it. These methods are very eﬀective in terms of computation time and robust to overﬁtting. By construction, ﬁlter methods may select redundant variables as they do not consider the relationships between variables. To stress this last point, we can present one of the most known criteria, the Pearson correlation coeﬃcient, which is simply the ratio between the covariance and the square root of the two variances: Cov(xi, y)/ p Var(xi) Var(y) with xi the ith feature in the model and y the label associated. It is well known that this correlation ranking can only detect linear dependencies between features ant the target label. 1.1.2 Wrappers methods Wrapper methods evaluate subsets of variables. They thus allow detecting possible interactions between variables. In wrapper methods, a model must be trained to test any subsequent feature subset. Consequently, these methods are iterative and computationally expensive. However, these methods can identify the best performing features set for that speciﬁc modeling algorithm. Some known examples of wrapper methods are forward and backward feature selection methods. The backward elimination starts with all features and progressively remove them. At the opposite, the forward selection starts with an empty set and progressively add them. If we have n features, we need to train n classiﬁers for the ﬁrst step, then n−1 classiﬁers for the second step and so on. We then have n(n+1) 2 training steps for both methods. However, forward selection starts with small features subsets',\n",
       " '1607.01092': 'Image segmentation is the process of partitioning an image into smaller meaningful regions based in part on some homogeneity characteristics. The goal of segmentation is to delineate (extract or contour) targeted objects for further analysis. For example, in medical image analysis (MIA), image segmentation of organs or tissue types is a necessary ﬁrst step for numerous applications, e.g. measuring tumour burden (or volume) from positron emission tomography (PET) or computed tomography (CT) scans (Hatt et al., 2009; Bagci et al., 2013), analyzing vasculature from magnetic resonance angiography (MRA) (e.g. measuring tortuosity) (Bullitt et al., 2003; Yan and Kassim, 2006), grading cancer from histopathology images (Tabesh et al., 2007), performing fetal measurements from prenatal ultrasound (Carneiro et al., 2008), performing augmented reality in robotic image guided surgery (Su et al., 2009; Pratt et al., 2012), building statistical atlas for population studies and voxel-based morphometry (Ashburner and Friston, 2000). Given an input image, I, the goal of a typical image segmentation system is to assign every pixel in I a speciﬁc label where each label represents a structure of interest. Several traditional segmentation algorithms have been proposed for assigning labels to pixels; these include thresholding (Otsu, 1975; Sahoo et al., 1988), regiongrowing (Adams and Bischof, 1994; Pohle and Toennies, 2001; Pan and Lu, 2007), watershed (Vincent and Soille, 1991; Grau et al., 2004; Hamarneh and Li, 2009) and optimizationbased methods (Grady, 2012; McIntosh and Hamarneh, 2013a; Ul´en et al., 2013). The existence of noise, low contrast and objects complexity in medical images, typically cause the aforementioned methods to fail. In addition, all these traditional methods assume that objects’ entire appearance have some notion of homogeneity; however, this is not necessarily the case for complex objects (e.g. multi-region cells with membrane, nucleus and nucleolus; or brain regions aﬀected by magnetic ﬁeld of a magnetic resonance imaging (MRI) device nonuniformity). Many real-world objects are better described by a combination of regions with distinct appearance models. This is where more elaborate prior information about the targeted objects becomes helpful. The majority of state-of-the-art image segmentation methods are formulated as optimization problems, i.e. energy minimization or maximum-a-posteriori estimation, mainly because of their: 1) formal and rigorous mathematical formulation, 2) availability of mathematical tools for optimization, 3) capability to incorporate multiple (competing) criteria as terms in the objective function, 4) ability to quantitatively measure the extent by which a method satisﬁes the diﬀerent criteria/terms, and 5) ability to examine the relative performance of diﬀerent solutions. In this paper, we review the various types of prior information that are utilized in diﬀerent optimization-based frameworks for segmentation of targeted objects. Prior information can take many forms: user interaction; appearance models; boundaries and edge polarity; shape models; topology speciﬁcation; moments (e.g. area/volume and centroid constraints); geometrical Preprint submitted to arXiv.org July',\n",
       " '1407.6560': 'In this paper we consider networks with one sender and more receivers. All receivers wish to obtain all messages generated at the sender. In the seminal paper [1] Ahlswede, Cai, Li, and Yeung showed that it is often possible to obtain a much higher throughput than what can be achieved by using routing. This is done by allowing the vertices of the network to linearly combine received information before forwarding it. This method is now known as linear network coding. Another important breakthrough was made in [4] where it was shown that if the ﬁeld size is chosen large enough and if the coeﬃcients in the linear combinations are chosen by random then with a very high probability the maximal throughput is attained. The above model can be extended to also deal with errors and erasures in the network [10, 3, 2, 11]. However, another important model was introduced by Kötter, Kschischang and Silva in [5, 8] where the network is treated as a black box. They named their channel-model the operator channel and showed how to correct errors and erasures with respect to the corresponding metric by employing subspace codes. Subspace codes by 1  now is a very active research area attracting a lot of attention. In the present paper we are concerned with building a bridge between the two points of view on a network. We will assume that what the black box is actually doing is random network coding. It is well-known [12] that in such a case the strength of subspace codes lies in its ability to correct erasures and in its ability to keep adversaries from obtaining too much information [7, 6] rather than in its errorcorrecting ability. In this paper we discuss why subspace codes are vulnerable to errors in the network. We then show how to combine them with a classical linear code to obtain simultaneously protection against errors and erasures. 2 The protocol for communication through the network Consider an acyclic network G = (V, E) with one sender s and t receivers r1, . . . , rt. Without loss of generality we shall assume that s has no incoming edges. All edges in the network have capacity 1. We consider a multicast scenario meaning that all receivers wish to obtain the entire message generated at s. As a preparation – before sending information into the network – the given message is encoded using a subspace code. A subspace code is a collection of subspaces C = {V1, . . . , V|C|}. Each of these subspaces is called a code word. We have Vi ⊆W ⊆Fk q, i = 1, . . . , |C|, where W is called the ambient space of C. When errors and erasures possibly occurs during the communication process a send code word will be transformed into another word (vetorspace) in W. In the following we shall without loss of generality always assume that W equals Fk q. We have a set M of messages with |M| = |C| and a bijective encoding function identifying each',\n",
       " '1802.05155': 'Nonconvex stochastic optimization naturally arises in many machine learning problems. Taking training deep neural networks as an example, given n samples denoted by {(xi,yi)}n i=1, where xi is the i-th input feature and yi is the response, we solve the following optimization problem, min θ F (θ) := 1 n n X i=1 ℓ(yi,f (xi,θ)), (1.1) where ℓis a loss function, f denotes the decision function based on the neural network, and θ denotes the parameter associated with f . Stochastic Gradient Descent (SGD), which has been known for a long time as stochastic approximation in the control and simulation literature (Robbins and Monro, 1951; Borkar and Meyn, 2000; Kushner and Yin, 2003; Borkar, 2009; Fu et al., 2015), has been applied to solve machine learning problems such as (1.1) (Newton et al., 2018). Momentum Stochastic Gradient Descent (MSGD, Polyak (1964)) is one of the most popular variants of SGD. Speciﬁcally, at the t-th iteration, we uniformly sample i from (1,...,n). Then, we take θ(t+1) = θ(t) −η∇ℓ(yi,f (xi,θ(t))) + µ(θ(t) −θ(t−1)), (1.2) where η is the step size parameter and µ ∈[0,1) is the parameter for controlling the momentum. Note that when µ = 0, (1.2) is reduced to Vanilla Stochastic Gradient Descent (VSGD). ∗Working in progress. †T. Liu, Z. Chen, E. Zhou, and T. Zhao are aﬃliated with School of Industrial and Systems Engineering at Georgia Tech; Tuo Zhao is the corresponding author; Email: tourzhao@gatech.edu. 1 arXiv:1802.05155v5  [cs.LG]  6 Mar 2021  Although SGD-type algorithms have demonstrated signiﬁcant empirical success for training deep neural networks, their convergence properties for nonconvex optimization are still largely unknown. For VSGD, existing literature (Ghadimi and Lan, 2013) shows that it is guaranteed to converge to a ﬁrst-order optimal solution (i.e., ∇F (θ) = 0) under general smooth nonconvex optimization. The theoretical investigation of MSGD is even more limited than that of VSGD. The momentum in (1.2) has been observed to signiﬁcantly accelerate computation in practice. To the best of our knowledge, we are only aware of Ghadimi and Lan (2016) in existing literature, which shows that MSGD is guaranteed to converge to a ﬁrst-order optimal solution for smooth nonconvex problems. Their analysis, however, does not justify the advantage of the momentum in MSGD over VSGD. To ﬁll the gap between the signiﬁcant empirical success and the lack of theoretical understanding of MSGD, we are interested in answering a natural and fundamental question in this paper: What is the role of the momentum in nonconvex stochastic optimization? The major technical bottleneck in analyzing MSGD and answering the above question comes from the nonconvex optimization landscape of these highly complicated problems, e.g., training large recommendation systems and deep neural networks. We propose to analyze MSGD for nonconvex optimization problems under the assumption of isolated local optima and strict saddle points. This allows us to make progress toward understanding MSGD and gaining new insights',\n",
       " '1612.03217': 'Immunetheropy with tumor inﬁltrated lymphocytes is an promising approach, and being widely investigated, for the treatment of cancers [16]. Detecting lymphocyte in H&E stained histological tissue images is a critical step in the clinical studies. The quantiﬁcation of lymphocytes provides a feasible solution to quantify the immune response, so that researchers can analyze the treatment outcome of immunetheropy quantitatively. With the fast development of digital pathology, lymphocytes can be detected and examined by pathologists on computer screens with diﬀerent visualization and annotation tools. However, the possible amount of lymphocytes in a single whole-slice (WS) image may range from tens to thousands, even maybe hundreds of lymphocytes in a small ﬁeld of view (FOV). A reliable fully-automated lymphocyte detection system can make the study reproducible and faster by orders of magnitude. ⋆This work was done when Jianxu Chen was an intern at Ventana Medical Systems, Inc. arXiv:1612.03217v1  [cs.CV]  9 Dec 2016  In this work, we demonstrate the eﬀectiveness of deep learning approaches in automatic lymphocyte detection in H&E images. In particular, we take the following practical considerations to make our deep learning scheme eﬀective in lymphocyte detection. – Staining and tissue variations: A noteworthy feature of H&E stained histpathological images is the possibly large variation of staining conditions and tissue types. Our experiments show that our approach is robust to considerable staining and tissue variability. – Prior knowledge: The physical appearance of lymphocytes is a disk-like shape with diameter ranging from 14 to 20 microns. Given the image solution, it is straightforward to calculate the estimated size of lymphocytes in pixels. We take such important prior knowledge into account in the training process (see Section 2.2 for details). – Free-form supervision: Labelling lymphocytes in H&E images requires special expertise, which makes the annotation hard to crowd-source, like [1]. So, the availability of ground truth is so limited that annotations should be expected free from any restricted form, such as a point around the center of lymphocytes, a point within similar non-lymphocyte objects (e.g., tumor cells or stromal cells), or even scribbles at non-lymphocyte pixels provided as negative examples. – Human computer interaction for ﬁne-tuning: In case detection errors are found and corrected by pathologists, the model should be able to adapt to such “new knowledge”. By carefully designing the training scheme and supporting free-form supervision, our model can be easily ﬁne-tuned through such human computer interaction. As a consequence, it make the entire model able to improve by itself in the progress of application in practice. In the literature, the ﬁrst, and only, deep learning model for lymphocyte detection was discussed in [8], which employs a generic model to classify a small image patch as a lymphocyte or not. Formulating the problem as a patch-based CNN classiﬁcation can result in an extremely long inference time and potentially lower accuracy than fully convolutional networks (FCN) [10]. Such inferior performance',\n",
       " '1407.5754': 'Markov random ﬁelds (MRFs) [2, 13, 33] are popular probabilistic graphical representation for encoding the object’s state space using sites and the correlation between local objects using edges. For example, a grid is a powerful image representation for pixels, where each site represents a pixel state (e.g., intensity or label) and an edge represents local relations between neighboring pixels (e.g., smoothness). In other words, we can encode prior knowledge about the nature of interaction between objects in a MRF. Once the model has been built, we can perform inference in a principled manner. One of the most important MRF inference problems in many applications is ﬁnding maximum a posteriori (MAP) assignment. The goal is to search for the the most probable state conﬁguration of all objects, or equivalently, the lowest energy of the model. The problem is known to be NPcomplete [7]. Given a MRF of N objects each of which has S states, a brute-force search must explore SN state conﬁgurations. In image denoising, for example, N is the number of pixels, which can range from 104 −107, and S is the number of pixel intensity levels, which are in the order of 28−232. This calls for heuristic methods which can ﬁnd reasonable solutions in practical time. There have been a great number of attempts to solve this problem. An early approach was based on simulated annealing (SA), where the convergence is also guaranteed for log-time cooling schedule [13]. The main drawback of this approach is its low speed – it takes long time to achieve reasonably good solutions. Another early attempt involves local greedy search, and the iterated conditional mode (ICM) [3] is probably the most well-known method. In probabilistic terms, 1 arXiv:1407.5754v1  [cs.AI]  22 Jul 2014  it iteratively seeks for the mode of the local distribution of states of an object conditioned on the states of nearby objects. Translated in combinatorial terms, it greedily searches for the local valley - here the neighborhood size is limited to S - the number of possible states per object. Not surprisingly, this method is prone to getting stuck at poor local minima. A more successful approach is belief-propagation (BP) [43], which exploits the problem structure better than the ICM. The main idea is that we maintain a set of messages sending simultaneously along all edges of the MRF network. A message carries the information of the state of the sites it originates from, and as a result, any update of a particular site is informed by messages from all nearby sites. However, this method can only be guaranteed to work for a limited class of network structures – when the network reduces to a tree, where there are no loops in the network. Another drawback is that the memory requirement for BP is high - this is generally linear in the number of edges in the network. More recently, efﬁcient algorithms with theoretical guarantees have been introduced based on the theory',\n",
       " '1804.10822': 'Multimedia applications involve the presentation of different audiovisual objects organized in time and space [1], [2]. Given the nature of the content they present, the majority of current multimedia applications stimulate only two human senses: sight and hearing. As discussed in [3], aiming at increasing the user quality of experience (QoE) and immersion with multimedia applications, the literature present works [4]–[6] that propose the use of other sensory effects in multimedia applications in order to provide users with new sensations during a multimedia presentation. In [3], the term mulsemedia (MULtiple SEnsorial MEDIA) is put forward to denote multimedia applications in which traditional media content (text, image, audio, video, etc.) can be related to media objects that target other human senses (e.g., smell, haptics, etc.). To clarify, let us describe a simple yet powerful example1. 1The application we describe here is inspired by the Day’s Route application available at http://club.ncl.org.br/node/69 Consider a non-linear show, i.e., a show whose narrative line is not known a priori and is constructed based on user interaction. In this show the user actively participates in the construction of the narrative line by choosing the next sight in a city tour from a list of available options provided by the application. At each sight, a video and complementary information about it are presented to the user. At the beginning of the show, the user may choose whether he/she wants to interact with the application. If not, a default tour is presented. Let us now consider an evolution of such application which includes sensory effects. In this new application, several sensory effects are presented along the narrative line in a synchronized way, with the purpose of increasing the immersion of the user in the audiovisual content. In this scenario, if the user chooses to visit a particular sight, e.g., the beach at Rio de Janeiro, the sensory effects to be presented by the application would mimic the sight’s environmental conditions (e.g., hot wind blowing, smell of the sea breeze, etc). Synchronization plays an important role for multimedia applications. Multimedia authoring languages are domain speciﬁc languages that provide constructions for deﬁning how media objects shall be presented during the execution of a multimedia application, i.e., their temporal synchronization. Moreover, those languages also manage user interaction as a special case of temporal synchronization. Examples of such languages are SMIL (Synchronized Multimedia Integration Language) [7] and NCL (Nested Context Language) [8]. When considering the use of sensory effects in multimedia applications, the usual approach is to use audiovisual media objects as the base for synchronization, such that the timestamps in which sensory effects are to be executed are deﬁned in relation to certain media objects. For example, light and heat effects may be presented when an explosion occurs in the main video. One should notice, however, that although multimedia languages easy the speciﬁcation of the synchronization aspect in an application, the',\n",
       " '1701.09135': 'Man-made environments like houses, buildings, neighborhoods and cities have a structure - microwaves are found in kitchens, restrooms are usually situated in the corners of buildings, and restaurants are found in speciﬁc kinds of commercial areas. This structure is also shared across environments - for example, most cities will have restaurants in their business district. It has been a long-standing goal of computer vision to learn this structure and use it to guide exploration of unknown man-made environments like unseen cities, buildings and houses. Knowledge of such structure can be used to recognize tougher visual concepts like occluded or small objects [8, 29], to better delimit the boundaries of objects [6, 38], and for robotic automation tasks like deciding drivable terrain for robots [13], etc. In this paper, we address a task that requires understanding the large-scale structure of cities – navigation in a new city to reach a destination in as few steps as possible. The agent neither has a map of the environment, nor does it Figure 1: These street-view images are taken from roughly the same location. Which direction do you think the nearest gas station is in?1 know the location of the destination or itself. All it knows is that it needs to reach a particular type of destination, e.g. go to the nearest gas station in the city. The naive approach is a random walk of the environment. But if the agent has some learnt model of the structure of cities, then it can make informed decisions - for example, gas stations are very likely to be found near freeway exits. We ﬁnely discretize the city into a grid of locations connected by roads. At each location, the agent has access only to street view images pointing towards the navigable directions and it has to pick the next direction to take a step in (Figure 1). We show that learning structural characteristics of cities can help the agent reach a destination faster than random walk. Two approaches have been used in the past to achieve this: 1) Reinforcement Learning (RL): a positive reward is associated with each destination location and a negative reward with all other locations. The agent then learns a policy (mapping from state to action) that maximizes the reward 1The correct answer is: W. 1 arXiv:1701.09135v2  [cs.CV]  20 May 2017  expected by executing that policy. In deep RL the policy is encoded by a CNN that outputs the value of performing an action in the current state. A state transition and the observed reward forms a training data-point. Typically, a mini-batch for CNN training is formed by some transitions that are driven by the current policy and some that are random. Some recent works have used this approach to navigate mazes [27] and small game environments [30]. 2) Supervised Learning: this form of learning requires a large training set of images with',\n",
       " '1901.04112': 'Recent years have witnessed the rise and success of Neural Machine Translation (NMT) (Sutskever, Vinyals, and Le 2014; Bahdanau, Cho, and Bengio 2014; Luong, Pham, and Manning 2015; Wu et al. 2016; Vaswani et al. 2017; Hassan et al. 2018). However, NMT relies heavily on large in-domain parallel data, resulting in poor performance on low-resource language pairs (Koehn and Knowles 2017). For some low-resource pairs without any bilingual corpus, how to train NMT models with only a monolingual corpus is a popular and interesting topic. Existing methods for unsupervised machine translation (Artetxe et al. 2017; Lample, Denoyer, and Ranzato 2017; Yang et al. 2018; Lample et al. 2018) are mainly the modiﬁcations of encoder-decoder schema. In their work, source ∗The ﬁrst two authors contributed equally to this work. This work is supported in part by NSFC U1636210 and 61421003, and Shenzhen Institute of Computing Sciences. Copyright c⃝2019, Association for the Advancement of Artiﬁcial Intelligence (www.aaai.org). All rights reserved. Figure 1: The effect of noisy training data. The ﬁrst training sample contains the noise (“malade” in French means “ill”, not “ill-fated”), leading to the wrong test result (sys). sentences in two languages are mapped into the same latent space with a shared encoder, which is expected to be the internal information representation irrelevant to the languages themselves. From that target sentences are generated by a shared or different decoders. Some of them also use denoising auto-encoders (Vincent et al. 2010) and adversarial training. Despite the differences in structures and training methods, they reach a consensus to use the pseudo parallel data generated iteratively with the back-translation method (Sennrich, Haddow, and Birch 2016; Zhang et al. 2018a) to train their unsupervised NMT models, i.e. they use monolingual data in the target language and a target-to-source translation model to generate source sentences, then use the pseudo parallel data of generated sources and real targets to train the source-to-target model, and vice versa. However, since the pseudo data are generated by unsupervised models, random errors and noises are inevitably introduced, such as redundant or unaligned words deviating from the meaning of source sentences. Due to the lack of supervision, those infrequent errors will be accumulated and reinforced by NMT models into frequent patterns during the training iterations, leading to bad translation performance. For instance in Figure 1, the French word “malade” is mistakenly translated into the English word “ill-fated” in the ﬁrst training sample. With strong abilities to identify and memorize patterns, NMT models mistakenly translate this word into “ill-fated” when “old” (similar to “grandmother” arXiv:1901.04112v1  [cs.CL]  14 Jan 2019  in the ﬁrst training sample) occurs in the test. Even so, there are also many good translation patterns (such as “malade” →“ill” or “sick” in the second and third training samples), which could have been extracted in time to guide the NMT models into the correct training direction. The extraction',\n",
       " '1408.1664': 'Bayesian networks (BNs) are probabilistic graphical models that represent a set of random variables and their conditional dependencies via a directed acyclic graph (DAG). Learning the structures of Bayesian networks from data has been a major concern in many applications of BNs. In some of the applications, one aims to ﬁnd a BN that best explains the observations and then utilizes this optimal BN for predictions or inferences (we call this 1 arXiv:1408.1664v3  [cs.AI]  13 Aug 2016  Chen, Tian, Nikolova, Aluru structure learning). In others, we are interested in ﬁnding the local structural features that are highly probable (we call this structure discovery). In causal discovery, for example, one aims at the identiﬁcation of (direct) causal relations among a set of variables, represented by the edges in the network structure (Heckerman et al., 1997). Among the approaches to the structure learning problem, score-based search method formalizes the problem as an optimization problem where a scoring function is used to measure the ﬁtness of a DAG to the observed data, then a certain search approach is employed to maximize the score over the space of possible DAGs (Cooper and Herskovits, 1992; Heckerman et al., 1997). While for structure discovery, Bayesian method is extensively used. In this method, we provide a prior probability distribution P(G) over the space of possible Bayesian networks and compute the posterior distribution P(G|D) of the network structure G given data D. We can then compute the posterior probability of any structural features by averaging over all possible networks. Both structure learning and structure discovery are considered hard since the number of possible networks is super-exponential, i.e., O(n!2n(n−1)/2), with respect to the number of variables n. Indeed, it has been showed in (Chickering et al., 1995) that ﬁnding an optimal Bayesian network structure is NP-hard even when the maximum in-degree is bounded by a constant greater than one. Recently, a family of DP algorithms have been developed to ﬁnd the optimal BN in time O(n2n) and space O(2n)(Ott et al., 2004; Singh and Moore, 2005; Silander and Myllym¨aki, 2006; Yuan et al., 2011; Yuan and Malone, 2012). Likewise, the posterior probability of structural features can be computed by analogous DP techniques. For example, the algorithms developed in (Koivisto and Sood, 2004) and (Koivisto, 2006a) can compute the exact marginal posterior probability of a subnetwork (e.g., an edge) and the exact posterior probabilities for all n(n −1) potential edges in O(n2n) time and space, assuming that the in-degree, i.e., the number of parents of each node, is bounded by a constant. However, these algorithms require a special form of the structural prior (called order modular prior), which deviates from the simplest uniform prior and does not respect Markov equivalence (Friedman and Koller, 2003). If adhering to the standard (structure modular) prior, the fastest known algorithm is slower, taking time O(3n) and',\n",
       " '1402.0556': 'In today’s rapidly expanding disciplines, scientists and scholars are constantly faced with the daunting task of keeping up with knowledge in their ﬁeld. In addition, the increasingly interconnected nature of real-world tasks often requires experts in one discipline to rapidly learn about other areas in a short amount of time. Cross-disciplinary research requires scientists in areas such as linguistics, biology, and sociology to learn about computational approaches and applications such as computational linguistics, biological modeling, and social networks. Authors of journal articles and books must write accurate summaries of previous work, ranging from short summaries of related research to in-depth historical notes. Interdisciplinary review panels are often called upon to review proposals in a wide range of c⃝2013 AI Access Foundation. All rights reserved.  Qazvinian et Al. areas, some of which may be unfamiliar to panelists. Thus, they must learn about a new discipline “on the ﬂy” in order to relate their own expertise to the proposal. Our goal is to eﬀectively serve these needs by combining two currently available technologies: (1) bibliometric lexical link mining that exploits the structure of citations and (2) summarization techniques that exploit the content of the material in both the citing and cited papers. It is generally agreed upon that manually written abstracts are good summaries of individual papers. More recently, Qazvinian and Radev (2008) argued that citation sentences (i.e., set of sentences that appear in other papers and cite a given article) are useful in creating a summary of important contributions of a research paper. Kaplan, Iida, and Tokunaga (2009) introduced “citation-site” as a block of text that includes a citation and discusses the cited text. This work used a machine learning method for extracting citations from research papers and evaluates the result using an annotated corpus of 38 papers citing 4 articles. Moreover, Qazvinian and Radev (2010) showed the usefulness of using implicit citations (i.e., context sentences, sentences that occur before or after a citation sentence and do not explicitly cite the target paper, but discuss its contributions) in summary generation. Teufel (2005) argued that citations could contain subjective content, and that this content can be exploited for summary generation. Additional work (Mohammad et al., 2009) demonstrated the usefulness of citations for producing multi-document summaries of scientiﬁc articles. Follow-up work indicated that further improvements to citation handling enables the production of more ﬂuent summaries (Whidby, 2012). In our work, we develop summarization systems that exploit citations. Speciﬁcally, • We compare and contrast the usefulness of abstracts and of citations in automatically generating a technical summary on a given topic from multiple research papers. Our ﬁndings suggest that abstracts and citations have some overlapping information but they also have a signiﬁcant amount of unique summary-amenable information. Particularly, we provide evidence that citation sentences contain crucial information that is not available, or hard to extract, from abstracts and papers alone. • We propose C-LexRank, a graph based summarization system. This',\n",
       " '1805.12009': 'We investigate the problem of channel estimation in millimeter wave (mm-wave) wireless communication networks. Mm-wave refers to the wavelength of electromagnetic signals at 30-300 GHz frequency bands. At these high frequencies, channel measurement campaigns revealed that wireless communication channels exhibit very limited number of scattering clusters in the angular domain [1]–[3]. A cluster refers to a propagation path or continuum of paths that span a small interval of transmit Angles of Departure (AoD) and receive Angles of Arrival (AoA). Moreover, signal attenuation is very signiﬁcant at mm-wave frequencies. This motivates the use of large antenna arrays at the transmitter (TX) and receiver (RX) to provide high antenna gains that compensate for high path losses [4]. Nevertheless, due to the high power consumption of mixed signal components, e.g., Analog to Digital Converters (ADCs) [5], conventional digital transceiver architectures that employ a complete RF chain per antenna is not practical. Hence, alternate architectures have been proposed for mmwave radios with the objective of maintaining a close performance to channel capacity. Among the proposed solutions are the use of i) hybrid analog/digital beamforming [6]–[8] and ii) fully digital beamforming with low resolution ADCs [9]–[11]. For all proposed solutions, channel estimation remains one of the most critical determinants of performance in communication. Due to the large number of antennas at TX and RX, estimation of the full channel gain matrix may require a large Eylem Ekici is supported in part by NSF grants CNS-1421576 and CNS1731698. C. Emre Koksal is supported in part by NSF grants CNS-1618566, CNS-1514260. number of measurements, proportional to the product of the number of transmit and receive antennas. This imposes a great burden on the estimation process. To address this issue, various methods have been used, the most prevalent among them, is compressed sensing [6], [11]–[14], which leverages channel sparsity. Performance of compressed sensing based approaches is heavily dependent on the design of system (sensing) matrices. For instance, while random sensing matrices are known to perform well, in practice, sensing matrices involve the design of transmit and receive beamforming vectors and the choice of dictionary matrices1. Hence, purely random matrices have not been used in practice [15]. On the other hand, no design that involves deterministic sensing matrices has been considered for sparse channel estimation. Despite the efforts, we do not have a full understanding of the dependence of channel estimation performance on the channel parameters and number of measurements. In an effort to understand this relationship, the study in [16] proposed a multi-user mm-wave downlink framework based on compressed sensing in which the authors evaluate the achievable rate performance against the number of measurements. In this work, we follow a different approach. We propose a systematic method in which we use sequences of error correction codes chosen in a way to control the channel estimation performance. To demonstrate our approach, consider the following simple',\n",
       " '1709.03698': 'Deep learning powers many research areas and impacts various aspects of society (LeCun, Bengio, and Hinton 2015) from computer vision (He et al. 2016; Huang et al. 2017), natural language processing (Cho et al. 2014) to biology (Esteva et al. 2017) and e-commerce. Recent progress in designing architectures for deep networks has further accelerated this trend (Simonyan and Zisserman 2015; He et al. 2016; Huang et al. 2017). Among the most successful architectures are deep residual network (ResNet) and its variants, which are widely used in many computer vision applications (He et al. 2016; Pohlen et al. 2017) and natural language processing tasks (Oord et al. 2016; Xiong et al. 2017; Wu et al. 2016). However, there still are few theoretical analyses and guidelines for designing and training ResNet. In contrast to the recent interest in deep residual networks, system of Ordinary Differential Equations (ODEs), special kinds of dynamical systems, have long been studied in mathematics and physics with rich theoretical and empirical Copyright c⃝2018, Association for the Advancement of Artiﬁcial Intelligence (www.aaai.org). All rights reserved. success (Coddington and Levinson 1955; Simmons 2016; Arnold 2012). The connection between nonlinear ODEs and deep ResNets has been established in the recent works of (E 2017; Haber and Ruthotto 2017; Haber, Ruthotto, and Holtham 2017; Lu et al. 2017; Long et al. 2017; Chang et al. 2017). The continuous interpretation of ResNets as dynamical systems allows the adaption of existing theory and numerical techniques for ODEs to deep learning. For example, the paper (Haber and Ruthotto 2017) introduces the concept of stable networks that can be arbitrarily long. However, only deep networks with simple single-layer convolution building blocks are proposed, and the architectures are not reversible (and thus the length of the network is limited by the amount of available memory), and only simple numerical examples are provided. Our work aims at overcoming these drawbacks and further investigates the efﬁcacy and practicability of stable architectures derived from the dynamical systems perspective. In this work, we connect deep ResNets and ODEs more closely and propose three stable and reversible architectures. We show that the three architectures are governed by stable and well-posed ODEs. In particular, our approach allows to train arbitrarily long networks using only minimal memory storage. We illustrate the intrinsic reversibility of these architectures with both theoretical analysis and empirical results. The reversibility property easily leads to a memoryefﬁcient implementation, which does not need to store the activations at most hidden layers. Together with the stability, this allows one to train almost arbitrarily deep architectures using modest computational resources. The remainder of our paper is organized as follows. We discuss related work in Sec. 2. In Sec. 3 we review the notion of reversibility and stability in ResNets, present three new architectures, and a regularization functional. In Sec. 4 we show the efﬁcacy of our networks using three common',\n",
       " '1303.3934': 'In this paper we develop a novel clustering algorithm, inspired by biological quorum sensin, and applicable to time-varying data. Quorum sensing [1] [2] [3] [4] [5], is a decentralized biological process by which a community of bacteria cells interact through their local environment, with no global information to coordinate collective behaviors. Each cell secretes signaling molecules called auto-inducers into its environment and builds up concentration. These autoinducers can be captured by receptors, which activate transcription of certain genes in the cell (Fig. 1). When few cells of the same kind exist in the neighborhood, the density of the inducers is low, and no functional behavior is awakened. However, when the concentration reaches a certain threshold, a positive feedback loop is triggered to secrete more auto-inducers and fully activate the receptors. Speciﬁc genes start being transcribed in all cells, and functions expressed by the genes are performed collectively. Cells can determine whether they are surrounded in a colony by measuring the autoinducer concentration with the response regulators. Such colony identiﬁcation results in cell clustering, and we draw inspirations from it to develop a new computational algorithm for data clustering analysis. • F. Tan is with Nonlinear Systems Laboratory, Massachusetts Institute of Technology, Cambridge, MA 02139, USA E-mail: fengtan at mit.edu • J.J.S. Slotine is with Nonlinear Systems Laboratory, Massachusetts Institute of Technology, Cambridge, MA 02139, USA E-mail: jjs at mit.edu This work was sponsored in part by a grant from the Boeing Corporation We propose this novel learning clustering algorithm to integrate real-time applications where data evolves over-time. We are now faced with novel and challenging control problems for groups or swarms of dynamic systems, such as manipulators, robots and basic oscilators. Especially as researches in robotics advance, traditional control theories are no longer sufﬁcient to provide ideal solutions to all problems in the ﬁeld. Although many algorithms of self-organization and group behavior work well on static data sets - we gain the toolbox of synchronization and contraction analysis from control theory and we learn the ideas of tracking and community detection from machine learning, rarely have these learning algorithms been applied to controlling real-time dynamic systems. we must acknowledge that successful applications on time-varying data in image processing, video and audio recognition have thrived in the past decades, but we believe more can be done. Clustering is a basic problem in data analysis and machine learning. Its task is to separate a set of unlabeled objects into clusters, so that objects in the same clusters are more similar to each other than those in other clusters. Many clustering algorithms have been developed: Hierarchical clustering methods as discussed in CURE [6], BIRCH [7], have two types: one is a bottom up approach, also known as the “Agglomerative”, which starts from a state in which every single data forms its own cluster and merges small clusters as the hierarchy moves up; the other',\n",
       " '1804.06003': 'For a prime power q, let GF(q) denote the ﬁnite ﬁeld with q elements. Let wt(c) denote the Hamming weight of a vector c ∈GF(q)n. An [n,k,d] code C over GF(q) is a k-dimensional subspace of GF(q)n with minimum Hamming distance d. Denote by C ⊥the dual code of a linear code C. We call an [n,k,d] code distance-optimal if no [n,k,d + 1] code exists and dimensionoptimal if no [n,k + 1,d] code exists. Let Ai denote the number of codewords with Hamming weight i in a code C of length n. The weight enumerator of C is deﬁned by 1+A1z+A2z2 +···+ Anzn. The sequence (1,A1,A2,··· ,An) is referred to as the weight distribution of the code C. A code C is said to be a t-weight code if the number of nonzero Ai in the sequence (A1,A2,··· ,An) is equal to t. The weight distribution of a code is used to estimate the error correcting capability and compute the error probability of error detection and correction of the code [11]. The weight distributions of linear codes have also applications in cryptography and combinatorics. Let PG(2,GF(q)) denote the projective plane over GF(q). An r-arc A of PG(2,GF(q)) is a set of r points in PG(2,GF(q)) such that no three of them are collinear, where r ≥3. It is known that |A| ≤q + 2 for even q. It is conjectured that |A| ≤q + 1 for odd q [3]. ✩C. Ding’s research was supported by The Hong Kong Research Grants Council, Proj. No. 16300415. Email addresses: zilingheng@163.com (Ziling Heng), cding@ust.hk (Cunsheng Ding) Preprint submitted to Elsevier April 18, 2018  When q is odd, (q + 1)-arcs are called ovals. When q is even, (q + 2)-arcs are referred to as hyperovals. Hyperovals are maximal arcs as they have the maximal number of points as arcs. For even q, all hyperovals in PG(2,GF(q)) can be constructed with a special type of permutation polynomials on GF(q), which is described in the following theorem. Theorem 1. [12, Th. 9.67] Let q > 2 be a power of 2. Any hyperoval H in PG(2,GF(q)) can be written in the form H (f) = {(f(c),c,1) : c ∈GF(q)} ∪{(1,0,0)} ∪{(0,1,0)}, where f ∈GF(q)[x] is such that (i) f is a permutation polynomial of GF(q) with deg(f) < q and f(0) = 0, f(1) = 1; (ii) for each a ∈GF(q), ga(x) = (f(x + a) + f(a))xq−2 is also a permutation polynomial of GF(q). Conversely, every such set H (f) is a hyperoval. Polynomials satisfying Conditions (i) and (ii) in Theorem 1 are called o-polynomials. Let q = 2m. The following two o-polynomals over GF(q) are well',\n",
       " '1707.07397': 'The existence of adversarial examples for neural networks (Szegedy et al., 2013; Biggio et al., 2013) was initially largely a theoretical concern. Recent work has demonstrated the applicability of adversarial examples in the physical world, showing that adversarial examples on a printed page remain adversarial when captured using a cell phone camera in an approximately axis-aligned setting (Kurakin et al., 2016). But while minute, carefully-crafted perturbations can cause targeted misclassiﬁcation in neural networks, adversarial examples produced using standard techniques fail to fool classiﬁers in the physical world when the examples are captured over varying viewpoints and affected by natural phenomena such as lighting and camera noise (Luo et al., 2016; Lu et al., 2017). These results indicate that real-world systems may not be at risk in practice because adversarial examples generated using standard techniques are not robust in the physical world. *Equal contribution 1Massachusetts Institute of Technology 2LabSix. Correspondence to: Anish Athalye <aathalye@mit.edu>. Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018 by the author(s). classiﬁed as turtle classiﬁed as riﬂe classiﬁed as other Figure 1. Randomly sampled poses of a 3D-printed turtle adversarially perturbed to classify as a riﬂe at every viewpoint2. An unperturbed model is classiﬁed correctly as a turtle nearly 100% of the time. We show that neural network-based classiﬁers are vulnerable to physical-world adversarial examples that remain adversarial over a different viewpoints. We introduce a new algorithm for synthesizing adversarial examples that are robust over a chosen distribution of transformations, which we apply for reliably producing robust adversarial images as well as physical-world adversarial objects. Figure 1 shows an example of an adversarial object constructed using our approach, where a 3D-printed turtle is consistently classiﬁed as riﬂe (a target class that was selected at random) by an ImageNet classiﬁer. In this paper, we demonstrate the efﬁcacy and generality of our method, demonstrating conclusively that adversarial examples are a practical concern in real-world systems. 1.1. Challenges Methods for transforming ordinary two-dimensional images into adversarial examples, including techniques such as the L-BFGS attack (Szegedy et al., 2013), FGSM (Goodfellow et al., 2015), and the CW attack (Carlini & Wagner, 2017c), are well-known. While adversarial examples generated through these techniques can transfer to the physical world (Kurakin et al., 2016), the techniques have limited success in affecting real-world systems where the input may be transformed before being fed to the classiﬁer. Prior work has shown that adversarial examples generated using these standard techniques often lose their adversarial nature once 2See https://youtu.be/YXy6oX1iNoA for a video where every frame is fed through the ImageNet classiﬁer: the turtle is consistently classiﬁed as a riﬂe. arXiv:1707.07397v3  [cs.CV]  7 Jun 2018  Synthesizing Robust Adversarial Examples subjected to minor transformations (Luo et al., 2016; Lu et al., 2017). Prior techniques attempting to synthesize adversarial',\n",
       " '1607.07959': 'Premature or preterm birth (PTB) is a major long-lasting public health problem with heavy emotional and ﬁnancial consequences to families and society (March of Dimes, 2012; Conova, 2016). PTB is the leading cause of neonatal mortality and, long-term disabilities. Furthermore, over 26 billion dollars are spent annually on the delivery and care of the 1213% of infants who are born preterm in the United States (Behrman et al., 2007). A crucial challenge is to identify women who are at the highest risk for very early preterm birth and to develop interventions. Equally important, would be the ability to identify women at the lowest risk to avoid unnecessary and costly interventions. A particularly challenging population to determine PTB risk is ﬁrst time mothers (nulliparous women) due to the lack of prior pregnancy history. Prediction of preterm birth represents a compelling application from a machine learning perspective. It has been an exceedingly challenging problem, predominantly due to (1) the inherent complexity of its heterogeneous multifactorial etiology, (2) the temporal dynamics 1 arXiv:1607.07959v2  [cs.LG]  5 Sep 2016  Vovsha et al. of pregnancy and (3) the lack of approaches capable of integrating and interpreting large multidimensional data. Risk factors of PTB are heterogenous and include history of PTB, race, age, parity of the mother, bacterial vaginosis, urinary tract infection, smoking, bleeding, cervix length. Most studies to date have examined individual risk factors independently of each other through univariate analyses of their coincidence with PTB. While these studies led to many insights on the PTB problem, current models lack suﬃciently good prediction to be used clinically (Mercer et al., 1996). Previous results on this dataset using a multivariate logistic regression model show a sensitivity of 24.2% and 18.2%, and speciﬁcity of 28.6% and 33.3%, for nulliparous and multiparous women respectively. We describe our eﬀorts towards developing multivariate linear and non-linear models that integrate all risk factors for predicting preterm birth.1 We use the “Preterm Prediction Study,” a clinical trial dataset collected by the National Institute of Child Health and Human Development (NICHD) – Maternal-Fetal Medicine Units Network (MFMU). We compare three approaches for deriving predictive models: a support vector machine (SVM) approach with linear and non-linear kernels, logistic regression with model selection along with a hand-picked model. We also focus our attention (as recommended by (NICHD, 2005)) on predicting (1) any kind of preterm birth, (2) spontaneous preterm birth, and (3) predicting preterm birth for nulliparous women. Furthermore, etiologies of preterm birth are believed to be diﬀerent as pregnancy progresses. Hence, we also derive models at diﬀerent time points, which represent the three main prenatal visits in the preterm prediction study, that is at 24, 26 and 28 weeks gestation. Our results for the spontaneous preterm birth class at 28 weeks gestation show an improvement of 20% and 30% for sensitivity and speciﬁcity respectively as compared to (Mercer et al., 1996). In addition, we obtain approximately 50% sensitivity and speciﬁcity across',\n",
       " '1211.2304': 'In several data mining applications, one builds an initial classiﬁcation model that needs to be applied to unlabeled data acquired subsequently. Since the statistics of the underlying phenomena being modeled changes with time, these classiﬁers may also need to be occasionally rebuilt if performance degrades beyond an acceptable level. In such situations, it is desirable that the classiﬁer functions well with as little labeling of new data as possible, since labeling can be expensive in terms of time and money, and a potentially errorprone process. Moreover, the classiﬁer should be able to adapt to changing statistics to some extent, given the aforementioned constraints. This paper addresses the problem of combining multiple classiﬁers and clusterers in a fairly general setting, that includes the scenario sketched above. An ensemble of classiﬁers is ﬁrst learnt on an initial labeled training dataset after which the training data can be ∗University of Texas at Austin, Austin, TX, USA. Email: {aacharya@, ghosh@ece}.utexas.edu †University of Sao Paulo at Sao Carlos, Brazil. Email: erh@icmc.usp.br ‡eBay Research Lab, San Jose, CA, USA. Email: {bsarwar, jruvini}@ebay.com discarded. Subsequently, when new unlabeled target data is encountered, a cluster ensemble is applied to it, thereby generating cluster labels for the target data. The heart of our approach is a Bayesian framework that combines both sources of information (class/cluster labels) to yield a consensus labeling of the target data. The setting described above is, in principle, diﬀerent from transductive learning setups where both labeled and unlabeled data are available at the same time for model building [19], as well as online methods [6]. Additional diﬀerences from existing approaches are described in the section on related works. For the moment we note that the underlying assumption is that similar new objects in the target set are more likely to share the same class label. Thus, the supplementary constraints provided by the cluster ensemble can be useful for improving the generalization capability of the resulting classiﬁer system. Also, these supplementary constraints can be useful for designing learning methods that help determining diﬀerences between training and target distributions, making the overall system more robust against concept drift. We also show that our approach can combine cluster and classiﬁer ensembles in a privacy-preserving setting. This approach can be useful in a variety of applications. For example, the data sites can represent parties that are a group of banks, with their own sets of customers, who would like to have a better insight into the behavior of the entire customer population without compromising the privacy of their individual customers. The remainder of the paper is organized as follows. The next section addresses related work. The proposed Bayesian framework — named BC3E, from Bayesian Combination of Classiﬁers and Clusterer Ensembles — is described in Section 3. Issues with privacy preservation are discussed in Section 4 and the experimental results are reported in Section 5. Finally, Section 6 concludes the paper. 2 Related Work',\n",
       " '1606.02407': 'Deep convolutional networks have, in recent times, achieved near-human performance on an array of visual, auditory, and other cognitive tasks [1, 2]. The intriguing possibility of delivering deep learning applications on mobile devices, as well as providing energy-efﬁcient cognitive solutions on the cloud have inspired an increasing number of researchers to search for low-precision state-of-the-art convolutional networks that can be deployed on extremely energy-efﬁcient platforms [3, 4, 5, 6, 7, 8]. Binary convolutional networks that use binary convolutional kernels, and binary neuron activations are ideally suited to be run on low-power neuromorphic architectures that use spike-based communication [9]. In addition, storage and computational efﬁciency may be gained by using structured matrices in convolutional layers. Using structured matrices in the fully connected layers (also known as linear layers) of deep networks has been studied in the literature [10, 11, 12] with the objective of reducing the number of learned parameters. The main idea behind these approaches is to restrict the connectivity matrix of a (fully connected) layer to be from a known family of matrices, which are parametrised by a few variables and adapt the backpropagation to update those variables. On the other hand, reducing the memory and computation requirements of convolutional layers has been addressed by several approaches to model compression [13, 14, 15, 7, 16, 17, 18, 19, 20, 21] – mostly after training. In this work, we propose the use of structured matrices in convolutional layers that are inspired by low-power neuromorphic hardware architectures [9, 22, 23, 24, 25, 26, 21]. By connecting the efﬁcient weight representation schema used in neuromorphic architectures [9, 21] with block Toeplitz matrices that arise in discrete convolution, we identify a family of convolution kernels that are arXiv:1606.02407v1  [cs.NE]  8 Jun 2016  naturally hardware efﬁcient. The primary motivation behind our investigation is in the tradition of discovering algorithms that are native to a chosen architecture [27, 28, 29, 30] and thereby harvesting the best that a particular architecture offers. We incorporate learning structured convolutional matrices into traditional stochastic gradient descent [31] so that the trained inference networks are hardware-ready. Furthermore, we exploit a known equivalence between stochastic bounded rectiﬁed linear units and deterministic threshold neurons and propose a novel approach to training networks with binary neuron activations. This procedure allows us to obtain accurate gradient estimates during backward step, and speed-up convergence of training and enriches the library of tools available to train low-precision deep neural networks. We evaluate our system on Cifar10 data set and compare against best energy vs accuracy numbers reported on currently available hardware [3] – our approach reduces the number of TrueNorth cores required to achieve 87.5% on Cifar10 from 31872 TrueNoth cores in [3] to 13216 cores. We begin the next section by discussing binary convolutional networks and their suitability for neuromorphic hardware and introduce the weight representation mechanism used in TrueNorth architecture [9]. In Section 3, we discuss the structure of',\n",
       " '1507.02407': 'In this work, we formulate hierarchical image segmentation from the perspective of estimating an ultrametric over the set of image pixels that agrees closely with an input set of noisy pairwise distances. An ultrametric is a metric space in which the triangle inequality is replaced by the ultrametric inequality d(u, v) ≤max{d(u, w), d(v, w)}. This inequality captures the transitive property of clustering (if u and w are in the same cluster and v and w are in the same cluster, then u and v must also be in the same cluster). Thresholding an ultrametric immediately yields a partition into sets whose diameter is less than the given threshold and varying the threshold naturally produces a hierarchical clustering in which clusters at high thresholds are composed of clusters at lower thresholds. Inspired by the approach of [1], our method represents an ultrametric explicitly as a hierarchical collection of segmentations. Determining the appropriate segmentation at a single distance threshold is equivalent to ﬁnding a minimum-weight multicut in a graph with both positive and negative edge weights [3, 14, 2, 11, 20, 21, 4, 19, 7]. Finding an ultrametric imposes the additional constraint that these multicuts are hierarchically consistent across different thresholds. We focus on the case where the input distances are speciﬁed by a planar graph which arises naturally in the domain of image segmentation where elements are pixels or superpixels and distances are deﬁned between neighbors. This allows us to exploit fast combinatorial algorithms for partitioning planar graphs that yield tighter LP relaxations than the local polytope relaxation [20]. This paper is organized as follows. We ﬁrst introduce the ultrametric rounding problem and the relation between multicuts and ultrametrics. We then introduce a LP relaxation that uses a delayed column generation approach that exploits planarity to efﬁciently ﬁnd cuts using the classic reduction to minimum-weight perfect matching [13, 8, 9, 10]. We apply our algorithm to the task of natural image segmentation on the Berkeley Segmentation Data Set benchmark [16]. We show compelling visual results and demonstrate that our algorithm converges rapidly and produces near optimal or optimal solutions in practice with guarantees. ∗JY acknowledges the support of Experian, CF acknowledges support of NSF grants IIS-1253538 and DBI1262547 1 arXiv:1507.02407v3  [cs.DS]  10 Sep 2015  2 Ultrametric Rounding and Multicuts Let G = (V, E) be a weighted graph with non-negative edge weights θ indexed by edges e = (u, v) ∈E. Our goal is to ﬁnd an ultrametric distance d(u,v) over vertices of the graph that is close to θ in the sense that the distortion P (u,v)∈E ∥θ(u,v) −d(u,v)∥2 2 is minimized. We begin by reformulating this rounding problem in terms of ﬁnding a set of nested multicuts in a family of weighted graphs. We specify a partitioning or multicut of the vertices of the graph G into components using a binary vector ¯X ∈{0, 1}|E',\n",
       " '1812.02391': 'While deep learning systems have achieved great performance when sufﬁcient amounts of labeled data are available [58, 17, 46], there has been growing interest in reducing the required amount of data. Few-shot learning tasks have been deﬁned for this purpose. The aim is to learn new concepts from few labeled examples, e.g. 1-shot learning [25]. While humans tend to be highly effective in this ∗Yaoyao Liu did this work during his internship at NUS. 1Code: https://github.com/y2l/meta-transfer-learning-tensorﬂow meta-training Transfer Learning [35] Meta-Learning [9] task2 model1 + FT ... task1 model1 taskN modelN taskN+1 modelN+1 Meta-Transfer Learning (ours) ... task model task1 model1 k tasks Meta-Batch [9] Hard Task Meta-Batch (ours) ... k tasks  +  k’ hard tasks batch i k tasks batch i+1 batch i batch i+1 meta-test ... ... k tasks  +  k’ hard tasks online re-sample online re-sample ... large-scale training task1 model + SS1 + FT1 taskN model + SSN + FTN taskN+1 model + SSN + FTN+1 Figure 1. Meta-transfer learning (MTL) is our meta-learning paradigm and hard task (HT) meta-batch is our training strategy. The upper three rows show the differences between MTL and related methods, transfer-learning [35] and meta-learning [9]. The bottom rows compare HT meta-batch with the conventional metabatch [9]. FT stands for ﬁne-tuning a classiﬁer. SS represents the Scaling and Shifting operations in our MTL method. context, often grasping the essential connection between new concepts and their own knowledge and experience, it remains challenging for machine learning approaches. E.g., on the CIFAR-100 dataset, a state-of-the-art method [34] achieves only 40.1% accuracy for 1-shot learning, compared to 75.7% for the all-class fully supervised case [6]. Few-shot learning methods can be roughly categorized into two classes: data augmentation and task-based metalearning. Data augmentation is a classic technique to increase the amount of available data and thus also useful for few-shot learning [21]. Several methods propose to learn a data generator e.g. conditioned on Gaussian noise [29, 44, 54]. However, the generation models often underperform when trained on few-shot data [1]. An alterarXiv:1812.02391v3  [cs.CV]  9 Apr 2019  native is to merge data from multiple tasks which, however, is not effective due to variances of the data across tasks [54]. In contrast to data-augmentation methods, meta-learning is a task-level learning method [2, 33, 52]. Meta-learning aims to accumulate experience from learning multiple tasks [9, 39, 48, 31, 13], while base-learning focuses on modeling the data distribution of a single task. A state-of-theart representative of this, namely Model-Agnostic MetaLearning (MAML), learns to search for the optimal initialization state to fast adapt a base-learner to a new task [9]. Its task-agnostic property makes it possible to generalize to few-shot',\n",
       " '1601.07091': 'Since the pioneering work of Shannon, the problems of deriving single-letter (S-L) characterizations for performance limits of communication systems - capacity, rate-distortion regions as the case maybe - have been regarded to be of fundamental importance. In order to derive achievable rate regions, i.e., inner bounds to performance limits, a so-called ‘S-L coding scheme’ is analyzed. Informally speaking, a random coding scheme is referred to as S-L, if the probability mass function (pmf) induced on the n−letter Cartesian product of the associated This work was supported by the Center for Science of Information (CSoI), an NSF Science and Technology Center, under grant agreement CCF-0939370. This work was presented in part at the IEEE International Symposium on Information Theory held in Barcelona, Spain (July 2016) and Aachen, Germany (June 2017). Rx Tx1 Tx2 S1 S2 X1 WS1S2 ~ ~ S1S2 X2 Y WY|X1X2 Fig. 1. Transmission of correlated sources over MAC. Tx1 Tx2 S1 S2 X1 WS1S2 ~ ~ X2 WY1Y2|X1X2 Rx1 Rx1 Rx2 Y1 S1 S2 Y1 Y2 Fig. 2. Transmission of correlated sources over 2-IC. arXiv:1601.07091v7  [cs.IT]  18 Feb 2019  1 alphabet sets factors as a product of n identical S-L pmfs. Since the performance is characterized in terms of an information functional of the induced pmf, the performance of a S-L scheme can be characterized in terms of the information functional of this factor pmf which is indeed a S-L pmf. Naturally, the goal of providing a S-L characterization for the target inner bound has restricted us to analyzing performance of S-L coding schemes. In this work, we take a new approach. Recognizing that the current known best S-L coding scheme is strictly sub-optimal, we devise a multi-letter coding scheme by carefully stitching together S-L coding techniques. Indeed, the pmf induced by the devised random coding scheme does not factor as a product of S-L pmfs. However, we characterize an inner bound to its performance via S-L expression i.e., an expression involving information functionals of S-L pmfs. We identify examples for which the derived inner bound is strictly larger that the current known largest inner bound derived via a S-L coding scheme. Our primary focus in this article is the Shannon-theoretic study of the two scenarios depicted in Figures 1, 2. Figure 1 depicts the MAC problem wherein a pair S1, S2 of correlated sources, observed at the transmitters (Txs) of a 2−user multiple access channel (MAC), have to be communicated to the receiver (Rx). The Rx intends to reconstruct both the sources losslessly. Given a (generic) MAC WY |X1X2, the MAC problem concerns characterizing the set T (WY |X1X2) of all transmissible source pairs WS1S2 over the MAC. Figure 2 depicts the IC problem wherein a pair S1, S2 of correlated sources have to be communicated over a 2−user interference channel (IC) WY1Y2|X1X2. Receiver (Rx) j wishes to reconstruct Sj',\n",
       " '1810.12482': 'Variational Inference (VI) [29, 2, 11] is a framework for approximate probabilistic inference. It has been successfully applied in several areas including topic modeling [3, 21], generative models [13, 5, 22], reinforcement learning [6], and parsing [15], among others. Recently, VI has been able to address a wider range of problems by adopting a \"black box\" [25] view based on only evaluating the value or gradient of the target distribution. Then, the target can be optimized via stochastic gradient descent. It is desirable to reduce the variance of the gradient estimate, since this governs convergence. Control variates (CVs), a classical technique from statistics, is often used to accomplish this. This paper investigates how to use many CVs in concert. We present a systematic view of existing CVs, which starts by splitting the exact gradient into four terms (Eq. 2). Then, a CV is obtained by application of a generic \"recipe\": Pick a term, possibly approximate it, and take the difference of two estimators (Fig. 2). This suggests many possible CVs, including some seemingly not used before. With many possible CVs, one can naturally ask how to use many together. In principle, the optimal combination is well known (Eq. 6). However, this requires unknown (intractable) expectations. We address this using decision theory. The goal is a “decision rule” that takes a minibatch of evaluations together with the set of CVs to be used, and returns a gradient estimate. We adopt a Bayesian risk measuring how gradient variance impacts convergence rates of stochastic optimization, with simple prior over gradients and sets of CVs. A simple optimal decision rule emerges, where the intractable expectations are replaced with \"regularized\" empirical estimates (Thm 4.1). To share information across iterations, we suggest combining this Bayesian approach with exponential averaging by using an “effective” minibatch size. 32nd Conference on Neural Information Processing Systems (NIPS 2018), Montréal, Canada. arXiv:1810.12482v2  [cs.LG]  22 Oct 2020  We demonstrate practicality on logistic regression problems, where careful combination of many CVs improves performance. For all learning rates, convergence is improved over any single CV. 1.1 Contributions 0 20 40 60 80 100 Iteration 0 5 10 15 20 ∥ˆg∥2 Base\\xa0gradient All\\xa0CVs\\xa0combined Best\\xa0CV\\xa0alone Figure 1: An example of how combining control variates reduces gradient variance for the same sequence of weights (australian dataset). The contribution of this work is twofold. First, in Section 3, we propose a systematic view of how to generate many existing control variates. Second, we propose a an algorithm to use multiple control variates simultaneously, described in Section 4. As shown in Section 5, combining these two ideas result in gradients with low variance that allow the use of larger learning rates, while retaining convergence. 2 Preliminaries Variational Inference (VI) works by transforming an inference problem into an optimization, by decomposing the marginal likelihood of the observed data x given latent variables z as: log p(x) = E Z∼qw(Z) \" log p(Z, x) qw(Z) # | {z } ELBO(w',\n",
       " '1705.00673': 'FAILED',\n",
       " '1901.03149': 'In modern distributed storage systems (DSSs) failures happen frequently, whence decreasing the number of connections required for node repair is crucial. Locally repairable codes (LRCs) are a subclass of erasure-correcting codes, which allow a small number of failed nodes to be repaired by accessing only a few other nodes. LRCs were introduced in [6], [11] where the codes can locally repair one failure. They were later extended in [12], [8] to be able to locally repair up to δ −1 failures. An [n,k,d] linear code C of length n, dimension k, and minimum hamming distance d, has all-symbol locality (r,δ) if for all code symbols i ∈[n] = {1,...,n}, there exists a set Ri ⊆[n] containing i such that |Ri| ≤r +δ −1 and the minimum distance of the restriction of C to Ri is at least δ. We refer to C as an (n,k,d,r,δ)-LRC and to the sets Ri as repair sets or local sets. Related Singleton-type bounds have been derived for various cases in [6, 11, 12] and the ﬁrst bound with a ﬁxed code alphabet was obtained in [3] for δ = 2. Constructions achieving the Singleton-type bounds and the bound in [3] for δ = 2 were provided in [8,9,11–14,16–18,20]. Part of the results were submitted without any proofs to IEEE International Symposium Information Theory (ISIT) 2019. Matthias Grezet · Camilla Hollanti Department of Mathematics and Systems Analysis, Aalto University, Finland E-mail: matthias.grezet@aalto.ﬁ, camilla.hollanti@aalto.ﬁ  2 Matthias Grezet, Camilla Hollanti The authors of [1] proposed the ﬁrst alphabet-dependent bound on LRCs over the alphabet Q using an upper bound B(n,d) on the cardinality of a code of length n and minimum distance d. The global bound is as follows: k ≤ \\x12\\x18n−d +1 r +δ −1 \\x19 +1 \\x13 logq B(r +δ −1,δ). (1) Recently, [7] provided a different alphabet-dependent bound for LRCs of the same type as the bound in [3] using the Griesmer bound Gq(k,d) := k−1 ∑ i=0 ⌈d/qi⌉. The bound has the following form : For any linear (n,k,d,r,δ)-LRC C with κ the upper bound on the local dimension of the repair sets, k ≤min λ∈Z+ n λ +k(q) opt(n−µ,d) o (2) where a,b ∈Z such that λ = aκ +b,0 ≤b < κ and µ = (a+1)Gq(κ,δ)−Gq(κ −b,δ). In [15], the authors introduced the notion of codes with hierarchical locality (H-LRCs), which optimizes futher the number of nodes contacted for repair according to the number of failures. A 2-level H-LRC is a code where the restrictions to the repair sets are themselves LRCs, thus providing an extra layer of locality. If an H-LRC has locality [(r1,δ1),(r2,δ2)], then the number of nodes contacted to repair up to δ2−1 failures',\n",
       " '1204.2611': 'Since many systems in science and engineering are approximately linear, linear inverse problems have attracted great attention in the signal processing community. An input signal x ∈RN is recorded via a linear operator under additive noise: y = Φx + z, (1) where Φ is an M × N matrix and z ∈RM denotes the noise. The goal is to estimate x from the measurements y given knowledge of Φ and a model for the noise z. When M ≪N, the setup is known as compressed sensing (CS) and the estimation problem is commonly referred to as recovery or reconstruction; by posing a sparsity or compressibility1 requirement on the signal and using this requirement as a prior during recovery, it is indeed possible to accurately estimate x from y [4, 5]. On the other hand, we might need more measurements than the signal length when the signal is dense or the noise is substantial. Wu and Verd´u [6] have shown that independent and identically distributed (i.i.d.) Gaussian sensing matrices achieve the same phase-transition threshold as the optimal (potentially nonlinear) measurement operator, for any i.i.d. signals following the discrete/continuous mixture distribution fX(x) = p·Pc(x)+(1−p)·Pd(x), where p is the probability for x to take a continuous distribution Pc(x) and Pd(x) is an arbitrary discrete distribution. For non-i.i.d. signals, Gaussian matrices also work well [7–9]. Hence, in CS the acquisition can be designed independently of the particular signal prior through the use of randomized Gaussian matrices Φ. Nevertheless, the majority of (if not all) existing recovery algorithms require knowledge of the sparsity structure of x, i.e., the choice of a sparsifying transform W that renders a sparse coefﬁcient vector θ = W −1x for the signal. The large majority of recovery algorithms pose a sparsity prior on the signal x or the coefﬁcient vector θ, e.g., [4, 5, 10]. A second, separate class of Bayesian CS recovery algorithms poses a probabilistic prior for the coefﬁcients of x in a known transform domain [11–15]. Given a probabilistic model, some related message passing approaches learn the parameters of the signal model and achieve the minimum mean squared error (MMSE) in some settings; examples include EM-GM-AMP-MOS [16], turboGAMP [17], and AMP-MixD [18]. As a third alternative, complexity-penalized least square methods [19–23] can use arbitrary prior information on the signal model and provide analytical guarantees, but are only computationally efﬁcient for speciﬁc signal models, such as the independent-entry Laplacian model [21]. For example, Donoho et al. [20] relies on Kolmogorov complexity, which cannot be computed [24, 25]. As a fourth alternative, there exist algorithms that can formulate dictionaries that yield sparse representations for the signals of interest when a large amount of training data is available [23, 26– 28]. When the signal is non-i.i.d., existing algorithms require either prior knowledge of the probabilistic model [17] or the use of',\n",
       " '1709.08025': 'Mobile edge computing (MEC) is often referred to as a plausible approach to reduce end-to-end delay by moving cloud-computing capabilities to the edge [1]. In addition, MEC can provide location awareness services for cellular-networkbased applications. While MEC is becoming an increasingly popular computing paradigm for dynamic systems/scenarios, new types of vulnerabilities, especially those that can come from the edge network itself, are also becoming serious concerns. For instance, when an edge customer connects with the closest edge computing device to access a service in a certain location, an attacker can tamper with the address of the currently connected edge computing device stored with the edge customer, to possibly interrupt the connection. Such manipulations are location-aware. Detecting such attacks and associating them with the locations of their origins are both important. Moreover, such attacks can result in extra energy consumption. Tampering with the address of the closest connected edge computing device to disconnect the edge customer from its closest edge computing device is a typical example of such an attack. The edge customer in this case has to connect to a remote edge computing device, thus resulting in extra energy consumption of the network connection. Based on the above description, the research problem is illustrated in Figure 1. An edge customer in location A attempts to connect to the closest edge computing device 1, but the connection is ineffective because of the attack. As the customer moves, it attempts to connect to the closest edge computing device 2 in location B. Because the attack takes place in location A, not in location B, the connection to edge computing device 2 is successful. To detect this attack, the detection method needs location information to automate the detection process. Corresponding author: Yan Zhang In order to detect such attacks, we introduce a deeplearning-based model. As an example, the introduced model is used to detect the malicious application on Android devices [2], which is a kind of serious security threat for mobile devices in the MEC environment. Using machine learning algorithms to detect such malicious attacks, requires extracting features from the applications. The state of the art provides quite a good volume of work in this direction. DynaLog [3] is a dynamic analysis framework that automatically extracts dynamic behaviors (features) of applications for further processing. The authors in [4] presented a dynamic framework called Andromaly that applies several different machine learning algorithms to classify applications. MADAM [5] is also a dynamic analysis framework that uses machine learning to classify applications. It extracted 13 features at the user and kernel levels. Marvin [6] combined static and dynamic analysis and applied machine learning techniques to assess the risk of unknown applications. Crowdroid [7] is a cloud-based machine learning framework for malicious application detection. However, the existing work has not considered the location information related to the attack that can be exploited to learn more about it, and thus detect the attack in',\n",
       " '1505.00066': 'Class-based processing signiﬁcantly simpliﬁes tasks such as object segmentation [17, 4], reconstruction [6, 21, 38] and, more generally, the propagation of knowledge from class objects we have seen before to those we are seeing for the ﬁrst time. Looking at the lion in Figure 1 humans can not only easily perceive its shape, but also tell that it is strong and dangerous, get an estimate of its weight and dimensions and even approximate age and gender. We get to know all of this because it is a lion like others we have seen before and that we know many facts about. Despite its many virtues, class-based processing does not scale well. Learning predictors for all variables of interest – ﬁgure-ground segmentation, pose, shape – requires expensive manual annotations to be collected for at least dozens of examples per class and there are millions of classes. Consider again Figure 1 but now look at object A. The underlying structure in our visual world allows us to perceive a rich representation of this object despite encountering it for the ﬁrst time. We can infer that it is probably hair that covers its surfaces – we have seen plenty of hair-like materials before – and that it has parts and determine their conﬁguration by analogy with our own parts or with other animals. We are able to achieve this remarkable feat by leverOur implementations and trained models are available at https:// github.com/shubhtuls/poseInduction Figure 1. Inductive pose inference for novel objects. Right : Novel object A. Left : instances from previously seen classes having similar pose as object A. aging commonalities across object categories via generalizable abstractions – not only can we perceive that all the other animals in Figure 1 are “right-facing”, we can also transfer this notion to object A. This type of cross-category knowledge transfer has been successfully demonstrated before for properties such as materials [37, 8], parts [35, 10] and attributes [22, 13]. In this paper we deﬁne and attack the problem of predicting object poses across categories – we call this pose induction. The ﬁrst step of our approach, as highlighted in Figure 2, is to learn a generalizable pose prediction system from the given set of annotated object categories. Our main intuition is that most objects have appearance and shape traits that can be associated with a generalized notion of pose. For example, the sentences “I am in front of a car” or “in front of a bus” or “in front of a lion” are clear about where“I” am with respect to those objects. The reason for this may be that there is something generic in the way“frontality” manifests itself visually across different object classes – e.g.“fronts” usually exhibit an axis of bilateral symmetry. Pushing this observation further leads to our solution: to align all the objects in a small seed set of classes, by endowing them',\n",
       " '1310.2053': 'The commercial success of the Microsoft Kinect [27] in November 2010 sparked a multitude of signiﬁcant research papers in the computer vision community. The Microsoft Kinect was originally designed as a motion sensing input device for the gaming console Microsoft XBOX 360 by tracking the player’s motions. As structured light sensor, the Kinect emits a deﬁned light spot pattern, which was ﬁrst patented by PrimeSense. Users can access the Kinect data streams via USB 2.0 with the help of OpenKinect’s libfreenect. The main advantage of Kinect capturing setups over conventional time-of-ﬂight (ToF) setups is that the cost is only a fraction of the usual ToF-setups, which makes experimenting with one or many Kinects very convenient. The projected spot pattern, used for computing the depth maps, is generated as follows: an infrared laser, projects a deﬁned pattern at 850nm onto all surfaces of the scene facing the sensor in the frustum. The diffuse reﬂection of the pattern in the scene is captured by a camera, which has its infrared ﬁlter removed. An onboard circuit computes the disparity for each 9 × 9 subpattern by computing the distance to their default positions for an image of a default scene (this is likely to be a wall parallel to the sensor at a deﬁned distnce of 3m). The disparity values are mapped to distance values in meters. This technique has been introduced by PrimeSense. The project pattern is a texture of 211 × 165 spot positions. 3861 spot positions are brighter, the rest is assumed dark. That pattern is replicated in a 3 × 3 pattern to broaden the ﬁeld of view. The central spot of the pattern appears brighter than all the other spots and no two bright spots are adjacent. The pattern looks quasi-random but in fact is the same for all cameras. Thus, one device can compute the depth map from the emitted pattern of another adjacent device, if its own laser is obstructed. It is assumed that the depth computation follows a block search approach, i.e. the integrated circuit looks the corresponding position in the neighbourhood of the original subpattern position and computs depth values from the distance to the original position. The visual tact rate can be computed from a central distinguishable subpattern, where a horizontal line alternates bright and dark spots. As several brighter spots are visible over the complete pattern, it can be assumed, that distortions might be calculated from their location information in the received image. Located within the Kinect device, there is one RGB camera, that operates at 30Hz with a resolution of 640 × 480 pixels or 15Hz with a resolution of 1280 × 1024 pixels, and one IR camera, that operates at 30Hz with a resolution of 640 × 480 pixels or 10Hz with a resolution of 1280 × 1024 pixels. In the IR view it can be noticed, that visible light is captured with the chip at a small intensity range as',\n",
       " '1207.3994': 'In many networks, nodes divide naturally into modules or communities, where nodes in the same group connect to the rest of the network in similar ways. Discovering such communities is an important part of modeling networks (Porter et al., 2009), as community structure offers 50 clues to the processes which generated the graph, on scales ranging from face-to-face social interaction (Zachary, 1977) through social-media communications (Adamic & Glance, 2005) to the organization of food webs (Allesina & Pascual, 2009; Moore et al., 2011). The stochastic block model (Fienberg & Wasserman, 1981a; Holland et al., 1983; Snijders & Nowicki, 1997; Airoldi et al., 2008; Bickel & Chen, 2009) has, deservedly, become one of 55 the most popular generative models for community detection. It splits nodes into communities or blocks, within which all nodes are stochastically equivalent (Wasserman & Anderson, 1987). That is, the probability of an edge between any two nodes depends only on which blocks they belong to, and all edges are independent given the nodes’ block memberships. Block models are highly ﬂexible, representing assortative, disassortative and satellite community structures, as 60 well as combinations thereof, in a single generative framework (Newman, 2002, 2003; Bickel & Chen, 2009). Their asymptotic properties, including phase transitions in the detectability of communities, can be determined exactly using tools from statistical physics (Decelle et al., 2011b,a) and random graph theory (Mossel et al., 2012). Despite this ﬂexibility, stochastic block models impose real restrictions on networks; notably, 65 the degree distribution within each block is asymptotically Poisson for large graphs. This makes the stochastic block model implausible for many networks, where the degrees within each community are highly inhomogeneous. Fitting stochastic block models to such networks tends to split the highand lowdegree nodes in the same community into distinct blocks; for instance, dividing both liberal and conservative political blogs into high-degree “leaders” and low-degree 70 “followers” (Adamic & Glance, 2005; Karrer & Newman, 2011). To avoid this pathology, and allow degree inhomogeneity within blocks, there is a long history of generative models where the probability of an edge depends on node attributes as well as their group memberships (e.g.,  Model Selection for Degree-corrected Block Models 3 Mørup & Hansen 2009; Reichardt et al. 2011). Here we use the variant due to Karrer & Newman (2011), called the degree-corrected block model1. 75 We often lack the domain knowledge to choose between the ordinary and the degree-corrected block model, and so face a model selection problem. The standard methods of model selection are largely based on likelihood ratios (possibly penalized), and we follow that approach here. Since both the ordinary and degree-correct block models have many latent variables, calculating likelihood ratios is itself non-trivial; the likelihood must be summed over all partitions of nodes 80 into blocks, so (in statistical physics terms) the log-likelihood is a free energy. We approximate the log-likelihood using belief propagation and the Bethe free energy, giving a highly scalable algorithm that can deal with large',\n",
       " '1805.04623': 'Language models are an important component of natural language generation tasks, such as machine translation and summarization. They use context (a sequence of words) to estimate a probability distribution of the upcoming word. For several years now, neural language models (NLMs) (Graves, 2013; Jozefowicz et al., 2016; Grave et al., 2017a; Dauphin et al., 2017; Melis et al., 2018; Yang et al., 2018) have consistently outperformed classical n-gram models, an improvement often attributed to their ability to model long-range dependencies in faraway context. Yet, how these NLMs use the context is largely unexplained. Recent studies have begun to shed light on the information encoded by Long Short-Term Memory (LSTM) networks. They can remember sentence lengths, word identity, and word order (Adi et al., 2017), can capture some syntactic structures such as subject-verb agreement (Linzen et al., 2016), and can model certain kinds of semantic compositionality such as negation and intensiﬁcation (Li et al., 2016). However, all of the previous work studies LSTMs at the sentence level, even though they can potentially encode longer context. Our goal is to complement the prior work to provide a richer understanding of the role of context, in particular, long-range context beyond a sentence. We aim to answer the following questions: (i) How much context is used by NLMs, in terms of the number of tokens? (ii) Within this range, are nearby and long-range contexts represented differently? (iii) How do copy mechanisms help the model use different regions of context? We investigate these questions via ablation studies on a standard LSTM language model (Merity et al., 2018) on two benchmark language modeling datasets: Penn Treebank and WikiText-2. Given a pretrained language model, we perturb the prior context in various ways at test time, to study how much the perturbed information affects model performance. Speciﬁcally, we alter the context length to study how many tokens are used, permute tokens to see if LSTMs care about word order in both local and global contexts, and drop and replace target words to test the copying abilities of LSTMs with and without an external copy mechanism, such as the neural cache (Grave et al., 2017b). The cache operates by ﬁrst recording tararXiv:1805.04623v1  [cs.CL]  12 May 2018  get words and their context representations seen in the history, and then encouraging the model to copy a word from the past when the current context representation matches that word’s recorded context vector. We ﬁnd that the LSTM is capable of using about 200 tokens of context on average, with no observable differences from changing the hyperparameter settings. Within this context range, word order is only relevant within the 20 most recent tokens or about a sentence. In the long-range context, order has almost no effect on performance, suggesting that the model maintains a high-level, rough semantic representation of faraway words. Finally, we ﬁnd that LSTMs can regenerate some',\n",
       " '1801.09383': 'The promising Internet of Things (IoT) paradigm aims to bridge diverse technologies to support intelligent decision making by connecting pervasive physical objects together [1]. One of the most important technologies for enabling IoT is backscatter radio, which has received increasing attention from both academic and industrial communities nowadays due to its distinguished low-energy requirement and rapid cut down of manufacture cost [2]. The most prominent commercial application of backscatter radio lies in radio frequency identiﬁcation (RFID), which is the ﬁrst technology realizing the machineto-machine (M2M) concept (RFID tag and reader) and plays Q. Yang, H.-M. Wang, and T.-X. Zheng are with the School of Electronic and Information Engineering, Xi’an Jiaotong University, Xi’an 710049, China, and also with the Ministry of Education Key Laboratory for Intelligent Networks and Network Security, Xi’an Jiaotong University, Xi’an 710049, China (e-mail: yangq36@gmail.com; xjbswhm@gmail.com; txzheng@stu.xjtu.edu.cn). Z. Han is with the University of Houston, Houston, TX 77004, USA (email:zhan2@uh.edu), and also with the Department of Computer Science and Engineering, Kyung Hee University, Seoul, South Korea. M. H. Lee is with the Division of Electronics Engineering, Chonbuk National University, Jeonju 561-756, South Korea (e-mail: moonho@jbnu.ac.kr). an indispensable role in the evolution of the IoT [1]. A typical RFID system consists of a RFID reader (interrogator) and a RFID tag (transponder) where the RFID reader interrogates the RFID tag for the desired information like an identiﬁcation number [3]. Among all kinds of RFID tags, the passive tag receives more emphasis compared with the active and semipassive tags, since it has no on-tag power source but relies on the electromagnetic (EM) ﬁeld transmitted by a RFID reader and “backscattering” for energy harvesting and information transmission, respectively [4]. An illustration of passive tag applications is the wireless integrated sensing platform (WISP) [5], which is a programmable sensor platform based on RFID and aims to create a wirelessly-networked, battery-less sensor device. In the revolution of replacing the conventional barcode system, the commercial adoption of RFID is largely predicated on the passive tag due to its high energy efﬁciency, tiny size, and ultra low cost [6]. In a passive RFID system, to initiate a querying procedure the RFID reader ﬁrst transmits a continuous standardized signal to power up the passive RFID tag. Then the RFID tag wakes up after harvesting sufﬁcient energy from the RFID reader’s radio frequency (RF) signal and responds to the RFID reader via backscatter modulation. Finally, the RFID reader extracts the tag information from the signal backscattered by the passive RFID tag [3]. With the prevalence of the above described RFID backscatter system, there emerge the following three main research branches in the backscatter communication system. The ﬁrst and most important research branch is the transmit signal design and performance analysis in the point-to-point backscatter system. To meet the increasing expectation of the data rate and data reliability for prominent RFID applica',\n",
       " '1511.07409': 'Structured labeling is a key machine learning problem: structured inputs and outputs are common in a wide range of machine learning and computer vision applications [1,2,3]. The goal of structured labeling is to simultaneously assign labels (from some ﬁxed label set) to individual elements in a structured input. Markov random ﬁelds (MRFs) [4] and conditional random ﬁelds (CRFs) [2] have been widely used to model the correlations between the structured labels. However, due to the heavy computational burden in their training and † equal contribution. arXiv:1511.07409v2  [cs.CV]  26 Jul 2016  2 Saining Xie, Xun Huang, Zhuowen Tu testing/inference stages, MRFs and CRFs are often limited to capturing a few neighborhood interactions with consequent restrictions of their modeling capabilities. Structural SVM methods [5] and maximum margin Markov networks (M3N) [6] capture correlations in a way similar to CRFs, but they try to specifically maximize the prediction margin; these approaches are likewise limited in the range of contexts, again due to associated high computational costs. When long range contexts are used, approximations are typically used to trade between accuracy and eﬃciency [7]. Other approaches to capture output variable dependencies have been proposed by introducing classiﬁer cascades. For example, cascade models [8,9,10] in the spirit of stacking [11], are proposed to take the outputs of classiﬁers of the current layer as additional features for the next classiﬁers in the cascade. Since these approaches perform direct label prediction (in the form of functions) instead of inference as in MRFs or CRFs, the cascade models [8,9] are able to model complex and long-range contexts. Despite the eﬀorts in algorithmic development with very encouraging results produced in the past, the problem of structured labeling remains a challenge. To capture high-order conﬁgurations of the interacting labels, top-down information, or prior oﬀers assistance in both training and testing/inference. The demonstrated role of top-down information in human perception [12,13,14] provides a suggestive indication of the form that top-down information could play in structured visual inference. Systems trying to explicitly incorporate topdown information under the Bayesian formulation point to a promising direction [15,16,17,18] but in the absence of a clear solution. Conditional random ﬁelds family models that learn the posterior directly [2,8,9,19] alleviates some burdens on learning the labeling conﬁguration, but still with many limitations and constraints. The main diﬃculty is contributed by the level of complexity in building high-order statistics to capture a large number of interacting components within both shortand longrange contexts. From a diﬀerent angle, building convolutional neural networks for structured labeling [20] has resulted in systems that greatly outperform many previous algorithms. Recent eﬀorts in combining CNN with CRF and RNN models [21,22] have also shed light onto the solution of extending CNN to structured prediction. However, these approaches still rely on CRF-like graph structure with limited neighborhood connections',\n",
       " '1001.3193': 'Wireless sensor networks (WSNs) have become practical technology due to the production of low cost, low-power, and small size sensors. Different applications such as habitat and climate monitoring, detection of human/vehicular intrusion, and etc. are increasingly employing WSNs [1]. Such applications require sensor nodes to be deployed over a remote area to collect data from the surrounding environment and communicate it to far base stations or access points (BSs/APs). As a result, the challenges faced in the WSN applications are quite different from that of considered in the applications of the traditional wireless ad-hoc networks [2]. These differences can be summarized as follows. (i) Typical WSN is densely deployed and may consist of thousands of sensor nodes. (ii) The network geometry changes all the time due to failure of sensor nodes or deployment of new sensor nodes. (iii) Sensor nodes are battery-powered and the battery often cannot be replaced. Thus, the sensor node life time is limited by the battery lifetime. (iv) Sensor nodes have simple hardware with limited computational capabilities and small memory in order to keep the production cost of the sensor node reasonable. (v) Sensor nodes can fail easily. Thus, it is desired that the WSN performance does not depend on individual sensor nodes. (vi) Data and trafﬁc models in WSNs depend on the application, and usually the data is redundant, while the trafﬁc has low-rate burst nature. (vii) Sensor nodes in WSNs are usually deployed at the ground level and have no mobility. Thus, the channel path loss for individual node is high and the channel variations are slow. Practical communication schemes for WSNs should overcome the problem of limited transmission range of individual sensor nodes, while being distributed and scalable. Moreover, for designing such communication schemes, power consumption and implementation complexity issues have to be taken into account as the most signiﬁcant design constraints for WSNs. To address the aforementioned issues, the inherent high density deployment of sensor nodes has been used to introduce collaborative beamforming (CB) for the uplink communication to a BS/AP [3], [4]. CB extends the transmission range of individual sensor nodes by using a cluster of sensor nodes in a power-efﬁcient way. Particularly, sensor nodes from a cluster of nodes October 23, 2018 DRAFT  3 act collaboratively as distributed antenna array to form a beam toward the direction(s) of the intended BS(s)/AP(s). Given that each sensor node is equipped with a single omnidirectional antenna and operates in half-duplex mode, CB is performed in two stages. In the ﬁrst stage, the data from source node(s) in a cluster is shared with all other collaborative nodes, while in the second stage, this data is transmitted by all sensor nodes simultaneously and coherently. In the latter stage, sensor nodes adjust the initial phase of their carriers so that the individual signals from different sensor nodes arrive in phase and constructively add at the intended BS/AP. In this',\n",
       " '1406.2616': 'One key problem robots face in performing tasks in human environments is identifying trajectories desirable to the users. In this work we present a crowdsourcing system PlanIt that learns user preferences by taking their feedback over the Internet. In previous works, user preferences are usually encoded as a cost over trajectories, and then optimized using planners such as RRT* [1], CHOMP [2], TrajOpt [3]. However, most of these works optimize expert-designed cost functions based on different geometric and safety criteria [4], [5], [6]. While satisfying safety criteria is necessary, they alone ignore the contextual interactions in human environments [7]. We take a data driven approach and learn a context-rich cost over the trajectories from the preferences shown by non-expert users. In this work we model user preferences arising during human activities. Humans constantly engage in activities with their surroundings – watching TV or listening to music, etc. – during which they prefer minimal interruption from external agents that share their environment. For example, a robot that blocks the view of a human watching TV is not a desirable social agent. How can a robot learn such preferences and context? This problem is further challenging because human environments are unstructured, and as shown in Fig. 1 an environment can have multiple human activities happening simultaneously. Therefore generalizing the learned model to new environments is a key challenge. We formulate the problem as learning to ground each human activity to a spatial distribution signifying regions crucial to the activity. We refer to these spatial distributions A. Jain, D. Das, J. K. Gupta and A. Saxena are with the Department of Computer Science, Cornell University, USA. ashesh@cs.cornell.edu, dd367@cornell.edu, mail@rejuvyesh.com, asaxena@cs.cornell.edu Fig. 1: Various human activities with the objects in the environment affect how a robot should navigate in the environment. The ﬁgure shows an environment with multiple human activities: (1) two humans interacting, (2) watching, (3) walking, (4) working, (5) sitting, and (6) reaching for a lamp. We learn a spatial distribution for each activity, and use it to build a cost map (aka planning affordance map) for the complete environment. Using the cost map, the robot plans a preferred trajectory in the environment. as planning affordances1 and parameterize the cost function using these distributions. Our affordance representation is different by relating to the object’s functionality, unlike previous works which have an object centric view. The commonly studied discrete representation of affordances [9], [10], [11], [12] are of limited use in planning trajectories. For example, a TV has a watchable affordance and undergoes a watching activity, however these labels themselves are not informative enough to convey to the robot that it should not move between the user and the TV. The grounded representation we propose in this work is more useful for planning tasks than the discrete representations. To generalize well across diverse environments we develop a crowdsourcing web-service PlanIt to collect large-scale preference data. On',\n",
       " '1506.06558': 'The Interference Channel (IC) has attracted a lot of attention recently due its practical relevance in wireless networks. The central question is how to deal cleverly with the interference instead of simply avoiding it or treating it as noise, as currently done in commercial networks. The breakthrough idea of Interference Alignment (IA) was presented in [4] as a way to “consolidate” interference in a lower dimensional space of the received space at each receiver. IA was shown to achieve the optimal sum degrees of freedom (DoF) for the IC for any number of active users and for the ﬁrst time showed that Gaussian IC are not intrinsically interference limited [4]. IA has found many applications beyond the classical IC setting. For example, relays can play an important role in IA-based scheme. In [24], it was shown that joint beam-forming between the relay and the transmitters makes IA feasible without channel state information at the transmitters. In multi-hop scenarios [12], the relays can cooperate to perform interference neutralization at the receivers. In spite of these improvements brought by relays, it is known that conventional (strictly causal) relaying can not provide DoF gain for fully connected ICs with generic channel matrices [5]. However, this is not true for a novel type of relay called Instantaneous Relay (IR). IRs were ﬁrst introduced in [10] as a model where the signal transmitted by the relay in channel use t can depend on all received signals up to and including that at channel use t. This is in contrast to conventional relaying, where the transmitted signal can depend on previously received signals in a strictly causal fashion. IRs have been shown recently to be a special case of channels with in-block memory [16], which generalize classical memoryless networks. In channel with a single transmitter-receiver pair, the rate achieved with an IR is in general larger than the one achieved with a conventional relay [1]. For the two-user IC with an IR, outer bounds were derived in [6] and shown to be achievable by amplify-forward relaying in a non-asymptotic way for strong and very strong interference scenarios. In [14], the uninformed non-cooperative (where the transmitter-receiver pairs are not aware of the existence of an IR) and the informed cooperative K-user IC with an IR were studied. It was shown that the IR improves the achievable rate region and provides better user-fairness in both scenarios compared to the classical IC setting. In [3] general networks with IRs were investigated. Depending on whether the IRs have their own messages or not, two different cut-set bounds were proposed. The bounds were proved to October 15, 2018 DRAFT  3 be tight for the causal vector Gaussian two-way relay channel and the causal vector Gaussian relay channel. Besides rate, IRs markedly differ from conventional relays as the can provide strict DoF gain compared to the case of absence of relays. The interference aligned neutralization scheme proposed in',\n",
       " '1610.09996': 'Reading comprehension-based question answering (RCQA) is the task of answering a question with a chunk of text taken from related document(s). A variety of neural models have been proposed recently either for extracting a single entity or a single token as an answer from a given text (Hermann et al. 2015; Kadlec et al. 2016; Trischler et al. 2016b; Dhingra et al. 2016; Chen, Bolton, and Manning 2016; Sordoni, Bachman, and Bengio 2016; Cui et al. 2016a); or for selecting the correct answer by ranking a small set of human-provided candidates (Yin, Ebert, and Sch¨utze 2016; Trischler et al. 2016a). In both cases, an answer boundary is either easy to determine or already given. Different from the above two assumptions for RCQA, in the real-world QA scenario, people may ask questions about both entities (factoid) and non-entities such as explanations and reasons (non-factoid) (see Table 1 for examples). In this regard, RCQA has the potential to complement other QA approaches that leverage structured data (e.g., knowledge bases) for both the above question types. This is because RCQA can exploit the textual evidences to ensure increased answer coverage, which is particularly helpful for non-factoid answers. However, it is also challenging for RCQA to identify answer in arbitrary position ∗Both authors contribute equally Copyright c⃝2017, Association for the Advancement of Artiﬁcial Intelligence (www.aaai.org). All rights reserved. in the passage with arbitrary length, especially for nonfactoid answers which might be clauses or sentences. As a result, apart from a few exceptions (Rajpurkar et al. 2016; Wang and Jiang 2016), this research direction has not been fully explored yet. Compared to the relatively easier RC task of predicting single tokens/entities1, predicting answers of arbitrary lengths and positions signiﬁcantly increase the search space complexity: the number of possible candidates to consider is in the order of O(n2), where n is the number of passage words. In contrast, for previous works in which answers are single tokens/entities or from candidate lists, the complexity is in O(n) or the size of candidate lists l (usually l ≤5), respectively. To address the above complexity, Rajpurkar et al. (2016) used a two-step chunk-and-rank approach that employs a rule-based algorithm to extract answer candidates from a passage, followed by a ranking approach with hand-crafted features to select the best answer. The rule-based chunking approach suffered from low coverage (≈70% recall of answer chunks) that cannot be improved during training; and candidate ranking performance depends greatly on the quality of the hand-crafted features. More recently, Wang and Jiang (2016) proposed two endto-end neural network models, one of which chunks a candidate answer by predicting the answer’s two boundary indices and the other classiﬁes each passage word into answer/notanswer. Both models improved signiﬁcantly over the method proposed by',\n",
       " '1107.3253': 'Irregular low-density parity-check (LDPC) codes can be carefully designed to achieve the capacity of the binary erasure channel (BEC) [1] and closely approach the capacity of general binary-input symmetricoutput memoryless (BMS) channels [2] under belief-propagation (BP) decoding. LDPC convolutional codes, which were introduced in [3] and shown to have excellent BP thresholds in [4], [5], have recently been observed to universally approach the capacity of various channels. The fundamental mechanism behind this is explained well in [6], where it is proven analytically for the BEC that the BP threshold of a particular spatially-coupled ensemble converges to the maximum a-posteriori (MAP) threshold of the underlying ensemble. A similar result was also observed independently in [7] and stated as a conjecture. Such a phenomenon is now called “threshold saturation via spatial coupling” and has also been empirically observed for general BMS channels [8]. In fact, threshold saturation seems to be quite general and has now been observed in a wide range of problems, e.g., see [9], [10], [11], [12], [13], [14]1. In the realm of channels with memory and particularly intersymbol interference (ISI) channels, the capacity may not be achievable via equiprobable signaling. For linear codes, a popular practice is to compare instead with the symmetric information rate (SIR), which is also known as Ci.u.d. [15], because this the rate is achievable by random linear codes with maximum-likelihood (ML) decoding. A numerical method for tightly estimating the SIR of ﬁnite-state channels in general was ﬁrst proposed in [16], [17]. For LDPC codes over ISI channels, a joint iterative BP decoder that operates on a large graph representing both the channel and the code constraints [18], [15] can perform quite well and even approach the SIR [19], [20]. Progress has been made on the design of SIR-approaching irregular LDPC codes for some speciﬁc ISI channels [19], [21], [22], [23], [20]. However, channel parameters must be known at the transmitter for such designs and therefore universality across ISI channels appears difﬁcult to achieve. Since spatially-coupled codes and the threshold saturation effect have now shown beneﬁts in many communication problems, it is quite natural to consider them as a potential candidate to universally approach the SIR of ISI channels with low decoding complexity. In fact, the combination of spatiallycoupled codes and ISI channels was recently considered by Kudekar and Kasai [11] for the simple dicode 1To be precise, the papers [9], [11], [12] only observe the threshold saturation effect indirectly because the considered EXIT-like curves provide no direct information about the MAP threshold of the underlying ensemble. October 22, 2019 DRAFT  3 erasure channel (DEC) from [24], [20]. They provided a numerical evidence that the joint BP threshold of the spatially coupled codes can approach the SIR over the DEC (by increasing the degrees while keeping the rate ﬁxed). Also, they outlined a tentative proof approach for the threshold saturation following the ideas in [6]. However, the EXIT',\n",
       " '1411.7632': 'In this paper, we study a fundamental performance limitation of zero-delay communication systems using the sequential rate-distortion (SRD) theory. Suppose that xt is an Rn-valued discrete time random process with known statistical properties. At every time step, the encoder observes a realization of the source xt and generates a binary sequence bt ∈{0, 1}lt of length lt, which is transmitted to the decoder. The decoder produces an estimation zt of xt based on the messages bt received up to time t. Both encoder and decoder have inﬁnite memories of the past. A zero-delay communication system is determined by a selected encoder-decoder pair, whose performance is analyzed in the trade-off between the rate (viz. the average number of bits that must be transmitted per time step) and the distortion (viz. the discrepancy between the source signal xt and the reproduced signal zt). The region in the ratedistortion plane achievable by a zero-delay communication system is referred to as the zero-delay rate-distortion region.1 The standard rate-distortion region identiﬁed by Shannon only provides a conservative outer bound of the zero-delay rate-distortion region. This is because, in general, achieving the standard rate-distortion region requires the use of anticipative (non-causal) codes (e.g., [1, Theorem 10.2.1]). It is well known that the standard rate-distortion region can be T. Tanaka is with ACCESS Linnaeus Center, KTH Royal Institute of Technology, Stockholm, 10044 Sweden. P. A. Parrilo, and S. K. Mitter are with the Laboratory for Information and Decision Systems, Massachusetts Institute of Technology, Cambridge, MA, 02139 USA. K.-K. K. Kim is with the Electronic Control Development Team of Hyundai Motor Company (HMC) Research & Development Division in South Korea. 1Formal deﬁnition of the zero-delay rate-distortion region is given in Section VI-A. expressed by the rate-distortion function2 for general sources. In contrast, description of the zero-delay rate-distortion region requires more case-dependent knowledge of the optimal source coding schemes. For scalar memoryless sources, it is shown that the optimal performance of zero-delay codes is achievable by a scalar quantizer [2]. Witsenhausen [3] showed that for the k-th order Markov sources, there exists an optimal zerodelay quantizer with memory structure of order k. Neuhoff and Gilbert considered entropy-coded quantizers within the class of causal source codes [4], and showed that for memoryless sources, the optimal performance is achievable by timesharing memoryless codes. This result is extended to sources with memory in [5]. An optimal memory structure of zerodelay quantizers for partially observable Markov processes on abstract (Polish) spaces is identiﬁed in [6]. The rate of ﬁnitedelay source codes for general sources and general distortion measures is analyzed in [7]. Zero-delay or ﬁnite-delay joint source-channel coding problems have also been studied in the literature; [8]–[11] to name a few. In [12], [13], Tatikonda et al. studied the zero',\n",
       " '1801.05104': 'The continuously increasing demand for high-speed data transfer over the air imposes severe burdens on current wireless networks, and thus calls for the design of extremely efﬁcient transmission solutions. Moreover, the scarcity of the radio resources raises extra challenges on the next generation wireless networks to meet the expected quality of service requirements by end-users. To address these issues, a revolution in the network’s architecture design is required. The move towards dense cellular architectures solved a component of the problem but raised more problems regarding interference management. The solution was recently proposed in [1] which gave birth to cloud radio access networks (CRANs) [2], [3] in which multiple remote radio heads (RRHs) are coordinated in a centralized fashion by a computing unit known as the cloud. With this new architecture, there is a need to design scheduling schemes of RRHs and their associations to users in order to fully utilize its beneﬁts. Without cloud coordination, RRH scheduling in heterogeneous networks was performed using a preassigned association of mobile users and RRHs, e.g., proportional fair scheduling [4], [5]. Recent works on CRANs, e.g., [6], [7], suggested scheduling users to RRHs in a coordinated fashion at the cloud so as to maximize the network total ergodic capacity. These works, however, view the network solely from the physical layer, e.g., [8]. Therefore, each radio resource block (RRB) serves only one user in each transmission instant. Clearly, this does not take into consideration upper layer facts. For instance, it has been recently found that users tend to have a common interest in downloading popular ﬁles (especially videos) within a small interval of time, thus creating a pool of side information in the network. This paper proposes to incorporate network coding (NC) in the scheduling decisions of RRHs and RRBs in order to utilize this side information in enhancing the system throughput when other users request to download these same ﬁles. NC was introduced [9] as a new paradigm that performs ﬂow mixing (i.e., coding) at intermediate nodes in the network. It has demonstrated great beneﬁts to improve the performance for numerous network metrics such as throughput improvement and delay minimization [10]. A particularly interesting sub-class of NC is the instantly decodable network coding (IDNC). Indeed, thanks to its instant decodability properties and straightforward operations to encode/decode ﬁles, IDNC was the subject of numerous studies, e.g., [11]-[14]. IDNC uses XOR-based operations for encoding at the transmitters and decoding at the receivers. These simple operations are well-adapted to small and battery-powered devices. Different studies on IDNC revealed various code construction schemes with excellent potential in minimizing various system parameters for different applications and network settings. For example, while the authors in [11] suggest minimizing the total transmission time, i.e., the completion time, reference [12] optimizes the decoding delay. Similarly, the authors in [13] introduce a delay-based framework to reduce the completion time. Recently, IDNC was employed in a heterogeneous network setting to minimize the completion',\n",
       " '1101.5317': 'The average binary error probabilities (ABEP) and average capacity (AC) are important performance metrics of wireless communication systems operating over fading channels. As such, considerable efforts  IEEE TRANSACTIONS ON COMMUNICATIONS, VOL. X, NO. XX, JAN. 2011 2 have been devoted so far to develop analytical tools/frameworks to evaluate these two performance metrics [1, and the references therein]. However, and to the best authors’ knowledge, these tools/frameworks were developed separately and the computation of these two performance metrics was viewed as two independent problems. For instance, based on Craig’s representation of the complementary error function, a uniﬁed moment generating function (MGF)-based approach was developed to compute the ABEP of a wide variety of modulation techniques over generalized fading [1, and the references therein]. More recently, other MGF-based approaches [2]–[4] were also proposed for the capacity calculation of wireless channels subject to generalized fading. In contrast, this paper presents a novel MGF-based uniﬁed expression for the exact evaluation of both the ABEP and AC of single an multiple links generalized faded channels. The paper introduces also the hyper-Fox’s H distribution as a versatile fading model including a variety of well-known models as special cases. With these two unifying frameworks at hand, we propose new generic expressions for the ABEP and AC with and without diversity reception. We also present some selected numerical examples to validate our newly derived results. The remainder of this paper is organized as follows. In Section II, a uniﬁed performance measure analysis of diversity receivers over additive white Gaussian noise (AWGN) channels is introduced and some key results are presented. In Section III, new results for single link and multiple link reception are presented and applied to the newly proposed unifying hyper-Fox’s H fading model. Finally, the main results are summarized and some conclusions are drawn in the last section. II. UNIFIED CONDITIONAL PERFORMANCE EXPRESSION A compact form for the conditional bit error probability (BEP) PBEP (γend) for a certain value of instantaneous SNR γend for different binary modulations was proposed by Wojnar in [5, Eq. (13)] as PBEP (γend) = Γ (b, aγend) 2Γ (b) , a, b ∈ \\x1a 1, 1 2 \\x1b , (1) where a depends on the type of modulation (1 2 for orthogonal frequency shift keying (FSK), 1 for antipodal phase shift keying (PSK)), b depends on the type of detection (1 2 for coherent, 1 for non-coherent), and Γ (·, ·) denotes the complementary incomplete Gamma function [6, Eq. (6.5.3)]. In the following theorem, we introduce an alternative representation of (1) using the incomplete beta function. Theorem 1 (Uniﬁed BEP Expression Using the Incomplete Beta Function). An alternative representation  IEEE TRANSACTIONS ON COMMUNICATIONS, VOL. X, NO. XX, JAN. 2011 3 of the compact form of the conditional bit error probability PBEP (γend) represented in (1) is given by PBEP (γend) = 1 2 −exp (−iπb) 2Γ (b) lim d→∞d bB \\x10 −a dγend; b, 1 −d \\x11 , (2) where the parameters a and b depend on',\n",
       " '1805.09045': 'An important challenge for reinforcement learning is to balance exploration and exploitation. There have been many strategic exploration algorithms (Auer and Ortner, 2007; Strehl et al., 2012; Dann and Brunskill, 2015), yet many of the recent successes in deep reinforcement learning rely on algorithms with simple exploration mechanisms. While some of these approaches also require many samples, this still highlights an important question: when is exploration easy? In particular, we consider when a simple approach of random exploration followed by greedy exploitation can enable a strong eﬃciency criteria, Probably Approximately Correct (PAC): that on all but a number of sample that scales as a polynomial function of the domain, the algorithm will take near-optimal actions. Random exploration followed by greedy exploitation approach is related to popular e-greedy methods: it can be viewed as a particular thresholding decay schedule in e-greedy methods: e is initially set to 1, and then dropped to 0 after a ﬁxed number of steps. This simpliﬁcation enables us to focus on when random exploration can still be eﬃcient, and there are many domains where having a ﬁxed budget for exploration is reasonable where our analysis will directly apply. Most prior work on formal analysis of exploration before exploitation approach (Langford and Zhang, 2008; Kearns and Singh, 2002) focused on strategic exploration during the exploration phase. In contrast, to our knowledge our work is the ﬁrst to consider under what c⃝2018 Yao Liu and Emma Brunskill. License: CC-BY 4.0, see https://creativecommons.org/licenses/by/4.0/. arXiv:1805.09045v4  [cs.LG]  17 Apr 2019  Liu and Brunskill conditions random action selection during the exploration phase might still be suﬃcient to enable provably sample eﬃcient reinforcement learning. Some restrictions on the decision process are needed: there exist challenging Markov decision processes where relying on random exploration will require an exponential bound (in the MDP parameters) on the sample complexity, in contrast to the polynomial dependence required for the algorithm to be PAC. In some such domains, like the combination lock setting(Li, 2012; Whitehead, 2014)), any greedy actions will (for a very long time) cause the agent to undo productive exploration towards ﬁnding the optimal policy, and therefore ϵgreedy (for any ϵ) will be no better and likely worse than random exploration, and therefore will also not have PAC performance. Rather than focusing on new algorithmic contributions, in this paper we seek to explore suﬃcient conditions on the domains that ensure that random exploration then exploitation methods will quickly lead to high performance, as formalized by satisfying the PAC criteria. Our work is related to recent work (Jiang et al., 2016) which considered structural properties of Markov decision processes that bound the loss when performing shallow planning: in contrast to their work, our work focused on the structural properties of MDPs that enable simple exploration to quickly enable good performance during learning. As our main contribution, we introduce new structural properties of MDPs, and prove that',\n",
       " '1511.07404': 'Imagine a hypothetical person who has never encountered the game of billiards. While this person may not be very adept at playing the game, he would still be capable of inferring the direction in which the cue ball needs to be hit to displace the target ball to a desired location. How can this person make such an inference without any prior billiards-speciﬁc experience? One explanation is that humans are aware of the laws of physics, and a strategy for playing billiards can be inferred from knowledge about dynamics of bouncing objects. However, humans do not appear to consciously solve Newton’s equations of motion, but rather have an intuitive understanding of how their actions affect the world. In the speciﬁc example of billiards, humans can imagine the trajectory that the ball would follow when a force is applied, and how the trajectory of ball would change when it hits the side of the billiards table or another ball. We term models that can enable the agents to visually anticipate the future states of the world as visual predictive models of physics. A visual predictive model of physics equips an agent with the ability to generate potential future states of the world in response to an action without actually performing that action (“visual imagination”). Such visual imagination can be thought of as running an internal simulation of the external world. By running multiple internal simulations to imagine the effects of different actions, the agent can perform planning, choosing the action with the best outcome and executing it in the real world. The idea of using internal models for planning actions is well known in the control literature (Mayne, 2014). However, the question of how such models can be learned from raw visual input has received comparatively little attention, particularly in situations where the external world can change signiﬁcantly, requiring generalization to a variety of environments and situations. Previous methods have addressed the question of learning models, including visual models, of the agent’s own body (Watter et al., 2015; Lillicrap et al., 2015). However, when performing actions in complex environments, models of both the agent and the external world are required. The external world can exhibit considerably more variation than the agent itself, and therefore such models must generalize more broadly. This makes problem of modelling the environment substantially harder than modelling the agent itself. ∗equal contribution 1 arXiv:1511.07404v3  [cs.CV]  19 Jan 2016  Under review as a conference paper at ICLR 2016 neural\\t\\r \\xa0\\t\\r \\xa0 network\\t\\r \\xa0 visual\\t\\r \\xa0stream\\t\\r \\xa0 next\\t\\r \\xa0frame\\t\\r \\xa0 force\\t\\r \\xa0ﬁeld\\t\\r \\xa0stream\\t\\r \\xa0 neural\\t\\r \\xa0\\t\\r \\xa0 network\\t\\r \\xa0 F` 1 · · · F` t u` t+1 displacements\\t\\r \\xa0 visual\\t\\r \\xa0stream\\t\\r \\xa0centered\\t\\r \\xa0 on\\t\\r \\xa0the\\t\\r \\xa0lth\\t\\r \\xa0object\\t\\r \\xa0\\t\\r \\xa0 force\\t\\r \\xa0stream\\t\\r \\xa0on\\t\\r \\xa0the\\t\\r \\xa0lth\\t\\r \\xa0 object\\t\\r \\xa0 8` 2 1 · · · L next\\t\\r \\xa0frame\\t\\r \\xa0 Figure 1: Frame-centric versus object-centric prediction. Left: Frame-centric model predicts takes as input the the image of the the entire billiards and forces applied by the agent to make predictions about the future. Right: Object-centric model predicts the future states',\n",
       " '1804.05296': 'Over the past seven years, deep learning has transformed computer vision and has been implemented in scores of consumer-facing products. Many are excited that these approaches will continue to expand in scope and that new tools and products will be improved through the use of deep learning. One particularly exciting application area of deep learning has been in clinical medicine. There are , 2019. ACM ISBN 978-x-xxxx-xxxx-x/YY/MM...$15.00 https://doi.org/10.1145/nnnnnnn.nnnnnnn many recent high-profile examples of deep learning achieving parity with human physicians on tasks in radiology [21, 56], pathology [9], dermatology [19], and opthalmology [25]. In some instances, the performance of these algorithms exceed the capabilities of most individual physicians in head-to-head comparisons. This has lead some to speculate that entire specialties in medical imaging, such as radiology and pathology, may be radically reshaped [27] or cease to exist entirely. Furthermore, on April 11, 2018, an important step was taken towards this future: the U.S. Food and Drug Administration announced the approval of the first computer vision algorithm that can be utilized for medical diagnosis without the input of a human clinician [3]. In parallel to this progress in medical deep learning, the discovery of so-called ‘adversarial examples’ has exposed vulnerabilities in even state-of-the-art learning systems [22]. Adversarial examples – inputs engineered to cause misclassification – have quickly become one of the most popular areas of research in the machine learning community [41, 42, 49, 61]. While much of the interest with adversarial examples has stemmed from their ability to shed light on possible limitations of current deep learning methods, adversarial examples have also received attention because of the cybersecurity threats they may pose for deploying these algorithms in both virtual and physical settings [7, 12, 24, 32, 39, 49]. Given the enormous costs of healthcare in the US, it may seem prudent to take the expensive human ‘out of the loop’ and replace him or her with an extremely cheap and highly accurate deep learning algorithm. This seems especially tempting given a recent study’s finding that physician and nursing pay is one of the key drivers of high costs in the US relative to other developed countries [46]. However, there is an under-appreciated downside to widespread automation of medical imaging tasks given the current vulnerabilities of these algorithms. If we seriously consider taking the human doctor completely ‘out of the loop’ (which now has legal sanction in at least one setting via the FDA, with many more to likely follow), we are forced to also consider how adversarial attacks may present new opportunities for fraud and harm. In fact, even with a human in the loop, any clinical system that leverages a machine learning algorithm for diagnosis, decision-making, or reimbursement could be manipulated with adversarial examples. In this paper, we extend previous results on adversarial examples to three medical deep learning systems',\n",
       " '1511.00418': 'Random access protocols based on slotted ALOHA [1], [2] are widely used in wireless communication systems in order to support uncoordinated transmissions from a large number of users. These protocols offer low latency in scenarios in which each user is only intermittently transmitting. In slotted ALOHA, time is divided into slots and users select a single slot at random for transmission. If two packets are transmitted in the same slot, the respective receiver observes a collision and the colliding packets are considered lost, which signiﬁcantly limits the efﬁciency of slotted ALOHA. In [3], it was suggested to repeat packets twice in randomly selected slots, thus slightly increasing the probability of a successful transmission. In [4], it was further suggested to utilize successive interference cancellation (SIC), as explained in the following. The system operates in frames, where each This research was supported in part by the Swedish Research Council, under Grants No. 2011-5950 and 2011-5961, by the Ericsson’s Research Foundation, by Chalmers Antenna Systems Excellence Center in the project ‘Antenna Systems for V2X Communication’, and by the European Research Council, under Grant No. 258418 (COOPNET). The work of P. Popovski has been in part supported by the European Research Council (ERC Consolidator Grant No. 648382 WILLOW) within the Horizon 2020 Program. M. Ivanov, F. Br¨annstr¨om, and A. Graell i Amat are with the Department of Signals and Systems, Chalmers University of Technology, SE-41296 Gothenburg, Sweden (e-mail: {mikhail.ivanov, fredrik.brannstrom, alexandre.graell}@chalmers.se). Petar Popovski is with the Department of Electronic Systems, Aalborg University, 9220 Aalborg, Denmark (e-mail: petarp@es.aau.dk). Parts of this work were presented at the IEEE International Conference on Communications (ICC), London, UK, June 2015. frame is a periodically occurring structure that consists of a predeﬁned number of slots. All users are assumed to be frame-synchronized. Each user transmits multiple copies (two or three) of its packet in a single frame, each copy in a different slot. Each copy of a packet contains pointers to all other copies of a packet. Once one copy is successfully received, the positions of the other copies are obtained and their interference in the respective slots is subtracted. Exploiting SIC in [4] provides signiﬁcant performance improvement with respect to slotted ALOHA. SIC is also used in many other applications, e.g., [5], [6] to combat the hidden terminal problem in wireless networks, or in [7], where it is combined with network coding. In [8], it was proposed to use different repetition factors for different users. To that end, users choose their repetition factor by drawing a random number according to a predeﬁned distribution. It was recognized in [8] that SIC for the described protocol is similar to decoding of graph-based codes over the binary erasure channel. Hence, the theory of codes on graphs can be used to design good distributions. In [9], it was shown that using the so-called soliton distribution allows transmittin',\n",
       " '1411.1045': 'FAILED',\n",
       " '1808.05054': '1 1.1. Background and Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . 2 1.2. Problem Statement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 1.2.1. Research Question . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 1.2.2. Research Methodology . . . . . . . . . . . . . . . . . . . . . . . . . . 6 1.3. Thesis Structure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7 2. Preliminaries 8 2.1. Machine Learning and Statistical Foundations . . . . . . . . . . . . . . . . . 8 2.1.1. Supervised Machine Learning . . . . . . . . . . . . . . . . . . . . . . 9 2.1.1.1. Extreme Gradient Boosting (XGB) . . . . . . . . . . . . . 10 2.1.1.2. Multilayer Perceptron (MLP) . . . . . . . . . . . . . . . . . 12 2.1.1.3. Excursus: Long Short-Term Memory Network (LSTM) . . 14 2.1.2. Unsupervised Machine Learning . . . . . . . . . . . . . . . . . . . . 15 2.1.2.1. Agglomerative Hierarchical Clustering (AGNES) . . . . . . 16 2.1.2.2. K-Means Clustering . . . . . . . . . . . . . . . . . . . . . . 17 2.1.3. Statistical Measures . . . . . . . . . . . . . . . . . . . . . . . . . . . 19 2.1.3.1. Jaccard Similarity Coeﬃcient . . . . . . . . . . . . . . . . . 19 2.1.3.2. Spearman’s Rank Correlation Coeﬃcient . . . . . . . . . . 20 2.2. The Role of Interpretability in Machine Learning . . . . . . . . . . . . . . . 21 2.2.1. The Value of Interpretability . . . . . . . . . . . . . . . . . . . . . . 21 2.2.1.1. Value in the Data Mining Process . . . . . . . . . . . . . . 23 2.2.1.2. Ethical and Societal Concerns . . . . . . . . . . . . . . . . 24 2.2.2. The Scope of Interpretability . . . . . . . . . . . . . . . . . . . . . . 25 2.2.2.1. Algorithm Interpretability . . . . . . . . . . . . . . . . . . 25 2.2.2.2. Global Model Interpretability . . . . . . . . . . . . . . . . . 26 2.2.2.3. Local Model Interpretability . . . . . . . . . . . . . . . . . 27 2.2.3. Evaluating Interpretability Quality . . . . . . . . . . . . . . . . . . . 28 2.2.3.1. Goals of Interpretability . . . . . . . . . . . . . . . . . . . . 29 vii  viii Contents 2.3. Explanations as Tools to Establish Interpretability . . . . . . . . . . . . . . 30 2.3.1. Recipe for a ”good” Human-Style Explanation . . . . . . . . . . . . . 31 2.3.2. Interpretable Models and Explanations . . . . . . . . . . . . . . . . 33 2.3.2.1. Linear Regression . . . . . . . . . . . . . . . . . . . . . . . 34 2.3.2.2. Decision Tree . . . . . . . . . . . . . . . . . . . . . . . . . . 36 2.3.3. Explanation Methods . . . . . . . . . . . . . . . . . . . . . . . . . . 38 2.3.3.1. Model-Dependent Explanation Methods . . . . . . . . . . . 39 2.3.3.2. Model-Agnostic Explanation Methods . . . . . . . . . . . . 39 2.4. Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43 3. Axiomatic Explanation Consistency 46 3.1. Regression Case . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48 3.2. Classiﬁcation Case . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50 3.3. Explanation Consistency Veriﬁcation with Big Data . . . . . . . . . . . . . 51 4. Experiments and Evaluation 53 4.1. Datasets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53 4.1.1. Seattle House Prices (SHP) . . . . . . . . . . . . . . . . . . . . . . . 53 4.1.2. Machine Component Failures (MCF) . . . . . . . . . . . . . . . . . . 55 4.2. Prediction Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57 4.2.1. Model Fitting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57 4.2.2. Model Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59 4.3. Application of Explanation Methods . . . . . . . . . . . . . . . . . . . . . . 64 4.4. Evaluation of the Explanation Consistency . . . . . . . . . . . . . . . . . . 65 4.4.1. Regression Case – SHP Dataset . . . . . . . . . . . . . . . . . . . . . 65 4.4.2. Classiﬁcation Case – MCF Dataset . . . . . . . . . . . . . . . . . . . 67 4.4.3. Strengths and Weaknesses of LIME and SHAP . . . . . . . . . . . . 70 5. Discussion and Conclusion 73 5.1. Results Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73 5.2. Limitations and Future Work . . . . . . . . . . . . . . . . . . . . . . . . . . 75 5.3. Contribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76 5.4. Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76 6. Declaration 78 Appendix 79 A. LIME: Formal Model Deﬁnition . . . . . . . . . . . . . . . . . . . . . . . . . 79 B. SHAP: Formal Deﬁnition of the Shapley Values . . . . . . . . . . . . . . . . 79 C. Codebase and Datasets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80 References 81 viii  List of Figures 1.1. Venn Diagram of AI, ML, RL and DL [based on Goodfellow, Bengio, and Courville (2016)] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 1.2. Black Box ML Model without vs with an Explanation Method . . . . . . . 3 1.3. Research Methodology: an Iterative and Sequential Process . . . . . . . . . 6 2.1. Tree Ensembles: Bagging vs Boosting . . . . . . . . . . . . . . . . . . . . . 11 2.2. Multilayer Perceptron: Architecture',\n",
       " '1806.04009': 'Hourglass networks such as the U-Net [7] and V-Net [6] are popular neural architectures for medical image segmentation and counting problems. Typical instances of hourglass networks contain shortcut connections between mirroring layers. These shortcut connections improve the performance and it is hypothesized that this is due to mitigating effects on the vanishing gradient problem and the ability of the model to combine feature maps from earlier and later layers. We propose a method for not only combining feature maps of mirroring layers but also feature maps of layers with different spatial dimensions. For instance, the method enables the integration of the bottleneck feature map with those of the reconstruction layers. The proposed approach is applicable to any hourglass architecture. We evaluated the contextual hourglass networks on image segmentation and object counting problems in the medical domain. We achieve competitive results outperforming popular hourglass networks by up to 17 percentage points. 2 Contextual Convolutions Intuitively, hourglass networks have two stages. In the ﬁrst stage, an image is encoded with each convolutional layer into a more compressed and spatially smaller representation. During this encoding process, the scope of the receptive ﬁeld increases. We refer to the most compressed representation located at the center of the network as the bottleneck representation. In the second stage, every transpose convolutional layer decodes an increasingly less compressed and spatially larger representation beginning with the bottleneck. This is often referred to as the decoding stage. In several hourglass type networks such as the U-Net, every layer from the second stage is connected to its mirroring layer in the ﬁrst stage. These shortcut connections perform some aggregation operation such as a summation or concatenation between the respective feature maps. Figure 1(a) illustrates a simple hourglass architecture with two layers in the ﬁrst stage, a bottleneck representation, and two layers in the second stage. The shortcut connections between mirroring layers are indicated with dashed lines. The aggregation operation is a concatenation. In the proposed contextual hourglass networks, there are additional shortcut connections between layers of differing spatial dimensions. This has several advantages. First, it allows to incorporate the bottleneck representation in later spatially more extensive layers – the bottleneck representation provides a context for the decoding layers. Second, it facilitates a more direct ﬂow of gradients from the output layer to the more compressed representations such as the bottleneck. The main contribution of this paper is a mechanism to spatially tie two different ﬁlter banks and their movement over two feature maps of differing size. Let T1 be a feature map of dimension w1 × h1 × d1, that is, a feature map with width w1, height h1 and with d1 channels. Moreover, let T2 be a feature map of dimension w2 × h2 × d2 with w2 > w1 and h2 > h1. Here, T1 is a more compressed feature map of an earlier layer. T2 is a less compressed feature map, with larger spatial extent, and the output of a later layer in an hourglass type network. To create',\n",
       " '1505.03581': 'FAILED',\n",
       " '1901.02404': 'Generating images from text is a challenging task and has many applications in computer vision. Recent works have shown that Generative Adversarial Networks (GAN) are effective in synthesizing high-quality, realistic images from datasets with low variability and low-resolution [8, 3]. Further work also showed that given a text description, conditional GANs (cGAN) [5] generate convincing images related directly to the text content [9]. All recent text to image synthesis cGANs used a short visual description of the image, with low complexity and a consistent pattern of descriptions, and the images themselves had low variability. E.g. Zhange et al. [15, 16] used the CUB dataset [14] containing 200 bird species with 11,788 images and corresponding description and Oxford102 dataset [6] containing 8,189 images of ﬂowers from 102 different categories (see Figure 1). Recently the dataset recipe1M, containing 800K pairs of recipes and their corresponding images, was published as part of [11]. In comparison to the CUB and Oxford-102 datasets, this dataset has a high variability due to the variety of food categories and subcategories. Moreover, the text related to the image is complex. It consists of 2 sections (ingredients and instructions), that together might contain tens of lines (e.g. Figure 2). Figure 1. Image samples from CUB and Oxford-102 datasets, and their corresponding text descriptions We propose a novel task of synthesizing images from long text, that is related to the image but does not contain visual description of it. Speciﬁcally, We propose a baseline to this task by combining the state-of-the-art Stacked Generative Adversarial Network [15] and the two proposals of recipe embeddings computed in im2recipe [11] to generate food images conditioned on their recipes. We also present extensive qualitative and quantitative experiments using hu1 arXiv:1901.02404v1  [cs.CV]  8 Jan 2019  man ranking, MS-SSIM [13] and inception scores [10], to compare the effectiveness of the two embedding methods. Our code is available at https://github.com/netanelyo/Recipe2ImageGAN. 2. Related Work Generating high-resolution images conditioned on text descriptions is a fundamental problem in computer vision. This problem is being studied extensively and various approaches were suggested to tackle it. Deep generative models, such as [16, 15, 12, 17], achieved tremendous progress in this domain. In order to get high-resolution images they used multi-stage GANs, where each stage corrects defects and adds details w.r.t. the previous stage. In [12], Xu et al. use Deep Attentional Multimodal Similarity Model (DAMSM) for text embedding. DAMSM learns two neural networks that map sub regions of the image and words of the sentence to a common semantic space. Thus, measures the image-text similarity at the word level to compute a ﬁne-grained loss for image generation. 3. Learning Embeddings Our cGAN uses the embedding of the entire recipe (except for its title) as a condition. To generate that embedding we leverage',\n",
       " '1312.7557': 'Retinal angiography images are extensively used in the  diagnosis of important diseases such as hypertension,  arteriosclerosis and diabetes. Furthermore, there has been an  increasing inclination for personal authentication techniques  by using human biometric features Retinal is one of these  features. One of the most important diseases that causes blood  vessels structure to change is diabetic retinopathy that leads  to adults blindness. To overcome this problem specialist  analysis is required [1].valuable applications have been  described in [2, 3] for identification of a variety of systematic  diseases such as diabetes and hypertension. Several  supervised [2-4] and unsupervised [5-7] vessel segmentation  methods have already been proposed and implemented. In  the literature, several techniques have been reported for  blood vessel segmentation and diagnosis of such diseases [8– 13]. These methods generally can be classified into three  categories: (1) kernel-based, (2) tracking based and (3)  classifier-based methods. Kernel-based methods convolve  the image with a kernel based on a predefined model [14,  15]. Methods based on classifier include two steps: first, a  segmentation of the image and then a classification of  regions. In tracking based methods vessels edge are followed  using local information. There are also other methods in which two of above methods are combined [16, 18]. For image analysis,  detecting the vessels means generating a binary mask that  helps us to label pixels as vessel or background. The goal is  to find and detect more details, at the same time to avoid  false positives and, ideally, to keep vessel connectivity. It  should be noticed that many clinical studies do not use fine  vessels, just taking measurements on main ones in area  around optic disc [19, 20, 21]. Traditional approaches to retinal vessel segmentation  mostly use line detection and tracking based methods [32].Since line detection methods are reliant and do not have  acceptable result in all cases [11]. A side from these  traditional methods retinal vessel segmentation using  classifiers has become popular recently [32]. In previous works, continuous wavelet transform (CWT)  [22,23] is used and for the next step, integration of multiscale information is used for supervised classification [24].Here a Bayesian classifier is usedwith Gaussian mixture  models as class likelihoods and evaluate performances by accuracy analysis. In pixel classification approach [33], a feature vector is  constructed for each pixel of the image and two-dimensional Gabor wavelet transform responses taken at multiple scales.  Then, a classifier is trained using these feature vectors to  segment the image. Each pixel is represented by a feature vector composed of the pixel’s intensity and twodimensional Gabor wavelet transform responses taken at  multiple scales. In our approach, each pixel is represented by a feature  vector which uses measurements of different scales taken  from Morlet wavelet transform. A Bayesian classifier with  class conditional probability density functions is used and described as Gaussian mixtures that can model complex  decision surface.  The CWT is a robust transform and has been applied to  many different image processing problems, from image  coding [25',\n",
       " '1807.04093': 'Recurrent Neural Networks (RNNs) and in particular Long Short-Term Memory (LSTM) have achieved state-of-the-art classiﬁcation accuracy in many applications such as language modeling [2], machine translation [3], speech recognition [4], and image caption generation [5]. However, high classiﬁcation accuracy comes at high compute, storage, and memory bandwidth requirements, which makes their deployment particularly challenging, especially for energy-constrained platforms such as for portable devices. Furthermore, many applications have hard real-time constraints such as mobile robots, hearing aids and autonomous vehicles. Compared to feed-forward Neural Networks (NNs), LSTM networks are especially challenging as they require state keeping in between processing steps. This has various adversary effects. First of all, extra processing is required of the recurrent connections along with the “feed-forward” input activations. Additionally, even though the required state memory is not particularly large, the state keeping creates data dependencies to previous steps, which forces sequentialization of the processing in parts and limits the degrees of parallelism that can be leveraged in customizable architectures and that makes multi-core general-purpose computing platforms inefﬁcient. Many techniques have been proposed to alleviate the compute and storage challenges described above. Among the most common ones are pruning [6], [7], [8], and quantization (see Section II for details) or a combination thereof [9]. All of them are based on the typically inherent redundancy contained within the NNs, meaning that the number of parameters and precision of operations can be signiﬁcantly reduced without affecting accuracy. Within this paper, we focus on the latter method, namely reducing compute cost and storage requirements through reduction of precision in the leveraged data types, whereby we leverage Field-Programmable Gate Arrays (FPGAs) as they are they only computing platform that allows for customization of pipelined compute data paths and memory subsystems at the level of data type precision, in a programmable manner. As such they can take maximum advantage of the proposed optimization techniques. Within this paper, we extend a vast body of existing research on implementation of quantized NN accelerators for standard CNNs [10] to recurrent models. The novel contributions are: • We conduct the ﬁrst systematic exploration of the design space comprised of hardware computation cost, storage cost, power and throughput scalability as a function of precision for LSTM and Bidirectional LSTM (BiLSTM) in particular. • We investigate the effects of quantization of weights, input, output, recurrent, and in-memory cell activations during training. • We cross-correlate achievable performance with accuracy for a range of precisions to identify optimal performanceaccuracy trade-offs with the design space. • To the best of our knowledge, we present the ﬁrst hardware implementation of binarized (weights and activations constrained to 1 and 0) LSTM and BiLSTM in particular. • Last but not least, we provide the ﬁrst open source HLS library extension of FINN [1] for parameterizable hardware architectures of LSTM layers on FPGAs, which provides full precision ﬂexibility, allows for parameterizable performance scaling and supports a full training ﬂow  that allows to train the network on new datasets',\n",
       " '1304.2694': 'Many successful applications of artiﬁcial intelligence research are based on large probabilistic models. Examples include Markov logic networks (Richardson and Domingos 2006), conditional random ﬁelds (Lafferty, McCallum, and Pereira 2001) and, more recently, deep learning architectures (Hinton, Osindero, and Teh 2006; Bengio and LeCun 2007; Poon and Domingos 2011). Especially the models one encounters in the statistical relational learning (SRL) literature often have joint distributions spanning millions of variables and features. Indeed, these models are so large that, at ﬁrst sight, inference and learning seem daunting. For numerous of these models, however, scalable approximate and, to a lesser extend, exact inference algorithms do exist. Most notably, there has been a strong focus on lifted inference algorithms, that is, algorithms that group indistinguishable variables and features during inference. For an overview we refer the reader to (Kersting 2012). Lifted algorithms facilitate efﬁcient inference in numerous large probabilistic models for which inference is NP-hard in principle. We are concerned with the estimation of marginal probabilities based on a ﬁnite number of sample points. We show that the feasibility of inference and learning in large and highly symmetric probabilistic models can be explained with the Rao-Blackwell theorem from the ﬁeld of statistics. The theory and algorithms do not directly depend on the syntactical nature of the relational models such as arity of predicates and number of variables per formula but only on the given automorphism group of the probabilistic model, and are applicable to classes of probabilistic models much broader than the class of statistical relational models. Copyright c⃝2021, Association for the Advancement of Artiﬁcial Intelligence (www.aaai.org). All rights reserved. Consider an experiment where a coin is ﬂipped n times. While a frequentist would assume the ﬂips to be i.i.d., a Bayesian typically makes the weaker assumption of exchangeability – that the probability of an outcome sequence only depends on the number of “heads” in the sequence and not on their order. Under the non-i.i.d. assumption, a possible corresponding graphical model is the fully connected graph with n nodes and high treewidth. The actual number of parameters required to specify the distribution, however, is only n+1, one for each sequence with 0 ≤k ≤n “heads.” Bruno de Finetti was the ﬁrst to realize that such a sequence of random variables can be (re-)parameterized as a unique mixture of n+1 independent urn processes (de Finetti 1938). It is this notion of a parameterization as a mixture of urn processes that is at the heart of our work. A direct application of de Finetti’s results, however, is often impossible since not all variables are exchangeable in realistic probabilistic models. Motivated by the intuition of exchangeability, we show that arbitrary model symmetries allow us to re-paramterize the distribution as a mixture of independent urn processes where each urn consists of isomorphic joint assignments. Most importantly, we develop a novel Rao-Blackwellized estimator that',\n",
       " '1703.02921': 'We consider the problem of novel 3D view synthesis— given a single view of an object in an arbitrary pose, the goal is to synthesize an image of the object after a speciﬁed transformation of viewpoint. It has a variety of practical applications in computer vision, graphics, and robotics. As an image-based rendering technique [20], it allows placing a virtual object on a background with a desired pose or manipulating virtual objects in the scene [21]. Also, multiple generated 2D views form an efﬁcient representation for 3D reconstruction [36]. In robotics, synthesized novel views give the robot a better understanding of unseen parts of the object through 3D reconstruction, which will be helpful for Project homepage: http://www.cs.unc.edu/˜eunbyung/ tvsn grasp planning [40]. This problem is generally challenging due to unspeciﬁed input viewing angle and the ambiguities of 3D shape observed in only a single view. In particular inferring the appearances of unobserved parts of the object that are not visible in the input view is necessary for novel view synthesis. Our approach attacks all of these challenges, but our contributions focus on the later aspect, dealing with disoccluded appearance in novel views and outputting highly-detailed synthetic images. Given the eventual approach we will take, using a carefully constructed deep network, we can consider related work on dense prediction with encoder-decoder methods to see what makes the structure of the novel 3D view synthesis problem different. In particular, there is a lack of pixel-topixel correspondences between the input and output view. This, combined with large chunks of missing data due to occlusion, makes novel view synthesis fundamentally different than other dense prediction or generation tasks that have shown promising results with deep networks [30, 6, 19]. Although the input and desired output views may have similar low-level image statistics, enforcing such constraints directly is difﬁcult. For example, skip or residual connections, are not immediately applicable as the input and output have signiﬁcantly different global shapes. Hence, previous 3D novel view synthesis approaches [48, 36] have not been able to match the visual quality of geometry-based methods that exploit strong correspondence. The geometry-based methods are an alternative to pure generation, and have been demonstrated in [16, 21, 33]. Such approaches estimate the underlying 3D structure of the object and apply geometric transformation to pixels in the input (e.g. performing depth-estimation followed by 3D transformation of each pixel [12]). When successful, geometric transformation approaches can very accurately transfer original colors, textures, and local features to corresponding new locations in the target view. However, such approaches are fundamentally unable to hallucinate where new parts are revealed due to disocclusion. Furthermore, even for the visible geometry precisely estimating the 3D 1 arXiv:1703.02921v1  [cs.CV]  8 Mar 2017  Figure 1. Results on test images from 3D ShapeNet dataset [4]. 1st-input, 2nd-ground truth. From 3rd to',\n",
       " 'cs/0701050': 'Shannon’s entropy power inequality (EPI) gives a lower bound on the differential entropy of the sum of independent random variables X, Y with densities: exp(2h(X + Y )) ≥exp(2h(X)) + exp(2h(Y )) (1) with equality if X and Y are Gaussian random variables. The differential entropy of the probability density function p(x) of X is deﬁned as h(X) = E n log 1 p(X) o , (2) where it is assumed throught this paper that all logarithms are natural. The EPI ﬁnds its application in proving converses of channel or source coding theorems. It was used by Shannon as early as his 1948 paper [1] to bound the capacity of non-Gaussian additive noise channels. Recently, it was used to determine the capacity region of the Gaussian MIMO broadcast channel [2]. The EPI also ﬁnds application in blind source separation and deconvolution (see, e.g., [3]) and is instrumental in proving a strong version of the central limit theorem with convergence in relative entropy [4]. Shannon’s proof of the EPI [1] was incomplete in that he only checked that the necessary condition for a local minimum of h(X +Y ) is satisﬁed. Available rigorous proofs of the EPI are in fact proofs of an alternative statement h( √ λ X + √ 1 −λ Y ) ≥λh(X) + (1 −λ)h(Y ) (3) for any 0 ≤λ ≤1, which amounts to the concavity of the entropy under the “variance preserving” transformation [5]: (X, Y ) 7−→W = √ λ X + √ 1 −λ Y. (4) To see that (3) is equivalent to (1), deﬁne U, V by the relations X = √ λ U, Y = √ 1 −λ V , and rewrite (1) as follows: e2h( √ λ U+√1−λ V ) ≥λe2h(U) + (1 −λ)e2h(V ). Taking logarithms of both sides, (3) follows from the concavity of the logarithm. Conversely, taking exponentials, (3) written for U, V implies (1) for λ chosen so that U and V have equal entropies: exp 2h(U) = exp 2h(V ), that is, exp 2h(X) λ = exp 2h(Y ) 1−λ or λ = e2h(X))/(e2h(X) + e2h(Y )). The ﬁrst rigorous proof of the EPI was given by Stam [6] (see also Blachman [7]). It is based on the properties of Fisher’s information (FI) J(X) = E n\\x10p′(X) p(X) \\x112o , (5) the link between differential entropy and FI being de Bruijn’s identity [8, Thm. 17.7.2]: d dth(X + √ t Z) = 1 2J(X + √ t Z), (6) where Z ∼N(0, 1) is a standard Gaussian random variable, which is independent of X. Recently, Verd´u, Guo and Shamai [9], [10] provided an alternative proof of the EPI based on the properties of the MMSE in estimating the input X to a Gaussian channel given the output Y = √ t X + Z, where t denotes the signal-to-noise ratio. This MMSE is achieved by the conditional mean estimator ˆX(Y ) = E(X|Y ) and is given by the conditional variance Var',\n",
       " '1707.05807': 'The Gibbs sampler of Geman and Geman [GG84], also known as the Glauber dynamics or the heatbath algorithm, is a leading Markov chain Monte Carlo (MCMC) method for approximating expectations unavailable in closed form. First detailed as a technique for restoring degraded images [GG84], Gibbs sampling has since found diverse applications in statistical physics [Jan08], stochastic optimization and parameter estimation [Gey91], and Bayesian inference [Lun+00]. The hallmark of any Gibbs sampler is conditional simulation: individual variables are successively simulated from the univariate conditionals of a multivariate target distribution. The principal degree of freedom is the scan, the order in which variables are sampled [He+16]. While it is common to employ a systematic scan, sweeping through each variable in turn, or a uniform random scan, sampling each variable with equal frequency, it is known that non-uniform scans can lead to more accurate inferences both in theory and in practice [LWK95; LC06]. This effect is particularly pronounced when certain variables are of greater inferential interest. Past approaches to optimizing Gibbs sampler scans were based on asymptotic quality measures approximated with the output of a Markov chain [Lev+05; LC06]. In this work, we propose a computable non-asymptotic scan quality measure for discrete target distributions based on Dobrushin’s notion of variable inﬂuence [DS85]. We show that for a given subset of variables, this Dobrushin variation (DV) bounds the marginal total variation between a target distribution and T steps of Gibbs sampling with a speciﬁed scan. More generally, Dobrushin variation bounds a weighted total variation based on user-inputted importance weights for each variable. We couple this quality measure with an efﬁcient procedure for optimizing scan quality by minimizing Dobrushin variation. Our Dobrushin-optimized Gibbs samplers (DoGS) come equipped with a guaranteed bound on scan quality, are never worse than the standard 1 arXiv:1707.05807v1  [stat.ML]  18 Jul 2017  uniform random and systematic scans, and can be tailored to a target number of sampling steps and a subset of target variables. Moreover, Dobrushin variation can be used to evaluate and compare the quality of any user-speciﬁed set of scans prior to running any expensive simulations. The improvements achieved by DoGS are driven by an inputted matrix, ¯C, of pairwise variable inﬂuence bounds discussed in more detail in Section 3. While DoGS can be used with any discrete distribution, it was designed for targets with total inﬂuence ∥¯C∥< 1, measured in any matrix norm. This criterion is known to hold for a variety of distributions, including Ising models with sufﬁciently high temperatures, hard-core lattice gas models, random graph colorings [Hay06], and classes of weighted constraint satisfaction problems [FSY17]. Moreover, as we will see in Section 4.1, suitable variable inﬂuence bounds are readily available for pairwise and binary Markov random ﬁelds. These user-friendly bounds give rise to total inﬂuence ∥¯C∥< 1 in all of our experiments and thereby enable improvements in both inferential speed and accuracy over standard scans. The remainder of the',\n",
       " '1811.11222': 'An important challenge in drug discovery is to ﬁnd molecules with desired chemical properties. While ultimate usefulness as a drug can only be determined in a laboratory or clinical context, that process is expensive, and it is thus advantageous to pre-select likely candidates in software. While deep learning has been extensively investigated for molecular graph encoding ([Duvenaud et al., 2015], [Kearnes et al., 2016], [Gilmer et al., 2017]), molecule generation is still subject of active research. The simplest natural approach to candidate molecule generation is to generate some sort of a linear representation, such as a string of characters in the SMILES format [Weininger, 1988], using an encoder-decoder network architecture similar to that used in machine translation, as done in [G´omez-Bombarelli et al., 2016]. This approach’s performance was comparatively poor because a molecule’s structure is not linear, but rather a graph which typically includes cycles, so it falls to the model to learn how to generate SMILES strings that correspond to chemically valid molecules - a nontrivial task that leaves the model with little spare capacity to additionally optimize a given chemical metric of the molecules produced. A way to partially remedy that involves generating not the actual SMILES strings, but a sequence of production rules of a context-free grammar (CFG) for SMILES, as done by [Kusner et al., 2017]. That guarantees that the SMILES strings produced are grammatically valid, putting less burden on the model to ensure validity and thereby achieving better metrics. However, [Kusner et al., 2017] give two reasons why this is still not guaranteed to produce chemically valid molecules: ﬁrstly, a grammatically valid SMILES string is not guaranteed to be chemically possible (because of atom valences being wrong, for example), and secondly, because a 1The source code to produce these results can be found at https://github.com/ZmeiGorynych/generative playground 1 arXiv:1811.11222v1  [cs.LG]  27 Nov 2018  model typically assumes a maximum number of steps per molecule, and the rule expansion is not guranteed to terminate by that number of steps. Rather than generating SMILES strings, one could directly generate a molecular graph out of a vocabulary of valid components, an approach taken by [Jin et al., 2018]. An important insight of that approach is that one can regard a molecule as an acyclic graph if one considers cycles to be graph nodes, along with atoms not part of a cycle. Thus, by ﬁrst constructing such a graph and then resolving that into an actual molecule, the molecules produced by this approach are guaranteed to be chemically valid, so model optimization can focus on optimizing the properties of the actual molecule, resulting in state-of-the-art scores. Unfortunately the approach of [Jin et al., 2018] is also quite complex, using a two-part internal latent representation, a graph message-passing network, a tree message-passing network, and scoring for subgraphs as they are being assembled. Information transfer between nodes was done via message',\n",
       " '1007.3858': 'Constraint Handling Rules (Fr¨uhwirth 2009; Sneyers et al. 2010) is a high-level language extension based on multi-headed rules. Originally, CHR was designed as a special-purpose language to implement constraint solvers, but in recent years it has matured into a general purpose programming language. Being a language extension, CHR is implemented on top of an existing programming language, which is called the host language. An implementation of CHR in host language X is called CHR(X). For instance, several CHR(Prolog) systems are available. PRISM (PRogramming In Statistical Modeling) is a probabilistic extension of Prolog (Sato 2008). It supports several probabilistic inference tasks, including sampling, probability computation, and expectation-maximization (EM) learning. In this paper, we construct a new formalism, called CHRiSM — short for CHance Rules induce Statistical Models. It is based on CHR(PRISM) and it combines the advantages of CHR and those of PRISM. Like CHR, CHRiSM is a very concise and expressive programming language. Like PRISM, CHRiSM has built-in support for several probabilistic inference tasks. Furthermore, since CHRiSM is implemented as  2 Jon Sneyers et.al. a translation to CHR(PRISM) — which itself is translated to PRISM and ultimately Prolog — CHRiSM rules can be freely mixed with CHR rules and Prolog clauses. This paper is based on an earlier workshop paper (Sneyers et al. 2009). Although it is mostly self-contained, some familiarity with CHR and PRISM is recommended. We use ⊎for multiset union, F for multiset subset, and ¯∃AB to denote ∃x1, . . . , xn : B, with {x1, . . . , xn} = vars(B) \\\\ vars(A), where vars(A) are the (free) variables in A; if A is omitted it is empty (so ¯∃B denotes the existential closure of B). 2 Syntax and Semantics of CHRiSM In this section we deﬁne CHRiSM. The syntax is deﬁned in Section 2.1 and the (abstract) operational semantics is deﬁned in Section 2.2. Finally, in Section 2.3 the notion of observations is introduced. 2.1 Syntax and Informal Semantics A CHRiSM program P consists of a sequence of chance rules. Chance rules rewrite a multiset S of data elements, which are called (CHRiSM) constraints (mostly for historical reasons). Syntactically, a constraint c(X1,..,Xn) looks like a Prolog predicate: it has a functor c of some arity n and arguments X1,..,Xn which are Prolog terms. The multiset S of constraints is called the constraint store or just store. The initial store is called the query or goal, the ﬁnal store (obtained by exhaustive rule application) is called the answer or result. Chance rules. A chance rule is of the following form: P ?? Hk \\\\ Hr <=> G | B. where P is a probability expression (as deﬁned below), Hk is a conjunction of (kept head) constraints, Hr is a conjunction of (removed head) constraints, G is a guard condition (a Prolog goal to be satisﬁed), and B is the body of the rule. If Hk is empty, the',\n",
       " '1301.4730': 'In this paper, we consider the ﬁnite-ﬁeld multi-way relay channel where multiple users exchange messages through a relay, and where the channel from the users to the relay is modeled by a ﬁnite-ﬁeld channel (see Figure 1). The ﬁnite-ﬁeld multi-way relay channel with independent messages was ﬁrst considered in [1] where we proposed an optimal scheme that achieves the capacity. The scheme is, however, suboptimal when the messages are correlated, e.g., when there is message sharing (a special correlation structure in which every user pair may have part of their messages in common). See Appendix A for a proof of the suboptimality of the scheme in [1] when there are shared messages. The shortcoming of this scheme is that it ignores the fact that some parts of the messages are known to two users (i.e., the shared parts). For the special case of three users with message sharing, an optimal function was constructed by Ong et al. [2]. However, the function is speciﬁc to three users, and is not extendable to more users. Indeed, prior to the current paper, it was not clear if optimal functions existed for an arbitrary number of users. In this paper, we design a scheme that constructs an optimal function for any number of users with pairwise message sharing, thereby obtaining the capacity of the channel. A. A Challenge: To Design an Optimal Function to be Decoded by the Relay The multi-way relay channel models many relay-aided communication networks where there is no direct user-to-user link, e.g., cellular mobile networks and satellite communications. Lawrence Ong is the recipient of an ARC Discovery Early Career Researcher Award (DE120100246). Sarah Johnson and Christopher Kellett are recipients of ARC Future Fellowships (FT110100195 and FT110100746 respectively). 1 2 Y1 · · · p(y1, . . . , yL|x0) 0 Y0 N0 X1 X2 XL 1 2 L · · · L Y2 YL 0 X0 Fig. 1. The multi-way relay channel with ﬁnite-ﬁeld uplink (left) and arbitrary downlink (right), where users (nodes 1, 2, . . . , L) exchange messages through a relay (node 0). Theoretically, the multi-way relay channel poses new challenges in multi-user information theory not encountered in the classical setups [3], e.g., the multi-access channel, the broadcast channel, the interference channel, and the relay channel. Although a relay is present in both the relay channel and the multi-way relay channel, the latter involves data transmission in multiple directions. Classical relaying schemes [4] (decode-forward, amplifyforward, compress-forward) can be used for the multi-way relay channel. However, the functional-decode-forward scheme (also known as compute-forward [5]) outperforms the classical relaying schemes in certain network conﬁgurations [6], and even achieves the capacity when the channel is a ﬁnite-ﬁeld channel [1]. The functional-decode-forward scheme incorporates network coding [7] in the design of the channel codes to facilitate bidirectional relaying. For example, consider the two-way relay channel, where node 1 sends its',\n",
       " '1802.00868': 'The stochastic and intermittent nature of renewable resources has brought new challenges to the scheduling, operation, and planning of power systems. One popular framework to capture these uncertainties in renewable generation is to use a set of scenarios, each representing a possible time series realization of the random physical process [1], [2]. These scenarios can then be used in a variety of optimization problems, including stochastic economic dispatch, unit commitment, operation of wind farms, storage management, trading and planning (see, e.g. [3], [4], [5], [6] and the references within). A key requirement of the generated scenarios is that they accurately reﬂect the spatial/temporal patterns in the physical generation process and exhibit enough diversity to capture a wide range of behaviors. For instance, most land-based wind farms have diurnal patterns but may also output very little power over a long period of time, and a set of scenarios should ideally capture both phenomena. To capture underlying stochastic processes, several model-based approaches have been proposed, where the process is assumed to have some parametrized probability distribution P, and historical data is used to learn these parameters [7], [8]. For example, in [2], [9], copula methods are ﬁrst applied to model the distribution and correlation of power generation time-series, then scenarios are generated via a sampling method. In [1], an autoregressive moving average (ARMA) model is ﬁrst learned and then used to generate spatiotemporal scenarios using power generation proﬁles at each renewables generation site. However, the time-varying and nonlinear dynamics of weather along with the complex spatial and temporal interactions make model-based approaches difﬁcult to apply and hard to scale, especially when multiple renewable power plants are considered. In particular, even if the exact distribution of the stochastic process is known, sampling from it is usually nontrivial and time consuming. Moreover, some of previous methods depend on certain probabilistic forecasts as inputs, which could limit the diversity of the generated scenarios and under-explore the overall variability of renewable resources [10]. In [11], we proposed a deep generative machine learning framework to capture and learn the power generation dynamics. We adopted the Generative Adversarial Networks (GAN), which is a data-driven, model-free approach that generates new scenarios directly from historical data without explicitly ﬁtting a probabilistic model. This approach is easily scalable, and outperforms existing state-of-the-art model-based approaches especially in the setting of multiple correlated renewable generators. However, despite its success, if the historical data contains several distinct modes (e.g., high wind and low wind proﬁles), the generated scenarios can contain a mixture of these modes. These “mixed” scenarios maybe inappropriate for the subsequent optimization problems and need to be ﬁltered out with an additional post-processing step. To overcome this challenge, we extend the results of [11] by introducing a Bayesian formulation into the GAN training process. This Bayesian formulation allows us to use the GAN architecture to directly ﬁnd',\n",
       " '1802.04791': 'Past decades have witnessed increasing attention of Markov Chain Monte Carlo (MCMC) methods in modern machine learning problems (Andrieu et al., 2003). An important family of Markov Chain Monte Carlo algorithms, called Langevin Monte Carlo method (Neal et al., 2011), is proposed based on Langevin dynamics (Parisi, 1981). Langevin dynamics was used for modeling of the dynamics of molecular systems, and can be described by the following Itˆo’s stochastic differential equation (SDE) (Øksendal, 2003), dXt = −∇f(Xt)dt + p 2βdBt, (1.1) where Xt is a d-dimensional stochastic process, t ≥0 denotes the time index, β > 0 is the temperature parameter, and Bt is the standard d-dimensional Brownian motion. Under certain assumptions on the drift coefﬁcient ∇f, Chiang et al. (1987) showed that the distribution of Xt in (1.1) *Equal contribution 1Department of Computer Science, University of California, Los Angeles, CA 90095, USA. Correspondence to: Quanquan Gu <qgu@cs.ucla.edu>. Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018 by the author(s). converges to its stationary distribution, a.k.a., the Gibbs measure πβ ∝exp(−βf(x)). Note that πβ is smooth and log-concave (resp. strongly log-concave) if f is smooth and convex (resp. strongly convex). A typical way to sample from density πβ is applying Euler-Maruyama discretization scheme (Kloeden & Platen, 1992) to (1.1), which yields Xk+1 = Xk −∇f(Xk)η + p 2ηβ · ϵk, (1.2) where ϵk ∼N(0, Id×d) is a standard Gaussian random vector, Id×d is a d × d identity matrix, and η > 0 is the step size. (1.2) is often referred to as the Langevin Monte Carlo (LMC) method. In total variation (TV) distance, LMC has been proved to be able to produce approximate sampling of density πβ ∝e−f/β under arbitrary precision requirement in Dalalyan (2014); Durmus & Moulines (2016b), with properly chosen step size. The non-asymptotic convergence of LMC has also been studied in Dalalyan (2017); Dalalyan & Karagulyan (2017); Durmus et al. (2017), which shows that the LMC algorithm can achieve ϵ-precision in 2-Wasserstein distance after eO(κ2d/ϵ2) iterations if f is L-smooth and µstrongly convex, where κ = L/µ is the condition number. In order to accelerate the convergence of Langevin dynamics (1.1) and improve its mixing time to the unique stationary distribution, Hamiltonian dynamics (Duane et al., 1987; Neal et al., 2011) was proposed, which is also known as underdampled Langevin dynamics and is deﬁned by the following system of SDEs dVt = −γVtdt −u∇f(Xt)dt + p 2γudBt, dXt = Vtdt, (1.3) where γ > 0 is the friction parameter, u denotes the inverse mass, Xt, Vt ∈Rd are the position and velocity of the continuous-time dynamics respectively, and Bt is the Brownian motion. Let Wt = (X⊤ t , V ⊤ t )⊤, under mild assumptions on the drift coefﬁcient ∇f(x), the distribution of Wt',\n",
       " '1803.10158': 'Autonomous driving has seen dramatic advances in recent years, for instance for road scene parsing [23,67,79,24], lane following [46,37,17], path planning [12,18,62,63], and end-to-end driving models [77,22,21,56]. By now, autonomous vehicles have driven many thousands of miles and companies aspire to sell such vehicles in a few years. Yet, signiﬁcant technical obstacles, such as the necessary robustness of driving models to adverse weather/illumination conditions [67,79,24] or the capability to anticipate potential risks in advance [58,35], must be overcome before assisted driving can be turned into full-ﬂetched automated driving. At the same time, research on the next steps arXiv:1803.10158v2  [cs.CV]  6 Aug 2018  2 S. Hecker, D. Dai and L. Van Gool Fig. 1: An illustration of our driving system. Cameras provide a 360-degree view of the area surrounding the vehicle. The driving maps or GPS coordinates generated by the route planner and the videos from our cameras are synchronized. They are used as inputs to train the driving model. The driving model consists of CNN networks for feature encoding, LSTM networks to integrate the outputs of the CNNs over time; and fully-connected networks (FN) to integrate information from multiple sensors to predict the driving maneuvers. towards ‘complete’ driving systems is becoming less and less accessible to the academic community. We argue that this is mainly due to the lack of large, shared driving datasets delivering more complete sensor inputs. Surround-view cameras and route planners. Driving is inarguably a highly visual and intellectual task. Information from all around the vehicle needs to be gathered and integrated to make safe decisions. As a virtual extension to the limited ﬁeld of view of our eyes, side-view mirrors and a rear-view mirror are used since 1906 [1] and in the meantime have become obligatory. Human drivers also use their internal maps [74,54] or a digital map to select a route to their destination. Similarly, for automated vehicles, a decision-making system must select a route through the road network from its current position to the requested destination [76,47,50]. As said, a single front-view camera is inadequate to learn a safe driving model. It has already been observed in [64] that upon reaching a fork - and without a clearcut idea of where to head for - the model may output multiple widely discrepant travel directions, one for each choice. This would result in unsafe driving decisions, like oscillations in the selected travel direction. Nevertheless, current research often focuses on this setting because it still allows to look into plenty of challenges [37,9,77]. This is partly due to the simplicity of training models with a single camera, both in terms of available datasets and the complexity an effective model needs to have. Our work includes a surroundview camera system, a route planner, and a data reader for the vehicle’s CAN bus. The setting',\n",
       " '1807.10965': 'The authoritative source for conveying the latest climate research ﬁndings, recommendations and mitigations steps is the Intergovernmental Panel on Climate Change (IPCC) [6]. The reports produced by the IPCC are published every ﬁve years and are composed of four separate volumes: Physical Science Basis; Impacts, Adaptations and Vulnerability; Mitigation of Climate Change; and Synthesis Reports. Each IPCC volume has eight to twenty-ﬁve chapters and each chapter cites between 800 and 1200 external research documents. The IPCC reports provide not only a comprehensive assessment of the climate science, but the analysis of the 30-year series of reports shows how the scientiﬁc ﬁeld has and continues to evolve. For a new climate scientist, absorbing this information in order to perform research or make policy contributions can be daunting. However, if machine understanding of these reports could be used to summarize, synthesize and model the knowledge, the researcher’s task is improved. We propose this could improve the overall scientiﬁc research contributions that could be made by making the process more efﬁcient. In our previous work [17,15,16,14] we described a process by which we converted 25 years of IPCC reports and their cited articles into raw text. We treated these two 1This is a preprint of work that will be presented at the Semantic Web for Social Good Workshop of the International Semantic Web Conference, October 2018 and published as part of the book ”Emerging Topics in Semantic Technologies. ISWC 2018 Satellite Events”, E. Demidova, A.J. Zaveri, E. Simperl (Eds.), ISBN: 978-3-89838-736-1, 2018, AKA Verlag Berlin. Copyright held by the authors. arXiv:1807.10965v2  [cs.CL]  31 Jul 2018  document collections, the report chapters and the scientiﬁc research papers they cite, as two different domains. We used a topic modeling cross-domain approach to show how these two domains interacted and how the cited research in one report inﬂuenced the subsequent reports. This allows us to more accurately predict how the ﬁeld of climate science is evolving. We quickly discovered that the standard topic modeling approaches did not work as well as we hoped on the text in the report domain, and were even less effective on the cited research documents from the scientiﬁc domain. One reason is that scientiﬁc literature is written more formally and typically contains more phrases that provide the context through which one understands the literature [4]. Many phrases in a given scientiﬁc domain do not follow the usual pattern of compositional semantics in which their meaning can be obtained by combining the meanings of their words. Rather, they have a speciﬁc meaning in the domain that must be learned. In climate science, for example, black carbon refers not to carbon whose color is black, but to the sooty material emitted from gas and diesel engines, coal-ﬁred power plants and other sources that burn fossil fuel. Background Topic modeling has a long history of relevance to natural language processing, often used to model large',\n",
       " '1901.06560': 'There has been a recent surge of work in explanatory artiﬁcially intelligent (XAI) systems. One reason these systems are gaining traction is due to changes in policy, law, and regulation. Indeed, with the rise of AI-based decision making in areas of societal interest–from ﬁnance and employment to driving and journalism–policymakers see the need to discuss certain standards around XAI. For example, the European Union’s General Data Protection Regulation (GDPR) creates obligations for automatic decision making processes [11], with a provision including right to explanation. This broad obligation puts the burden on those who process data with (and develop for) AI systems to generate reasonable explanations for their systems’ decision making processes. We can also observe broad societal concerns with issues of AI liability [33]. For example, as autonomous vehicles are being introduced, we need a better understanding of what happened in the case of an accident (as it has already happened [5]). How can there be an appropriate investigation process if opaque decisionmaking algorithms are involved? How can we ensure that these machines are acting in our best interest? AI algorithms and more general, complex AI systems cannot currently provide answers to these prior questions. These algorithms and systems are not built to explain to the general public nor policy-makers. Although there have been calls for work on creating systems and algorithms that can interpret [7, 27] and explain [12] some parts of their decisions, the current state-of-the-art explanatory systems are made for the programmer or expert, not an end user or policy-maker. The key difference here is that the current systems produce what we refer to as inside explanations. They point to a plausible technical explanation, either by looking at the relationships between the inputs and outputs of a model, or examining the role of individual parts, or by producing a surface-level explanation itself. Crucially, though, these explanations do not answer why questions. Continuing with the autonomous vehicle example, when an accident happens involving this autonomous ma32nd Conference on Neural Information Processing Systems (NIPS 2018), Montréal, Canada.  chine, police ofﬁcials, insurance companies, and the people who are harmed will want to know who or what is accountable for the accident and why it happened. In this paper, we examine the types of questions that explanatory DNN algorithms can and cannot answer. We focus on DNNs speciﬁcally because of the recent shift in AI research from symbolic approaches to machine learning and deep learning 1, and because these are the systems are making safety-critical decisions in applications like autonomous driving[3] and malware detection[35]. In order to bridge the gap between the current, technical deep neural network explanations (which we refer to as inside explanations) and the explanations that answer why questions that would beneﬁt society (which we refer to as outside explanations) we must develop explanations for DNNs that can answer these questions and be probed. We extend the work of a previously deﬁned',\n",
       " '1709.04090': 'Recently, there has been great interest in mapping the interactions between brain regions, a ﬁeld known as functional connectomics (Smith et al. 2013b). The resulting maps, or connectomes, are fundamental to the study of neuroscience, as having a map of the brain allows for understanding neural pathways and systems (Seung 2011). Furthermore, these connectomes have immediate applications to pathologists trying to understand the neural characteristics underlying clinical disorders (Uddin et al. 2013). Here, we focus on the important problem of estimating brain connectivity for more than one group (i.e. a disease group and a control group). Generally, studies use the simple pairwise correlations (i.e. the pearson correlation coefﬁcient) between the activity of different areas as markers of a connection (Rogers et al. 2007). However, from a neuroscience perspective, this fails to extract the conditional correlations present in the brain and results in spurious connections. Copyright c⃝2018, All rights reserved. Mathematically, determining functional connectivity amounts to ﬁrst calculating a covariance matrix (Σ) from the data and then estimating the connectivity graph with the precision matrix (Ω= Σ−1). Zeros in Ωcorrespond to conditionally independent nodes, while non-zero values represent conditional edges (Lauritzen 1996). Recently, Gaussian graphical models (GGMs) have proven to be well-suited to estimating Ω(Koller et al. 2007). This study’s main contribution is the novel formulation of W-SIMULE, which arises naturally from brain-imaging data. W-SIMULE is a weighted-ℓ1, multi-task graphical model which robustly estimates Ωfor each group. The main advantages of this method are: • Effectiveness: it yields quantiﬁably accurate connectivity in terms of log-likelihood and classiﬁcation accuracy • Domain adaptivity: it elegantly enforces a prior based on the problem at hand and can overcome the often-incorrect Gaussian assumption by using nonparanormality • Interpretability: it calculates a connectome for each group which can be tuned to the desired sparsity level and is particularly effective at low sparsity levels • Efﬁciency: the formulation is column-wise parallelizable and quickly solvable This study examines a large, resting-state fMRI dataset which serves to compare and validate several recent multitask learning models. W-SIMULE outperforms other graphical models on this dataset in terms of (1) maximizing the log-likelihood of the connectome, (2) ﬁnding edges that differentiate groups, and (3) classifying subjects into their group (autism vs. control). Finally, W-SIMULE is used to analyze the neural basis of autism. The organization of the paper is as follows: Sec. 2 reviews related work, Sec. 3 develops the model, Sec. 4 shows experiments demonstrating the effectiveness of W-SIMULE, and Sec. 5 explains the conclusions. 2 Background and Related Work A variety of related work exists. We divide it into four categories: (1) weighted-ℓ1 models, (2) brain connectivity priors, (3) multi-task brain studies, and (4) multi-task baselines. None of the existing work meets all the speciﬁcations of WSIMULE. Notably, W-SIMULE outperforms all previous arXiv:1709',\n",
       " '1506.01929': 'Recent work on action recognition mostly focuses on the problem of action classiﬁcation [22, 33, 43]. The goal is to assign a category label to a video, in most cases cropped to the extent of the action. In a long stream of video, an action may have varying temporal extent. Furthermore, the action is also spatially localized. Yet, detecting an action in space and time remains a challenging task which received little attention so far. Some previous works address related issues by putting emphasis either on the spatial or on the temporal localization. Action recognition and localization in still images [3] is an extreme example along the ﬁrst line, where local detectors are trained e.g. with HOG features and localize spatially the person and/or the object. On the other extreme, recent work on action recognition and localization from videos [7, 19, 31] perform temporal localization, for which dense motion features such as dense trajectories [43] proved effective. ∗LEAR team, Inria Grenoble Rhone-Alpes, Laboratoire Jean Kuntzmann, CNRS, Univ. Grenoble Alpes, France. Several recent works address spatial and temporal localization jointly. They resort to ﬁgure-centric models [27, 34, 23], discriminative parts [30] or proposals [15, 46, 11]. Proposals are obtained by hierarchical merging of supervoxels [15], by maximizing an actionness score [46] or by relying on selective search regions and CNN features [11]. The main challenge in spatio-temporal localization is to accommodate the uncertainty of per-frame spatial localization and the temporal consistency. If the spatial localization performed independently on each frame is too selective and at the same time uncertain, then enforcing the temporal consistency of the localization may fail. Here we use proposals to obtain a set of per frame spatial proposals and enforce temporal consistency based on a tracker, that simultaneously relies on instance-level and class-level detectors. Our approach starts from frame-level proposals extracted with a high-recall proposal algorithm [47]. Proposals are scored using CNN descriptors based on appearance and motion information [11]. To ensure the temporal consistency, we propose to track them with a tracking-by-detection approach combining an instance-level and class-level detector. We then score the tracks with the CNN features as well as a spatio-temporal motion histogram descriptor, which captures the dynamics of an action. At this stage, the tracks are localized in space, but the temporal localization needs to be determined. Temporal localization is performed using a multi-scale sliding-window approach at the track level. In summary, this paper introduces an approach for spatio-temporal localization, by learning to track, with state-of-the-art experimental results on UCF-Sports, JHMDB and UCF-101. A spatio-temporal local descriptor allows to single out more relevant tracks and temporally localize the action at the track level. This paper is organized as follows. In Sec. 2, we review related work on action localization. We then',\n",
       " '1804.10992': 'Zeuxis having painted a child carrying grapes, the birds came to peck at them; upon which [...] he expressed himself vexed with his work, and exclaimed – “I have surely painted the grapes better than the child, for if I had fully succeeded in the last, the birds would have been in fear of it.” – Pliny the Elder, The Natural History, 79 AD Photographic image synthesis by deep networks can open a new route to photorealism: a problem that has traditionally been approached via explicit manual modeling of three-dimensional surface layout and reﬂectance distributions [24]. A deep network that is capable of synthesizing photorealistic images given a rough speciﬁcation could become a new tool in the arsenal of digital artists. It could also prove useful in the creation of AI systems, by endowing them with a form of visual imagination [19]. Recent progress in photographic image synthesis has been driven by parametric models – deep networks that represent all data concerning photographic appearance in their weights [11, 2]. This is in contrast to the practices of human photorealistic painters, who do not draw purely on memory but use external references as source material for reproducing detailed object appearance [17]. It is also in contrast to earlier work on image synthesis, which was based on nonparametric techniques that could draw on large datasets of images at test time [7, 15, 3, 13, 10]. In switching from nonparametric approaches to parametric ones, the research community gained the advantages of end-to-end training of highly expressive models. But it relinquished the ability to draw on large databases of original photographic content at test time: a strength of earlier nonparametric techniques. In this paper, we present a semi-parametric approach to photographic image synthesis from semantic layouts. The presented approach exempliﬁes a general family of methods that we call semi-parametric image synthesis (SIMS). Semi-parametric synthesis combines the complementary strengths of parametric and nonparametric techniques. In the presented approach, the nonparametric component is a database of segments drawn from a training set of photographs with corresponding semantic layouts. At test time, given a novel semantic layout, the system retrieves compatible segments from the database. These segments are used as raw material for synthesis. They are composited onto a canvas with the aid of deep networks that align the segments to the input layout and resolve occlusion relationships. The canvas is then processed by a deep network that produces a photographic image as output. We conduct experiments on the Cityscapes, NYU, and ADE20K datasets. The experimental results indicate that images produced by SIMS are considerably more realistic than the output of purely parametric models for photographic image synthesis from semantic layouts. 2. Related Work Recent work on conditional image synthesis is predominantly based on parametric models [26, 34, 32, 25, 6, 21, 22, 8, 11, 2, 37]. Most related to ours are the works of Isola et al. [11] and Chen',\n",
       " '1408.2303': 'Over the last decade there has been increased interest in Gabidulin codes, mainly because of their relevance to network coding [15, 35]. Gabidulin codes are optimal rank-metric codes over a ﬁeld Fqm (where q is a prime power). They were ﬁrst derived by Gabidulin in [9] and independently by Delsarte in [6]. These codes can be seen as the q-analog of Reed-Solomon codes, using q-linearized polynomials instead of arbitrary polynomials. They are optimal in the sense that they are not only MDS codes with respect to the Hamming metric, but also achieve the Singleton bound with respect to the rank metric and are thus MRD codes. They are not only of interest in network coding but also in space-time coding [24], crisscross error correction [28] and distributed storage [32]. The decoding of Gabidulin codes has obtained a fair amount of attention in the literature, starting with work on decoding within the unique decoding radius in [9, 10] and more recently [23, 27, 29, 31, 33, 39]. If n is the length of the Gabidulin code and k denotes the dimension of the code as a linear space over the ﬁeld Fqm, the ∗ALHT was partially supported by Swiss National Science Foundation Fellowship no. 147304. 1  unique decoding radius is given by (n−k)/2. Decoding beyond the unique decoding radius was addressed in e.g. [22, 25, 30, 37, 38, 40]. In this case, one speaks of listdecoding, i.e. ﬁnding all codewords within a given radius to the received word. A main open question is whether Gabidulin codes can be list decoded eﬃciently. This paper seeks to contribute to current research eﬀorts on this open question. In [37] it was shown that, beyond the Johnson radius n− √ kn, list decoding with a polynomial size list of codewords is not possible. This raises the question up to which radius list decoding with a polynomial list size is possible. Recent results [12, 13] show an explicit construction of rank-metric codes, constructed as subcodes of Gabidulin codes, that can be list-decoded in polynomial time up to a certain radius beyond the unique decoding radius. This motivates further research of what happens in the original Gabidulin setting between the unique and the Johnson radius. A closely related family of codes is the one of lifted Gabidulin codes [35]. These codes are sets of vector spaces and can be used for non-coherent (also called random) network coding [15]. Unique decoding of lifted Gabidulin codes was investigated in e.g. [15, 35], whereas list-decoding of these codes was studied in [36, 41]. Using the close resemblance between Reed-Solomon codes and Gabidulin codes, the paper [23] translates Gabidulin decoding into a set of polynomial interpolation conditions. Essentially, this setup is also used in the papers [15, 41] that present iterative algorithms that perform Gabidulin list decoding with a list size of 1. In this paper we present an iterative algorithm that bears similarity to the',\n",
       " '1809.05786': 'Visual odometry (VO) and depth recovery are essential modules of simultaneous localization and mapping (SLAM) applications. In the last few decades, VO systems have attracted a substantial amount of attention, enabling robust localization and accurate depth map reconstruction. Monocular VO is confronted with numerous challenges such as large scale drift, the need for hand-crafted mathematical features and strict parameter tuning [3], [4]. Supervised deep learning based VO and depth recovery techniques have showed good performance in challenging environments and succesfuly alleviated issues such as scale drift, need for feature extraction and parameter ﬁnetuning [5]–[8]. VO as a regression problem in supervised deep learning exploits the capability of convolutional neural network (CNN) and recurrent neural network (RNN) to estimate camera motion, to calculate optical ﬂow, and to extract efﬁcient feature representations from raw RGB input [5]–[7], [9]. In recent years, unsupervised deep learning approaches have achieved remarkable results in various domains eliminating the need for labelled data [10], [11]. Years of research in visual SLAM have been inspired by human navigation that easily locates obstacles even in 1Yasin Almalioglu, Muhamad Risqi U. Saputra, Pedro P. B. de Gusmo, Andrew Markham, and Niki Trigoni are with the Computer Science Department, The University of Oxford, UK {yasin.almalioglu, muhamad.saputra, pedro.gusmao, andrew.markham, niki.trigoni}@cs.ox.ac.uk Fig. 1: Architecture overview. The unsupervised deep learning approach consists of depth generation, multi-view pose estimation, view reconstruction, and target discrimination modules. Unlabelled image sequences from different temporal points are given to the networks to establish a supervision signal. The networks estimate relative translation and rotation between consecutive frames from different perspectives parametrized as 6-DoF motion, and depth image as a disparity map for a given view. unknown environments. A neuroscientiﬁc insight is that human brain saves a structural perception of the world, which makes it capable of real and imaginary scene reconstruction through vast previous experiences [12], [13]. In this study, we propose a novel real-time localization and generative depth estimation approach that mimics the remarkable egomotion estimation and re-constructive scene representation capabilities of human beings by training an unsupervised deep neural network. The proposed network consists of a pose regressor and depth generator network. The former regresses 6 degree-of-freedom (DoF) pose values using CNNRNN modules, and the latter generates depth maps using deep convolutional generative adversarial network (GAN) [14]. The model takes a sequence of monocular images to estimate 6-DoF camera motion and depth map that is sampled from the same input data distribution, which is trained in an end-to-end and unsupervised fashion directly from raw input pixels. A view reconstruction approach is utilized as part of the objective function for the training in a similar way to prior works [15]–[18]. The entire pose estimation and depth map reconstruction pipeline is a consistent and systematic learning framework which continually improves its performance by collecting unlabelled monocular video arXiv:1809',\n",
       " '1810.07433': 'E MPHYSEMA is a lung pathology characterized by destruction of lung tissue and enlargement of airspaces in the lung, causing shortness of breath. It is a main component of chronic obstructive pulmonary disease (COPD), a leading cause of mortality and morbidity world-wide [1]. Emphysema can be assessed on chest CT scans and its extent quantiﬁed by densitometry, where the amount of tissue affected by emphysema is estimated by measuring the percentage of lung volume with attenuation below a speciﬁc threshold. Although densitometry is simple and provides a single interpretable measurement of emphysema extent, it is also highly dependent on scanner hardware, reconstruction parameters [2] and software used for analysis [3]. This study was ﬁnancially supported by the Danish Council for Independent Research (DFF) and the Netherlands Organization for Scientiﬁc Research (NWO). The sponsors had no involvement in the work. S. Ørting and J. Petersen are with Department of Computer Science, University of Copenhagen, Copenhagen, Denmark L. Thomsen is with Department of Internal Medicine, Hvidovre Hospital, Copenhagen Denmark M. M. W. Wille is with Department of Diagnostic Imaging, Bispebjerg Hospital, Copenhagen, Denmark M. de Bruijne is with Department of Computer Science, University of Copenhagen, Copenhagen, Denmark and Biomedical Imaging Group Rotterdam, Departments of Radiology and Medical Informatics, Erasmus MC - University Medical Center Rotterdam, The Netherlands Manuscript received September 7th, 2018 An alternative to densitometry is visual assessment that can quantify extent and characterize emphysema subtype. The COPDGene CT Workshop Group [4] proposed a standard for visual assessment of COPD based on the characterization of emphysema appearance from the Fleischner society [5]. A slightly modiﬁed version of the standard was used for visual assessment in the Danish Lung Cancer Screening Trial (DLCST), where it was shown to be predictive of lung cancer [6]. A similar classiﬁcation scheme deﬁned in [7] was used in [8] where it was shown that visual presence and severity of emphysema is associated with increased mortality independent of densitometric measures of emphysema severity. The downside of visual assessment is that it is time-consuming and subject to inter-rater variability [4], [9]. Automated approaches based on the appearance of emphysema could provide fast and reproducible assessment of emphysema extent, location and sub-type, thus combining the superior disease characterization of visual assessment with the ease of densitometry. For instance [10] has shown that a shapemodel of bullae-like structures can be used for emphysema detection. We have previously used machine learning algorithms based on texture features to predict regional emphysema presence [11] and emphysema extent [12]. Other learning based approaches have focused on discovery of emphysema patterns using supervised [13] and unsupervised [14], [15] learning, COPD detection and staging [16], [17] and emphysema detection in the more general context of interstitial lung disease classiﬁcation [18], [19]. Multiple Instance Learning (MIL) has been used with success in a number of the prior works on emphysema and COPD detection [11], [16], [17] and for many related medical image analysis tas',\n",
       " '1806.03578': 'The goal of current MRC tasks is to develop agents which are able to comprehend passages automatically and answer open-domain questions correctly. With the release of several large-scale datasets like SQuAD (Rajpurkar et al., 2016), MS-MARCO (Nguyen et al., 2016) and DuReader (He et al., 2017), many MRC models have been proposed in previous works (Wang and Jiang, 2016; Seo et al., 2016; Wang et al., 2017). Although MRC model architectures have been intensively studied, the evaluation metrics for them are rarely discussed. For early cloze-style and multiple choice datasets (Richardson et al., 2013; Hermann et al., 2015), this may not be problematic. However, considering the trend that the model is required to generate answers and question type is becoming more variable and closer to real cases, we believe the design *This work was done while the ﬁrst author was doing internship at Baidu Inc. of evaluation metric is indeed an issue to be focused on. Currently, the criterion for comparing generated and gold answers is mostly based on lexical overlap. For example, SQuAD uses exact-match ratio and word-level F1-score, while MS-MARCO and DuReader employ ROUGE-L (Lin, 2004) and BLEU (Papineni et al., 2002) which measure ngram consistency or longest common sequence (LCS) length. For some question types, we notice these metrics may not correlate with semantic correspondence well in some cases. In this paper, we mainly tackle the issue of yes-no and entity questions. For yes-no questions, overlapbased metrics may ignore the yes-or-no opinion which is more crucial in determining agreement between answers. Answers with contrary opinions may have high lexical overlap, such as “The radiation of wireless routers has an impact on people” and “The radiation of wireless routers has no impact on people”. Similarly, for entity questions, we think the agreement should be more reﬂected by the correctness of entity listing. Answers which lack or mispredict entities should be in distinction from correct answers, but the mistakes actually affect little in BLEU and ROUGE, especially when the entity is a number. These two question types are quite common in MRC datasets and real scenario. As is shown in He et al. (2017), 36.2% queries in DuReader and 47.5% in Baidu real search data are classiﬁed into these two categories. For the reasons above, developing an automatic evaluation system which takes consideration of the inherent characteristics of these question types is of great necessity. In previous work, Dang et al. (2007) employed type-speciﬁc metrics for evaluating candidate answers in TREC 2007 QA track. Setting the accuracy of yes-no opinion type and F1-score of entity list as extra metrics may solve the problem  to some extent. However, from the perspective of simplicity and scalability to growing question type category, we hope to design a uniﬁed and end',\n",
       " '1811.07988': 'P AIN assessment is essential to providing proper patient care and assessing its efﬁcacy under clinical settings. A patients’ self-report is commonly used as the ’gold standard’ to report pain through manual pain measurement tools, including the verbal numerical scale (VNS) and visual analogue scale (VAS). However, human sensing and judgement of pain is subjective and the scale report may vary signiﬁcantly among individuals. Behavioral observation of a patient, in particular the use of facial expression, as a key behavioral indicator of pain, has been identiﬁed as an important modality for assessing pain [99] , especially when the patient’s ability to communicate pain is impaired [36]. Patients who are dying, intellectually disabled [63], critically ill and sedated [68] [1], or have dementia [61], head and neck cancer, or brain metastasis [35] [31] [71] are particularly vulnerable and in need of technology that could provide reliable and valid alerts about their pain to busy clinicians. The American Society for Pain Management Nursing (ASPMN), in its position statement on pain assessment in the nonverbal patient [35], describes a hierarchy of pain assessment in which the observation of behavior including facial expressions is noted to be a valid approach to pain assessment. McGuire et al [63] concluded that pain in the intellectual disability population may be under-recognized and under-treated, especially in • Z. Chen and R. Ansari are with the Department of Electrical and Computer Engineering, University of Illinois at Chicago E-mail: zchen35@uic.edu, ransari@uic.edu • D. Wilkie is with the Department of Biobehavioral Nursing, University of Florida E-mail : diwilkie@uﬂ.edu Manuscript received May 28, 2018; those with impaired capacity to communicate about their pain. A study of patients undergoing procedural pain [71] showed a strong relationship between procedural pain and behavioral responses and it identiﬁed speciﬁc procedural pain behaviors that included facial expressions of grimacing, wincing, and shutting of eyes. It was relatively rare for facial expressions to be absent during a painful procedure. Findings by Payen et al [68] strongly support the use of facial expression as a pain indicator in critically ill sedated patients. A study of pain assessment [61] in elderly patients with severe dementia provides evidence that patients with pain show more pronounced behavioral response compared with patients without pain and note that clinician observations of facial expressions are accurate means for assessing the presence of pain in patients unable to communicate verbally because of advanced dementia. Research has shown that facial expressions can provide reliable measures of pain across human lifespan and culture varieties [99] and there is also good consistency of facial expressions corresponding to painful stimuli. Assessment of facial expression of pain not only brings added value when verbal report is available but also served as a key behavior indicator for pain in the scenario of non-communicating patients. Detailed coding of facial activity provides a mechanism for understanding of different parameters of pain that are unavailable in self-report measures [17',\n",
       " '1408.2584': 'The ﬁeld of digital topology has been developed over the past few decades, motivated by computer graphics, image processing, and other applications. See [14] for an early foundational work. Three main settings for studying digital objects have emerged: the Khalimsky topology on Zn [13, 15], geometric realizations of subsets of Zn into Rn [5], and graph-like adjacency structures on discrete sets [2, 4, 9] typically called digital images. This paper works in the ﬁnal setting but de-emphasizes the traditional focus on spaces given by subsets of Zn with various “rectangular” adjacency grids. As in classical topology, invariants are of particular interest in the study of digital spaces. Homeomorphism invariants, such as the fundamental group, homology groups, and the Euler characteristic are studied in [2, 4, 9]. But homeomorphisms of digital images are very strict (for example, they must preserve the number of points), so it is natural to expand this study to homotopy equivalences, which allow for more freedom. In classical topology, the Euler characteristic and homology groups are also homotopy equivalence invariants, but a counterexample is given in [9] showing this does not hold for digital images. Digital homotopy equivalence often behaves counterintuitively when compared to classical topology. For example, we will see that all cycles of fewer than ﬁve points are homotopy equivalent to a point, while any two cycles of diﬀerent lengths greater than or equal to 5 will not be homotopy equivalent to one another (this result also appears in [3]). The aim of this paper is to develop tools and a numerical invariant to capture properties which are preserved by homotopy equivalences and to use these tools to classify digital images by their homotopy types. Unlike several other existing invariants for digital images, ours is a “true” digital invariant: it is not analogous to any invariant in classical topology. Homotopy equivalence of digital images is deﬁned in the obvious way as in [3]. While the equivalence relation has been mentioned in several papers, no numerical invariants seem to have been developed (other than the number of connected components, which is easily seen to be an invariant). We note that there is an established notion of homotopy equivalence for graphs described in [6]; however, 1  2 J. HAARMANN, M. MURPHY, C. PETERS, AND P. C. STAECKER the homotopy equivalence relation used in that theory is not equivalent to the one used in digital topology. A catalog of “irreducible” graphs similar to our own, but using this other homotopy notion, appears in [12]. Our homotopy relation more closely parallels the homotopy equivalence of classical topology. The paper is organized as follows: In Section 2 we present the necessary background. Then in Section 3 we propose a “loop-counting” homotopy equivalence invariant for digital images and compute this number for some digital images. In Section 4 we catalog all connected digital images on 7 and fewer points, up to homotopy equivalence, and give some partial results for images on 8 points. In Section 5 we show how our techniques answer a question posed by Boxer in [3',\n",
       " '1106.4221': 'Opinions represent a conspicuous part of our mental representations. A large part of our social time is spent in exchanging, evaluating, revising and comparing our opinions. We also say, about many diﬀerent issues, that we have opinions and we try to convince others about the groundedness of our own opinions. Since the beginning of the last century, social psychologists have been interested in understanding the speciﬁcity of opinions, as compared to other kinds of mental representations, by focusing their attention on the multiplicity of dimensions, including attitudes, beliefs ∗Central European University, Hungary email: GiardiniF@ceu.hu †University of Siena, Italy email: walter.quattriocchi@unisi.it ‡Labss-ISTC-CNR, Italy email: rosaria.conte@istc.cnr.it 1  September 21, 2018 7:14 WSPC/INSTRUCTION FILE OpinionsECCS˙ArxiV 2 Francesca Giardini, Walter Quattrociocchi, Rosaria Conte and evaluations, that take part within this phenomenon. Also political science has always been very attentive to what is considered as a way to measure people’s preferences and beliefs about publicly relevant issues. Many of these contributions have been directed towards understanding the so-called public opinion and the processes through which it is possible to inﬂuence it, manipulating people’s awareness and tendencies ([18]). More recently, other disciplines have shown a great interest regarding such an issue, ranging from computer science passing through socio-physics ([7, 13]) up to complexity science ([19]). Despite the large amount of studies on opinions, the term itself and the underlying concept are poorly speciﬁed and too general, since there are at least two classes of mental representations that can be termed opinions but they diﬀer with regard to important aspects. Moreover, relevant contributions coming from social psychology and computer science try to model distinct issues, thus making the analysis of opinions quite diﬃcult. This lack of sound theoretical contributions is often compensated by giving more preeminence to transmission and communication processes, thus partially putting aside the ontological issue. In this work we propose a theoretical account in which, starting from a critical review of approaches coming from social psychology and computer science, the necessity of a cognitive approach is claimed. Deﬁning the speciﬁc cognitive features that characterize an opinion, thus distinguishing it from other mental representations, and introducing also two diﬀerent kinds of opinions, evaluative and factual, we will claim for the necessity of investigating the mental roots of opinions, in order to understand how they are transformed and manipulated within and between minds. This means that an opinion is speciﬁc with regard to other mental representations, that has special features and is transformed through speciﬁc mental processes. Deﬁning an opinion in terms of its mental ingredients permits to predict opinion change, its persistence, the eﬀects of contrasting forces and alternative paths of diﬀusion, because the diﬀerent forces are endogenously determined by speciﬁc rules. Understanding opinions, describing how they are generated and revised, and how fare opinions travel over the social space both as a consequence of social inﬂuence and as one of',\n",
       " '1811.10790': 'We consider the following index volatility model: y | x “ fpxβ‹, xyq ` gpG‹T xqϵ (1) where y is the response variable, x P Rd is the vector of predictors, and ϵ is a random error independent of x with Erϵs “ 0 and Erϵ2s “ 1. In the model above, the conditional mean and variance of the response depend on the multivariate predictors only through linear projections. The unknown parts of this semi-parametric model are link functions f : R Ñ R and g : Rv Ñ R, which are nonparametric components, and signals β‹ P Rd and G‹ “ pγ‹ 1, . . . , γ‹ vq P Rdˆv, which are parametric components satisfying β‹T β‹ “ 1 and G‹T G‹ “ Iv. See Yang et al. (2017a) and Dudeja and Hsu (2018) for a similar setup. Li (1991) termed the linear space spanned by the direction of the projections as eﬀective dimension reduction (e.d.r.). In this paper, we focus our attention to the estimation of G‹. In order to emphasize the main contribution of the work, we assume that the conditional mean of y given x follows a single index model. We note, however, that this assumption is not crucial and we will be able to estimate G‹ as long as the mean function can be estimated suﬃciently quickly, as we illustrate later. Estimators of f and g only depend on the projection of predictors x onto the e.d.r. direction. In particular, one can apply local polynomial regression or a spline-based method on tyi, bβT xi, b GT xiun i“1 to estimate f and g once bβ and b G are computed. Furthermore, the estimation of the nonparametric components does not depend on the ambient dimensionality d of the problem. 1 arXiv:1811.10790v3  [math.ST]  25 May 2020  Thus, our focus will be on estimating parametric components in a high-dimensional setting, allowing for heavy-tailed covariates x, without using knowledge of f and g. Model in (1) has been widely studied in the literature as it allows for ﬂexible modeling of data without making rigid assumptions that parametric models make, while at the same time allowing for tractable estimation without suﬀering from the curse of dimensionality that obsesses fully nonparametric methods (Robins and Ritov, 1997; Bach, 2017). When the variance function is constant and does not depend on the predictors x, the model (1) becomes the homoscedastic single index model (SIM), which plays a prominent role in econometrics and applied quantitative sciences (see, for example, Sharpe (1963); Collins and Barry (1986); Stock and Watson (1988)). Due to its wide-ranged applicability, a number of estimation procedures were proposed and studied (see Ichimura (1993); H¨ardle et al. (1993); Horowitz and H¨ardle (1996); Xia et al. (2002b); Delecroix et al. (2006) and references therein). Li (1991) developed the sliced inverse regression (SIR), which is one of the ﬁrst widespread methods for estimating the e.d.r. direction. Subsequently, a number of more advanced methods were proposed for estimating',\n",
       " '1808.02932': 'Sequential decision making aims to optimize interactions with the world (exploit), while simultaneously learning how the world operates (explore). The multi-armed bandit (MAB) [Lattimore and Szepesv´ari, 2020] is a natural abstraction for a wide variety of real-world challenges that require learning while simultaneously maximizing rewards [Lai and Robbins, 1985]. The name ‘bandit’ ﬁnds its origin in the playing strategy one must devise when facing a row of slot machines. The contextual MAB, where at each interaction with the world side information (known as ‘context’) is available, is a natural extension of the bandit problem. The study of the exploration-exploitation trade-oﬀcan be traced back to the beginning of the past century, with important contributions by Thompson [1935], Robbins [1952] and Lai and Robbins [1985]. Recently, a renaissance of the study of MAB algorithms has ﬂourished [Slivkins, 2019, Lattimore and Szepesv´ari, 2020], attracting interest for its application in science, medicine, engineering, business and operations research [Li et al., 2010, Villar et al., 2015, Hill et al., 2017, Aziz et al., 2021]. In practice, bandit applications are personalized via the contextual MAB paradigm, and often deal continuous observations: e.g., to measure dwell time in online advertising and content recommendation, or to quantify drug responses in clinical trials. Among the many bandit algorithms available, Thompson [1933] sampling provides an elegant approach to tackle the exploration-exploitation dilemma. It updates a posterior over expected rewards for each arm, and chooses actions based on the probability that they are optimal. It has been empirically and theoretically proven to perform competitively for MAB models within the exponential family [Agrawal and Goyal, 2013b,a, Korda et al., 2013]. Its applicability to the more general reinforcement learning setting of Markov decision processes [Burnetas and Katehakis, 1997] has tracked momentum as well [Gopalan and Mannor, 2015, Ouyang et al., 2017]. A Thompson sampling policy requires access to posterior samples of the true reward model. Unfortunately, maintaining such posterior is intractable for distributions not in the exponential family [Russo et al., 2018]. Therefore, developing practical MAB methods to balance exploration and exploitation in domains that do not pertain to such a reward family remains largely unsolved. In an eﬀort to extend Thompson sampling to complex bandit scenarios, where the true reward model distribution is often unknown, researchers have considered neural-network based reward functions with Bayesian inference [Riquelme et al., 2018], bootstrapping [Osband and Roy, 2015] and ensembling [Lu and Roy, 2017] based techniques —a detailed overview of state-of-the art MAB methods is provided in Section 2.1. On the contrary, the novelty of this work is on exploiting Bayesian nonparametric (BNP) mixture models for Thompson sampling to perform MAB optimization under reward model uncertainty. We here adopt the Bayesian generative view of Thompson sampling, and argue that modeling bandit reward distributions via BNP mixtures —which can estimate continuous reward distributions and adjust model complexity to the observed distribution of rewards— can provide successful bandit',\n",
       " '1702.07463': 'Segmental structure is a common pattern in many types of sequences, typically, phrases in human languages and letter combinations in phonotactics rules. For instances, • Phrase structure. “Machine learning is part of artiﬁcial intelligence” →[Machine learning] [is] [part of] [artiﬁcial intelligence]. • Phonotactics rules. “thought” →[th][ou][ght]. The words or letters in brackets “[ ]” are usually considered as meaningful segments for the original sequences. In this paper, we hope to incorporate this type of segmental structure information into sequence modeling. 1Microsoft Research 2Carnegie Mellon University 3Amazon 4Citadel Securities LLC. Correspondence to: Chong Wang <chowang@microsoft.com>. Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017 by the author(s). 1The source code is available at https://github.com/ posenhuang/NPMT. Mathematically, we are interested in constructing a conditional probability distribution p(y|x), where output y is a sequence and input x may or may not be a sequence. Suppose we have a segmented sequence. Then the probability of this sequence is calculated as the product of the probabilities of its segments, each of which is modeled using existing tools such as recurrent neural networks (RNNs), long-short term memory (LSTM) (Hochreiter & Schmidhuber, 1997), or gated recurrent units (GRU) (Chung et al., 2014). When the segmentation for a sequence is unknown, we sum over the probabilities from all valid segmentations. In the case that the input is also a sequence, we further need to sum over all feasible alignments between inputs and output segmentations. This sounds complicated. Fortunately, we show that both forward and backward computations can be tackled with a dynamic programming algorithm without resorting to any approximations. This paper is organized as follows. In Section 2, we describe our mathematical model which constructs the probability distribution of a sequence via its segments, and discuss related work. In Section 3, we present an efﬁcient dynamic programming algorithm for forward and backward computations, and a beam search algorithm for decoding the output. Section 4 includes two case studies to demonstrate the usefulness of our approach through both quantitative and qualitative results. We conclude this paper and discuss future work in Section 5. 2. Sequence modeling via segmentations In this section, we present our formulation of sequence modeling via segmentations. In our model, the output is always a sequence, while the input may or may not be a sequence. We ﬁrst consider the non-sequence input case, and then move to the sequence input case. We then show how to carry over information across segments when needed. Related work is also discussed here. 2.1. Case I: Mapping from non-sequence to sequence Assume the input x is a ﬁxed-length vector. Let the output sequence be y1:T . We are interested in modeling the probability p(y1:T |x) via the segmentations of y1:T . Denote by Sy the set containing all valid segmentations of y1:T . Then for',\n",
       " '1306.1520': 'We consider the reinforcement learning problem formalized through Markov Decision Processes (MDP) (Sutton and Barto, 1998; Puterman, 1994), in the situation where the state space is large and approximation is required. On the one hand, Approximate Dynamic Programming (ADP) is a standard approach for handling large state spaces. It consists in mimicking in an approximate form the standard algorithms that were designed to optimize globally the policy (maximizing the associated value function for each state). On the other hand, Local Policy Search (LPS) consists in parameterizing the policy (the so-called “actor”) and locally maximizing the associated expected value function, for example using a (natural) gradient ascent (Baxter and Bartlett, 2001; Kakade, 2001) (possibly with a critic (Sutton et al., 1999; Peters and Schaal, 2008)), expectation-maximization (EM) (Kober and Peters, 2011), or even directly using some black-box optimization algorithm (Heidrich-Meisner and Igel, 2008). The distinction we make here between ADP and LPS relies on the overall algorithmic scheme that is considered (dynamic programming or local expected value maximization). For example, we see the Direct (or Classiﬁcation-based) Policy Iteration (DPI) algorithm (Lagoudakis and Parr, 2003; Fern et al., 2006; Lazaric et al., 2010) as belonging to the ADP family: even if it can be seen as a policy search method (since there is no representation for the value function), the algorithm follows the general approximate policy iteration (API) scheme. The Conservative Policy Iteration (CPI) algorithm (Kakade and Langford, 2002)—of which the analysis has close connections with what we are going to argue in this paper—might be considered at the frontier of ADP and LPS: it is based on a damped version of API, where each new policy is a convex mixture of the current policy and the greedy one, the precise combination being chosen such as guaranteeing an improvement in terms of the local ﬁtness (the value function averaged over some predeﬁned distribution). Following the seminal works by Bertsekas and Tsitsiklis (1996), it has been shown that ADP algorithms enjoy global performance guarantees, bounding the loss of using the computed policy instead of using the optimal one as a function of the approximation errors involved along the iterations, for example for approximate policy iteration (API) (Munos, 2003), for approximate value iteration (AVI) (Munos, 1  2007), or more generally for approximate modiﬁed policy iteration (AMPI) (Scherrer et al., 2012). To the best of our knowledge, similar general guarantees do not exist in the literature for LPS algorithms. Bounds have been derived for the CPI algorithm by Kakade and Langford (2002), and at ﬁrst glance, one may think that this was due to its closeness to the ADP family. In general though, the best one can hope for LPS is to get a local optimum of the optimized ﬁtness (that is, a local maximum of the averaged value function), and the important question of the loss with respect to the optimal policy remains open. As for in',\n",
       " '1501.04704': 'Nowadays, data play a more and more important role in our life. At the same time, the scientiﬁc community face a challenging problem: how to eﬃciently extract useful information from massive amount of data. In many real world problems, especially in engineering and physical problems, frequencies of the signal are usually very useful to help us understand the underlying physical mechanism. Hence, many time frequency analysis methods have been developed, for instance, the windowed Fourier transform, the wavelet transform [3, 11], the Wigner-Ville distribution [8], etc. In recent years, an adaptive time frequency analysis method, the Empirical Mode Decomposition (EMD) method [7, 16] was developed. This method provides an eﬃcient adaptive method to extract frequency information. The EMD method has found to be very useful in many applications. EMD method is purely empirical, it still lacks a rigorous mathematical foundation. Recently, several methods have been proposed attempting to provide a mathematical foundation for EMD ∗Applied and Comput. Math, MC 9-94, Caltech, Pasadena, CA 91125. Email: hou@cms.caltech.edu. †Mathematical Sciences Center, Tsinghua University, Beijing, China, 100084. Email: zqshi@math.tsinghua.edu.cn. 1  method, see e.g. the synchrosqueezed wavelet transform [4], the Empirical wavelet transform [6], the variational mode decomposition [9]. In the last few years, inspired by the EMD method and compressive sensing [1, 2, 5], we proposed a novel time-frequency analysis method based on the sparsest time-frequency representation of multiscale data [12]. In this method, the signal is decomposed into several components f(t) = M X j=1 aj(t) cos θj(t) + r(t), t ∈R, (1) where aj(t), θj(t) are smooth functions, θ′ j(t) > 0, j = 1, · · · , M, and r(t) is a small residual. We assume that aj(t) and θ′ j are less oscillatory than cos θj(t). The exact meaning of less oscillatory will be made clear later. We call aj(t) cos θj(t) as the Intrinsic Mode Functions (IMFs) [7]. One main diﬃculty in computing the decomposition (1) is that the decomposition is not unique. To pick up the ”best” decomposition, we proposed to decompose the signal by looking for the sparsest decomposition by solving a nonlinear optimization problem: Minimize M (ak)1≤k≤M ,(θk)1≤k≤M Subject to: f = M X k=1 ak cos θk, ak cos θk ∈D, where D is the dictionary consist of all IMFs (see [12] for its precise deﬁnition). To solve (2), we proposed two algorithms. The ﬁrst one is based on matching pursuit [12] and the other one is based basis pursuit [13]. In a subsequent paper [14], the authors proved the convergence of their nonlinear matching pursuit algorithm for periodic data that satisfy certain scale separation property. Although the model (1) has been applied to a number of applications with success and the decomposition methods have been shown to be eﬀective and eﬃcient, there are also some applications such as the Stokes waves or some nonlinear dynamic systems for which',\n",
       " '1812.00893': 'In many real-world application of visual recognition, the training and testing data distributions are often different due to dataset bias [41]. This distribution discrepancy decreases the generalization capability of the learned visual representations. One example is that the model trained on synthetic images fails to generalize well on the real-world images. To eliminate the effect of the dataset bias, a common used strategy is unsupervised domain adaption (UDA). In UDA, we ∗Corresponding Author (a) ResNet (b) Domain alignment (c) SCA Figure 1. Visualization of cross-domain embeddings for task A → W on Ofﬁce-31 [35]. We present the 2D visualization of t-SNE for embeddings learned by (a) ResNet (trained on source images only), (b) domain alignment (based on JMMD [28]), and (c) SCA (ours). For the ﬁrst row, different colors denote data of different object categories. For the second row, red color represents the data of W, and blue color represents data of A. Under SCA, different classes are well-separated, and the two domains are wellaligned on the class level. Best viewed in color. are provided with a labeled source dataset and an unlabeled target dataset, and the goal is to learn a model on the source dataset which minimizes the test error on the target dataset. In literature, recent UDA methods [10, 28, 9, 42, 43, 25] adopt deep neural networks to learn a shared embedding space where the distribution discrepancy can be reduced. These methods typically involve two objectives: 1) learn embeddings that maintain a low classiﬁcation error on the source dataset; 2) make embeddings domain-invariant, such that the classiﬁer trained on the source can be directly used on the target dataset. To learn domain-invariant embeddings, recent methods usually minimize some measure of domain variance [43, 28, 25] (such as correlation distance [40]) or adopt the adversarial learning [10, 9, 42]. However, this line of methods have an intrinsic limitation: they only focus on reducing the global distribution discrepancy, without exploiting the class-level relations among the source and 1 arXiv:1812.00893v2  [cs.CV]  22 Jan 2019  target images. Thus, even with perfect distribution alignment, the images with different labels from different domains might be misaligned nearby in the embedding space. As shown in Fig. 1(b), domain-level alignment (based on JMMD [28]) has the ability to reduce distribution discrepancy. However, these exists the semantic misalignment problem in the aligned embeddings. For examples, some samples from different classes are mapped nearby in the embedding space. This semantic misalignment is detrimental to the classiﬁer performance on the target dataset. Motivated by this problem, we present a similarity constrained alignment (SCA) method for UDA. The working mechanism of SCA is that it can align the distributions, while preserving the class-level relations among source and target images. Speciﬁcally, we add a similarity-preserving constraint for the source and target images during domain alignment. The impact of the similarity-preserving constraint',\n",
       " '1609.02200': 'Unsupervised learning of probabilistic models is a powerful technique, facilitating tasks such as denoising and inpainting, and regularizing supervised tasks such as classiﬁcation (Hinton et al., 2006; Salakhutdinov & Hinton, 2009; Rasmus et al., 2015). Many datasets of practical interest are projections of underlying distributions over real-world objects into an observation space; the pixels of an image, for example. When the real-world objects are of discrete types subject to continuous transformations, these datasets comprise multiple disconnected smooth manifolds. For instance, natural images change smoothly with respect to the position and pose of objects, as well as scene lighting. At the same time, it is extremely difﬁcult to directly transform the image of a person to one of a car while remaining on the manifold of natural images. It would be natural to represent the space within each disconnected component with continuous variables, and the selection amongst these components with discrete variables. In contrast, most stateof-the-art probabilistic models use exclusively discrete variables — as do DBMs (Salakhutdinov & Hinton, 2009), NADEs (Larochelle & Murray, 2011), sigmoid belief networks (Spiegelhalter & Lauritzen, 1990; Bornschein et al., 2016), and DARNs (Gregor et al., 2014) — or exclusively continuous variables — as do VAEs (Kingma & Welling, 2014; Rezende et al., 2014) and GANs (Goodfellow et al., 2014).1 Moreover, it would be desirable to apply the efﬁcient variational autoencoder framework to models with discrete values, but this has proven difﬁcult, since backpropagation through discrete variables is generally not possible (Bengio et al., 2013; Raiko et al., 2015). We introduce a novel class of probabilistic models, comprising an undirected graphical model deﬁned over binary latent variables, followed by multiple directed layers of continuous latent variables. This class of models captures both the discrete class of the object in an image, and its speciﬁc continuously deformable realization. Moreover, we show how these models can be trained efﬁciently using the variational autoencoder framework, including backpropagation through the binary latent variables. We ensure that the evidence lower bound remains tight by incorporating a hierarchical approximation to the posterior distribution of the latent variables, which can model strong correlations. Since these models efﬁciently marry the variational autoencoder framework with discrete latent variables, we call them discrete variational autoencoders (discrete VAEs). 1Spike-and-slab RBMs (Courville et al., 2011) use both discrete and continuous latent variables. 1 arXiv:1609.02200v2  [stat.ML]  22 Apr 2017  Published as a conference paper at ICLR 2017 1.1 VARIATIONAL AUTOENCODERS ARE INCOMPATIBLE WITH DISCRETE DISTRIBUTIONS Conventionally, unsupervised learning algorithms maximize the log-likelihood of an observed dataset under a probabilistic model. Even stochastic approximations to the gradient of the loglikelihood generally require samples from the posterior and prior of the model. However, sampling from undirected graphical models is generally intractable (Long & Servedio, 2010), as is sampling from the posterior of a directed graphical model conditioned on its leaf variables (Dagum & Luby, 1993). In contrast to the exact log-likelihood, it can be computationally efﬁcient to optimize a lower',\n",
       " '1605.08671': 'In this paper we study a speciﬁc combinatorial, pure exploration, stochastic bandit setting. More precisely, consider a stochastic bandit setting where each arm has mean µk. The learner can sample sequentially T > 0 samples from the arms and aims at ﬁnding as efﬁciently as possible the set of arms whose means are larger than a threshold τ ∈R. In this paper, we refer to this setting as the Thresholding Bandit Problem (TBP), which is a speciﬁc instance of the combinatorial pure exploration bandit setting introduced in (Chen et al., 2014). A simpler ”one armed” version of this problem is known as the SIGN-ξ problem, see (Chen & Li, 2015). This problem is related to the popular combinatorial pure exploration bandit problem known as the TopM problem where the aim of the learner is to return the set of M arms with highest mean (Bubeck et al., 2013b; Gabillon et al., 2012; Kaufmann et al., 2015; Zhou et al., 2014; Cao et al., 2015) - which is a combinatorial version of the best arm identiﬁcation problem (Even-Dar et al., 2002; Mannor & Tsitsiklis, 2004; Bubeck et al., 2009; Audibert & Bubeck, Proceedings of the 33 rd International Conference on Machine Learning, New York, NY, USA, 2016. JMLR: W&CP volume 48. Copyright 2016 by the author(s). 2010; Gabillon et al., 2012; Jamieson et al., 2014; Karnin et al., 2013; Kaufmann et al., 2015; Chen & Li, 2015). To formulate this link with a simple metaphor, the TopM problem is a ”contest” and the TBP problem is an ”exam”: in the former, the learner wants to select the M arms with highest mean, in the latter the learner wants to select the arms whose means are higher than a certain threshold. We believe that this distinction is important and that in many applications the TBP problem is more relevant than the TopM, as in many domains one has a natural ”efﬁciency”, or ”correctness” threshold above which one wants to use an option. For instance in industrial applications, one wants to keep a machine if its production’s value is above its functioning costs, in crowd-sourcing one wants to hire a worker as long as its productivity is higher than its wage, etc. In addition to these applications derived from the TopM problem, the TBP problem has applications in dueling bandits and is a natural way to cast the problem of active and discrete level set detection, which is in turn related to the important applications of active classiﬁcation, and active anomaly detection - we detail this point more in Subsection 3.1. As mentioned previously, the TBP problem is a speciﬁc instance of the combinatorial pure exploration bandit framework introduced in (Chen et al., 2014). Without going into the details of the combinatorial pure exploration setting for which the paper (Chen et al., 2014) derives interesting general results, we will summarize what these results imply for the particular TBP and TopM',\n",
       " '1804.06252': 'W E give a brief review of the classical low rank approximation of matrices and introduce the background modeling problem. A. Low-rank approximation The standard low rank approximation aka the principal component analysis (PCA) problem can be deﬁned as an approximation to a given matrix A ∈Rm×n by a rank r matrix under the Frobenius norm: X∗= arg min X∈Rm×n rank(X)≤r ∥A −X∥2 F , (1) where ∥· ∥F denotes the Frobenius norm of matrices. The solutions to (1) are given by X∗= Hr(A) := UΣrV T , (2) where A has singular value decompositions A = UΣV T , and Σr(A) is the diagonal matrix obtained from Σ by hardthresholding operation that keeps only r largest singular values and replaces the other singular values by 0 along the diagonal. This is also referred to as Eckart-Young-Mirsky’s theorem ([1]) and is closely related to the PCA method in statistics [2]. In image processing, rank-reduced signal processing, computer vision, and in many other engineering applications Aritra Dutta is with the Visual Computing Center, Division of Computer, Electrical and Mathematical Sciences and Engineering (CEMSE) at King Abdullah University of Science and Technology, Thuwal, Saudi Arabia-239556900, e-mail: aritra.dutta@kaust.edu.sa (see https://aritradutta.weebly.com/) Xin Li is with the Department of Mathematics, University of Central Florida, FL, USA-32816, email: xin.li@ucf.edu. Peter Richt´arik is with the Visual Computing Center, Division of Computer, Electrical and Mathematical Sciences and Engineering (CEMSE) at King Abdullah University of Science and Technology, University of Edinburgh, and MIPT, e-mail: peter.richtarik@kaust.edu.sa (see http://www.maths.ed.ac.uk/∼prichtar/). SVD is a successful dimension reduction tool. The low rank matrix obtained through PCA is a good approximation to the data matrix A if A contains only normally (and independently) distributed noise. But, in many real world problems, if sparse large errors or outliers are present in the data matrix, PCA fails to deal with it and thus additional regularization has been introduced to accommodate the sparse outliers. One can think the background modeling problem in video sequences as a good example of such a real world problem. In the next section we will review the classic background modeling problem in light of matrix decomposition and brieﬂy survey several stateof-the-art algorithms used to solve it. B. Background modeling in matrix decomposition framework Background modeling and moving object detection are two key steps in many computer vision systems and videosurveillance applications. In the past decade, one of the most prevalent approaches used in background estimation is to treat it as a matrix decomposition problem ([3], [4], [5]). Given a sequence of n video frames with each frame converted into a vector ai ∈Rm, i = 1, 2, ..., n, the data matrix A = (a1, a2, ..., an) ∈Rm×n is the collection of all the frame vecto',\n",
       " '1604.00326': 'Semantic attributes describe the object’s shape, texture and parts. They have the unique property of being both machine detectable and human understandable. By changing the recognition task from labeling to describing, attributes represent an adequate knowledge that can be easily transferred and shared with new visual concepts. Thus, they can be used to recognize unseen classes with no training samples (i.e. zero-shot classiﬁcation). In the prevailing approach, attributes are learned from all seen classes and then reused to describe or classify an unseen one. However, this doesn’t account for the high intra-attribute variance. Using all the seen classes helps in learning visual semantics in a very abstract manner. Hence, subsets of classes that share similar attributes cannot be distinguished easily. Eventually, the ﬁne properties of the attribute that help in discriminating a group from another are lost when it is learned from all the classes. Consider for example the attribute beak in Figure 1. The global attribute model would learn that a beak is an elongated extension at a certain position relative to the head; i.e. ignoring the disRed-HeadedPileated-  Red-BeliedWoodpecker  GreenFlorida-  BlueRufous-  Ruby-ThroatedAnna-  LaysanBlack-FootedSooty-  California-Gull  Beak?  Jay  Hummingbird  Albatross  Figure 1: The high intra-attribute variance is better represented at different semantic levels of abstraction. This helps in directing the transfer process to identify the most suitable source of knowledge to share with a novel class. tinctive long thin beak shape of the hummingbird species or the wide curved-end of the albatross species. In other words, the global model does not take advantage of the rich information already available in the source dataset. This results in transferring less discriminative attributes to the novel class. On the other hand, capturing these speciﬁc properties of beak relative to each subgroup of birds is beneﬁcial. It gives us the option to select the most proper type of beak to share with the unseen class. Accordingly, knowing that both Gull and Albatross are Seabirds, it is intuitive and probably more discriminative to describe the beak of the California-Gull as an albatross-like-beak. In this work we study the beneﬁt of learning attributes at different levels of abstraction, from the most speciﬁc that distinguish one class from another to the most general that are learned over all categories. We propose a novel hierarchical transfer model that can ﬁnd the best type of attributes to be shared with an unseen class. We evaluate the proposed model on three challenging datasets each with a different granularity of object categories. The evaluation shows that signiﬁcant gain can be achieved with our guided transfer model with improvements from 26% and up to 35% over state-of-the-art in zero-shot classiﬁcation. arXiv:1604.00326v1  [cs.CV]  1 Apr 2016  2. Related work Our work relates to two ﬁelds in computer vision literature; the attribute-based recognition',\n",
       " '1811.04136': 'Kernel methods are a pillar of machine learning and general data analysis. These approaches consider classic problems such as PCA, linear regression, linear classiﬁcation, k-means clustering which at their heart ﬁt a linear subspace to a complex data set. Each of the methods can be solved by only inspecting the data via a dot product ⟨x, p⟩. Kernel methods, and speciﬁcally the “kernel trick,” simply replaces these Euclidean dot products with a non-linear inner product operation. The two most common inner products are the polynomial kernel Kz(x, p) = (⟨x, p⟩+ 1)z and the Gaussian kernel K(x, p) = exp(−∥x −p∥2). The “magic” of the kernel method works mainly because of the existence of a reproducing kernel Hilbert space (RKHS) HK associated with any positive deﬁnite (p.d.) kernel [43] K. It is a function space, so for any data point x ∈Rd, there is a mapping φ : Rd →HK so φ(x) = K(x, ·). Since φ(x) is a function with domain Rd, and each “coordinate” of φ(x) is associated with another point p ∈Rd, there are an inﬁnite number of “coordinates,” and HK can be inﬁnite dimensional. However, since ⟨φ(x), φ(p)⟩HK = K(x, p), this embedding does not ever need to be computed, we can simply evaluate K(x, p). And life was good. However, at the dawn of the age of big data, it became necessary to try to explicitly, but approximately, compute this map φ. Kernel methods typically start by computing and then analyzing the n × n gram matrix KX where (KX)i,j = K(xi, xj) for a data sets X of size n. As n became huge, this became untenable. In a hallmark paper, Rahimi and Recht [37] devised random Fourier features (RFFs) for p.d. kernels (with max value 1, e.g., Gaussians) that compute a random map ˜φ : Rd →R ˜ D so  ˜φ(x), ˜φ(p) \\x0b is an unbiased estimate  2 of K(x, p), and with probability at least 1 −δ has error |K(x, p) −  ˜φ(x), ˜φ(p) \\x0b | ≤ε. For just one pair of points they require ˜D = O((1/ε2) log(1/δ)), or for all comparisons among n points ˜Dn = ((1/ε2) log(n/δ)), or for any points in a region Λ of volume vol(Λ) ≤V , then ˜DV = ((1/ε2) log(V/δ)). However, relative-error-preserving RKHS embeddings for p.d. kernels are impossible without some restriction on the size n or domain Λ of the data. Consider n data points each far from each other so any pair x, p ∈Rd satisﬁes K(x, p) < 1/n. In any relative-errorapproximate embedding ˆφ : Rd →R ˆ D, each point must be virtually orthogonal to all other points, and hence Ω(n) dimensions are required [28]. Instead, to obtain (almost) relative-error results in big data sets, researchers have relied on other approaches such as sampling [45], exploiting structure of p.d',\n",
       " '1611.05088': 'A recent trend in developing visual recognition models is to scale up the number of object categories. However, most existing recognition models are based on supervised learning and require a large amount (at least 100s) of training samples to be collected and annotated for each object class to capture its intra-class appearance variations [7]. This severely limits their scalability – collecting daily objects such as chair is easier, but many other categories are rare (e.g., a newly identiﬁed specie of beetle on a remote paciﬁc island). None of these models can work with few or even no training samples for a given class. In contrast, humans are very good at recognising objects without seeing any visual samples, i.e., zero-shot learning (ZSL). For example, a child would have no problem recognising a zebra if she has seen horses before and also read elsewhere that a zebra is a horse but with black-and-white stripes on it. Inspired by humans’ ZSL ability, recently there is a surge of interest in machine ZSL [3, 54, 25, 1, 40, 46, 11, 34, 12, 15, 27, 52, 37, 5, 14, 4, 6, 55, 56]. A zero-shot learning method relies on the existence of a labelled training set of seen classes and the knowledge about how an unseen class is semantically related to the seen classes. Seen and unseen classes are usually related in a high dimensional vector space, called semantic space, where the knowledge from seen classes can be transferred to unseen classes. The semantic spaces used by most early works are based on semantic attributes [9, 10, 35]. Given a deﬁned attribute ontology, each class name can be represented by an attribute vector and termed as a class prototype. More recently, semantic word vector space [46, 11] and sentence descriptions/captions [37] have started to gain popularity. With the former, the class names are projected into a word vector space so that different classes can be compared, whilst with the latter, a neural language model is required to provide a vector representation of the description. With the semantic space and a visual feature representation of image content, ZSL is typically solved in two steps: (1) A joint embedding space is learned where both the semantic vectors (prototypes) and the visual feature vectors can be projected to; and (2) nearest neighbour (NN) search is performed in this embedding space to match the projection of an image feature vector against that of an unseen class prototype. Most state-of-the-arts ZSL models [12, 14, 3, 4, 40, 54, 25] use deep CNN features for visual feature representation; the features are extracted with pretrained CNN models. They differ mainly in how to learn the embedding space given the features. They are thus not end-to-end deep learning models. In this paper, we focus on end-to-end learning of a deep embedding based ZSL model which offers a number of advantages. First, end-to-end optimisation can potentially',\n",
       " '1711.05795': 'Recognizing entities and their types is a core problem in natural language processing, underlying complex natural language understanding problems in relation extraction (Yaghoobzadeh et al., 2017), knowledge base construction, question answering (Lee et al., 2006), and query comprehension (Dalton et al., 2014). Early attempts at entity recognition focused only on very coarse grained types (Tjong Kim Sang and De Meulder, 2003; Hovy et al., 2006). More recently, there has been growing interest in models explicitly focused on entity typing with ﬁner grained typesets e.g. FIGER (Ling and Weld, 2012). The increasingly sophisticated natural language understanding tasks undertaken by the machine learning community often require commensurately more sophisticated world knowledge. This world knowledge, often organized hierarchically in ontologies, motivates our creation of a new ﬁne-grained, deep, and high-quality dataset of hierarchical types. Despite the increasing focus on ﬁne-grained typing, existing typesets still contain only on the order of 100 different types. Further, these typesets are either endowed with only a shallow hierarchy, typically on the order of two levels deep or don’t have links to existing KBs (see Table 1). In this work, we advocate for larger, deeper typesets and models that exploit the inherently hierarchical nature of these types. To this end, we present TypeNet, an expert-annotated type hierarchy containing 1941 individual types, with an average depth of 7.8. We also evaluate several models for ﬁne-grained entity typing, and establish a strong baseline of 74.8 MAP on the CoNLL-YAGO dataset (Hoffart et al., 2011) for our best model. With each entity having on the order of 30 types, there are clearly exciting opportunities for improvement from future research. Additionally, we investigate multi-task models that explicitly incorporate the hierarchical relations between types into the learning objective. 31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA. arXiv:1711.05795v1  [cs.CL]  15 Nov 2017  entity part physical entity relation abstraction location substance matter fluid object artifact whole broadcasting  station  beverage liquid device facility instrumentality station communication  system  conveyance mechanism /amusement_park/  ride  computer machine network mechanical  device  radio station /broadcast/  radio_network  standard communication measure medium of  exchange  system of  measurement  auditory  communication  /event/ speech  topic  /medicine/  hormone  secretion craft vehicle /food/nutrient narrative body_substance /finance/  currency  subject message liquid body  substance  /food/ingredient  /aviation/  aircraft_model  /comic_books/  comic_book_story  aircraft foodstuff Figure 1: Sampled types in the TypeNet hierarchy 2 Dataset Creation We now discuss TypeNet1, a new dataset of entity types for extremely ﬁne grained entity typing. TypeNet was created by manually aligning Freebase types to noun synsets from the WordNet hierarchy (Fellbaum, 1998), naturally producing a hierarchical type set. This was done by ﬁrst ﬁltering out all Freebase types that were linked to ≥20 entities, and then ﬁltering Freebase API types. The Freebase API types we ﬁltered were those in the domain \"/freebase\",\"/dataworld\",\"/schema\", \"/atom\", \"/scheme\" and \"/topics\". For each Freebase type in our ﬁltered set, we generate a list of candidate WordNet synsets through a substring match. The annotator the',\n",
       " '1602.07726': 'Generalization, informally, is the ability of a learner to reﬂect not just its training data, but properties of the underlying distribution from which the data are drawn. When paired with empirical risk minimization, it is one of the fundamental tools of learning. Typically, we say that a learning algorithm generalizes if, given access to some training set drawn i.i.d. from an underlying data distribution, it returns a hypothesis whose empirical error (on the training data) is close to its true error (on the underlying distribution). This is, however, a surprisingly brittle notion—even if the output of a learning algorithm generalizes, one may be able to extract additional hypotheses by performing further computations on the output hypothesis—i.e., by postprocessing—that do not themselves generalize. As an example, notice that the standard notion of generalization does not prevent a learner from encoding the entire training set in the hypothesis that it outputs, which in turn allows a data analyst to generate a hypothesis that over-ﬁts to an arbitrary degree. In this sense, traditional generalization is not robust to misinterpretation by subsequent analyses (postprocessing) (either malicious or naive). Misinterpretation of learning results is only one face of the threat—the problem is much more alarming. Suppose the output of a (generalizing) learning algorithm inﬂuences, directly or indirectly, the choice of future learning tasks. For example, suppose a scientist chooses a scientiﬁc hypothesis to explore on some data, on the basis of previously (generalizingly!) learned correlations in that data set. Or suppose a data scientist repeatedly iterates a model selection procedure while validating it on the same holdout set, attempting to optimize his empirical error. These approaches are very natural, but also can lead to false discovery in the ﬁrst case, and disastrous overﬁtting to the holdout set in the second [DFH+15c], because traditional generalization is not robust to adaptive composition. In this paper, we study two reﬁned notions of generalization—robust generalization and perfect generalization, each of which is preserved under post-processing (we discuss their adaptive composition guarantees more below). Viewed in relation to these two notions, diﬀerential privacy can also be cast as a third, intermediate generalization guarantee. It was previously known that diﬀerentially private algorithms were also robustly generalizing [DFH+15b, BNS+16]. As we show in this paper, however, diﬀerential privacy is a strictly stronger guarantee—there are proper learning problems that can be solved subject to robust generalization that cannot be solved subject to diﬀerential privacy (or with any other method previously known to guarantee robust generalization). Moreover, we show that every PAC learnable class (even over inﬁnite data domains) is learnable subject to robust generalization, with almost no asymptotic blowup in sample complexity (a comparable statement is not known for diﬀerentially private algorithms, and is known to be false for algorithms satisfying pure diﬀerential privacy). We also show that, in a sense, diﬀerential privacy is a strictly weaker guarantee',\n",
       " '1611.07174': 'S EQUENCE modeling is an important part of artiﬁcial intelligence, and an efﬁcient sequential model can help machine learn how to think as human intelligence and how to interact with the world by sequential actions and logical thinking skills. A major problem faced by sequence modeling is that the deep learning model suffers too much training time, and new powerful sequential models should be invented to meet the demand of both robustness and efﬁciency. Automatic speech recognition(ASR) is designed to transcript human speech into spoken phonemes. ASR has been Z. Zhang, Z. Sun, J. Liu, J. Chen and X. Zhang are with the Department of Physics, Sun Yat–Sen University, Guangzhou, 510275 P.R. China (e-mail: zhangzw3@mail2.sysu.edu.cn; sunzh6@mail2.sysu.edu.cn; liujq33@mail2.sysu.edu.cn; chenjw93@mail2.sysu.edu.cn; zhangxiao@mail.sysu.edu.cn). Z. Huo is with China University of Political Science and Law (e-mail: huozhao@cupl.edu.cn). C. H. Lee is with the Institute of High Performance Computing (e-mail: calvin-lee@ihpc.a-star.edu.sg). Manuscript received MM DD, YYYY; revised MM DD, YYYY. investigated for several decades. Traditionally, a statistical model of maximum likelihood decoding and maximum mutual information estimation are used for speech recognition [1], [2], the use of gaussian mixture model (GMM) combined with hidden markov model (HMM) for speech recognition had also become predominant several years ago [3], [4], [5]. With the spring-up of deep learning, deep neural network (DNN) with HMM states has been shown to outperform the traditional method of GMM-HMM [6], [7], [8], [9], [10], [11], thus many new training tricks have been proposed to improve the performance of DNNs for acoustic modeling, such as powerful non-linear activation functions, layer-wise mini-batch training, batch normalization, dropout and fast gradient descent method [21], [22], [23], [24], [25]. DNN is very good at exploiting non-linear feature representation, but it lacks internal time dependency and sequential modeling ability, since human speech is a sequential problem with dynamic features to handle. Recurrent neural network (RNN) is a powerful tool for sequential modeling owing to its recurrent hidden states between adjacent time-steps, and DNNs are gradually replaced by RNNs which have been successfully applied in ASR in the last several years. Meanwhile, Deep Long Short-term Memory RNNs and deep bidirectional RNNs are proposed to exploit long time memory in ASR [12], [13], [14], [15], [16], [17]. Besides, sequence training of RNNs with connectionist temporal classiﬁcation (CTC) has shown great performance in end-to-end ASR [18], [19], [20]. Traditional frame-wise cross entropy training needs pre-segmented data by hand, but CTC is an end-to-end training method for RNNs which decodes the output probability distribution into phoneme sequences without requiring pre-segmented training data. RNN has been widely used in ASR, but RNN can’t depict very long time dependency because of its vanishing gradient problem, and deeper RNN seems to',\n",
       " '1811.00287': 'Neural Machine Translation (NMT) is an endto-end learning approach to machine translation which has recently shown promising results on multiple language pairs (Luong et al., 2015; Shen et al., 2015; Wu et al., 2016; Gehring et al., 2017a; Kalchbrenner et al., 2016; Sennrich et al., 2015; Vaswani et al., 2017). Unlike conventional Statistical Machine Translation (SMT) systems (Koehn 1The work is partially done when the ﬁrst author worked at Tencent. et al., 2003; Chiang, 2005) which consist of multiple separately tuned components, NMT aims at building upon a single and large neural network to directly map input text to associated output text (Sutskever et al., 2014). In general, there are several research lines of NMT architectures, among which the Enc-Dec NMT (Sutskever et al., 2014) and the Enc-Dec Att NMT are of typical representation (Bahdanau et al., 2014; Wu et al., 2016; Vaswani et al., 2017). The Enc-Dec represents the source inputs with a ﬁxed dimensional vector and the target sequence is generated from this vector word by word. The Enc-Dec, however, does not preserve the source sequence resolution, a feature which aggravates learning for long sequences. This results in the computational complexity of decoding process being O(|S| + |T|), with |S| denoting the source sentence length and |T| denoting the target sentence length. The Enc-Dec Att preserves the resolution of the source sentence which frees the neural model from having to squash all the information into a ﬁxed represention, but at a cost of a quadratic running time. Due to the attention mechanism, the computational complexity of decoding process is O(|S| × |T|). This drawbacks grow more severe as the length of the sequences increases. Currently, most work focused on the Enc-Dec Att, while the Enc-Dec paradigm is less emphasized on despite its advantage of linear-time decoding (Kalchbrenner et al., 2016). The lineartime approach is appealing, however, the performance lags behind the Enc-Dec Att. One potential issue is that the Enc-Dec needs to be able to compress all the necessary information of the input source sentence into context vectors which are ﬁxed during decoding. Therefore, a natural question was raised, Will carefully designed aggregation operations help the Enc-Dec paradigm arXiv:1811.00287v4  [cs.CL]  12 Oct 2020  to achieve the best performance? In recent promising work of capsule network, a dynamic routing policy is proposed and proven to effective (Sabour et al., 2017; Zhao et al., 2018; Gong et al., 2018). Following a similar spirit to use this technique, we present CAPSNMT, which is characterized by capsule encoder to address the drawbacks of the conventional linear-time approaches. The capsule encoder processes the attractive potential to address the aggregation issue, and then introduces an iterative routing policy to decide the credit attribution between nodes from lower (child) and higher (parent) layers. Three strategies are also proposed to stabilize the',\n",
       " '1212.5316': 'Schumacher proved that the optimal rate of data compression of a memoryless, quantum information source is given by its von Neumann entropy [1]. This data compression limit was evaluated under the requirement that the data compression scheme is lossless, in the sense that the information emitted by the source is recovered with arbitrary precision in the limit of asymptotically many copies of the source. However, the lack of sufﬁcient storage could make it necessary to compress a source beyond its von Neumann entropy. By the converse of Schumacher’s theorem, this would mean that the information recovered after the compression-decompression scheme would suffer a certain amount of distortion compared to the original Mark M. Wilde is with the School of Computer Science, McGill University, Montr´eal, Qu´ebec, Canada H3A 2A7. Nilanjana Datta is with the Statistical Laboratory, University of Cambridge, Wilberforce Road, Cambridge CB3 0WB, United Kingdom. Min-Hsiu Hsieh is with Centre for Quantum Computation and Intelligent Systems (QCIS), Faculty of Engineering and Information Technology (FEIT), University of Technology, Sydney (UTS), PO Box 123, Broadway NSW 2007, Australia. Andreas Winter is with ICREA & F´ısica Te`orica: Informaci´o i Fenomens Qu`antics,Universitat Aut`onoma de Barcelona, ES-08193 Bellaterra (Barcelona), Spain, the Department of Mathematics, University of Bristol, Bristol BS8 1TW, UK, and the Centre for Quantum Technologies, National University of Singapore, 2 Science Drive 3, Singapore 117542, Singapore. information. In other words, the data compression scheme would be lossy. The theory of lossy quantum data compression is called quantum rate distortion theory, in analogy with its classical counterpart developed by Shannon [2]. It deals with the tradeoff between the rate of compression and the allowed distortion. The trade-off is characterized by a rate distortion function which is deﬁned as the minimum rate of data compression for a given distortion, with respect to a suitably deﬁned distortion measure. In the ﬁrst paper to discuss quantum rate distortion theory, Barnum considered a symbol-wise entanglement ﬁdelity as a distortion measure [3]. With respect to it, he obtained a lower bound on the quantum rate distortion function in terms of an entropic quantity, namely, the coherent information [4]. Even though this was the ﬁrst result in quantum rate distortion theory, it is unsatisfactory since the coherent information can become negative, whereas the rate distortion function, by its very deﬁnition, is always non-negative. In [5], we obtained an expression for the quantum rate distortion function in terms of the entanglement of puriﬁcation [6], which, in contrast to the coherent information, is always non-negative. However, our result too is not entirely satisfactory since the expression is given in terms of a regularized formula and hence cannot be effectively computed. Furthermore, there is recent evidence that the entanglement of puriﬁcation is a non-additive quantity [7], which if true would lead to further complications in evaluating the expression. The search for a single-letter formula for the quantum rate distortion function hence',\n",
       " '1407.5234': 'We consider the general problem of ﬁnding the subspace that best approximates a ﬁxed signal h0 ∈RN from a parameterized collection of K-dimensional subspaces {Sθ : θ ∈Θ}, where θ is a parameter vector chosen from some compact parameter set Θ ⊂RD. Given this collection, the subspace best matched to h0 is the solution to ¯θ = arg min θ∈Θ min h∈Sθ ∥h0 −h∥2 2 = arg min θ∈Θ ∥h0 −Pθh0∥2 2. (1) The operator Pθ above is the orthogonal projection onto subspace Sθ. In words, program (1) returns the (index of the) subspace in the collection which contains the closest point to h0 in terms of the standard Euclidean distance. In this paper, we explore how eﬀectively this matching can be done from a set of indirect linear observations of h0. In particular, we will quantify how eﬀectively this problem can be solved when our observations y = Φh0 are compressed samples, meaning Φ is a M × N underdetermined matrix whose rows are diverse. For simplicity, we will consider the case where the entries of Φ are independent and Gaussian, but we expect that the majority of our results could be extended to other types of measurement scenarios. ∗W.M. is at Qualcomm in San Diego, CA; J.R. is in School of Electrical and Computer Engineering at Georgia Tech in Atlanta, GA. Email: wmantzel@gmail.com, jrom@ece.gatech.edu. This work was supported by ONR grant N00014-11-1-0459 and a grant from the Packard Foundation. 1 arXiv:1407.5234v1  [cs.IT]  20 Jul 2014  Given measurements y = Φh0, we match a subspace using a variation of (1): ˆθ = arg min θ∈Θ min h∈Sθ ∥y −Φh∥2 2 = arg min θ∈Θ ∥y −˜ Pθy∥2 2, (2) where ˜ Pθ is the orthogonal projection onto the range of ΦPθ, the K dimensional subspace of RM consisting of measurements induced by signals in Sθ. We would like the compressed estimate produced by (2) to be close to the standard estimate in (1). We will judge the diﬀerence between these two estimates based on how well the subspaces they return can approximate the original signal h0. Our main result bounds the diﬀerence in the relative approximation errors ˆE2 −¯E2, where ¯E2 = ∥h0 −P¯θh0∥2 2 ∥h0∥2 2 = 1 −∥P¯θh0∥2 2 ∥h0∥2 2 , and ˆE2 = ∥h0 −Pˆθh0∥2 2 ∥h0∥2 2 = 1 −∥Pˆθh0∥2 2 ∥h0∥2 2 . Since all of the terms above scale with the size of h0, we will assume (without loss of generality) from this point forward that ∥h0∥2 = 1, and derive a bound for the gap ˆE2 −¯E2 = ∥P¯θh0∥2 2 −∥Pˆθh0∥2 2. (3) Notice that the diﬀerence above must be positive, as ¯θ as given by (1) is the index for the optimal subspace. Note also that we are making no assumptions about whether or not h0 is in or even close to one of the Sθ. Bounding (3) also does',\n",
       " '1401.1974': 'In many situations, content data naturally present themselves in groups, e.g., students are grouped into classes, classes grouped into schools, words grouped into documents, etc. Furthermore, each content group can be associated with additional context information (teachers of the class, authors of the document, time and location stamps). Proceedings of the 31 st International Conference on Machine Learning, Beijing, China, 2014. JMLR: W&CP volume 32. Copyright 2014 by the author(s). Dealing with grouped data, a setting known as multilevel analysis (Hox, 2010; Diez-Roux, 2000), has diverse application domains ranging from document modeling (Blei et al., 2003) to public health (Leyland & Goldstein, 2001). This paper considers speciﬁcally the multilevel clustering problem in multilevel analysis: to jointly cluster both the content data and their groups when there is group-level context information. By context, we mean a secondary data source attached to the group of primary content data. An example is the problem of clustering documents, where each document is a group of words associated with grouplevel context information such as time-stamps, list of authors, etc. Another example is image clustering where visual image features (e.g. SIFT) are the content and image tags are the context. To cluster groups together, it is often necessary to perform dimensionality reduction of the content data by forming content topics, effectively performing clustering of the content as well. For example, in document clustering, using bag-of-words directly as features is often problematic due to the large vocabulary size and the sparsity of the in-document word occurrences. Thus, a typical approach is to ﬁrst apply dimensionality reduction techniques such as LDA (Blei et al., 2003) or HDP (Teh et al., 2006b) to ﬁnd word topics (i.e., distributions on words), then perform document clustering using the word topics and the document-level context information as features. In such a cascaded approach, the dimensionality reduction step (e.g., topic modeling) is not able to utilize the context information. This limitation suggests that a better alternative is to perform context-aware document clustering and topic modeling jointly. With a joint model, one can expect to obtain improved document clusters as well as context-guided content topics that are more predictive of the data.  Bayesian Nonparametric Multilevel Clustering with Group-Level Contexts Recent work has attempted to jointly capture word topics and document clusters. Parametric approaches (Xie & Xing, 2013) are extensions of the LDA (Blei et al., 2003) and require specifying the number of topics and clusters in advance. Bayesian nonparametric approaches including the nested Dirichlet process (nDP) (Rodriguez et al., 2008) and the multi-level clustering hierarchical Dirichlet Process (MLC-HDP) (Wulsin et al., 2012) can automatically adjust the number of clusters. We note that none of these methods can utilize context data. This paper propose the Multilevel Clustering with Context (MC2), a Bayesian nonparametric model to jointly cluster both content and groups',\n",
       " '1505.04657': 'Mobile apps are the software applications developed specially for mobile devices such as smartphones and tablets. As the use of mobile devices explodes, developing mobile apps becomes a popular and proﬁtable business in software development. However, it is also a highly competitive business, as millions and counting apps of different categories are made available on app markets. Since the revenue and proﬁt of a mobile app is often proportional to the size of its userbase, improving user experience and satisfaction to retain existing users and attract new ones is of important to its developers. User opinions like complaints or suggestions would be valuable for that task. As mobile app markets typically provide rating and reviewing mechanisms, reviews from users of apps purchased on those markets provide an important source of user opinions. However, analyzing those reviews manually for useful opinions would be inherently challenging. First, a popular app with millions of users often gets thousands of reviews each day and reading all of those reviews would be very time-consuming. In addition, user reviews of mobile apps are often noisy. They can have typos, acronyms, abbreviations, emoji icons, etc. Even worse, prior research reports that more than 60% of user reviews do not contain useful opinions [1]. In this paper, we introduce MARK (Mining and Analyzing Reviews by Keywords), a semi-automated framework for mining user opinions from user reviews of mobile apps. ConsidTABLE I. NEGATIVE KEYWORDS FOR FACEBOOK MESSENGER Rank Keyword Rank Keyword Rank Keyword Rank Keyword 1 battery 6 expire 11 phone 16 say 2 message 7 drain 12 app 17 space 3 download 8 crash 13 keep 18 use 4 install 9 ﬁx 14 facebook 19 freeze 5 session 10 log 15 reinstall 20 network ... ... ... ... ... ... ... ... TABLE II. CLUSTERS OF NEGATIVE KEYWORDS Energy consumption Unrecoverable error Authentication battery, drain, crash, freeze, session, login, hog, consume hang, break fail, connect ering this mining task as an information retrieval problem, MARK follows a keyword-based approach. That is, it allows a review analyst to specify his/her interests in one or some mobile apps by a set of keywords. Then, it uses those keywords to search for and visualize the most relevant reviews, expecting them to contain opinions usefully matched the analyst’s speciﬁed interests. The key departure of MARK from a typical information retrieval system is that it employs several automated, customized techniques for extracting keywords from raw reviews, ranking those keywords based on review ratings and occurrence frequencies, grouping related keywords, searching for reviews that are relevant to a set of keywords, visualizing their occurrences over time, and reporting if such occurrences contain unusual patterns. Let us illustrate MARK and those techniques via an example. Assume that a review analyst is interested in negative user opinions about Facebook Messenger, one of the most popular mobile apps with around 700 millions active users by July 2015 [2]. Initially, he has no idea about which aspects of the app that get negative opinions',\n",
       " '1509.00539': 'With each generation of wireless standards, the number of antennas at the infrastructure nodes has continued to grow to meet the increasing demand of mobile data. For example, both cellular and WiFi standards now support up to 8 antennas at infrastructure nodes. A promising and now standardized approach to use multiple antennas at the infrastructure is to use Multi-User Multiple Input Multiple Output (MU-MIMO) for supporting multiple uplink or downlink data streams in same time-slot. More recently, massive MIMO regime has been explored, which allows for a large number of antennas to reside at the infrastructure (with orders of magnitude more antennas compared to conventional MIMO systems), has attracted large interests in both academia and industry. The theoretical ([13], [18], [19]) and experimental results ([25], [27]) have shown that massive MIMO can lead to a number of desirable properties from the network design point of view, that include reduced inter-beam interference, improved energy efﬁciency, and reduced inter-cell interference, among others. As a result, massive MIMO is being considered for standardization as one of the key technologies in next-generation of The authors are with the Department of ECE, Rice University (e-mails: {wenzhuo.ouyang, jingwen, ashu}@rice.edu). The work of all three authors was partially supported by NSF Grants CNS-1161596 and CNS-1314822. wireless systems in both cellular and WiFi (e.g., 3GPP LTE Release 12 [2] and 802.11-ax [3]). Channel models with 64 BS antennas have already been standardized [2], with research platform supporting even larger conﬁgurations; e.g. 96 BS antennas [26]. In addition to MU-MIMO, another potential avenue to achieve higher spectral efﬁciency is to leverage full-duplex transmission, where a full-duplex-capable device can transmit and receive at the same time using the same frequency spectrum. The full-duplex mode of network operation has the potential to double the spectrum efﬁciency of wireless networks and can bring substantial ﬂexibility to higher layer design [9]. In fact, in-band full-duplex has already become part of the ongoing standard both in 3GPP [1] and 802.11-ax [3]. While it can be hard to integrate the full-duplex capabilities to client devices due to the processing and energy constraint, it is in fact feasible to design near-perfect full-duplex basestations thanks to available freedom (bigger size, non-batterypowered operation) in their designs (e.g., see [11], [12], [22] and the references therein). One method to leverage fullduplex infrastructure with half-duplex mobile handsets is to have simultaneous multi-user upand downlink transmissions. However, the potential for simultaneous upand downlink MU-MIMO at the BS leads to a new challenge – the internode interference within each cell, i.e intra-cell interference, as the transmissions of uplink interfere with the receptions of downlink as illustrated in Figure 1. The inter-node interference hence poses a fundamental challenge to enabling full-duplex at the BS and needs to be managed efﬁciently. In the presence of intra-cell interference, a centralized',\n",
       " '1710.10164': 'During the past few years, different approaches to allow elderly and people with special needs to retain their independence as long as possible, while living at home, have been pursued both in academic research and as part of product-oriented design and development efforts. As a reference, the Ambient Assisted Living (AAL) market is valued today approximately $1 billion, with a 55.6% CAGR over the 2017-2021 period. Assistance models based on the home care paradigm are being adopted rapidly in almost all industrialized and emerging countries. It addresses two intertwined needs: (i) supporting elderly and people with special needs, both in a post-hospitalization phase and when it is necessary to have a personalized midor long-term care service; (ii) helping people who do not have an easy access to hospital-based services, e.g., because they live in the countryside. In both cases, the home care paradigm assumes that it is necessary to ensure that the so-called Activities of Daily Living (ADL) are correctly and regularly performed by the assisted person to increase the perception of an improved quality of life. ADL are daily activities related to motion, rest, nutrition, and personal hygiene, which are a qualitative indicator of a person’s wellbeing, determine their quality of life and level of independence. This chapter describes the computational inference engine at the core of Arianna, a system able to understand whether an assisted person performs a given set of ADL and to motivate him/her in performing them through a speech-mediated motivational dialogue, using a set of nearables to be installed in an apartment, plus a wearable to be worn or ﬁt in garments. Arianna originates from joint work carried out by University of Genoa and Teseo srl. The ideas underlying Arianna are based on new approaches to the management of chronic diseases such as cognitive decline [2,3], i.e., adopting personalized and multi-therapeutic approaches. ADL are particularly relevant to such treatments. These studies show that adopting a proper lifestyle is an essential step in the management and in some cases the regression of disabling chronic diseases. A number of functional requirements are expected from such a system: – localizing people in their home or apartment; – identifying their signiﬁcant gestures and correlating them to position and time of day; – determining people activities related to ADL; – interacting with the assisted person through dialogues; – reminding people, by means of voice interaction, to perform typical ADL, if not detected or performed too rarely, acting as a personal assistant; – checking their posture, to allow for a quick intervention in case of falls or fainting; – learning their habits and identifying anomalous situations; – automatically notifying anomalous situations to relatives, friends, or medical staff.  Towards a new paradigm for assistive technology at home 3 In particular, the contribution of this chapter is a discussion about the design and the implementation choices related to a semantic model (and the associated inference engine) able to perform multiple human activity recognition and classiﬁcation',\n",
       " '1608.00641': 'User-assisted image segmentation has recently attracted considerable attention within the computer vison community, especially because of its potential applications in a variety of different problems such as image and video editing, medical image analysis, etc. [1,2,3,4,5,6,7,8]. Given an input image and some information provided by a user, usually in the form of a scribble or of a bounding box, the goal is to provide as output a foreground object in such a way as to best reﬂect the user’s intent. By exploiting high-level, semantic knowledge on the part of the user, which is typically difﬁcult to formalize, we are therefore able to effectively solve segmentation problems which would be otherwise too complex to be tackled using fully automatic segmentation algorithms. Existing algorithms fall into two broad categories, depending on whether the user annotation is given in terms of a scribble or of a bounding box, and supporters of the two approaches have both good reasons to prefer one modality against the other. For example, Wu et al. [3] claim that bounding boxes are the most natural and economical form in terms of the amount of user interaction, and develop a multiple instance learning algorithm that extracts an arbitrary object located inside a tight bounding box at unknown location. Yu et al. [9] also support the bounding-box approach, though their algorithm is different from others in that it does not need bounding boxes tightly enclosing the object of interest, whose production of course increases the annotation burden. They provide an algorithm, based on a Markov Random Field (MRF) energy function, that can handle arXiv:1608.00641v2  [cs.CV]  3 Aug 2016  2 E. Zemene and M. Pelillo Fig. 1: Left: An input image with different user annotations. Tight bounding box (Tight BB), loose bounding box (Loose BB), a scribble made (only) on the foreground object (Scribbles on FG), scribbles with errors. Right: Results of the proposed algorithm. input bounding box that only loosely covers the foreground object. Xian et al. [10] propose a method which avoids the limitations of existing bounding box methods - region of interest (ROI) based methods, though they need much less user interaction, their performance is sensitive to initial ROI. On the other hand, several researchers, arguing that boundary-based interactive segmentation such as intelligent scissors [8] requires the user to trace the whole boundary of the object, which is usually a time-consuming and tedious process, support scribble-based segmentation. Bai et al. [11], for example, propose a model based on ratio energy function which can be optimized using an iterated graph cut algorithm, which tolerates errors in the user input. In general, the input modality in an interactive segmentation algorithm affects both its accuracy and its ease of use. Existing methods work typically on a single modality and they focus on how to use that input most effectively. However, as noted recently by Jain and Grauman [12',\n",
       " '1708.05256': 'FAILED',\n",
       " '1206.4602': 'Quasi-Newton algorithms are arguably the most popular class of nonlinear numerical optimization methods, used widely in numerical applications not just in machine learning. Their deﬁning property is that they iteratively build estimators Bi for the Hessian B(x) = ∇∇⊺f(x) of the objective function f(x), from observations of f’s gradient ∇f(x), at each iteration searching for a local minimum along a line search direction −B−1 i ∇f(x), an estimate of the eponymous Newton-Raphson search direction. Some of the most widely known members of this family include Broyden’s (1965) method, the SR1 formula (Davidon, 1959; Broyden, 1967), the DFP method (Davidon, 1959; Fletcher & Powell, 1963) and the BFGS method (Broyden, 1969; Fletcher, 1970; Goldfarb, 1970; Shanno, 1970). Decades of continued research eﬀort in this area make it impossible to give even a superﬁcial overview over the available literature. The textbooks by NoAppearing in Proceedings of the 29 th International Conference on Machine Learning, Edinburgh, Scotland, UK, 2012. Copyright 2012 by the author(s)/owner(s). cedal & Wright (1999) and Boyd & Vandenberghe (2004) are good modern starting points for readers interested in background. An insightful and extensive contemporary review was compiled by Dennis & Mor´ee (1977). The ubiquity of optimization problems in machine learning has made these algorithms tools of the trade. But, perhaps because they predate machine learning itself, they have rarely been studied as learning algorithms in their own right. This paper oﬀers a probabilistic analysis. Throughout, let f ∶RN _ R be a suﬃciently regular, not necessarily convex, function; ∇f ∶RN _ RN its gradient; B ∶RN _ RN×N its Hessian. We consider iterative algorithms moving from location xℓ−1 ∈RD to location xℓ. The algorithm performs consecutive line searches along one-dimensional subspaces xi(α) = αei +x0 i , with α ∈R+ and a unit length vector ei ∈RN spanning the line search space starting at x0 i . Evaluations at xi evince the gradient ∇f(xi) (and usually also f(xi), though this will not feature in this paper). The goal is to ﬁnd a candidate x∗for a local minimum: a root ∇f(x∗) = 0 of the gradient. The derivations of classical quasi-Newton algorithms proceed along the following line of argument: We require an update rule incorporating an observation ∇f(xi+1) into a current estimate ˆBi to get a new estimate ˆBi+1, subject to the following desiderata: Low Rank/Cost Updates Optimization problems regularly have dimensionality above N ∼103, even beyond N ∼106. So the update should be of low rank M (usually M = 1 or 2), because, by Schur’s lemma, it has (worst-case) cost O(N 2+NM+M 3). Consistency with Quadratic Model If f is locally described well to second order, then yi ≡∇f(xi) −∇f(xi−1) ≈B(xi)si, (1) with si ≡xi −xi−1. Because this is the fundamental idea behind this family of algorithms',\n",
       " '1510.02822': 'In a typical cellular base-station, a passive antenna array is usually connected to an RF transceiver in the form of so-called remote radio head, where each ∗The authors are with Bell Laboratories, Alcatel Lucent, Dublin, Ireland. 1 arXiv:1510.02822v1  [cs.IT]  9 Oct 2015  Figure 1: Adaptive antenna array architecture: (a) full dimension active antenna array (AAA) architecture with Ntrx = Nt transceivers (denoted by RF{.}) and digital beamformer u(θd) for beamtilt range θd ∈Rθ (b) Architecture with adaptive ϑ(θd) beamforming signals connected to Nt × Ntrx RF beamforming network W and ﬁnally to Nt antennas. transmitted and received signal is shaped by the same beam. Though this passive architecture is quite simple, it has several disadvantages in terms of its applications in 4G and future/5G wireless communications: a) it does not allow spatial separation of multiple users, which can be considered as a very eﬃcient way to utilize limited frequency spectrum; b) it does not improve the signal to noise ratio (SNR) at the user equipment via the use of advanced beamforming technology, which has been largely accepted as a potential key technology for enabling the 5G wireless communications. In order to improve spectral eﬃciency and reduce the interference levels a multi-antenna RF transmitter architecture is being proposed for cellular base stations, where each antenna is connected to a dedicated RF chain and a baseband beamformer [9] as shown in Fig. 1(a). Such antenna arrays with active RF components are commonly referred as active antenna arrays (AAA). This approach allows us to form multiple beams at the same time to/from the same array. 1.1 Setup and Objective A full-size AAA architecture, i.e., each antenna element of an array connected to a dedicated RF chain, signiﬁcantly increases the cost, weight and overall power consumption, because of its inherent one-to-one mapping between antennas and RF transceivers. In order to reduce the complexity of a full-size AAA architecture, we propose a partially adaptive beamformer based modiﬁed AAA architecture, where a digital beamformer (DBF) with a reduced number of RF transceivers is connected to an increased number of antennas through an RF beamforming network (RFBN). This architectural modiﬁcation imposes a complex set of performance requirements such as spectral mask, microwave/insertion loss, side lobe suppression, eﬀective radiated power, and so on. Thus a compre2  hensive view to eﬃciently design RF communication systems is required. We consider a setup where an arbitrary Ntrx transmit signals in digital baseband are converted to RF using a set of Ntrx RF chains/transceivers. These RF signals are subsequently connected to Nt antennas using an Nt × Ntrx RFBN as shown in Fig. 1(b) (where Nt > Ntrx). Existing RF beamforming networks Tunable RF beamformer architectures with reduced number of RF chains have been previously proposed for low-power receivers fully implemented in Silicon [11, 12, 25]. However, the power levels of such designs are much lower than the power levels',\n",
       " '1612.08326': 'Quality-of-service-based scheduling has gained strong attention recently. It is shown in [1] and [2] that quality-of-serviceaware scheduling results in a better performance in LTE systems compared to quality-of-service-unaware techniques. Depending on the application, quality-of-service (QoS) metrics may refer to long-term throughput [3], short-term throughput [4], per-user average delay [5], average number of packets missing a speciﬁc deadline [6], or the average time a user waits to receive its data [7]. Real-time applications, such as audio and video applications, need to be served by algorithms that takes average packet delays or the probability of a packet missing the deadline into consideration. This is because these applications have stringent requirements for the service times of their packets. If a packet is not scheduled to be transmitted on time, the corresponding user might experience intermittent connectivity of its audio or video. The problem of scheduling for wireless systems under a hard deadline constraint has been widely studied in the literature (see, e.g., [8] and [9] for a survey). In [6] the authors consider binary erasure channels and present a sufﬁcient and necessary condition to determine if a given problem is feasible. The work is extended in three different directions. The ﬁrst direction studies the problem under delayed feedback [2]. The second considers general channel fading models. An example is [10] that present a scheduling algorithm that guarantees a pre-speciﬁed portion of the packets to be transmitted by the deadline. The third direction studies multicast video packets The work in this paper has been supported by NSF Grant CCF-1117041. that have strict deadlines and utilize network coding to improve the overall network performance [11], [12]. Unlike the time-framed assumption in the previous works, the authors of [13] assume that arrivals and deadlines do not have to occur at the edges of a time frame and present a scheduling algorithm with a ﬁxed power allocation. In [14] the authors study the scheduling problem in the presence of real-time and non-real-time data. Unlike real-time data, non-real-time data do not have a strict deadline but rather can be transmitted at any arbitrary point in time. However, there is an implicit constraint that the queues of the non-real-time data need to be stable. Using the dual function approach, the problem was decomposed into an online algorithm that guarantees network stability and real-time users’ satisfaction. Power allocation has not been considered for RT users in the literature, to the best of our knowledge. In this paper, we study the problem of resource allocation in the presence of simultaneous RT and NRT users in a downlink cellular system. We formulate the problem as a joint scheduling-andpower-allocation problem to maximize the sum throughput of the NRT users subject to an average power constraint on the base station (BS), as well as a delivery ratio requirement constraint for each',\n",
       " '1709.09770': 'Recently, erasure codes with both local and global erasurecorrecting properties have received considerable attention [3], [9], [17]–[19], [21], thanks to their promising application in storage systems. The idea behind them is that when only a few erasures occur, these erasures can be corrected fast using only local parities. If the number of erasures exceeds the local erasure-correcting capability, then the global parities are invoked. In this paper, we consider this kind of erasure codes with both local and global erasure-correcting capabilities for a ρ × n0 storage array [3], where each row contains some local parities, and additional global parities are distributed in the array. The array structure is suitable for many storage applications. For example, consider a redundant array of independent disks (RAID) type of architecture for solid-state drives (SSDs) [3], [8]. In this scenario, a ρ × n0 storage array can represent a total of ρ SSDs, each of which contains n0 ﬂash memory chips. Within each SSD, an erasure code is applied to these n0 chips for local protection. In addition, erasure coding is also done across all the SSDs for global protection of all the chips. More speciﬁcally, let us give the formal deﬁnition of this class of erasure codes as follows. Deﬁnition 1. Consider a code C over a ﬁnite ﬁeld Fq consisting of ρ × n0 arrays such that: 1) Each row in each array in C belongs to a linear local code C0 with length n0 and minimum distance d0 over Fq. 2) Reading the symbols of C row-wise, C is a linear code with length ρn0, dimension k, and minimum distance d over Fq. Then, we say that C is a (ρ, n0, k; d0, d)q Multi-Erasure Locally Recoverable Code (ME-LRC). □ Thus, a (ρ, n0, k; d0, d)q ME-LRC can locally correct d0 − 1 erasures in each row, and is guaranteed to correct a total of d −1 erasures anywhere in the array. Our work is motivated by a recent work by Blaum and Hetzler [3]. In their work, the authors studied ME-LRCs where each row is a maximum distance separable (MDS) code, and gave code constructions with ﬁeld size q ⩾max{ρ, n0} using generalized integrated interleaving (GII) codes [11], [22], [24]. Our Deﬁnition 1 generalizes the deﬁnition of the codes in [3] by not requiring each row to be an MDS code. There exist other related works. The ME-LRCs in Deﬁnition 1 can be seen as (r, δ) LRCs with disjoint repair sets. A code C is called an (r, δ) LRC [19], if for every coordinate, there exists a punctured code (i.e., a repair set) of C with support containing this coordinate, whose length is at most r +δ −1, and whose minimum distance is at least δ. Although the existing constructions [19], [21] for (r, δ) LRCs with disjoint repair sets can generate ME-LRCs as in Deﬁnition 1',\n",
       " '1703.08289': 'Scene text detection has drawn great interests from both computer vision and machine learning communities because of its great value in practical uses and the technical challenges. Owing to the signiﬁcant achievements of deep convolutional neural network (CNN) based generic object detection in recent years, scene text detection also has been greatly improved by regarding text words or lines as objects. High performance methods for object detection like FasterRCNN [19], SSD [14] and YOLO [18] have been modiﬁed to detect horizontal scene texts [27] [5] [21] [13] and (a) (b) Figure 1. Visualized explanation of indirect and direct regression. The solid green lines are boundaries of text “Gallery”, the dash blue lines are boundaries of text proposal, and the dashed yellow vectors are the ground truths of regression task. (a) The indirect regression predicts the offsets from a proposal. (b) The direct regression predicts the offsets from a point. gained great improvements. However, for multi-oriented text detection, methods like Faster-RCNN and SSD which work well for object and horizontal text detection may not be good choices. To illustrate the reasons, ﬁrst we explain the deﬁnitions of indirect and direct regression in detection task. Indirect Regression. For most CNN based detection methods like Fast-RCNN [3], Faster-RCNN, SSD, Multi-Box [2], the regression task is trained to regress the offset values from a proposal to the corresponding ground truth (See Fig.1.a). We call these kinds of approaches indirect regression. Direct Regression. For direct regression based methods, the regression task directly outputs values corresponding with the position and size of an object from a given point (See Fig.1.b). Take DenseBox [7] as an instance, this model learns to directly predict offsets from bounding box vertexes to points in region of interest. Indirect regression based detection methods may not be effective for multi-oriented text detection, even methods like Faster-RCNN and SSD have reached state-of-the-art performance for object detection and are also implemented for horizontal scene text detection. The reasons are mainly in three folds. First, there are few robust methods to gen1 arXiv:1703.08289v1  [cs.CV]  24 Mar 2017  Figure 2. Illustration for the deﬁciency of anchor mechanism in detecting long and heavily inclined text words or lines. The solid yellow lines are boundaries of the text line and the dashed lines are boundaries of anchors. There is no anchor that has sufﬁcient overlap with the text line in this image. erate word-level or line-level proposals for multi-oriented text. Most previous methods could only provide proposals of character-level by extracting connected components. Second, anchor mechanism in Faster-RCNN may not be an effective solution to generate text proposals. The anchor mechanism can be deemed as rectangular proposals of various sizes and aspect ratios being evenly placed on an image, and setting proposals which have high overlap with ground truths as positive, otherwise as “NOT CARE” or',\n",
       " '1606.00625': 'FAILED',\n",
       " '1811.07078': 'Affect is a psychological experience of feeling or emotion. As a vital part of human intelligence, having the capability to recognize, understand and express affect and emotions like human has been arguably one of the major milestones in artiﬁcial intelligence (Picard 1997). Open-domain conversational models aim to generate coherent and meaningful responses when given user input sentences. In recent years, neural network based generative conversational models relying on Sequence-to-Sequence network (Seq2Seq) (Sutskever, Vinyals, and Le 2014) have been widely adopted due to its success in neural machine translation. Seq2Seq based conversational models have the advantages of end-to-end training paradigm and unrestricted response space over conventional retrieval-based models. To make neural conversational models more engaging, various techniques have been proposed, such as using stochastic latent variable (Serban et al. 2017) to promote response diversity and encoding topic (Xing et al. 2017) into conversational models to produce more coherent responses. Copyright c⃝2019, Association for the Advancement of Artiﬁcial Intelligence (www.aaai.org). All rights reserved. However, embedding affect into neural conversational models has been seldom explored, despite that it has many beneﬁts such as improving user satisfaction (Callejas, Griol, and L´opez-C´ozar 2011), fewer breakdowns (Martinovski and Traum 2003), and more engaged conversations (Robison, McQuiggan, and Lester 2009). For real-world applications, Fitzpatrick, Darcy, and Vierhile (2017) developed a rule-based empathic chatbot to deliver cognitive behavior therapy to young adults with depression and anxiety, and obtained signiﬁcant results on depression reduction. Despite of these beneﬁts, there are a few challenges in the affect embedding in neural conversational models that existing approaches fail to address: (i) It is difﬁcult to capture the emotion of a sentence, partly because negators and intensiﬁers often change its polarity and strength. Handling negators and intensiﬁers properly still remains as a challenge in sentiment analysis. (ii) It is difﬁcult to embed emotions naturally in responses with correct grammar and semantics (Ghosh et al. 2017). In this paper, we propose an end-to-end single-turn opendomain neural conversational model to address the aforementioned challenges to produce responses that are natural and affect-rich. Our model extends Seq2Seq model with attention (Luong, Pham, and Manning 2015). We leverage an external corpus (Warriner, Kuperman, and Brysbaert 2013) to provide affect knowledge for each word in the Valence, Arousal and Dominance (VAD) dimensions (Mehrabian 1996). We then incorporate the affect knowledge into the embedding layer of our model. VAD notation has been widely used as a dimensional representation of human emotions in psychology and various computational models, e.g., (Wang, Tan, and Miao 2016; Tang et al. 2017). 2D plots of selected words with extreme VAD values are shown in Figure 1. To capture the effect of negators and intensiﬁers, we propose a novel biased attention mechanism that explicitly considers negators and intensiﬁers in attention computation. To maintain correct',\n",
       " '1804.00779': 'Invertible transformations with a tractable Jacobian, also known as normalizing ﬂows, are useful tools in many machine learning problems, for example: (1) In the context of deep generative models, training necessitates evaluating data samples under the model’s inverse transformation (Dinh et al., 2016). Tractable density is an appealing property for these models, since it allows the objective of interest to be directly optimized; whereas other mainstream methods rely on alternative losses, in the case of intractable density models (Kingma & Welling, 2013; Rezende et al., 2014), or *Equal contribution 1MILA, University of Montreal 2Element AI 3CIFAR fellow. Correspondence to: Chin-Wei Huang <chinwei.huang@umontreal.ca>. Preliminary work. Under review by the International Conference on Machine Learning (ICML). Do not distribute. 1Implementation can be found at https://github.com/CWHuang/NAF/ implicit losses, in the case of adversarial models (Goodfellow et al., 2014). (2) In the context of variational inference (Rezende & Mohamed, 2015), they can be used to improve the variational approximation to the posterior by parameterizing more complex distributions. This is important since a poor variational approximation to the posterior can fail to reﬂect the right amount of uncertainty, and/or be biased (Turner & Sahani, 2011), resulting in inaccurate and unreliable predictions. We are thus interested in improving techniques for normalizing ﬂows. Recent work by Kingma et al. (2016) reinterprets autoregressive models as invertible transformations suitable for constructing normalizing ﬂows. The inverse transformation process, unlike sampling from the autoregressive model, is not sequential and thus can be accelerated via parallel computation. This allows multiple layers of transformations to be stacked, increasing expressiveness for better variational inference (Kingma et al., 2016) or better density estimation for generative models (Papamakarios et al., 2017). Stacking also makes it possible to improve on the sequential conditional factorization assumed by autoregressive models such as PixelRNN or PixelCNN (Oord et al., 2016), and thus deﬁne a more ﬂexible joint probability. We note that the normalizing ﬂow introduced by Kingma et al. (2016) only applies an afﬁne transformation of each scalar random variable. Although this transformation is conditioned on preceding variables, the resulting ﬂow can still be susceptible to bad local minima, and thus failure to capture the multimodal shape of a target density; see Figure 1 and 2. 1.1. Contributions of this work We propose replacing the conditional afﬁne transformation of Kingma et al. (2016) with a more rich family of transformations, and note the requirements for doing so. We determine that very general transformations, for instance parametrized by deep neural networks, are possible. We then propose and evaluate several speciﬁc monotonic neural network architectures which are more suited for learning multimodal distributions. Concretely, our method amounts to using an autoregressive model to output the weights of multiple independent transformer networks, each of which operates on a single random variable, replacing the afﬁne arXiv:1804.00779v1  [cs.LG]  3 Apr 2018  Neural Autoregressive Flows Figure 1. Energy function ﬁtting using IAF. Left',\n",
       " '1201.0715': 'L ow-density parity-check (LDPC) codes are well known channel capacity-approaching (c.a.) linear codes. In his PhD [1], Gallager proposed LDPC codes along with lineartime practical decoding methods, among which the belief propagation (BP) algorithm plays a fundamental role. BP was later redescribed and popularized in the articial intelligence community to perform approximate inference over graphical models, see for instance [2], [3], [4]. Given a factor graph that represents a joint probability density function (pdf) p(V) of a set of discrete random variables [5], BP estimates the marginal probability function for each variable. It uses a local message-passing algorithm between the nodes of the graph. The complexity of this algorithm is linear in the number of nodes [2]. For tree-like graphs, the BP solution is exact, but for graphs with cycles, BP is strictly suboptimal [6], [7], [8]. Linear block codes can be represented using factor (Tanner) graphs [9], where the factor nodes enforce the parity check This work was partially funded by Spanish government (Ministerio de Educaci´on y Ciencia, TEC2009-14504-C02-01,02, Consolider-Ingenio 2010 CSD2008-00010), Universidad Carlos III (CCG10-UC3M/TIC-5304) and European Union (FEDER). P. M. Olmos and F. P´erez-Cruz are with Dept. Teor´ıa de la Se˜nal y Comunicaciones, Universidad Carlos III de Madrid (Spain). E-mail: {olmos, fernando}@tsc.uc3m.es J.J. Murillo-Fuentes is with the Dept. Teor´ıa de la Se˜nal y Comunicaciones, Escuela T´ecnica Superior de Ingenier´ıa, Universidad de Sevilla, Paseo de los Descubrimientos s/n, 41092 Sevilla, Spain. E-mail: murillo@us.es constraints. For LDPC codes, the presence of cycles in the Tanner graph quickly decays with the code length n. For large block lengths, a channel decoder based on BP achieves an excellent performance, close to the bitwise maximum a posteriori (bit-MAP) decoding, in certain scenarios [3], [10]. Nevertheless, the bit-MAP solution can only be achieved when the code length, code density and computational complexity go to inﬁnity [11], [12], [13]. The analysis of the BP for LDPC decoding over independent and identically distributed channels is detailed in [14], [15], in which the limiting performance and code optimization are addressed. For the binary erasure channel (BEC), the BP decoder presents an alternative formulation, in which the known variable nodes (encoded bits) are removed from the graph after each iteration. The BP, under this interpretation, is referred to as the peeling decoder (PD) [11]. In [16], the authors investigate the PD limiting performance by describing the expected LDPC graph evolution throughout the decoding process by a set of differential equations. The asymptotic performance for the BP decoder is summarized in the computation of the so-called BP threshold [10], [11], [16], [17], which deﬁnes the limit of its decodable region for an LDPC code. The analysis of BP decoding performance in the ﬁnitelength regime is based on the evaluation of the presence of stoppin',\n",
       " '1506.02632': 'Since the beginning of its history, mankind has been deeply immersed in designing and improving systems to serve humans needs. Policy makers are busy with designing systems that serve the education, transportation, economic, health and other needs of the public, while private sector enterprises or hard at creating and optimizing systems to serve further more specialized needs of their customers. While it has been long recognized that understanding human behavior is a prerequisite to best serving human needs (Simon 1959, e.g.,), it is only recently that this approach is gaining a wider recognition.1 In this paper we consider human-centered reinforcement learning problems where the reinforcement learning agent controls a system to produce long term outcomes (“return”) that are maximally aligned with the preferences of one or possibly multiple humans, an arrangement shown on Figure 1. As a running ∗prashla@isr.umd.edu †cjie@math.umd.edu ‡mfu@isr.umd.edu §marcus@umd.edu ¶szepesva@cs.ualberta.ca 1As evidence for this wider recognition in the public sector, we can mention a recent executive order of the White House calling for the use of behavioral science in public policy making, or the establishment of the “Committee on Traveler Behavior and Values” in the Transportation Research Board in the US. 1 arXiv:1506.02632v3  [cs.LG]  26 Feb 2016  example, consider trafﬁc optimization where the goal is to maximize travelers’ satisfaction, a challenging problem in big cities. In this example, the outcomes (“return”) are travel times, or delays. To capture human preferences, the outcomes are mapped to a single numerical quantity. While preferences of rational agents facing uncertain situations can be modeled using expected utilities (i.e., the expectation of a nonlinear transformation, such as the exponential function, of the rewards or costs) (Von Neumann and Morgenstern 1944; Fishburn 1970), it is well known that humans are subject to various emotional and cognitive biases, and, the psychology literature agrees that human preferences are inconsistent with expected utilities regardless of what nonlinearities are used (Allais 1953; Ellsberg 1961; Kahneman and Tversky 1979). An approach that gained strong support amongst psychologists, behavioral scientists and economists (e.g., Starmer 2000; Quiggin 2012) is based on Kahneman and Tversky (1979)’s celebrated prospect theory (PT). Therefore, in this work, we will base our models of human preferences on this theory. More precisely, we will use cumulative prospect theory (CPT), a later, reﬁned variant of prospect theory due to Tversky and Kahneman (1992), which is even more empirically and theoretically supported than prospect theory (e.g., Barberis 2013). CPT generalizes expected utility theory in that in addition to having a utility function transforming the outcomes, another function is introduced which distorts the probabilities in the cumulative distribution function. As compared to prospect theory, CPT is monotone with respect to stochastic dominance, a property that is thought to be useful and (mostly) consistent with human preferences2. Figure 1: Operational ﬂow of a human-based decision making system Our contributions: To our best knowledge',\n",
       " '1807.05118': 'Machine learning pipelines are growing in complexity and cost. In particular, the model selection stage, which includes model training and hyperparameter tuning, can take the majority of a machine learning practitioner’s time and consume vast amounts of computational resources. Take for example a researcher aiming to train ResNet-101, a convolutional neural-network model with millions of parameters. Training this model can take around 24 hours on a single GPU, and performing model selection sequentially will take weeks to complete. Naturally, one would be inclined to train the model on a cluster in a distributed fashion (Goyal et al. (2017)) and utilize many machines to perform model selection in parallel. To this end, the research community has developed numerous techniques for accelerating model selection including those that are sequential (Snoek et al. (2012)), parallel (Li et al. (2016)), and both (Jaderberg et al. (2017)). However, each technique is often implemented on its own, tied to a particular framework, is closed source, or perhaps not even reproducible without signiﬁcant computational resources (Zoph and Le (2016)). Further, often times these techniques require signiﬁcant investment in software infrastructure for the execution of experiments. c⃝2018 R. Liaw*, E. Liang*, R. Nishihara, P. Moritz, J.E. Gonzalez & I. Stoica. arXiv:1807.05118v1  [cs.LG]  13 Jul 2018  Tune: A Research Platform for Distributed Model Selection and Training # Function-based API def train():   for _ in range(N):     tune.report(...) # Class-based API class MyModel(Trainable):   def _setup(); def _train();   def _save(); def _restore(); Ray Tune API HyperBand Grid Search Population  Based Training Bayesian Optimization ... Trial schedulers  implement strategies for  distributed optimization Two simple APIs for integration with model training Figure 1: Tune provides narrow-waist interfaces that training scripts can implement with a few lines of code changes. Once done, this enables the use of Tune for experiment management, result visualization, and a choice of trial scheduling strategies. This narrow interface also enables AutoML researchers to easily swap out diﬀerent search algorithms for comparison, or release distributed implementations of new algorithms without needing to worry about distributed scaﬀolding. The contributions of this paper are as follows: 1. We introduce Tune, an open source framework for distributed model selection. 2. We show how Tune’s APIs enable the easy reproduction and integration of a wide variety of state-of-the-art hyperparameter search algorithms. 2. Related work There are multiple open source systems for model selection. HyperOpt, Spearmint, and HPOLib (Snoek et al. (2012); Eggensperger et al. (2013)) are distributed model selection tools that manage both the search and evaluation of the model, implementing search techniques such as random search and tree of parzen estimators (TPE). However, both frameworks are tightly coupled to the search algorithm structure and requires manual management of computational resources across a cluster. Further, systems such as Spearmint, HyperOpt, and TuPAQ (MLBase) (Sparks et al. (2015)) treat a full trial execution as an atomic unit, which does not allow for intermediate control of trial execution. This inhibits eﬃcient',\n",
       " '1712.05134': 'Best known for the sequence-to-sequence learning, the Recurrent Neural Networks (RNNs) belong to a class of neural architectures designed to capture the dynamic temporal behaviors of data. The vanilla fully connected RNN utilizes a feedback loop to memorize previous information, while it is inept to handle long sequences as the gradient exponentially vanishes along the time [13, 2]. Unlike the vanilla RNNs passing information between layers with direct matrix-vector multiplications, the Long Short-Term Figure 1: Architecture of BT-LSTM. The redundant dense connections between input and hidden state is replaced by low-rank BT representation. Memory (LSTM) introduces a number of gates and passes information with element-wise operations [14]. This improvement drastically alleviates the gradient vanishing issue; therefore LSTM and its variants, e.g. Gated Recurrent Unit (GRU) [5], are widely used in various Computer Vision (CV) tasks [3, 22, 37] to model the long-term correlations in sequences. The current formulation of LSTM, however, suffers from an excess of parameters, making it notoriously difﬁcult to train and susceptible to overﬁtting. The formulation of LSTM can be described by the following equations: ft = σ(Wf · xt + Uf · ht−1 + bf) (1) it = σ(Wi · xt + Ui · ht−1 + bi) (2) ot = σ(Wo · xt + Uo · ht−1 + bo) (3) ˜ct = tanh(Wc · xt + Uc · ht−1 + bc) (4) ct = ft ⊙ct−1 + it ⊙˜ct (5) ht = ot ⊙tanh(ct), (6) where ⊙denotes the element-wise product, σ(·) denotes the sigmoid function and tanh(·) is the hyperbolic tangent function. The weight matrices W∗and U∗transform the input xt and the hidden state ht−1, respectively, to cell uparXiv:1712.05134v2  [cs.LG]  11 May 2018  date ˜ct and three gates ft, it, and ot. Please note that given an image feature vector xt fetch from a Convolutional Neural Network (CNN) network, the shape of xt will raise to I = 4096 and I = 14 × 14 × 512 w.r.t vgg16 [33] and Inception v4 [35]. If the number of hidden states is J = 256, the total number of parameters in calculating the four W∗ is 4 × I × J, which can up to 4.1 × 106 and 1.0 × 108, respectively. Therefore, the giant matrix-vector multiplication, i.e., W∗· xt, leads to the major inefﬁciency – the current parameter-intensive design not only subjects the model difﬁcult to train, but also lead to high computation complexity and memory usage. In addition, each W∗· xt essentially represents a fully connected operation that transforms the input vector xt into the hidden state vector. However, extensive research on CNNs has proven that the dense connection is significantly inefﬁcient at extracting the spatially latent local structures and local correlations naturally exhibited in the image [20, 10]. Recent leading CNNs architectures, e.g., DenseNet [15], ResNet [11] and Inception v4 [35], also try to circumvent one huge cumbersome dense layer [36]. But the discussions of improving the dense connections',\n",
       " '1204.6725': 'FAILED',\n",
       " 'cmp-lg/9406010': 'When automated part of speech tagging was initially explored (Klein & Simmons 1963; Harris 1962), people manually engineered rules for tagging, sometimes with the aid of a corpus. As large corpora became available, it became clear that simple Markovmodel based stochastic taggers that were automatically trained could achieve high rates of tagging accuracy (Jelinek 1985). Markov-model based taggers assign a sentence the tag sequence that maximizes Prob(word|tag)∗ Prob(tag|previous n tags). These probabilities can be estimated directly from a manually tagged corpus.1 ∗This paper appears in the proceedings of the Twelfth National Conference on Artiﬁcial Intelligence (AAAI-94). This research was supported by ARPA under contract N00014-89-J-1332, monitored through the Oﬃce of Naval Research. Copyright c⃝2018, American Association for Artiﬁcial Intelligence (www.aaai.org). All rights reserved. 1One can also estimate these probabilities without a manually tagged corpus, using a hidden Markov model. However, it appears to be the case that directly estimating probabilities from even a very small manually tagged corpus gives better results than training a hidden Markov model on a large untagged corpus (see (Merialdo 1991)). Stochastic taggers have a number of advantages over the manually built taggers, including obviating the need for laborious manual rule construction, and possibly capturing useful information that may not have been noticed by the human engineer. However, stochastic taggers have the disadvantage that linguistic information is only captured indirectly, in large tables of statistics. Almost all recent work in developing automatically trained part of speech taggers has been on further exploring Markov-model based tagging (Jelinek 1985; Church 1988; Derose 1988; DeMarcken 1990; Merialdo 1991; Cutting et al. 1992; Kupiec 1992; Charniak et al. 1993; ?). In (Brill 1992), a trainable rule-based tagger is described that achieves performance comparable to that of stochastic taggers. Training this tagger is fully automated, but unlike trainable stochastic taggers, linguistic information is encoded directly in a set of simple non-stochastic rules. In this paper, we describe some extensions to this rule-based tagger. These include a rule-based approach to: lexicalizing the tagger, tagging unknown words, and assigning the k-best tags to a word. All of these extensions, as well as the original tagger, are based upon a learning paradigm called transformation-based error-driven learning. This learning paradigm has shown promise in a number of other areas of natural language processing, and we hope that the extensions to transformation-based learning described in this paper can carry over to other domains of application as well.2 Transformation-Based Error-Driven Learning Transformation-based error-driven learning has been applied to a number of natural language problems, including part of speech tagging, prepositional phrase attachment disambiguation, and syntactic parsing (Brill 1992; Brill 1993a; Brill 1993b). A similar approach is being explored for machine translation (Su, Wu, & Chang 1992). Figure 1 illustrates the learning process. First',\n",
       " '1710.10749': 'Object detection is a fundamental problem in computer vision. It has been widely studied for many years [1], among which the state-of-the-art approaches are based on convolutional neural networks (CNN) [2, 3, 4, 5, 6, 7]. Girshick et al. [8] proposed region-based CNN (R-CNN), which successfully transfers the image-level recognition power of CNN to object detection. Afterwards, R-CNN was subsequently developed and accelerated in SPP-Net [9], NoC [10], Fast R-CNN [11] and Faster R-CNN [12]. In Faster R-CNN, a carefully designed region proposal network (RPN) was introduced to extract high-quality region proposals. The extracted proposals are then fed into Fast R-CNN (FRCN) for object recognition. In this paper, we make extensive improvements on both region proposal quality (RPN side) and object recognition accuracy (FRCN side). Our contribution is three-fold. 1) We propose a lightweight cascade RPN architecture, which can extract accurately Email address: {zhongqiaoyong,lichao15,zhangyingying7,xiedi,yangshicai,pushiliang}@hikvision.com (Qiaoyong Zhong, Chao Li, Yingying Zhang, Di Xie, Shicai Yang, Shiliang Pu) Preprint submitted to Neurocomputing October 31, 2017 arXiv:1710.10749v1  [cs.CV]  30 Oct 2017  localized region proposals with marginal extra computational cost. 2) We revisit global context modeling. With a few modiﬁcations in network architecture and the idea of pretraining, we obtain signiﬁcant performance gain. 3) We systematically evaluate common training and testing tricks that can be found in the literature and report their contributions to detection performance. Based on these improvements over Faster R-CNN baseline, we achieve the state-of-the-art performance on PASCAL VOC 2012 [13], ILSVRC 2016 [14] and COCO [15]. 2. Related Work Cascade Region Proposal. Conventional region proposal methods are normally based on low-level features, either unsupervised (e.g. Selective Search [16] and EdgeBoxes [17]) or supervised (e.g. BING [18]). With the success of CNN in computer vision [19], high-level semantic CNN features are adopted for region proposal. Taking RPN as an example, a fully convolutional architecture is designed to extract high-level features and predict proposals in an end-to-end way. On the other hand, reﬁning region proposals with a multi-stage cascading pipeline has also been explored. DeepBox [20] uses CNN to rerank proposals from a conventional method, which may be considered as a special form of cascading. CRAFT [21] uses a two-class Fast R-CNN to reﬁne proposals from a standard RPN, which was further developed in [22]. DeepProposals [23] proposes an inverse cascade to exploit feature maps of diﬀerent levels. Although our design shares similar pipeline with CRAFT [21], we use a modiﬁed RPN instead of Fast R-CNN in the second cascading stage. The details are described in 3.2.2. Context Modeling. Objects in the real world do not exist on their own. They are surrounded by a background (e.g. sky, grassland) and likely to coexist with other objects, either of the same category or not. This context may provide',\n",
       " '1608.07636': 'As time series measurements become increasingly commonplace in many problems, developing algorithms that can learn the underlying structure and the relationships between the observed variables become necessary. An important class of such algorithms focuses on extracting the linear dependency of the observed variables; this line of work originated from the pioneering work [1] proposing Granger causality. The linear temporal models have been used in numerous ﬁelds such as ﬁnancial forecasting [2], biological network modeling [3], and traditional control systems [4], because they are simple enough to learn with limited data and yet are effective in practice to model time series data. In these problems, the ﬁrst step is to learn the model parameters, and then further questions about the system can be investigated, including prediction of future values, imputation of missing variables and causal inference. In many of the real-world datasets, some of the variables may be unobserved; most of the times, even the existence of such unobserved variables may be unknown. Therefore it is expedient to consider models which allow for some hidden or latent variables and extract relationships not only between the observed variables but also between the latent variables. Inference in the presence of models with hidden variables has a long and distinguished history; a particular breakthrough is the work of [5] which proposed the Expectation-Maximization This work was supported by ONR grants N00014-14-1-0029 and N0001416-1-2710. 1 2 3 4 Fig. 1: Example of Latent Temporal Model: The observed variables are shown in blue and the latent variables are shown in red. There is a sparse graph interconnecting the latent variables (edges shown in black). Also, each observed variable is inﬂuenced by its corresponding latent variable (edges shown in blue), and ﬁnally, each observed variable inﬂuences its latent variable (edges shown in red). (EM) algorithm for maximizing the likelihood of observations in presence of latent variables. EM-based algorithms however do not guarantee convergence to the global optima of the likelihood landscape. In this paper, we unite the two threads by considering the learning of linear temporal relationships with latent variables. Our main contributions are the following. 1) We propose a new linear model for incorporating temporal latent variables, which captures the effects of the temporal memory in the system. Our proposed model has two important features: • For each observed variable, there is a latent component that acts as its memory, • Each observed variable is affected by its memory with a random and time varying delay. 2) We provide the identiﬁability results for learning the system parameters using the observations. 3) We propose an efﬁcient algorithm to learn the system parameters. We demonstrate that the proposed algorithm outperforms the baseline method for linear temporal models both in synthetic and real-world datasets. To illustrate the ﬁrst aspect of our proposed model, consider an example where the variables are the disease states of various arXiv:1608.07636v1  [cs.LG]  27 Aug 2016  individuals over time, and we are',\n",
       " '1406.4852': 'Regenerating codes were introduced by Dimakis, Godfrey, Wu, Wainwright and Ramchandran [1]. Their main application is in large distributed storage systems where they lead to signiﬁcant savings by optimizing the trade-oﬀbetween storage size and repair bandwith. In a distributed storage system (DSS) an encoded ﬁle is stored on n servers such that it can be recovered from any combination of k servers. If a server fails it can be rebuilt by retrieving the information needed for its repair from any combination of d other servers. An encoding scheme realizing these parameters is called an (n, k, d) regenerating code. For background and details on distributed storage and regenerating codes we refer to [2], [5]. A common example is the use of a (4, 2, 3) code to store four bits x, y, z, t. By storing the pairs of bits (x, z + t), (y, t+ x), (z, x+ y), (t, y + z) on four diﬀerent servers (n = 4), the four bits x, y, z, t can be recovered from the combined information on any two servers (k = 2). And if a server fails it can be rebuilt by retrieving one bit from each of the remaining three servers (d = 3). In particular, the ﬁrst server can be rebuilt from the three bits y, y + x, and y + z + t. An (n, k, d) code comes with a secondary set of parameters (B, α, β). For a ﬁle of size B, a part of size at most α is stored on a single server, and bandwith between a server and any of the d servers helping in its repair is limited to β. For the example, B = 4, α = 2, β = 1. The gains in a DSS are obtained by using a total repair bandwith γ = dβ that is possibly larger than α but much smaller than the ﬁle size B. The challenge is, given (n, k, d), to optimize the trade-oﬀbetween the storage α per server and the repair bandwith β between servers in order to store a ﬁle of size B. For given parameters (n, k, d), the outer bound refers to the relation among the parameters (B, α, β). The outer bound can be interpreted as an upper bound on the ﬁle size B, for given α and β, or as a lower bound for α and β, for a given ﬁle size B. In the ﬁrst case it is standard to scale to variables B/β and α/β, and in the second case to variables α/B and β/B. In this work, we establish new outer bounds for exact-repair regenerating codes. In the exact-repair scenario it is required that a server be rebuilt to its original form. The weaker requirement, known as functional repair, only requires that a server be rebuilt to a form that preserves the functionality of the DSS. Upper bounds for the ﬁle size under functional repair are piece-wise linear and take the form B ≤Bq = qα + \\x12k −q',\n",
       " '1107.4623': 'Least squares problems occur in various signal processing and statistical inference applications. In these problems the relation between the vector of noisy observations y ∈Cm and the unknown parameter or signal x⋆∈Cn is governed by a linear equation of the form y = Ax⋆+ e, (1) where A ∈Cm×n is a matrix that may model a linear system or simply contains a set of collected data. The vector e ∈Cm represents the additive observation noise. Estimating x⋆from the observation vector y is achieved by ﬁnding the x ∈Cn that minimizes the squared error ∥Ax −y∥2 2. This least squares approach, however, is well-posed only if the nullspace of matrix A merely contains the zero vector. The cases in which the nullspace is greater than the singleton {0} , as in underdetermined scenarios (m < n), are more relevant in a variety of applications. To enforce unique least squares solutions in these cases, it becomes necessary to have some prior information about the structure of x⋆. One of the structural characteristics that describes parameters and signals of interest in a wide range of applications from medical imaging to astronomy is sparsity. Since the advent of the theory of compressed sensing, development and analysis of algorithms that exploit sparsity for estimation in underdetermined problems have become important topics of study. In the absence of noise x⋆can be uniquely determined from the observation vector y = Ax⋆, provided that spark (A) > 2 ∥x⋆∥0 (i.e., every 2 ∥x⋆∥0 columns of A are linearly independent) [12]. Then the ideal estimation procedure could simply be ﬁnding the sparsest vector x that incurs no residual error (i.e., ∥Ax −y∥2 = 0). This ideal estimation method can be extended ∗Corresponding author. Email addresses: sbahmani@cmu.edu (S. Bahmani), bhiksha@cs.cmu.edu (B. Raj) Preprint submitted to Elsevier March 15, 2018  to the case of noisy observations as well. Formally, given an upper bound ǫ on the ℓ2-norm of the noise, the vector x⋆can be estimated by solving the ℓ0-minimization arg min x ∥x∥0 s.t. ∥Ax −y∥2 ≤ǫ, (2) where ∥x∥0 denotes the ℓ0-norm1 of the vector x that merely counts the number of its non-zero entries. However, this minimization problem is in general NP-hard [17]. To avoid the combinatorial computational cost of (2), often the ℓ0-norm is substituted by the ℓp-norm1 ∥x∥p = (Pn i=1 |xi|p) 1/p for some p ∈(0, 1] providing the ℓp-minimization arg min x ∥x∥p s.t. ∥Ax −y∥2 ≤ǫ. (3) In particular, at p = 1 the ℓ1-minimization can be solved in polynomial time using convex programming algorithms. Several theoretical and experimental results [see e.g., 7, 20, 21] suggest that ℓp-minimization with p ∈(0, 1) requires fewer observations than the ℓ1-minimization to produce accurate estimates. However, ℓp-minimization is a non-convex problem where ﬁnding the global minimizer is not guaranteed and can be computationally',\n",
       " '1711.04268': '1.1 Overview Driven by advances in information sensing and acquisition, many application domains have evolved towards interconnected networks of information sources in which large-scale and complex data is constantly generated and processed for various inferential and decision-making purposes. Induced by their physical couplings, such information sources generate data streams that often bear strong statistical dependence structures. Probabilistic graphical models, in general, and Markov random ﬁelds (MRFs), in particular, provide effective analytical frameworks for encoding the statistical relationship among the datasets generated by different agents in a network [1–4]. Forming inferential decisions in an MRF strongly hinges on determining the dependence structure embedded in the MRF. There are two distinct aspects to determining an MRF structure: selecting (estimating) versus differentiating ∗ECSE Department, Rensselaer Polytechnic Institute, Troy, NY 12180. †Advanced AI Lab, LG Electronics USA, Santa Clara, CA 95054. ‡EE Department, Princeton University, Princeton, NJ 08540. This paper was presented in part at the 2015 Annual Allerton Conference on Communication, Control, and Computing. 1 arXiv:1711.04268v4  [stat.ME]  2 Aug 2020  (detecting) the models. In model selection (structure learning), the objective is to sample the random variables that form an MRF, and select (estimate) the edge set of the graphical model associated with the MRF (a representative list includes [5–18]). While the problem of graph structure learning is NP-hard in its general form [19], it becomes feasible under proper restrictions on the structure of the graph, e.g., limiting the graph to the classes of sparsely-connected graphs, edge-bounded graphs, and degree-bounded graphs. There is a rich literature investigating the algorithmic and information-theoretic aspects of structure learning, especially for Gaussian and Ising graphical models. The existing studies can be distinguished based on the sampling mechanisms that they adopt. Broadly, there exists two distinct approaches to sampling: (i) pre-speciﬁc sampling, in which sampling is agnostic to the data and follows prespeciﬁed rules [5–12], and (ii) active sampling, in which the sampling decisions are data-driven and they are updated dynamically as the data is collected [13–18]. In active sampling methods, sampling and model selection processes are inherently coupled, and the emphasis is on co-designing these two processes. In contrast, when the sampling mechanism is pre-speciﬁed, the sampling and model selection processes are decoupled, and the emphasis is placed on forming reliable decisions given a set of samples. In contrast to model selection, in model detection, the unknown model of an MRF is assumed to belong to a ﬁnite set of known models, and the objective is to sample the random variables in order to identify the true model. MRF model detection, in its simplest form, is used for deciding whether a given set of random variables are independent, which is referred to as testing against independence. More generally, dependence model detection is the process of deciding in favor of one dependence model against a group of alternative ones (a representative list of relevant literature includes',\n",
       " '1511.02954': 'Research in deep learning using neural networks has increased signiﬁcantly over the last years. This occurred due to the ability of deep neural networks to achieve higher performance when compared to other methods on problems with a large amount of data (Bengio et al., 2015) and advances in computing power, such as the use of graphic processing units (GPUs) (Raina et al., 2009). Despite the advances obtained by using GPUs for training deep neural networks, this step still can take a lot of time, which affects negatively both research and industry as new methods take longer to be tested and deployed. Some researches have focused on speeding up deep neural networks in general, including proposals based on hardware, such as using limited numerical precision (Gupta et al., 2015), which could increase the number of computing units on the hardware, and software, such as using Fourier transform to compute a convolution (Vasilache et al., 2014). These and other methods optimized for computation of neural networks on GPUs lead to the development of domainspeciﬁc libraries, such as cuDNN (Chetlur et al., 2014). In this paper, we focus on existing research interested in decreasing the training time, as these approaches are closer to the proposed method. However, we highlight that these improvements are not mutually exclusive and can be used together. Krizhevsky (2014) proposed a mixture of data and model parallelism over GPUs in a single machine based on the type of the layer, exploiting their particularities for increased speed. Essentially, the convolutional layers exploit data parallelism, since they are the most computing intensive part of the neural network, and the fully-connected layers exploit model parallelism, since they have most of the parameters and may not ﬁt in a single GPU. This leads to a signiﬁcant speedup in comparison to other existing methods for training convolutional neural networks over a GPU cluster. DistBelief (Dean et al., 2012) is another framework to speedup the training of large neural network by exploiting parallelism, but it focuses on clusters of computers. The data parallelism is exploited by dividing the data set in shards that are fed to different groups of computers, where each group replicates the full model and are synchronized through a parameter server. For the model parallelism, a locally connected neural network is used in order to reduce the communication among machines 1  Under review as a conference paper at ICLR 2016 that jointly represent one replica of the model. Since the model is locally connected, only the edges that cross the machine boundary need to be transmitted. This framework is extended in Coates et al. (2013) to use GPUs as computing units. These methods of model parallelization to handle large neural networks require communication between the multiple computing units, which usually is slower than the computation and characterizes an overhead in the learning process. Other methods of parallelization, such as computing the branches of a model like GoogleNet (Szegedy et al., 2014) in parallel, also require communication',\n",
       " '1303.1354': 'Stochastic geometry has recently been used for the analysis and performance evaluation of wireless (ad hoc as well as cellular) networks; in this approach, one models node locations as a spatial point process, e.g., homogeneous Poisson point processes, and one computes various network statistics, e.g., interference, successful transmission probability, coverage (or, outage) probability etc. as spatial averages. This often leads to tractable performance metrics that are amenable to parametric optimization with respect to network parameters (node density, protocol parameters, etc.). More precisely, this approach yields spatial averages of the performance metrics for given network parameters; then the parameters can be chosen to optimize performance. This approach takes a macroscopic view of the network with the underlying assumption that all nodes in the network have identical statistical characteristics. In practice, due to randomness and heterogeneity in networks, nodes need to adapt to local spatial and temporal conditions (e.g., channel conditions and topology) to reach optimum network wide performance. For example, nodes in wireless LANs adjust their window sizes based on acknowledgment feedback; in cellular networks nodes are scheduled based on channel conditions and adapt their transmit powers based on the measured SINRs, which in turn depend on the transmit powers set by other nodes. In all such scenarios, distributed adaptive algorithms are used to reach a desired network wide operating point e.g. that maximizing some utility. While the behavior of such distributed optimization protocols is often well understood on a given topology, there are usually no analytical characterizations of the statistical properties of the optimal state in large random and heterogeneous networks. The main aim of this work is to use stochastic geometry to study spatial adaptations of medium access control in Aloha that aim at optimizing certain utilities. While we identify a utility for which stochastic geometry can be used to compute the spatial distribution of MAP and the expected utility, we are far from being able to do so for all types of utilities within the α-fair class and we discuss the difﬁculties to be faced. Let us start with a review of the state of the art on Aloha. Wireless spectrum is well known to be a precious and scarce shared resource. Medium Access Control (MAC) algorithms are employed to coordinate access to the shared wireless medium. An efﬁcient MAC protocol should ensure high system throughput, and should also distribute the available bandwidth fairly among the competing nodes. The simplest of the MAC protocols, Aloha and slotted Aloha, with a ”random access” spirit, were introduced by Abramson [1] and Roberts [17] respectively. In these protocols, only one node could successfully transmit at a time. Reference [4] modeled node locations as spatial point processes, and also modeled channel fadings, interferences and SINR based reception. This allowed for spatial reuse and multiple simultaneous successful transmissions depending on SINR levels at the corresponding receivers. All the above protocols prescribe identical attempt probabilities for all the nodes. Reference [5] further proposed opportunistic Aloha in which',\n",
       " '1606.09184': 'Time series data is becoming increasingly important in medical research and practice. This is due, in part, to the growing adoption of electronic health records (EHRs), which capture snapshots of an individual’s state over time. These snapshots include clinical observations (apparent symptoms and vital sign measurements), laboratory test results, and treatment information. In parallel, medical researchers are beginning to recognize and appreciate that many diseases are in fact complex, highly heterogeneous syndromes [Craig, 2008] and that individuals may belong to disease subpopulations or subtypes that express similar sets of symptoms over time (see e.g. Saria and Goldenberg [2015]). Examples of such diseases include asthma [Lötvall et al., 2011], autism [Wiggins et al., 2012], and COPD [Castaldi et al., 2014]. The data captured in EHRs can help better understand these complex diseases. EHRs contain a multitude of types of observations and the ability to track their progression can help bring in to focus the subtle differences across individual disease expression. In this paper, we focus on two exploratory questions that we can begin to answer using repositories of biomedical time series data. First, we want to discover whether there are individuals with similar disease trajectories and whether there are a small number of degrees of freedom that account for differences across a heterogeneous population. A better understanding of the types of trajectories and how they differ can yield insights into the biological underpinnings of the disease. In turn, this may motivate new targeted therapies. In the clinic, physicians can analyze an individual’s clinical history to better understand the “ﬂavor” of the disease being expressed and can use this knowledge to make more accurate prognoses and guide treatment decisions. Second, we would like to know whether individuals with similar clinical outcomes (e.g. death, severe organ damage, or development of comorbidities) have similar disease trajectories. In complex diseases, individuals are often at risk of developing a number of severe complications and clinicians rarely have access to accurate prognostic biomarkers. Discovering associations between target outcomes and trajectory patterns arXiv:1606.09184v1  [stat.ML]  29 Jun 2016  may both generate new hypotheses regarding the causes of these outcomes and help clinicians to better anticipate the event using an individual’s clinical history. Contributions. Our approach to simultaneously answering these questions is to embed individual disease trajectories into a low-dimensional vector space wherein similarity in the embedded space implies that two individuals have similar trajectories. Such an embedding would naturally answer our ﬁrst question, and the results could also be used to answer the second by comparing distributions over embeddings across groups deﬁned by different outcomes. To produce such an embedding, we introduce a novel probabilistic model of biomedical time series data, which we term the Disease Trajectory Map (DTM). In particular, the DTM models the trajectory of a single clinical marker, which is an observation or measurement recorded over time by clinicians that are used to track the progression of a disease (see e.g. Schulam et al. [2015]). Examples',\n",
       " '1410.7550': 'High-dimensional time series include video streams, Electroencephalography (EEG) and sensor network Copyright 2014 by the authors. data. Dynamical models describing such data are desired for forecasting (prediction) and controller design, both of which play an important role, e.g., in autonomous systems, machine translation, robotics and surveillance applications. A key challenge is system identiﬁcation, i.e., ﬁnding a mathematical model of the dynamical system based on the information provided by measurements from the underlying system. In the context of state-space models this includes ﬁnding two functional relationships between (a) the states at diﬀerent time steps (prediction/transition model) and (b) states and corresponding measurements (observation/measurement model). In the linear case, this problem is very well studied, and many standard techniques exist, e.g., subspace methods [18], expectation maximization [16, 4] and prediction-error methods [9]. However, in realistic and practical scenarios we require non-linear system identiﬁcation techniques. Learning non-linear dynamical models is an inherently diﬃcult problem, and it has been one of the most active areas in system identiﬁcation for the last decades [10, 17]. In recent years, sequential Monte Carlo (SMC) methods have received attention for identifying non-linear state-space models [15], see also the recent surveys [6]. While methods based on SMC are powerful, they are also computationally expensive. Learning non-linear dynamical models from very high-dimensional sensor data is even more challenging. First, ﬁnding (non-linear) functional relationships in very high dimensions is hard (un-identiﬁability, local optima, overﬁtting, etc.); second, the amount of data required to ﬁnd a good function approximator is enormous. Fortunately, high-dimensional data often possesses an intrinsic lower dimensionality. We will exploit this property for system identiﬁcation by ﬁnding a low-dimensional representation of highdimensional data and learning predictive models in this low-dimensional space. For this purpose, we need an automated procedure for ﬁnding compact lowdimensional representations/features. arXiv:1410.7550v1  [stat.ML]  28 Oct 2014  Learning deep dynamical models from image pixels The state of the art in learning parsimonious representations of high-dimensional data is currently deﬁned by deep learning architectures, such as deep neural networks [5], stacked/deep auto-encoders [19] and convolutional neural networks [8], all of which have been successfully applied to image, text, speech and audio data in commercial products, e.g., by Google, Amazon and Facebook. Typically, these feature learning methods are applied to static data sets, e.g., for image classiﬁcation. The auto-encoder gives explicit expressions of two generative mappings: 1) an encoder g−1 mapping the high-dimensional data to the features, and 2) a decoder g mapping the features to high-dimensional reconstructions. In the machine learning literature, there exists a vast number of other well studied nonlinear dimensionality reduction methods such as the Gaussian process latent variable model (GP-LVM) [7], kernel PCA [14], Laplacian Eigenmaps [1] and Locally Linear Embedding [12',\n",
       " '1606.04289': 'Automated Text Scoring (ATS) refers to the set of statistical and natural language processing techniques used to automatically score a text on a marking scale. The advantages of ATS systems have been established since Project Essay Grade (PEG) (Page, 1967; Page, 1968), one of the earliest systems whose development was largely motivated by the prospect of reducing labour-intensive marking activities. In addition to providing a cost-effective and efﬁcient approach to large-scale grading of (extended) text, such systems ensure a consistent application of marking criteria, therefore facilitating equity in scoring. There is a large body of literature with regards to ATS systems of text produced by non-native English-language learners (Page, 1968; Attali and Burstein, 2006; Rudner and Liang, 2002; Elliot, 2003; Landauer et al., 2003; Briscoe et al., 2010; Yannakoudakis et al., 2011; Sakaguchi et al., 2015, among others), overviews of which can be found in various studies (Williamson, 2009; Dikli, 2006; Shermis and Hammer, 2012). Implicitly or explicitly, previous work has primarily treated text scoring as a supervised text classiﬁcation task, and has utilized a large selection of techniques, ranging from the use of syntactic parsers, via vectorial semantics combined with dimensionality reduction, to generative and discriminative machine learning. As multiple factors inﬂuence the quality of texts, ATS systems typically exploit a large range of textual features that correspond to different properties of text, such as grammar, vocabulary, style, topic relevance, and discourse coherence and cohesion. In addition to lexical and part-of-speech (POS) ngrams, linguistically deeper features such as types of syntactic constructions, grammatical relations and measures of sentence complexity are among some of the properties that form an ATS system’s internal marking criteria. The ﬁnal representation of a text typically consists of a vector of features that have been manually selected and tuned to predict a score on a marking scale. Although current approaches to scoring, such as regression and ranking, have been shown to achieve performance that is indistinguishable from that of human examiners, there is substantial manual effort involved in reaching these results on different domains, genres, prompts and so forth. Linguistic features intended to capture the aspects of writing to be assessed are hand-selected and tuned for speciﬁc domains. In order to perform well on different data, separate models with distinct feature sets are typically tuned. Prompted by recent advances in deep learning and the ability of such systems to surpass state-ofthe-art models in similar areas (Tang, 2015; Tai et arXiv:1606.04289v2  [cs.CL]  16 Jun 2016  al., 2015), we propose the use of recurrent neural network models for ATS. Multi-layer neural networks are known for automatically learning useful features from data, with lower layers learning basic feature detectors and upper levels learning more high-level abstract features (Lee et al., 2009). Additionally, recurrent neural networks are well-suited for modeling the compositionality of language and have been',\n",
       " '1802.06897': 'The assignment problem is a classic combinatorial optimization problem where the goal is to find a weighted matching within a bipartite graph such that the sum of the weights is minimized. Within the field of computer vision, it is often used as a framework for tackling data association in multi-object tracking. In this survey, we set out to reexamine the data association problem through the lens of assignment problems as a means to abstract away details and to create a clear conceptual framework for unifying the many recently proposed learning-based data association algorithms. Visual multi-object tracking is a highly complex topic, so rather than attempt to provide a comprehensive overview, we instead take a closer look at solely the association step. Later, we will suggest surveys that review other aspects of the complete multi-object tracking problem for the interested reader. In this work we argue that studying how machine learning can be used to solve data association is important for the following reasons. First, modern machine learning methods, particularly convolutional neural networks (CNNs), excel at learning discriminative Authors’ addresses: Patrick Emami, University of Florida, 432 Newell Dr, Gainesville, FL, 32611, USA, pemami@ufl.edu; Panos M. Pardalos, University of Florida, 401 Weil Hall, Gainesville, FL, 32611, USA, p.m.pardalos@gmail.com; Lily Elefteriadou, University of Florida, 512 Weil Hall, Gainesville, FL, 32611, USA, elefter@ce.ufl.edu; Sanjay Ranka, University of Florida, 432 Newell Dr, Gainesville, FL, 32611, USA, sanjayranka@gmail.com. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. © 2020 Association for Computing Machinery. XXXX-XXXX/2020/8-ART $15.00 https://doi.org/0000001.0000001 , Vol. 1, No. 1, Article . Publication date: August 2020. arXiv:1802.06897v2  [cs.CV]  25 Aug 2020  2 P. Emami et al. features from raw sensor inputs for computing similarities between objects, which is an integral step for any data-driven matching task. For example, a recent study by Bergman et al. [10] showed that a simple CNN bounding box regressor can be exploited to extend object tracks over time and drastically reduce the number of ID switches, putting into question the efficacy of sophisticated data association algorithms. Second, efficient probabilistic tools for approximate inference over highly structured models, such as those that arise in data association, have long been studied and are useful for dealing with noisy sensor measurements. Finally, there are many promising recent works on applying machine learning to directly solve a variety of combinatorial optimization',\n",
       " '0903.0548': 'Wireless communications channels today are vulnerable to eavesdropping or wiretapping due to the open nature of the channel, making the characterization of transmission rates for secure and reliable communication for the physical layer an important issue. In the wireless broadcast medium, the model of the broadcast channel (BC) with conﬁdential messages, which was studied by Csisz´ar and K¨orner [1], is used to study simultaneously secure The authors are with the Department of Electronic and Electrical Engineering, University College London, Torrington Place, London WC1E 7JE, United Kingdom (email: {l.choo, kwong}@ee.ucl.ac.uk). The material in this paper will be presented in part at the International Conference on Wireless Communications and Signal Processing 2009, Nov. 13-15, Nanjing, China, 2009.  2 and reliable communication. The model in [1] is a generalization of the characterization of the wiretap channel by Wyner [2]. In [1], a common message is sent to 2 receivers, while a conﬁdential message is sent to one of the receivers and kept secret from the other. The secrecy level is determined by the equivocation rate, which is the entropy rate of the conﬁdential message conditioned on the channel output at the eavesdropper or wiretapper. The secrecy capacity region is deﬁned as the set of transmission rates where the legitimate receiver decodes its conﬁdential message while keeping the message secret from the wiretapper. In more recent studies on the BC with conﬁdential messages, Liu et al. [3] studied the scenario where there are 2 receivers and private messages are sent to each one and kept secret from the unintended receiver, while Xu et al. [4] looked at the same model in [3] but with a common message to both receivers. Then, Bagherikaram et al. [5] addressed the scenario where there are 2 receivers and one wiretapper, with conﬁdential messages sent to the receivers. There have been recent studies where more than 2 receivers were considered. The authors in [6] and Ekrem and Ulukus in [7] independently studied the K-receiver BC with an external wiretapper. In [6], the K-receiver BC with conﬁdential messages sent to each receiver was studied, while in [7], the same scenario was studied with the addition that each receiver also received a common message. Both used the degraded BC. In another work, an achievable inner bound for the K-receiver BC with a common message sent to all receivers and a conﬁdential message sent to each of the receivers to be kept secret from an external wiretapper was derived by Kobayashi et al. in [8] for general conditions on the receivers’ and wiretapper’s channels. Finally, Chia and El Gamal in [9] derived an achievable inner bound for the 3-receiver BC with a common message sent to all receivers and a private message sent to 2 of the receivers to be kept secret from the third. Recently in [10]–[12], Nair and El Gamal introduced the channel model of the 3-receiver BC with degraded message sets. In the general',\n",
       " '1710.06425': 'Robotic grasping remains one of the core unsolved problems in manipulation. The earliest robotic grasping methods used analytical knowledge of a scene to compute an optimal 1 OpenAI 2 UC Berkeley 3 Weights and Biases, Inc 4 Embodied Intelligence 5 NVIDIA ∗Work done while at OpenAI † Equal advising Correspondence to josh@openai.com grasp for an object [1], [31], [32], [38], [39], [45]. Assuming a contact model and a heuristic for the likelihood of success of a grasp, analytical methods can provide guarantees about grasp quality, but they often fail in the real world due to inconsistencies in the simpliﬁed object and contact models, the need for accurate 3D models of the objects in question, and sensor inaccuracies [2]. As a result, signiﬁcant research attention has been given to data-driven grasp synthesis methods [2], [8], [27]–[29], [35], [43]. These algorithms avoid some of the challenges of analytic methods by sampling potential grasps and ranking them according to a learned function that maps sensor inputs to an estimate of a chosen heuristic. Recently, several works have explored using deep neural networks to approximate the grasp heuristic function [14], [23], [24], [36]. The promise of deep neural networks for learning grasp heuristics is that with diverse training data, deep models can learn features that deal with the edge cases that make real-world grasping challenging. A core challenge for deep learning grasp quality heuristics is data availability. Due to the difﬁculty and expense of collecting real-world data and due to the limited availability of high-quality 3D object meshes, current approaches use as few as hundreds or thousands of unique object instances, which may limit generalization. In contrast, ImageNet [18], the standard benchmark for image classiﬁcation, has about 15M unique images from 22K categories. In order to increase the availability of training data in simulation, we explore applying the idea of domain randomization [41], [46] to the creation of 3D object meshes. arXiv:1710.06425v2  [cs.RO]  3 Apr 2018  Domain randomization is a technique for learning models that work in a test domain after only training on low-ﬁdelity simulated data by randomizing all non-essential aspects of the simulator. One of the core hypotheses of this work is that by training on a wide enough variety of unrealistic procedurally generated object meshes, our learned models will generalize to realistic objects. Previous work in deep learning for grasping has focused on learning a function that estimates the quality of a given grasp given observations of the scene. Choosing grasps on which to perform this estimate has received comparatively little attention. Grasps are typically chosen using random sampling or by solving a small optimization problem online. The second goal of this paper is to propose a deep learningbased method for choosing grasps to evaluate. Our hypothesis is that a learned model for grasp sampling will be more likely to ﬁnd high-quality grasps for challenging objects and will do so more efﬁciently. We use an',\n",
       " '1511.04508': 'Deep Learning (DL) has been demonstrated to perform exceptionally well on several categories of machine learning problems, notably input classiﬁcation. These Deep Neural Networks (DNNs) efﬁciently learn highly accurate models from a large corpus of training samples, and thereafter classify unseen samples with great accuracy. As a result, DNNs are used in many settings [1], [2], [3], some of which are increasingly security-sensitive [4], [5], [6]. By using deep learning algorithms, designers of these systems make implicit security assumptions about deep neural networks. However, recent work in the machine learning and security communities have shown that adversaries can force many machine learning models, including DNNs, to produce adversary-selected outputs using carefully crafted inputs [7], [8], [9]. Speciﬁcally, adversaries can craft particular inputs, named adversarial samples, leading models to produce an output behavior of their choice, such as misclassiﬁcation. Inputs are crafted by adding a carefully chosen adversarial perturbation to a legitimate sample. The resulting sample is not necessarily unnatural, i.e. outside of the training data manifold. Algorithms crafting adversarial samples are designed to minimize the perturbation, thus making adversarial samples hard to distinguish from legitimate samples. Attacks based on adversarial samples occur after training is complete and therefore do not require any tampering with the training procedure. To illustrate how adversarial samples make a system based on DNNs vulnerable, consider the following input samples: a car a cat The left image is correctly classiﬁed by a trained DNN as a car. The right image was crafted by an adversarial sample algorithm (in [7]) from the correct left image. The altered image is incorrectly classiﬁed as a cat by the DNN. To see why such misclassiﬁcation is dangerous, consider deep learning as it is commonly used in autonomous (driverless) cars [10]. Systems based on DNNs are used to recognize signs or other vehicles on the road [11]. If perturbing the input of such systems, by slightly altering the car’s body for instance, prevents DNNs from classifying it as a moving vehicule correctly, the car might not stop and eventually be involved in an accident, with potentially disastrous consequences. The threat is real where an adversary can proﬁt from evading detection or having their input misclassiﬁed. Such attacks commonly occur today in non-DL classiﬁcation systems [12], [13], [14], [15], [16]. Thus, adversarial samples must be taken into account when designing security sensitive systems incorporating DNNs. Unfortunately, there are very few effective countermeasures available today. Previous work considered the problem of constructing such defenses but solutions proposed are deﬁcient in that they require making modiﬁcations to the DNN architecture or only partially prevent adversarial samples from being effective [9], [17] (see Section VII). Distillation is a training procedure initially designed to train a DNN using knowledge transferred from a different DNN. The intuition was suggested in [18] while distillation itself was formally introduced in [19]. The motivation behind the knowledge transfer operated by distillation is to reduce the computational complexity of DNN architectures',\n",
       " 'cs/0606052': 'The paper studies the problem of designing the topology of a graph network. As a motivational application we consider the problem of describing the connectivity graph of a sensor network, i.e., specifying with which sensors should each sensor in the network communicate. We will show that the topology of the network has a major impact on the convergence of distributed inference algorithms, namely, that these algorithms converge much faster for certain connectivity patterns than for others, thus requiring much less intersensor communication and power expenditure. The literature on topology design for distributed detection is scarce. Usually, the underlying communication graph is speciﬁed ab initio as a structured graph, e.g., parallel networks where sensors communicate with a fusion center, [1], [2], [3], [4], or serial networks where communication proceeds sequentially from a sensor to the next; for these and other similar architectures, see Varshney [5] or [6], [7]. These networks may not be practical; e.g., a parallel network depends on the integrity of the fusion center. We published preliminary results on topology design for distributed inference problems in [8], [9]. We restricted the class of topologies to structured graphs, random graphs obtained with the Erd¨osR´enyi construction, [10], [11], [12], see also [13], [14], or random constructions that exhibit small-world characteristics, see Watts-Strogatz [15], see also Kleinberg [16], [17]. We considered tradeoffs among these networks, their number of links M, and the number of bits b quantizing the state of the network at each sensor, under a global rate constraint, i.e., Mb = K, K ﬁxed. We adopted as criterion the convergence of the average probability of error Pe, which required extensive simulation studies to ﬁnd the desired network topology. Reference [18] designs Watts-Strogatz topologies in distributed consensus estimation problems, adopting as criterion the algebraic connectivity λ2(L) of the graph. This paper designs good topologies for sensor networks, in particular, with respect to the rate of convergence of iterative consensus and distributed detection algorithms. We consider the two cases of noiseless and noisy network links. We assume that the total number M of communication links between sensors is ﬁxed and that the graph weights are uniform across all network links. This paper shows that, for both the iterative average-consensus and the distributed detection problems, the topology design problem is equivalent to the problem of maximizing with respect to the network topology a certain graph spectral parameter γ. This parameter is the ratio of the algebraic connectivity of the graph over the largest eigenvalue λN(L) of the graph Laplacian L. The algebraic connectivity of a graph, terminology introduced by [19], is the second smallest eigenvalue λ2(L) of its discrete Laplacian; see section II, the Appendix, and reference [20] for the deﬁnition of relevant spectral graph concepts. With this reinterpretation, we show that the class of Ramanujan graphs essentially provides the optimal network topologies, exhibiting  3 remarkable convergence properties, orders of magnitude faster than other structured or random smallworld',\n",
       " '1512.09080': '1 1.1 Our results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2 1.2 Related literature . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 1.3 Related models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 2 Results 7 2.1 Achieving the KS threshold eﬃciently . . . . . . . . . . . . . . . . . . . . . 8 2.1.1 Acyclic Belief Propagation (ABP) Algorithm . . . . . . . . . . . . . 9 2.2 Crossing the KS threshold information-theoretically . . . . . . . . . . . . . 12 2.2.1 Typicality Sampling Algorithm . . . . . . . . . . . . . . . . . . . . . 13 2.3 Learning the model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14 3 Achieving the KS threshold: proof technique 14 3.1 Amplifying luck . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14 3.2 Nonbacktracking walks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17 3.3 Compensation for the average value . . . . . . . . . . . . . . . . . . . . . . 20 3.4 Vanilla ABP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21 3.5 ABP for the symmetric SBM . . . . . . . . . . . . . . . . . . . . . . . . . . 23 3.6 Spectral view of ABP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26 3.7 ABP for the general SBM . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28 3.8 Alternatives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30 4 Crossing the KS threshold: proof technique 31 5 Open problems 35 6 Proofs 36 6.1 Achieving the KS threshold . . . . . . . . . . . . . . . . . . . . . . . . . . . 36 6.1.1 Preliminaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40 6.1.2 The shard decomposition . . . . . . . . . . . . . . . . . . . . . . . . 41 6.1.3 Bounding the variance of Wm/S . . . . . . . . . . . . . . . . . . . . . 48 6.2 Crossing the KS threshold . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63 6.2.1 Atypicality of a bad clustering . . . . . . . . . . . . . . . . . . . . . 63 6.2.2 Size of the typical set . . . . . . . . . . . . . . . . . . . . . . . . . . 67 6.2.3 Sampling probability estimates . . . . . . . . . . . . . . . . . . . . . 74 6.3 Learning the model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75  1 Introduction The stochastic block model (SBM) is a canonical model of networks with communities, and a natural model to study various central questions in machine learning, algorithms and statistics. The model serves in particular as a test bed for clustering and community detection algorithms, commonly used in social networks [NWS], protein-to-protein interactions networks [CY06], gene expressions [CSC+07], recommendation systems [LSY03], medical prognosis [SPT+01], DNA folding [CAT15], image segmentation [SM97], natural language processing [BKN11] and more. The SBM emerged independently in multiple scientiﬁc communities. The block model terminology, which seems to have dominated in the recent years, comes from the machine learning and statistics literature [HLL83, WBB76, FMW85, WW87, BC09, KN11, SN97, RCY11, CWA12], while the model is typically called the planted partition model in theoretical computer science [BCLS87, DF89, Bop87, JS98, CK99, CI01, McS01], and the inhomogeneous random graphs model in the mathematical literature [BJR07]. Although the model was deﬁned as far back as the 80s, it resurged in recent years due in part to the following fascinating conjecture established ﬁrst in [DKMZ11], and backed in [MNS15], from deep but non-rigorous statistical physics arguments: Conjecture 1. Let (X, G) be drawn from SBM(n, k, a, b), i.e., X is uniformly drawn among partitions of [n] into k balanced clusters, and G is a random graph on the vertex set [n] where edges are placed independently with probability a/n inside the clusters and b/n across. Deﬁne SNR = (a−b)2 k(a+(k−1)b) and say that an algorithm detects communities if it takes as an input the graph G and outputs a clustering ˆX that is positively correlated with X with high probability. Then, (i) Irrespective of k, if SNR > 1, it is possible to detect communities in polynomial time, i.e., the Kesten-Stigum (KS) threshold can be achieved eﬃciently',\n",
       " '1802.05883': 'Natural language processing applications often count on the availability of word representations trained on large textual data as a means to alleviate problems such as data sparsity and lack of linguistic resources (Collobert et al., 2011; Socher et al., 2011; Tu et al., 2017; Bowman et al., 2015). Traditional approaches to inducing word representations circumvent the need for explicit semantic annotation by capitalising on some form of indirect semantic supervision. A typical example is to ﬁt a binary classiﬁer to detect whether or not a target word is likely to co-occur with neighbouring words (Mikolov et al., 2013). If the binary classiﬁer represents a word as a continuous vector, that vector will be trained to be discriminative of the contexts it co-occurs with, and thus words in similar contexts will have similar representations. Code available from https://github.com/ uva-slpl/embedalign MR and WA contributed equally. The underlying assumption is that context (e.g. neighbouring words) stands for the meaning of the target word (Harris, 1954; Firth, 1957). The success of this distributional hypothesis hinges on the deﬁnition of context and different models are based on different deﬁnitions. Importantly, the nature of the context determines the range of linguistic properties the representations may capture (Levy and Goldberg, 2014b). For example, Levy and Goldberg (2014a) propose to use syntactic context derived from dependency parses. They show that their representations are much more discriminative of syntactic function than models based on immediate neighbourhood (Mikolov et al., 2013). In this work, we take lexical translation as indirect semantic supervision (Diab and Resnik, 2002). Effectively we make two assumptions. First, that every word has a foreign equivalent that stands for its meaning. Second, that we can ﬁnd this equivalent in translation data through lexical alignments.1 For that we induce both a latent mapping between words in a bilingual sentence pair and distributions over latent word representations. To summarise our contributions: • we model a joint distribution over sentence pairs that generates data from latent word representations and latent lexical alignments; • we embed words in context mining positive correlations from translation data; • we ﬁnd that foreign observations are necessary for generative training, but test time predictions can be made monolingually; • we apply our model to a range of semantic natural language processing tasks showing its usefulness. 1These assumptions are not new to the community, but in this work they lead to a novel model which reaches more applications. §4 expands on the relation to other uses of bilingual data for word representation. arXiv:1802.05883v3  [cs.CL]  23 Apr 2018  x y z a θ m n |B| Figure 1: A sequence xm 1 is generated conditioned on a sequence of random embeddings zm 1 ; generating the foreign sequence yn 1 further requires latent lexical alignments an 1. 2 EMBEDALIGN In a nutshell, we model a distribution over pairs of sentences expressed in two languages, namely, a language of',\n",
       " '1609.07132': 'Denoising speech signals has been a long standing problem. Decades of works showed feasible solutions which estimated the noise model and used it to recover noise-deducted speech [1, 2, 3, 4, 5]. Nonetheless, estimating the model for a babble noise, which is encountered when a crowd of people are talking, is still a challenging task. The presence of babble noise, however, degrades hearing intelligibility of human speech greatly. When babble noise dominates over speech, aforementioned methods often times will fail to ﬁnd the correct noise model [6]. If so, the noise-deduction will render distortion in speech, which creates discomforts to the users of hearing aids [7]. Here, instead of explicitly modeling the babble noise, we focus on learning a ‘mapping’ between noisy speech spectra and clean speech spectra, inspired by recent works on speech enhancement using neural networks [8, 9, 10, 11]. However, the model size of Neural Networks easily exceeds several hundreds of megabytes, limiting its applicability for an embedded system. On the other hand, Convolutional Neural Networks (CNN) typically consist of lesser number of parameters than FNNs and RNNs due to its weight sharing property. CNNs already proved its efﬁcacy on extracting features in speech recognition [12, 13] or on eliminating noises in images [14, 15]. But upon our knowledge, CNNs have not been tested in speech enhancement. In this paper, we attempted to ﬁnd a ‘memory efﬁcient’ denoising algorithm for babble noise that creates minimal artifacts and that can be implemented in an embedded device: the hearing aid. Through experiments, we demonstrated that CNN can perform better than Feedforward Neural Networks (FNN) or Recurrent Neural Networks (RNN) with much smaller network size. A new network architecture, Redundant Convolutional Encoder Decoder (R-CED), is Fig. 1: Speech Enhancement Using a CNN proposed, which extracts redundant representations of a noisy spectrum at the encoder and map it back to clean a spectrum at the decoder. This can be viewed as mapping the spectrum to higher dimensions (e.g. kernel method), and projecting the features back to lower dimensions. The paper is organized as follows. In section 2, a formal deﬁnition of the problem is stated. In section 3, the fully convolutional network architectures are presented including the proposed R-CED network. In section 4, the experimental methods are provided. In section 5, description of the experiments and the corresponding network conﬁgurations are provided. In section 6, the results are discussed, and in section 7, we end with conclusion of this study. 2. PROBLEM STATEMENT Given a segment of noisy spectra {xt}T t=1 and clean spectra {yt}T t=1, our aim is to learn a mapping f which generates a segment of ‘denoised’ spectra {f(xt)}T t=1 that approximate the clean spectra in the ℓ2 norm, e.g. min T X t=1 ||yt −f(xt)||2 2. (1) Speciﬁcally, we formulate f using a Neural Network',\n",
       " '1610.05556': 'Bayesian Networks (BN) are a canonical formalism for representing probability distributions over sets of variables and reasoning about them. A useful extension for modeling phenomena with recurrent temporal behavior are Dynamic Bayesian Networks (DBN). While regular BN are directed acyclic graphs, DBN may contain cycles, with some edges indicating dependence of a variable at time t + 1 on another variable at time t. The cyclic graph in fact compactly represents an inﬁnite acyclic graph formed by inﬁnitely many replicas of the G. Blondel Universitat Polit`ecnica de Catalunya E-mail: gillesblondel@yahoo.com M. Arias Universitat Polit`ecnica de Catalunya E-mail: marias@cs.upc.edu R. Gavald`a Universitat Polit`ecnica de Catalunya E-mail: gavalda@cs.upc.edu cyclic net, with some of the edges linking nodes in the same replica, and others linking nodes in consecutive replicas. BN and DBN model conditional (in)dependences, so they are restricted to observational, non-interventional data or, equivalently, model association, not causality. Pearl’s causal graphical models and do-calculus [1] are a leading approach to modeling causal relations. They are formally similar to BN, as they are directed acyclic graphs with variables as nodes, but edges represent causality. A new notion is that of a confounder, an unobserved variable X that causally inﬂuences two variables Y and Z so that the association between Y and Z may erroneously be taken for causal inﬂuence. Confounders are unnecessary in BNs since the association between Y and Z represents their correlation, with no causality implied. Causal graphical models allow to consider the effect of interventions or experiments, that is, externally forcing the values of some variables regardless of the variables that causally affect them, and studying the results. The do-calculus is an algebraic framework for reasoning about such experiments: An expression Pr(Y |do(X)) indicates the probability distribution of a set of variables Y upon performing an experiment on another set X. In some cases, the effect of such an experiment can be obtained from observational data only; this is convenient as some experiments may be impossible, expensive, or unethical to perform. When the expression Pr(Y |do(X)), for a given causal network, can be rewritten as an expression containing only observational probabilities, without a do operator, we say that it is identiﬁable. [2,3] showed that a do-expression is identiﬁable if and only if it can be rewritten in this way with a ﬁnite number of applications of the three rules of docalculus, and [2] proposed the ID algorithm which performs this transformation if at all possible, or else returns fail indicating non-identiﬁability. In this paper we use a causal analog of DBNs to model phenomena where a ﬁnite set of variables evolves over time, with some variables causally inﬂuencing others at the same arXiv:1610.05556v1  [cs.AI]  18 Oct 2016  2 Gilles Blondel et al. time t but also others',\n",
       " '1310.3697': 'In Reinforcement Learning (RL; [1]) and planning in Markov Decision Processes (MDPs; [2]), the typical objective is to maximize the cumulative (possibly discounted) expected reward, denoted by J. When the model’s parameters are known, several well-established and efﬁcient optimization algorithms are known. When the model parameters are not known, learning is needed and there are several algorithmic frameworks that solve the learning problem effectively, at least when the model is ﬁnite. Among these, actor-critic methods [3] are known to be particularly efﬁcient. In typical actor-critic algorithms, the critic maintains an estimate of the value function – the expected reward-to-go. This function is then used by the actor to estimate the gradient of the objective with respect to some policy parameters, and then improve the policy by modifying the parameters in the direction of the gradient. The theory that underlies actor-critic algorithms is the policy gradient theorem [4], which relates the value function with the policy gradient. In A. Tamar and S. Mannor are with the Department of Electrical Engineering, Technion – Israel Institute of Technology, Haifa, Israel, 32000. September 14, 2018 DRAFT  2 practice, for the expected-return objective, actor-critic algorithms have been used successfully in many domains [5],[6]. In many applications such as ﬁnance and process control, however, the decision maker is also interested in minimizing some form of risk of the policy. By risk, we mean reward criteria that take into account not only the expected reward, but also some additional statistics of the total reward, such as its variance, denoted by V . In this work, we speciﬁcally consider a varianceadjusted objective of the form J −µV , where µ is a parameter that controls the penalty on the variance. Recently, several studies have considered RL with such an objective. In [7] a policy gradient (actor only) approach was proposed. Actor-critic algorithms are known to improve over actoronly methods by reducing variance in the gradient estimate, thus motivating the extension of the work in [7] to an actor-critic framework. In [8] a variance-penalized actor-critic framework was proposed, but without function approximation for the critic. Function approximation is essential for dealing with large state spaces, as required by any real-world application, and introduces signiﬁcant algorithmic and theoretical challenges. In this work we address these challenges, and extend the work in [8] to use linear function approximation for the critic. In [9] an actor-critic algorithm that uses function approximation was proposed for the variance-penalized objective. In this algorithm, however, the actor uses simultaneous perturbation methods [10] to estimate the policy gradient. One drawback of this approach is that convergence can only be guaranteed to locally optimal points of a modiﬁed objective function, which takes into account the error induced by function approximation. This error depends on the choice of features, and in general, there is no guarantee that it will be small. Another drawback of the method in [10] is that two trajectories are needed',\n",
       " '1611.10152': 'F ACIAL landmark detection, or face alignment, aims to localize a set of semantic points, such as eye-corners, nose tip, and lips, on a face image accurately and efﬁciently. It is a fundamental problem in computer vision study with wide applications in face recognition, facial expression analysis, human-computer interaction, video games, etc. Impressive progress has been made on facial landmark detection in recent years and current methods could provide reliable results for near-frontal face images [1], [2], [3], [4], [5], [6]. However, it is still a challenging problem for localizing landmarks in face images with partial occlusions or large appearance variations due to illumination conditions, poses, and expression changes. This work was supported in part by the National Key Research and Development Program of China under Grant 2016YFB1001000, in part by the National Natural Science Foundation of China under Grant 61573360, Grant 61427811 and Grant 61702513. (Corresponding author: Qi Li, Zhenan Sun.) H. Zhang, Q. Li, Z. Sun, and Y. Liu are with the Center for Research on Intelligent Perception and Computing, National Laboratory of Pattern Recognition, Institute of Automation, CAS Center for Excellence in Brain Science and Intelligence Technology, Chinese Academy of Sciences, 100190, Beijing, China. E-mail: hongwen.zhang@cripac.ia.ac.cn; qli@nlpr.ia.ac.cn; znsun@nlpr.ia.ac.cn; yunfan.liu@cripac.ia.ac.cn. H. Zhang and Z. Sun are also with the University of Chinese Academy of Sciences, Beijing, China. In order to deal with these difﬁculties in facial landmark detection, a robust solution should make use of both textural appearance information in facial images and the inherent structural constraint of facial landmarks. For appearance information, the classic Active Shape Models (ASMs) [7] build the proﬁle models via multivariate Gaussians to capture the appearance variance. Active Appearance Models (AAMs) [8], [9] construct the holistic appearance on the shape-free warped textures. Both ASMs and AAMs build generative models based on the appearance information, and it is hard for them to reﬂect complex and subtle face variations in natural conditions. In order to capture the textural information more effectively, Constrained Local Models (CLMs) [10], [11] train the local experts discriminatively for each facial landmark. For regression-based methods [1], [2], [3], the appearance information is encoded in shape-indexed features [1] represented by handcrafted descriptors (e.g. SIFT) [2] or learned in a data-driven manner [3]. Meanwhile, Deep Neural Networks (DNNs) also prove to be competent for extracting features invariant to various undesired conditions [12], [6], [13], [14]. Different network architectures including Convolutional Neural Networks (CNNs) [12], Auto-Encoder [4], [15], Recurrent Neural Networks (RNNs) [16], [14], [17] and Fully Convolutional Networks (FCNs) [13], [18] have been exploited as regressors to predict the facial landmark shapes or response maps for each individual facial landmark. Data-driven methods have shown their expressive power in handling the appearance variations caused by head poses and expressions [6], [19], [18]. For shape constraint, ASMs, AAMs and CLMs build Point Distribution Model (PDM) [7] by applying Principal Com',\n",
       " '1401.6330': 'Sentiment analysis (Pang and Lee 2008; Liu 2012) has received much attention from both research and industry communities in recent years. Sentiment classiﬁcation, which identiﬁes sentiment polarity (positive or negative) from text (sentence or document), has been the most extensively studied task in sentiment analysis. Up until now, there have been two mainstream approaches for sentiment classiﬁcation. The lexicon-based approach (Turney 2002; Taboada et al. 2011) aims to aggregate the sentiment polarity of a sentence from the polarity of words or phrases found in the sentence, while the learning-based approach (Pang, Lee, and Vaithyanathan 2002) treats sentiment polarity identiﬁcation as a special text classiﬁcation task and focuses on building classiﬁers from a set of sentences (or documents) annotated with their corresponding sentiment polarity. The lexicon-based sentiment classiﬁcation approach is simple and interpretable, but suffers from scalability and is inevitably limited by sentiment lexicons that are commonly created manually by experts. It has been widely recognized that sentiment expressions are colloquial and evolve over time very frequently. Taking tweets from Twitter1 and movie reviews in IMDB2 as examples, people use very casual language as well as informal and new vocabulary to comment on general topics and movies. In practice, it is not feasible to create and maintain sentiment lexicons to capture sentiment expressions with high coverage. On the other hand, the learning-based approach relies on large annotated samples to overcome the vocabulary coverage and deals with variations of words in sentences. Human ratings in reviews (Maas et al. 2011) and emoticons in tweets (Davidov, Tsur, and Rappoport 2010; Zhao et al. 2012) are extensively used to collect a large number of training corpora to train the sentiment classiﬁer. However, it is usually not easy to design effective features to build the classiﬁer. Among others, unigrams have been reported as the most effective features (Pang, Lee, and Vaithyanathan 2002) in sentiment classiﬁcation. Handling complicated expressions delivering people’s opinions is one of the most challenging problems in sentiment analysis. Among others, compositionalities such as negation, intensiﬁcation, contrast, and their combinations are typical cases. We show some concrete examples below. (1) The movie is not good. [negation] (2) The movie is very good. [intensiﬁcation] (3) The movie is not funny at all. [negation + intensiﬁcation] (4) The movie is just so so, but i still like it. [contrast] (5) The movie is not very good, but i still like it. [negation + intensiﬁcation + contrast] The negation expressions, intensiﬁcation modiﬁers, and the contrastive conjunction can change the polarity ((1), (3), (4), (5)), strength ((2), (3), (5)), or both ((3), (5)) of 1 http://twitter.com 2 http://www.imdb.com 2  Li Dong, Furu Wei, et al. A Statistical Parsing Framework for Sentiment Classiﬁcation the sentiment of the sentences. We do not need any detailed explanations here as they can be commonly found and easily understood in people’s daily lives. Existing works to address these issues usually relies on syntactic parsing results either used as features (Choi and Cardie',\n",
       " '1009.3083': 'The Cognitive InterFerence Channel (C-IFC) consists of a classical two-user interference channel with two independent messages, in which the messages of the “primary” user is noncausally provided to the transmitter of the other “secondary” or “cognitive” user. This channel models the ability of intelligent and adaptive devices to listen to the wireless environment and obtain information about the other nodes’ activity, which may be utilized in a selﬁsh or altruistic manner in the transmission of their own message. The C-IFC may be seen as a limiting case of the cooperative communications paradigm where cooperation between transmitters is modeled as asymmetric and non-causal – an idealization of the more realistic causal cooperation. The capacity of the C-IFC is known only for some classes of Discrete Memoryless (DM) and Additive White Gaussian Noise (AWGN) channels. In particular, capacity is known for the linear high-SNR deterministic C-IFC [1], a deterministic channel that models the AWGN C-IFC in the high-SNR regime, and for certain AWGN C-IFCs [2]–[7]. In this paper we derive the capacity of the general semi-deterministic CIFC: a discrete memoryless C-IFC in which the cognitive output is a deterministic function of the channel inputs, while the primary output remains fully general (probabilistic). This The work of S. Rini and D. Tuninetti was partially funded by NSF under award 0643954. class of channels contains the linear high-SNR deterministic channel [1] as special case. We next use the intuition provided by the capacity achieving scheme of the semi-deterministic C-IFC to obtain an achievable rate region for the AWGN CIFC which lies to within half a bit/sec/Hz per real dimension of the outer bound in [7, Th.4] – improving both on the previous available gap result of about two bits/sec/Hz per real dimension of [8], as well as achieving it with a single scheme. We furthermore obtain a multiplicative gap of a factor two for the AWGN C-IFC, of importance in approximately characterizing the channel capacity at low-SNR regime. This multiplicative gap result improves on the result in [6] as it holds for a general AWGN C-IFC. A. Past Work The C-IFC was ﬁrst introduced in [9] and has since been explored by numerous groups. Due to space constraints we outline only a few key results; more extended treatments and comparisons of achievable rate regions and outer bounds may be found in [5]. For the general DM C-IFC, capacity was known in the “very weak interference” regime [3], and in the “very strong interference” regime [4]; recently these two results have been uniﬁed and extended in [5] where capacity was shown for the “better cognitive decoding” regime. For the AWGN C-IFC, capacity is known in the “weak interference” regime [2], [3], in the “very strong interference” regime [4], and in the “primary decodes cognitive” regime [6]. Most of the',\n",
       " '1312.0482': 'The phrase translation model, also known as the phrase table, is one of the core components of  phrase-based statistical machine translation (SMT) systems. The most common method of constructing the phrase table takes a two-phase approach [17]. First, the bilingual phrase pairs are extracted heuristically from an automatically word-aligned training data. The second phase, which is  the focus of this paper, is parameter estimation where each phrase pair is assigned with some scores  that are estimated based on counting these phrases using the same word-aligned training data.  Phrase-based SMT systems have achieved state-of-the-art performance largely due to the fact that  long phrases, rather than single words, are used as translation units so that useful context information  can be captured in selecting translations. However, longer phrases occur less often in training data,  leading to a severe data sparseness problem in parameter estimation. There has been a plethora of  research reported in the literature on improving parameter estimation for the phrase translation  model [e.g., 6, 8, 10, 25].   This paper revisits the problem of scoring a phrase translation pair by developing a novel, Semantic-based Phrase Translation Model (SPTM). The translation score of a phrase pair in this model  is computed as follows. First, we represent each phrase as a bag-of-words vector, called word vector  henceforth. We then project the word vector, in either the source language or the target language,  into a respective continuous feature vector in a common low-dimensional latent semantic space that  is intended to be language independent. The projection is performed by a multi-layer neural network.  The projected feature vector forms the semantic representation of a phrase. Finally, the translation  score of a source-target phrase pair is computed by the distance between their feature vectors.  The main motivation behind the SPTM is to alleviate the data sparseness problem associated  with the traditional counting-based methods by grouping phrases with a similar meaning across  different languages. In this model, semantically related phrases, in both the source and the target  languages, would have similar (close) feature vectors in the semantic space. Since the translation   score is a smooth function of these feature vectors, a small change in semantics (e.g., the phrases  that differ only in morphological forms) should only lead to a small change in the translation score.  The primary research task in developing the SPTM is learning the semantic representation of a  phrase that is effective for SMT. Motivated by recent studies on continuous-space language models  (LM) [3, 19], we use a neural network to project a word vector to a feature vector. Ideally, the  projection would discover those latent semantic features that are useful to differentiate good translations from bad ones, for a given source phrase. However, there is no training data with explicit  annotation on the quality of phrase translations. The phrase translation pairs are hidden in the parallel source-target sentence pairs, which are used',\n",
       " '1710.10577': 'Given a convolutional neural network (CNN) that is pretrained to estimate image attributes (or labels), how to diagnose black-box knowledge representations inside the CNN and discover potential representation ﬂaws is a crucial issue for deep learning. In fact, there is no theoretical solution to identifying good and problematic representations in the CNN. Instead, people usually just evaluate a CNN based on the accuracy obtained using testing samples. In this study, we focus on representation ﬂaws caused by potential bias in the collection of training samples (Torralba and Efros 2011). As shown in Fig. 1, if an attribute usually co-appears with certain visual features in training samples, then the CNN may be learned to use the coappearing features to represent this attribute. When the used co-appearing features are not semantically related to the target attribute, we consider these features as biased representations. This idea is related to the disentanglement of the local, bottom-up, and top-down information components for prediction (Wu, Xia, and Zhu 2007; Yang, Wu, and Zhu 2009; Wu and Zhu 2011). We need to clarify correct and problematic contexts for prediction. CNN representations may be biased even when the CNN achieves a high accuracy on testing samples, because testing samples may have a similar bias. Copyright c⃝2018, Association for the Advancement of Artiﬁcial Intelligence (www.aaai.org). All rights reserved. Original Masked Pasted Original Masked Pasted -16.44 -12.96 -10.27 +16.93 +12.17 +19.77 Score of “wearing lipstick” wearing lipstick ... Figure 1: Biased representations in a CNN. Considering potential dataset bias, a high accuracy on testing images cannot always ensure that a CNN learns correct representations. The CNN may use unreliable co-appearing contexts to make predictions. For example, we manually modify mouth appearances of two faces by masking mouth regions or pasting another mouth, but such modiﬁcations do not signiﬁcantly change prediction scores for the lipstick attribute. We show heat maps of inference patterns of the lipstick attribute, where patterns with red/blue colors are positive/negitive with the attribute score. The CNN mistakenly considers unrelated patterns as contexts to infer the lipstick. We propose a method to automatically discover such biased representations from a CNN without any testing images. In this paper, we propose a simple yet effective method that automatically diagnoses representations of a pre-trained CNN without given any testing samples. I.e., we only use training samples to determine the attributes whose representations are not well learned. We discover blind spots and failure modes of the representations, which can guide the collection of new training samples. Intuition, self-compatibility of network representations: Given a pre-trained CNN and an image I, we use the CNN to estimate attribute A for I. We also mine inference patterns1 of the estimation result, which are hidden in conv1We regard a neural pattern as a group of units in',\n",
       " '1803.07617': 'Two of the most appealing features of online learning methods are (a) robustness, due to the absence of assumptions on the data-generating process, and (b) the ability to eﬃciently incorporate data on the ﬂy. According to this latter desideratum, online methods should not store all the data observed so far in memory, but instead maintain some “compressed” representation, suﬃcient for making online predictions. The focus of this work is the study of such suﬃcient statistics for online learning, and the design of computationally eﬃcient methods that employ them. It is natural to turn to Statistics for inspiration: a classical notion of suﬃcient statistics (Fisher, 1922) ensures that a statistician can search for methods that work on “compressed” representations of the data. Suﬃcient statistics have also been studied in sequential decision theory (Bahadur et al., 1954). However, the very notion of suﬃciency is inherently tied to the posited probabilistic model, and the corresponding notion for arbitrary sequences—as postulated by the above desideratum (a)—is all but obvious. The current theory of online learning oﬀers little guidance as to what summaries of past data should be recorded by an online algorithm. For instance, the Exponential Weights algorithm (Vovk, 1990; Littlestone and Warmuth, 1994) keeps in memory the cumulative losses of the experts, while the general potential-based forecaster (Cesa-Bianchi and Lugosi, 2006) updates the cumulative regret of the algorithm with respect to each expert. The methods from the Follow-the-Regularized-Leader family (also known as Dual Averaging methods) work with the sum of gradients of convex functions, ∗Cornell University †MIT 1 arXiv:1803.07617v1  [cs.LG]  20 Mar 2018  while the Online Newton Step (Hazan et al., 2007) method and the Vovk-Azoury-Warmuth forecaster (Cesa-Bianchi and Lugosi, 2006) also store the “covariance” matrix of outer products. The well-known adaptive gradient descent procedure (e.g. (Rakhlin and Sridharan, 2015)) tunes the step size of online gradient descent according to the cumulative squared norms of gradients, a statistic that appears to be necessary for achieving the adaptive bound, while the ZigZag method of Foster et al. (2017b) keeps track of a sign-transformed sequence of the gradients to achieve the empirical Rademacher complexity as a regret bound. The question of suﬃcient statistics for online methods appears to be unexplored and poorly understood, and it will take signiﬁcant eﬀort to answer it. In this paper we propose an approach that appears to be general yet, inevitably, incomplete. We propose a deﬁnition that brings many existing methods under the same umbrella, and allows us to develop new eﬃcient strategies that have been out of reach. The key workhorse for our development is the Burkholder method, studied in probability theory and harmonic analysis. Beyond studying a notion of suﬃcient statistic for online methods, our work can be seen as providing a further understanding of emerging connections between online learning, martingale inequalities, and deterministic geometric quantities. At the risk of being imprecise, let us describe the bird’s-eye view',\n",
       " '1803.02007': 'High-speed, autonomous navigation is predicated on the ability to reason about the environment for effective, collision-free path planning. Existing approaches operate on current sensor readings to update an occupancy map corresponding to an internal representation of where obstacles exist in the environment. These occupancy maps are then used by planning algorithms to generate a collision-free path to a target goal. One of the limitations of this approach is that the planning horizon is limited to the ﬁeld of view (FOV) of the sensor. On the other hand, behavioral neuroscience and biological psychology point to the potential role of prediction for navigation in animals and humans. In particular, the hypocampus appears to exhibit some neuronal structures as well as ﬁring sequences that could support not only mapping but also predictive mapping capabilities [2]. Indeed, humans continuously make predictions of what to expect based on past experiences. This allows us to adjust our control policy in real time depending on how close our observations match our predictions [9]. The advantage is most evident while running along a hallway approaching a T-intersection. Even though we cannot see the left or right paths, we generally assume the straight lines will continue and we can predict how the hallway will appear as we turn the corner. Because 1Research and Exploratory Development Dept., Johns Hopkins University Applied Physics Lab, Laurel, MD, USA. {Kapil.Katyal, Katie.Popek, Joseph.Moore, Kevin.Wolfe, Phillippe.Burlina}@jhuapl.edu 2Dept. of Computer Science, Johns Hopkins University, Baltimore, MD, USA. {cpaxton, ghager1}@jhu.edu Fig. 1. Two samples of predicted images. The left image is the input based on sensor readings, middle image is the predicted expanded occupancy map (1.50x) and the right image is the ground truth. of this prediction, we do not adjust our running speed unless our prediction is inaccurate. Following this intuition, we believe future predictions of occupancy maps can enable risk sensitive control policies for mobile and aerial vehicles. By being able to predict occupancy maps, we can enable faster navigation as the planning horizon can extend beyond the sensor’s limited FOV. This concept is similar to image completion, a problem for which multiple solutions have been suggested in the past [1], [3]. We take an alternate approach, leveraging the fact that structural information from the observed geometry of the world that can help us make useful predictions about the environment. Deep neural networks have signiﬁcant advantages over other approaches when used for image completion or image generation [23]. One of the most promising innovations in deep learning has been the development of autoencoder networks and generative adversarial networks (GANs) [5]. These networks use a minimax game adversarial training with opponent generative and discriminative networks, and are capable of encoding a latent representation of images used to generate new examples from latent space. In this paper, we demonstrate the ability to generate future predictions of occupancy maps without an explicit model using a variety of different neural',\n",
       " '1805.08777': 'Molecular communication (MC) is an emerging technology enabling communication among nanomachines. Inspired by biological systems, synthetic diffusion-based MC systems have been proposed as a potential solution for communication in nanonetworks where molecules play the  2 role of information carriers [1]. Nanonetworks are envisioned to facilitate revolutionary applications in areas such as biological engineering, healthcare, and environmental monitoring [2]–[4]. One of the key challenges in health monitoring and disease diagnosis applications is the problem of anomaly detection, e.g., early cancer detection, which has received signiﬁcant attention in medicine and other related ﬁelds [5], [6]. Since early cancer detection can signiﬁcantly decrease cancer mortality, great efforts have been devoted to the investigation of new technologies for detecting the symptoms of cancer at an early stage [5]–[9]. These symptoms are characteristics that can indicate the presence of anomaly, and include cancer biomarkers [5]. Cancer biomarkers cover a broad range of biochemical entities such as nucleic acids, proteins, sugars, small metabolites, and cytogenetic and cytokinetic parameters as well as entire cancer cells found in body ﬂuids [6]. Among these biomarkers, proteins are of particular interest since they are primarily found in blood and urine where they can be measured with current medical technologies, such as clinical blood tests [7], [8]. It has been shown in [9]–[11] that abnormal behavior/expressions of protein biomarkers can be associated with particular cancers. For example, α-fetoprotein, carcinoma antigen 125, carcinoembryonic antigen, and prostate-speciﬁc antigen are common biomarkers for liver, ovarian, colorectal, and prostate cancers, respectively [12]. Conventional blood tests may not be able to detect biomarkers secreted by cancer cells in the early stages of a cancer due to the very low concentration of the biomarkers inside the cardiovascular system (CS) [7], [8]. However, close to the cancer cells, the concentration of the cancer biomarkers is high such that reliable detection is possible if a corresponding sensor passes in the vicinity of the cancer cells. In this paper, we propose the use of engineered nanosensors for this purpose. Such nanosensors play a key role in nanomedicine and can carry and deliver imaging probes, therapeutic agents, and biological materials to target sites such as speciﬁc organs, tissues, and even particular cells [6], [13], [14]. The ability of engineered nanosensors to fast and intelligently release, move, observe, and read inside the CS motivates the investigation of the use of mobile nanosensors (MNSs) for anomaly detection [15]. In particular, MNSs can be released from an injection site, move through the CS, become activated at sites of high biomarker concentration, and eventually be captured at a fusion center (FC) which then decides on the presence of an anomaly. The time interval between release and capture of the MNSs at the FC is called the observation window and is on the order of a few minutes due to the fast ﬂow velocities inside CS. Anomaly detection has been extensively studied in different ﬁelds, including computer science,  3 segmentation of biomedical signals, and fraud',\n",
       " '1807.01511': 'Multiple viewpoint video of open spaces (e. g. for sports or surveillance) is often captured using a sparse set of wide-baseline static cameras, in which human subjects are relatively small (tens of pixels in height) due to their physical distance. Nevertheless, it is useful to infer human behavioural data from this limited knowledge for performance analytics or security. In this paper, we explore the possibility of using a deeply learned prior inferring high ﬁdelity three-dimensional (3D) body shape and skeletal pose data from a coarse (low-resolution) volumetric estimate of body shape estimated across a sparse set of camera views (Fig. 1). arXiv:1807.01511v1  [cs.CV]  4 Jul 2018  2 M. Trumble, A Gilbert, A Hilton & J Collomosse The technical contribution of this paper is to explore the possibility of learning a deep representation for volumetric (3D) human body shape driven by a latent encoding for skeletal pose that can, in turn, be inferred from coarse volumetric shape data. Speciﬁcally, we investigate whether convolutional autoencoder architectures, commonly applied to 2D visual content for de-noising and up-scaling (super-resolution), may be adapted to up-scale volumetric 3D human shape whilst simultaneously providing high-level information on the 3D human pose from the bottle-neck (latent) representation of the autoencoder. We propose a symmetric autoencoder with 3D convolutional stages capable of reﬁning a probabilistic visual hull (PVH) [1] i. e. voxel occupancy data derived at very coarse scale (grid resolution 32 × 32 × 32 encompassing the subject). We demonstrate that our autoencoder is able to estimate an up-scaled body shape volume at up to 128 × 128 × 128 resolution, whilst able to estimate the skeleton joint positions of the subject to equal or better accuracy than the current state of the art methods due to deep learning. 2 Related Work Our work makes a dual contribution to two long-standing Computer Vision problems: super-resolution (SR) and human pose estimation (HPE). Super-resolution: Data-driven approaches to image SR integrate pixel data e. g. from auxiliary images [2], or from a single image [3,4]) to perform image up-scaling or restoration. Model based approaches learn appearance priors from training images, applying these as optimization constraints to solve for SR content [5]. A wide variety of machine learning approaches have been applied to the latter e. g. sparse coding [6], regression trees [7], and stacked autoencoders [8]; many such approaches are surveyed in [9]. Deep learning has more recently applied convolutional autoencoders for up-scaling of images [10,11,12] and video [13]; our work follows suit, extending symmetric autoencoders commonly used for image restoration to volumetric data using 3D (up-)convolutional layers [14]. Our work is not the ﬁrst to propose volumetric super-resolution. Data-driven volumetric SR has been explored using multiple image fusion across the depth of ﬁeld in [15] and across multiple spectral channels in [6]. Very recent work by Brock et al. explores deep variational auto-encoders for volumetric SR of objects [16]. However, our work is unique in its ability to upscale to 4× whilst',\n",
       " '1812.02224': 'Neural networks are powerful function approximators that have excelled on a wide range of tasks (Simonyan and Zisserman, 2015; Mnih et al., 2015; He et al., 2016a; Silver et al., 2016; Vaswani et al., 2017). Despite the state of the art results across domains, they remain data-inefﬁcient and expensive to train. In supervised learning, large deep learning benchmarks with millions of examples are needed for training (Russakovsky et al., 2015) and the additional implication of requiring human intervention to label a large dataset can be prohibitively expensive. In reinforcement learning (RL), agents typically consume millions of frames of experiences before learning to act reasonably in complex environments (Silver et al., 2016; Espeholt et al., 2018), which not only puts pressure on computing power but also makes particular domains (e.g., robotics) impractical. Different techniques have been studied for improving data efﬁciency, from data augmentation (Krizhevsky et al., 2012; Simonyan and Zisserman, 2015; Hauberg et al., 2016) to multi-task learning (Teh et al., 2017; Kendall et al., 2018; Chen et al., 2018; Hessel et al., 2018; Sener and Koltun, 2018) to transfer learning (Taylor and Stone, 2009; Pan et al., 2010). In this work, we focus on a particular type of transfer learning: transferring knowledge of an auxiliary task to a main task. We assume that besides the main task, one has access to one or more additional auxiliary tasks that share some unknown structures with the main task. To improve data efﬁciency, these additional tasks can be used as auxiliary losses to transfer knowledge to the main task. Note that only the performance of the main task is of interest, even though the model is trained simultaneously on all tasks; any improvement on the auxiliary losses is useful only to the extent that it helps learning features or behaviors for the main task. Auxiliary tasks have been shown to work well for reinforcement learning (e.g., Zhang et al., 2016; Jaderberg et al., 2017; Mirowski et al., 2017; Papoudakis et al., 2018; Li et al., 2019). The success of these approaches depend on how well aligned the auxiliary losses are with the main task. Knowing this apriori is typically non-trivial and the usefulness of an auxiliary task can change through the ∗Equal Contribution †Washington State University. Work done during an internship at DeepMind. ‡DeepMind §Google Research, Brain Team. Work done while at DeepMind. 1 arXiv:1812.02224v2  [stat.ML]  25 Nov 2020  course of training. In this work, we explore a simple yet effective heuristic for measuring the similarity between an auxiliary task and the main task of interest (given the value of their parameters) using gradient information. 2 NOTATION AND PROBLEM DESCRIPTION Assume we have a main task Tmain and some update rule induced by an auxiliary task Taux. This can be given by the gradients of an auxiliary loss Laux (though our derivation holds also when there is no such loss',\n",
       " '1705.07522': 'The integration of algorithms for classiﬁcation and retrieval in medical images through effective machine learning schemes is at the forefront of modern medicine [8]. These tasks are crucial, among others, to detect and analyze abnormalities and malignancies to contribute to more informed diagnosis and decision makings. Digital pathology is one of the domains where such tasks can support more reliable decisions [23]. For several decades, the archiving of microscopic information of specimens has been organized through employing and storing glass slides [2]. Beyond the fragile nature of glass slides, hospitals and clinics need large and specially prepared storage rooms to store specimens, which naturally requires a lot of logistical infrastructures. Digital pathology, or whole slide imaging (WSI), can not only provide high image quality that is not subject to decay (i.e., stains decay over time) but also offers a range of other beneﬁts [2, 11]: They can be investigated by multiple experts at the same time, they can be more easily retrieved for research and quality control, and of course, WSI can be integrated into existing information systems of hospitals. In 1999, Wetzel and Gilbertson developed the ﬁrst automated WSI system [17], utilizing high resolution to enable pathologists to buffer through immaculate details presented through digitized pathology slides. Ever since, pathology bounded by WSI systems is emerging into an era of digital specialty, providing solutions for centralizing diagnostic solutions by improving the quality of diagnosis, patient safety, and economic concerns [12]. Like any other new technology, digital pathology has its pitfalls. The gigapixel nature of WSI scans makes it difﬁcult to store, transfer, and process samples in real-time. One also need tremendous digital storage to archive them. In this paper, we propose a new and uniquely designed data set, Kimia Path24, for the classiﬁcation and retrieval of digitized pathology images. In particular, the data set is comprised of 24 WSI scans of different tissue textures from which 1,325 test patches sized 1000×1000 are manually selected with special attention to textural differences. The proposed data set is structured to mimic retrieval tasks in clinical practice; hence, the users have the ﬂexibility to create training patches, ranging from 27,000 to over 50,000 patches – these numbers depend on the selection of homogeneity and overlap for every given slide. For retrieval, a weighted accuracy measure is provided to enable a uniﬁed benchmark for future works. 2. Related Works This section covers a brief literature review on image analysis in digital pathology, speciﬁcally on WSI, fol1 arXiv:1705.07522v1  [cs.CV]  22 May 2017  Accepted for presentation at Workshop for Computer Vision for Microscopy Image Analysis (CVMI 2017) @ CVPR 2017, Honolulu, Hawaii lowed by various content-based medical image retrieval techniques, and ﬁnally an overview of feature extraction techniques that emphasize local binary patterns (LBP). 2.1. Image Analysis in Digital Pathology In digital pathology, the large dimensionality of the image poses a challenge',\n",
       " '1806.02705': 'Superpixels have been a popular method of incorporating spatial priors in a wide variety of computer vision problems. This has been applied both to inﬂuence the resulting statistical models to favor spatial smoothness, but also for computation reasons. For graph cuts based inference, for example, superpixels have been widely employed to reduce the cubic time worst case computational cost. They have somewhat fallen out of favor with the recent popularization of deep neural networks, for classiﬁcation, segmentation, and many other vision tasks. However, the statistical and computational advantages of superpixels can also apply in the context of deep networks. A key reason for this is that deep neural networks designed for computer vision tasks have grown increasingly deep and complex over the last years. Although this allows for an increase in accuracy on a variety of problems, it typically also comes at an increased computational cost. Our aim is therefore to improve the accuracy of networks by simplifying the segmentation problem rather than building more complex models. We propose to do this by means of a superpixel pooling layer. Such a layer has two main beneﬁts: information grouping and introduction of a prior on the segmented output. This prior favors segmentations that preserve the edges provided by the superpixels. Information grouping and edge preservation are, however, conﬂicting objectives, since larger superpixels group more information but will generally not adhere to boundaries as well as smaller superpixels. In our experiments, we attempt to gain insight into this trade-oﬀand see how it aﬀects segmentation accuracy for diﬀerent types of networks. We generally use the term superpixel for 2D image segmentation, and supervoxel for volumetric image segmentation. We start by describing the superpixel pooling layer and propose a simple 1 arXiv:1806.02705v1  [cs.CV]  7 Jun 2018  but eﬃcient GPU-implementation for the forward and backward pass. We then propose several ways of integrating the layer into existing CNN architectures. Finally, we empirically evaluate these modiﬁcations using the VoxResNet [2] and ENet [8] architectures. 1.1 Related work Over the years, many diﬀerent superpixel segmentation algorithms have been developed. A recent benchmark study [11] classiﬁes 24 of the state-of-the-art methods by their high-level approach and constructs an overall ranking of the algorithms. The overall top-performing candidates from this benchmark are Eﬃcient Topology Preserving Segmentation (ETPS) [14] and Superpixels extracted via energy-driven sampling (SEEDS) [12]. These are closely followed by perhaps the most popular superpixel algorithm called Simple Linear Iterative Clustering (SLIC) [1]. Aside from its overall segmentation accuracy that is competitive with SEEDS and ETPS, SLIC has several additional beneﬁts for our purposes. These include its simplicity, native support for volumetric images and its parallelizability. The latter has led to gSLICr [9], a GPU-implementation of the SLIC algorithm. Such an implementation allows to provide superpixels to the network with at a minimal time cost. The ﬁrst network architecture we use in our experiments below is called VoxResNet [2]. This is a residual neural network',\n",
       " '1002.1531': 'T HE Gaussian broadcast channel (GBC) has been intensely researched in recent years. It is well-known that dirty paper coding (DPC) [1] achieves the capacity region of the GBC if perfect channel state information (CSI) is available at the transmitter (CSIT) and the receivers (CSIR) [2]. However, even though the assumption of perfect CSIR can be justiﬁed, it is unrealistic to assume the same about CSIT. Moreover, the rate achievable over the GBC is quite sensitive to the quality of CSIT as has been demonstrated in [3]–[5] (see also references in [5]). This paper therefore tackles the important problem of achieving high throughputs using DPC over the GBC with imperfect CSIT. It is well known that under perfect CSIT the DPC based transmission outperforms other known strategies such as zeroforcing beamforming (ZFBF) [3]. Nevertheless, under imperfect CSIT, it is the ZFBF strategy that has been intensely researched rather than DPC, mainly because ZFBF is analytical tractable [4], [6] and because of a perception that DPC based schemes are either not feasible without perfect CSIT or, even if feasible, they may be analytically intractable. The main hurdle with DPC is seen to be the difﬁculty of designing the inﬂation factor – a parameter that can critically affect its performance [1] – without perfect CSIT; it is even generally believed that the inﬂation factor cannot be effectively designed without perfect CSIT [4] implying that DPC may be overly This work was supported in part by NSF Grant CCF-0728955. The authors are with the Department of Electrical, Computer, and Energy Engineering, University of Colorado, Boulder, CO 80309-0425 USA (e-mail: vaze, varanasi@colorado.edu). sensitive to the imperfection in CSIT, thereby rendering it less desirable than even ZFBF. Making progress to this end, we recently developed iterative numerical algorithms for the determination of inﬂation factor under imperfect CSIT which yield high achievable rates [7], [8]. Some analytical results were also obtained in the high/low SNR (signal-to-noise ratio) regime [9], [10]. However, these results may not always reveal much insight on how DPC works with imperfect CSIT nor does it shed light on the behavior of DPC at moderate values of SNR. Moreover, due to the numerical nature of these algorithms, it is almost impossible to derive analytical results regarding the ﬁnite SNR performance of DPC based strategies or on how they compare with other transmission strategies such as ZFBF. Furthermore, the algorithms don’t lend themselves to answering important design questions about DPC based schemes – such as optimizing the sum-rate by selecting (and transmitting to) only a subset of users – other than through a tedious and un-insightful exhaustive search. Recall that the strategy of transmitting to a subset of users is known to indeed result in a considerable improvement in the sum-rate under perfect CSIT [3] and for the ZFBF even under imperfect CSIT [6]. To address the above issues, we undertake here a largesystem or asymptotic analysis',\n",
       " '1810.13105': 'Density-based clustering algorithms such as Mean Shift (Cheng, 1995) and DBSCAN (Ester et al., 1996) have made a large impact on a wide range of areas in data analysis, including outlier detection, computer vision, and medical imaging. As data volumes rise, non-parametric unsupervised procedures are becoming ever more important in understanding large datasets. Thus, there is an increasing need to establish more efﬁcient versions of these algorithms. In this paper, we focus on improving the classical DBSCAN procedure. It was long believed that DBSCAN had a runtime of O(n log n) until it was proven to be O(n2) in the worst case by Gan and Tao (2015). They showed that while DBSCAN can run in O(n log n) when the dimension is at most 1Uber 2Google Research. Correspondence to: Jennifer Jang <j.jang42@gmail.com>. 2, it quickly starts to exhibit quadratic behavior in high dimensions and/or when n becomes large. In fact, we show in Figure 1 that even with a simple mixture of 3-dimensional Gaussians, DBSCAN already starts to show quadratic behavior. The quadratic runtime for these density-based procedures can be seen from the fact that they implicitly must compute density estimates for each data point, which is linear time in the worst case for each query. In the case of DBSCAN, such queries are proximity-based. There has been much work done in using space-partitioning data structures such as KD-Trees (Bentley, 1975) and Cover Trees (Beygelzimer et al., 2006) to improve query times, but these structures are all still linear in the worst-case. Another line of work that has had practical success is in approximate nearest neighbor methods (e.g. Indyk and Motwani (1998); Datar et al. (2004)) which have sub-linear queries, but such methods come with few approximation guarantees. DBSCAN proceeds by computing the empirical densities for each sample point and then designating points whose densities are above a threshold as core-points. Then, a neighborhood graph of the core-points is constructed, and the clusters are assigned based on the connected components. In this paper, we present DBSCAN++, a step towards a fast and scalable DBSCAN. DBSCAN++ is based on the observation that we only need to compute the density estimates for a subset m of the n data points, where m can be much smaller than n, in order to cluster properly. To choose these m points, we provide two simple strategies: uniform and greedy K-center-based sampling. The resulting procedure has O(mn) worst-case runtime. We show that with this modiﬁcation, we still maintain statistical consistency guarantees. We show the trade-off between computational cost and estimation rates. Interestingly, up to a certain point, we can enjoy the same minimax-optimal estimation rates attained by DBSCAN while making m (instead of the larger n) empirical density queries, thus leading to a sub-quadratic procedure. In some cases, we saw',\n",
       " '1704.06497': 'Many NLP tasks involve learning to predict a structured output such as a sequence, a tree or a graph. Sequence-to-sequence learning with neural networks has recently become a popular approach that allows tackling structured prediction as a mapping problem between variable-length sequences, e.g., from foreign language sentences into target-language sentences (Sutskever et al., 2014), or from natural language input sentences into linearized versions of syntactic (Vinyals et al., 2015) or semantic parses (Jia and Liang, 2016). A known bottleneck in structured prediction is the requirement of large amounts of gold-standard structures for supervised learning of model parameters, especially for data-hungry neural network models. Sokolov et al. (2016a,b) presented a framework for stochastic structured prediction under bandit feedback that alleviates the need for labeled output structures in learning: Following an online learning protocol, on each iteration the learner receives an input, predicts an output structure, and receives partial feedback in form of a task loss evaluation of the predicted structure.1 They “banditize” several objective functions for linear structured predictions, and evaluate the resulting algorithms with simulated bandit feedback on various NLP tasks. We show how to lift linear structured prediction under bandit feedback to non-linear models for sequence-to-sequence learning with attentionbased recurrent neural networks (Bahdanau et al., 2015). Our framework is applicable to sequenceto-sequence learning from various types of weak feedback. For example, extracting learning signals from the execution of structured outputs against databases has been established in the communities of semantic parsing and grounded language learning since more than a decade (Zettlemoyer and Collins, 2005; Clarke et al., 2010; Liang et al., 2011). Our work can build the basis for neural semantic parsing from weak feedback. In this paper, we focus on the application of machine translation via neural sequence-to-sequence learning. The standard procedure of training neural machine translation (NMT) models is to compare their output to human-generated translations and to infer model updates from this comparison. However, the creation of reference translations or post-edits requires professional expertise of users. Our framework allows NMT models to learn from feedback that is weaker than human references or post-edits. One could imagine a scenario of personalized machine translation where translations have to be adapted to the user’s speciﬁc purpose and domain. The feedback required by our methods can be provided by laymen users or can even 1The name “bandit feedback” is inherited from the problem of maximizing the reward for a sequence of pulls of arms of so-called “one-armed bandit” slot machines. arXiv:1704.06497v2  [stat.ML]  13 Dec 2018  be implicit, e.g., inferred from user interactions with the translated content on a web page. Starting from the work of Sokolov et al. (2016a,b), we lift their objectives to neural sequence-to-sequence learning. We evaluate the resulting algorithms on the',\n",
       " '0710.1325': 'Multiple antennas are a valuable resource in wireless communications. Recently there has been a signiﬁcant activity in exploring both the theoretical and practical aspects of wireless systems with multiple antennas. In this work we explore the role of multiple antennas for physical layer security, which is an emerging area of interest. The wiretap channel [1] is an information theoretic model for physical layer security. The setup has three terminals — one sender, one receiver and one eavesdropper. The goal is to exploit the structure of the underlying broadcast channel to transmit a message reliably to the intended receiver, while leaking asymptotically no information to the eavesdropper. A single letter characterization of the secrecy capacity, when the underlying channel is a discrete memoryless broadcast channel, has been obtained by Csisz´ar and K¨orner [2]. An explicit solution for the scalar Gaussian case is obtained in [3]. In this paper we consider the case where all the three terminals have multiple antennas and naturally refer to it as multiple input, multiple output, multiple eavesdropper (MIMOME) channel. In this setup we assume that the channel matrices are ﬁxed and known to all the three terminals. While the assumption that the eavesdropper’s channel is known to both the sender and the receiver is obviously a strong assumption, we remark in advance that our solution provides ultimate limits on secure transmission with multiple antennas and could be a starting point for other formulations where the eavesdropper’s channel may not be known to the sender and the receiver. The main result of this paper is a characterization of the secrecy capacity of the MIMOME channel as the saddle value of a minimax problem. Our approach does not rely on the Csisz´ar and K¨orner capacity expression, but instead is based on the technique used in characterizing the sum This work was supported in part by NSF under Grant No. CCF-0515109. The authors are with the Dept. EECS, MIT, Cambridge, MA, 02139. Email:{khisti,gww}@mit.edu rate of the MIMO broadcast channel (see, e.g., [4] and its references). We ﬁrst develop a minimax expression that upper bounds the secrecy capacity and subsequently establish the tightness of this bound for the MIMOME channel. The case where the channel matrices of intended receiver and eavesdropper are square and diagonal follows from the results in [5]–[8] that consider secure transmission over fading channels. The difﬁculty of optimizing the Csisz´ar and K¨orner expression for the general case has been reported in [9]–[11] and achievable rates have been investigated. The approach used in the present paper has been used in our earlier work [12], [13] to establish the secrecy capacity for two special cases: the case when the intended receiver has a single antenna (MISOME case) and the MIMOME secrecy capacity in the high SNR regime. This upper bounding approach was independently conceived by Ulukus et. al. [14] and further applied to the 2x2x1 case [15]. Finally, a related approach',\n",
       " '1806.01261': 'A key signature of human intelligence is the ability to make “inﬁnite use of ﬁnite means” (Humboldt, 1836; Chomsky, 1965), in which a small set of elements (such as words) can be productively composed in limitless ways (such as into new sentences). This reﬂects the principle of combinatorial generalization, that is, constructing new inferences, predictions, and behaviors from known building blocks. Here we explore how to improve modern AI’s capacity for combinatorial generalization by ∗Corresponding author: peterbattaglia@google.com 1 arXiv:1806.01261v3  [cs.LG]  17 Oct 2018  biasing learning towards structured representations and computations, and in particular, systems that operate on graphs. Humans’ capacity for combinatorial generalization depends critically on our cognitive mechanisms for representing structure and reasoning about relations. We represent complex systems as compositions of entities and their interactions1 (Navon, 1977; McClelland and Rumelhart, 1981; Plaut et al., 1996; Marcus, 2001; Goodwin and Johnson-Laird, 2005; Kemp and Tenenbaum, 2008), such as judging whether a haphazard stack of objects is stable (Battaglia et al., 2013). We use hierarchies to abstract away from ﬁne-grained diﬀerences, and capture more general commonalities between representations and behaviors (Botvinick, 2008; Tenenbaum et al., 2011), such as parts of an object, objects in a scene, neighborhoods in a town, and towns in a country. We solve novel problems by composing familiar skills and routines (Anderson, 1982), for example traveling to a new location by composing familiar procedures and objectives, such as “travel by airplane”, “to San Diego”, “eat at”, and “an Indian restaurant”. We draw analogies by aligning the relational structure between two domains and drawing inferences about one based on corresponding knowledge about the other (Gentner and Markman, 1997; Hummel and Holyoak, 2003). Kenneth Craik’s “The Nature of Explanation” (1943), connects the compositional structure of the world to how our internal mental models are organized: ...[a human mental model] has a similar relation-structure to that of the process it imitates. By ‘relation-structure’ I do not mean some obscure non-physical entity which attends the model, but the fact that it is a working physical model which works in the same way as the process it parallels... physical reality is built up, apparently, from a few fundamental types of units whose properties determine many of the properties of the most complicated phenomena, and this seems to aﬀord a suﬃcient explanation of the emergence of analogies between mechanisms and similarities of relation-structure among these combinations without the necessity of any theory of objective universals. (Craik, 1943, page 51-55) That is, the world is compositional, or at least, we understand it in compositional terms. When learning, we either ﬁt new knowledge into our existing structured representations, or adjust the structure itself to better accommodate (and make use of) the new and the old (Tenenbaum et al., 2006; Griﬃths et al., 2010; Ullman et al., 2017). The question of how to build artiﬁcial systems which exhibit combinatorial generalization has been at the heart of AI since its origins',\n",
       " '1706.02823': 'One of the “Grand Challenges” of computer graphics is to allow anyone to author realistic visual content. The traditional 3d rendering pipeline can produce astonishing and realistic imagery, but only in the hands of talented and trained artists. The idea of short-circuiting the traditional 3d mod- † indicates equal contribution eling and rendering pipeline dates back at least 20 years to image-based rendering techniques [33]. These techniques and later “image-based” graphics approaches focus on re-using image content from a database of training images [22]. For a limited range of image synthesis and editing scenarios, these non-parametric techniques allow nonexperts to author photorealistic imagery. In the last two years, the idea of direct image synthesis without using the traditional rendering pipeline has gotten signiﬁcant interest because of promising results from deep network architectures such as Variational Autoencoders (VAEs) [21] and Generative Adversarial Networks (GANs) [11]. However, there has been little investigation of ﬁne-grained texture control in deep image synthesis (as opposed to coarse texture control through “style transfer” methods [9]). In this paper we introduce TextureGAN, the ﬁrst deep image synthesis method which allows users to control object texture. Users “drag” one or more example textures onto sketched objects and the network realistically applies these textures to the indicated objects. This “texture ﬁll” operation is difﬁcult for a deep network to learn for several reasons: (1) Existing deep networks aren’t particularly good at synthesizing highresolution texture details even without user constraints. Typical results from recent deep image synthesis methods are at low resolution (e.g. 64x64) where texture is not prominent or they are higher resolution but relatively ﬂat (e.g. birds with sharp boundaries but few ﬁne-scale de1 arXiv:1706.02823v3  [cs.CV]  14 Apr 2018  tails). (2) For TextureGAN, the network must learn to propagate textures to the relevant object boundaries – it is undesirable to leave an object partially textured or to have the texture spill into the background. To accomplish this, the network must implicitly segment the sketched objects and perform texture synthesis, tasks which are individually difﬁcult. (3) The network should additionally learn to foreshorten textures as they wrap around 3d object shapes, to shade textures according to ambient occlusion and lighting direction, and to understand that some object parts (handbag clasps) are not to be textured but should occlude the texture. These texture manipulation steps go beyond traditional texture synthesis in which a texture is assumed to be stationary. To accomplish these steps the network needs a rich implicit model of the visual world that involves some partial 3d understanding. Fortunately, the difﬁculty of this task is somewhat balanced by the availability of training data. Like recent unsupervised learning methods based on colorization [47, 23], training pairs can be generated from unannotated images. In our case, input training sketches and texture suggestions are automatically extracted from real photographs',\n",
       " '1901.08469': 'Learning the generative model, i.e., the underlying data generating distribution, based on large amounts of data is one the fundamental task in machine learning and statistics [46]. Recent advances in deep generative models have provided novel techniques for unsupervised and semi-supervised learning, with broad application varying from image synthesis [44], semantic image editing [60], image-to-image translation [61] to low-level image processing [29]. Implicit deep generative model is a powerful and ﬂexible framework to approximate the target distribution by learning deep samplers [38] including Generative adversarial networks (GAN) [16] and likelihood based models, such as variational auto-encoders (VAE) [23] and ﬂow based methods [11], as their main representatives. The above mentioned implicit deep generative models focus on learning a deterministic or stochastic nonlinear mapping that can transform low dimensional latent samples from referenced simple distribution to samples that closely match the target distribution. GANs build a minmax two player game between the generator and discriminator. During the training, the generator transforms samples from a simple reference distribution into samples that would hopefully to deceive the discriminator, while the discriminator conducts a diﬀerential two-sample test to distinguish the generated samples from the observed samples. The objective of vanilla GANs amounts to the Jensen-Shannon (JS) divergence between the learned distribution and target distributions. The vanilla GAN generates sharp image samples but suﬀers form the instability issues [3]. A myriad of extensions to vanilla GANs have been investigated, both theoretically or empirically, in order to achieve a stable training and high quality sample generation. Existing works include but are not limited to designing new learning procedures or network architectures [10, 43, 58, 59, 4, 51, 8], and seeking alternative distribution discrepancy measures as loss criteria in feature or data space [31, 15, 30, 49, 6, 3, 36, 39], and exploiting insightful regularization methods [9, 17, 37, 57], and building hybrid models [13, 53, 14, 54, 21]. VAE approximately minimizes the Kullback-Leibler (KL) divergence between the transformed distribution and the target distribution via minimizing a surrogate loss , i.e., the negative evidence lower bound deﬁned as the reconstruction loss plus the regularization loss, where the reconstruction loss measures the diﬀerence between the decoder and the encoder, and the regularization loss measures the diﬀerence between the encoder and the simple latent prior distribution [23]. VAE enjoys optimization stability but was disputed for generating blurry image samples caused by the Gaussian decoder and the marginal 2  log-likelihood based loss [53]. Adversarial auto-encoders [35] use GANs to penalize the discrepancy between the aggregated posterior of latent codes and the simple prior distribution. Wasserstein auto-encoders [52] that extend the adversarial auto-encoders to general penalized optimal transport objectives [7] alleviate the blurry. Similar ideas are found in some works on disentangled representations of natural images [20, 27]. Flow based methods minimize exactly the negative log-likelihood, i.e., the KL divergence, where the model density is the pushforward density of simple reference',\n",
       " '1105.2631': 'The behavior of the BP [1] decoder for the case of ﬁnite-length codes does not have simple characteristics, and can be very hard to predict. Linear programming is a well-studied discipline that provides efﬁcient analysis tools. The relationship between linear programming decoding and belief propagation decoding was observed and characterized [2], and the decision regions of these decoders are suggested to be tightly related. October 25, 2018 DRAFT  2 The LP decoder receives the channel likelihood ratios which deﬁne an objective function, for which it ﬁnds an optimal solution that satisﬁes a set of constraints. These constraints are inequalities arisen from a given parity check matrix and form a polytope, also known as the fundamental polytope [3]. The fundamental polytope is a relaxation of the codewords polytope. It has a clear geometrical representation which is well-suited for ﬁnite-length analysis. The vertices of the fundamental polytope are every codeword, but also some non-codewords pseudocodewords [4]. The fundamental cone [3] is the conic hull of the fundamental polytope. It has a vertex in the origin, and its edges are also referred to as minimal pseudo-codewords [3] or generators [5]. The fundamental cone has a more compact representation than the fundamental polytope, and it is sufﬁcient to consider the fundamental cone for evaluating the performance of the LP decoder [5]. The output of the LP decoder is always a vertex of the polytope which maximizes the channel likelihood ratios function. One of the most appealing properties of the LP decoder is the ML certiﬁcate property - whenever it returns an integral solution, the solution is guaranteed to be the ML codeword; otherwise an error is invoked. There are rare cases [6] for which the vertices of the polytope are codewords only, and in these cases the output of the LP decoder is identical to the output of the ML decoder. In these rare cases a polynomial-time ML decoding is attainable. However, for most cases, and when applied to good error-correcting codes, the LP decoder will suffer from decoding failures due to the presence of pseudocodewords. The minimal pseudoweight [3] of a pseudocodeword in LP decoding is the appropriate analog of the minimal Hamming weight in ML decoding. Furthermore, the minimum Hamming weight is known to be lower bounded by the minimal pseudoweight [7]. There are cases where the minimal pseudoweight equals the minimal Hamming weight, and in these cases, the existence of pseudocodewords may have a minor or even a negligible effect on the decoder’s optimality. High Density Parity Check (HDPC) codes are characterized by a dense parity check matrix. Linear classical codes have a dense parity check matrix by design, which makes them less suitable for LP decoding. The denser the parity check matrix is the more vertices the fundamental polytope will have. Keeping in mind that the number of codewords of a given code is constant, one can realize that increasing the number of vertices is equivalent to increasing the number of pseudocodewords',\n",
       " '1709.07814': 'Conventional large-vocabulary continuous speech recognition (LVCSR) systems typically perform multi-level pattern recognition tasks that map the acoustic speech waveform into a hierarchy of speech units such as sub-words (phonemes), words, and strings of words (sentences). Such systems basically consist of several sub-components (feature extractor, acoustic model, pronunciation lexicon, language model) that are trained and tuned separately [1]. First, the speech signal is processed into a set of observation features based on a carefully hand-crafted feature extractor, such as Mel frequency cepstral coefﬁcients (MFCC) or Mel-scale spectrogram. Then the acoustic model classiﬁes the observation features into subunit or phoneme classes. Finally, the search algorithm ﬁnds the most probable word sequence based on the evidence of the acoustic model, the lexicon, and the language model. But, it is widely known that information loss in the earlier stage can propagate through the later stages. Deep learning algorithms have produced many state-ofthe-art performances in various tasks that have revitalized the use of neural networks for ASR. One of the important factors behind the popularity of deep learning is the possibility of simplifying many complicated hand-engineered models by letting DNNs ﬁnd their way to map from input to output spaces. Interest has emerged recently in the possibility of learning DNN-based acoustic models directly from the raw speech waveform without any predeﬁned alignments and hand-engineered models. In this way, the feature extractor and acoustic model can be integrated into a single architecture. Palaz et al. [2, 3] proposed a convolutional neural network (CNN) to directly train an acoustic model from the raw speech waveform. Sainath et al. [4] used time-convolutional layers over raw speech and trained them jointly with the long short-term memory deep neural network (CLDNN) acoustic model. The results showed that raw waveform CLDNNs matched the performance of log-mel CLDNNs on a voice search task. Ghahremani et al. [5] recently proposed a CNN time-delay neural network (CNN-TDNN) with network-innetwork (NIN) architecture, and also showed that their model outperformed MFCC-based TDNN on the Wall Street Journal (WSJ) [6] task. But despite signiﬁcant progress that has been made, the successful models were mostly demonstrated only within the hybrid DNN-HMM speech recognition frameworks. On the other hand, some existing works constructed end-to-end neural network models for ASR and replaced the acoustic model, the lexicon model, and the language model with a single integrated model, thus simplifying the pipeline. Graves et al. [7, 8] successfully built an end-toend ASR based on the connectionist temporal classiﬁcation (CTC) framework. Amodei et al. [9] also constructed an end-to-end CTC-based ASR that directly produced character strings instead of phoneme sequences. But the CTC-based architecture still predicts the target outputs for every frame without any implicit knowledge about the language model. Another approach uses a sequence-to-sequence attentionbased encoder',\n",
       " '1710.01766': 'Computer-aided detection/diagnosis (CADe/CADx) has been a highly prosperous and successful research ﬁeld in medical image processing. Many commercial software packages have been developed for clinical usage and screening. Recent advances (e.g., automated classiﬁcation of skin lesions [3], detection of liver lesion [1], pulmonary embolism [10]) have attracted even more attention to the application of deep learning paradigms to CADe/CADx. Deep learning, namely Convolutional Neural Network ⋆These two authors contributed equally. arXiv:1710.01766v2  [cs.CV]  10 Oct 2017  2 (CNN) based algorithms, perform signiﬁcantly better than conventional statistical learning approaches combined with hand-crafted image features. However, these performance gains are often achieved at the cost of requiring tremendous amounts of training data accompanied with high quality labels. Unlike general computer vision tasks, medical image analysis currently lacks a substantial, large-scale annotated image dataset (comparable to ImageNet [2] and MS COCO [6]),for two main reasons: 1) The conventional methods for collecting image labels via Google search + crowd-sourcing from average users cannot be applied in the medical image domain, as medical image annotation reuqires extensive clinical expertise; 2) Signiﬁcant inter and intra-observer variability (among even well-trained, experienced radiologists) frequently occurs, and thus may compromise reliable annotation of a large amount of medical images, especially considering the great diversity of radiology diagnosis tasks. Current CADe/CADx methods generally target one particular type of diseases or lesions, such as lung nodules, colon polyps or lymph nodes [7]. Yet, this approach differs from the methods radiologists routinely apply to read medical image studies and compile radiological reports. Multiple ﬁndings can be observed and are often correlated. For instance, liver metastases can spread to regional lymph nodes or other body parts. By obtaining and maintaining a holistic picture of relevant clinical ﬁndings, a radiologist will be able to make a more accurate diagnosis. However, it remains greatly challenging to develop a universal or multi-purpose CAD framework, capable of detecting multiple disease types in a seamless fashion. Such a framework is crucial to building an automatic radiological diagnosis and reasoning system. In this paper, we attempt to address these challenges by ﬁrst introducing a new large-scale dataset of bookmarked radiology images, which accommodate lesions from multiple categories. Our dataset, named DeepLesion, is composed of 33,688 bookmarked images from 10,825 studies of 4,477 patients (see samples in Fig. 1). For each bookmarked image, a bounding box is generated to indicate the location of the lesions. Furthermore, we integrate an unsupervised deep mining method to compute pseudo image labels for database self-annotating. Categories of Liver lesion/tumor, Lung nodule/tumor, Abdomen lesions, Chest lymph node and others are identiﬁed by our computerized algorithm instead of radiologists’ annotation, which may be infeasible. After obtaining the dataset, we develop an automatic lesion detection approach to jointly localize and classify lesion candidates using discovered multiple categories. Last, how the unsupervisedly',\n",
       " '1408.4073': 'Suppose a point target is arbitrarily placed on the unitcircumference circle. The target then proceeds to move at some constant velocity v (either known or unknown). An agent is interested to determine the target’s position and velocity to within some resolution δ, with an error probability at most ε, as quickly as possible. To that end, the agent can probe any region of his choosing (contiguous or non-contiguous) on the circle for the presence of the target, say once per second. He then receives a binary measurement pertaining to the presence of the target in the probed region, which is corrupted by additive binary noise. While the noise sequence is assumed to be independent over time, its magnitude will generally depend on the size of the probed region. This postulate is practically motivated if one imagines that the circle is densely covered by many small sensors; probing a region then corresponds to activating the relevant sensors and obtaining a measurement that is a (Boolean) function of the sum of the noisy signals from these sensors. We therefore further operate under the assumption that the larger the probed region, the higher the noise level. Our goal is to characterize the relation between ε, δ, and the expected time E(τ) until the agent’s goal is met, for both adaptive and non-adaptive search strategies. The case of stationary target search with measurement independent noise p is well known (see e.g. [1]) to be equivalent to the problem of channel coding with noiseless feedback over a Binary Symmetric Channel (BSC) with crossover probability p, where the message corresponds to the target, the number of messages pertains to inverse of the resolution, the channel noise plays the role of measurement noise, and the existence of noiseless feedback pertains to the fact that the agent may Y. Kaspi and T. Javidi are with the Information Theory and Application (ITA) Center at the University of California, San Diego, USA. O. Shayevitz is with the Department of EE–Systems, Tel Aviv University, Tel Aviv, Israel. Emails: {ofersha@eng.tau.ac.il, ykaspi@ucsd.edu, tjavidi@ucsd.edu}. The work of O. Shayevitz was partially supported by the Marie Curie Career Integration Grant (CIG), grant agreement no. 631983. use past measurements to adapt his probing strategy. Based on the results of [2] it can be readily shown that using adaptive strategies one can achieve E(τ) = log (1/δ) C(p) + log (1/ε) C1(p) + O(log log 1 δε) where C(p) is the Shannon capacity of the BSC with crossover probability p, and C1(p) = D(p∥1−p). This result is also the best possible up to sub-logarithmic terms. For non-adaptive strategies, standard channel coding results [3] indicate for any ﬁxed 0 < R < C(p) there exists a strategy such that τ = log (1/δ) R , log (1/ε) = E(R, p) R · log (1/δ) where E(R, p) is the reliability function of',\n",
       " '1406.5614': 'Multi-view learning is a promising research direction with prevalent applicability (Sun, 2013). For instance, in multimedia content understanding, multimedia segments can be described by both their video and audio signals, and the video and audio signals are regarded as the two views. Learning from data relies on collecting data that contain a suﬃcient signal and encoding our prior knowledge in increasingly sophisticated regularization schemes that enable the signal to be extracted. With certain co-regularization schemes, multi-view learning performs well on various learning tasks. 1  Statistical learning theory (SLT) provides a general framework to analyze the generalization performance of machine learning algorithms. The theoretical outcomes can be used to motivate algorithm design, select models or give insights on the eﬀects and behaviors of some interesting quantities. For example, the well-known large margin principle in support vector machines (SVMs) is well supported by various SLT bounds (Vapnik, 1998; Bartlett and Mendelson, 2002; Sun and Shawe-Taylor, 2010). Diﬀerent from early bounds that often rely on the complexity measures of the considered function classes, the recent PAC-Bayes bounds (McAllester, 1999; Seeger, 2002; Langford, 2005) give the tightest predictions of the generalization performance, for which the prior and posterior distributions of learners are involved on top of the PAC (Probably Approximately Correct) learning setting (Catoni, 2007; Germain et al., 2009). Beyond the common supervised learning, PAC-Bayes analysis has also been applied to other tasks, e.g., density estimation (Seldin and Tishby, 2010; Higgs and Shawe-Taylor, 2010) and reinforcement learning (Seldin et al., 2012). Although the ﬁeld of multi-view learning has enjoyed a great success with algorithms and applications and is provided with some theoretical results, PAC-Bayes analysis of multi-view learning is still absent. In this paper, we attempt to ﬁll the gap between the developments in theory and practice by proposing new PAC-Bayes bounds for multi-view learning. An earlier attempt to analyze the generalization of two-view learning was made using Rademacher complexity (Farquhar et al., 2006; Rosenberg and Bartlett, 2007). The bound relied on estimating the empirical Rademacher complexity of the class of pairs of functions from the two views that are matched in expectation under the data generating distribution. Hence, this approach also implicitly relied on the data generating distribution to deﬁne the function class (and hence prior). The current paper makes the deﬁnition of the prior in terms of the data generating distribution explicit through the PAC-Bayes framework and provides several bounds. However, the main advantage is that it deﬁnes a framework that makes explicit the deﬁnition of the prior in terms of the data generating distribution, setting a template for other related approaches to encoding complex prior knowledge that relies on the data generating distribution. Kakade and Foster (2007) characterized the expected regret of a semi-supervised multiview regression algorithm. The results given by Sridharan and Kakade (2008) take an information theoretic approach that',\n",
       " '1708.00154': 'With the explosive growth of Internet information, recommendation systems have been playing an increasingly important role in on-line E-commerce and applications in a variety of areas, including music streaming service such as Spotify1 and Apple Music, movie rating such as IMDB2, video streaming service such as Netflix and Youtube, job recommendation such as LinkedIn3, and product recommendation such as Amazon. Many recommendation methods are based on Collaborative Filtering (CF) which mainly makes use 1http://www.spotify.com 2http://www.imdb.com 3http://www.linkedin.com arXiv:1708.00154v1  [cs.CL]  1 Aug 2017  of historical ratings [14, 15, 18, 22, 31, 33, 35]. Recently, some approaches also consider text information in addition to the rating data [1, 21, 23, 26, 40, 49]. After some investigations, we observe that the text information in most recommendation tasks can be generally classified into two types: item specifications [40–42] and user reviews [1, 21, 23, 26, 46, 47, 49]. Item specifications are the text information for describing the attributes or properties of the items. For example, in article recommendation such as CiteULike4, it refers to titles and abstracts of papers. In product recommendation such as Amazon, it refers to product descriptions and technical specification information. The second type is user reviews which are written by users to explain why they like or dislike an item based on their usage experiences. Multi-faceted information can be extracted from reviews and used as user preferences or item features, which otherwise cannot be obtained from the overall ratings [5]. Although both types of text data are found to be useful for the recommendation task, they have some inherent limitations. Concretely, the former cannot reflect users’ experience and preference, and the latter is usually too long and suffers from noise. Recently, some E-commerce sites such as Yelp5 launch a new interaction box called Tips on their mobile platforms. As shown in Figure 1, the left column is a review from the user “Monica H.”, and tips from several other users are shown on the right column. In the review text, Monica first generally introduced the restaurant, and then narrated her dining experience in detail. In the tips text, users expressed their experience and feelings plainly using short texts, such as “The risotto was excellent. Amazing service.”. They also provide some suggestions to other people directly in several words, such as “You have to make reservations much in advance.” In contrast to item specifications and user reviews, tips have several characteristics: (1) tips are typically single-topic nuggets of information, and shorter than reviews with a length of about 10 words on average; (2) tips can express user experience, feelings, and suggestions directly; (3) tips can give other people quick insights, saving the time of reading long reviews. In essence, writing some tips and giving a numerical rating are two facets of a user’s product assessment action, expressing the user experience and feelings. Jointly modeling these',\n",
       " '1807.02632': 'Reconstructing non-rigid (i.e., moving and deforming) objects, such as people and animals, has wide varieties of applications, such as novel view synthesis [1], [2]. Being different from rigid object/scene reconstruction (e.g. [3], [4], [5], [6], [7], [8]), which can cast 3D reconstruction into an alignment problem, captured frames with non-rigid objects must be handled as a sequence instead of as different views of the same scene since their shape may change from one frame to the next. This makes the problem challenging. Some approaches have addressed this problem without using any prior knowledge of the object [9], [10], [11], [12] or with using only the assumption of articulated objects (e.g. [13]). These approaches have an inherent weakness in synthesizing unobserved shapes and textures, which is critical for some applications because they often require view synthesis from arbitrary viewpoints, even from an unobserved direction. If we know in advance the object we are going to capture, we can make use of some prior knowledge in order to address this issue. A 3D geometry template is one possible source of prior knowledge for full-body reconstruction. Templatebased methods basically acquire a shape template of the target before actually capturing it in motion and subsequently ﬁt the template to measurements obtained from cameras or RGB-D sensors [13], [11]. This approach largely relies on non-rigid 3D registration and may suffer from insufﬁcient constraints over a possible motion of the target objects, which may be trapped in a local minimum far from the global one. For capturing humans, in particular, we can use human shape models (e.g. [14]) as prior knowledge. Particularly, statistic human shape models (e.g. [15], [16], [17], [18]) can serve as a strong regularizer on possible variations and deformations of human bodies, such as poses and body shape (e.g. tall, short, slim, and sturdy). These statistical models are trained with a number of full-body measurements. Through reducing the number of parameters, it is more likely to ﬁnd a local minimum sufﬁciently close to the optimal, even with a partial measurement. Generally, human bodies exhibit non-rigid deformations according to their poses (e.g. bending arms deforms muscles, skin, and clothes), which we call pose-dependent deformations, and statistic models can describe such pose-dependent deformation only partially. Existing datasets, such as [19], can be used for training a statistic model but contain measurements of people only in skin-tight clothes; therefore, pose-dependent deformations of muscles and skin are encoded in the model, but those of clothes are not. As mentioned above, the key role of such statistic human shape models is to interpolate unobserved surfaces in measurements of human bodies. However, people rarely wear skin-tight clothes in real situations, and the gap between real measurements and ones in the dataset may hinder from plausible interpolation (for example, clothing folds in unobserved volumes may be smoothed out during the ﬁtting process). A statistic model',\n",
       " '1503.01404': 'Let R = K[y] = K[y1, . . . , yn] be a polynomial ring over a ﬁnite ﬁeld K = Fq and let yv1, . . . , yvs be a ﬁnite set of monomials in K[y]. As usual we denote the aﬃne and projective spaces over the ﬁeld K of dimensions s and s −1 by As and Ps−1, respectively. Points of the projective space Ps−1 are denoted by [α], where 0 ̸= α ∈As. We consider a set X, in the projective space Ps−1, parameterized by yv1, . . . , yvs. The set X consists of all points [(xv1, . . . , xvs)] in Ps−1 that are well deﬁned, i.e., x ∈Kn and xvi ̸= 0 for some i. The set X is called of clutter type if supp(yvi) ̸⊂supp(yvj) for i ̸= j, where supp(yvi) is the support of the monomial yvi consisting of the variables that occur in yvi. In this case we say that the set of monomials yv1, . . . , yvs is of clutter type. This terminology comes from the fact that the condition supp(yvi) ̸⊂supp(yvj) for i ̸= j means that there is a clutter C, in the sense of [14], with vertex set V (C) = {y1, . . . , yn} and edge set E(C) = {supp(yv1), . . . , supp(yvs)}. A clutter is also called a simple hypergraph, see Deﬁnition 2.8. Let S = K[t1, . . . , ts] = ⊕∞ d=0Sd be a polynomial ring over the ﬁeld K with the standard grading. The graded ideal I(X) generated by the homogeneous polynomials of S that vanish at all points of X is called the vanishing ideal of X. There are good reasons to study vanishing ideals over ﬁnite ﬁelds. They are used in algebraic coding theory [8] and in polynomial interpolation problems [5, 17]. The Reed-Muller-type codes arising from vanishing ideals on monomial parameterizations have received a lot of attention [1, 3, 6, 8, 10, 13, 14, 16]. The vanishing ideal I(X) is a complete intersection if I(X) is generated by s−1 homogeneous polynomials. Notice that s−1 is the height of I(X) in the sense of [12]. The interest in complete intersection vanishing ideals over ﬁnite ﬁelds comes from information and communication theory, and algebraic coding theory [4, 7, 9]. Let T be a projective torus in Ps−1 (see Deﬁnition 2.15) and let X be the set in Ps−1 parameterized by a clutter C (see Deﬁnition 2.9). Consider the set X = X ∩T. In [14] it is shown that I(X) is a complete intersection if and only if X is a projective torus in Ps−1 . If the clutter 2000 Mathematics Subject Classiﬁcation. Primary 14M10; Secondary 14G15, 13P25, 13P10, 11T71. Key words and phrases. Complete intersection, monomial parameterization, projective space, vanishing ideal, binomial ideal, ﬁnite ﬁeld, Gr¨obner basis, clutter, Reed-Muller-type code. The ﬁrst author was partially supported by CONACyT. The second author was partially supported by SNI. 1  2 AZUCENA TOCHIMANI AND RAFAEL H. VILLARREAL C has all its edges',\n",
       " '1612.04318': 'Manual handcrafting of cost functions for motion planning systems is an inherently complex and time consuming task. It requires high competency in the target area and expert knowledge about robotics systems and the applied algorithms. Ideally, robotic behaviour can be deﬁned by untrained personnel, enabling task adaptation without involving highly trained experts. Inverse Reinforcement Learning (IRL) targets this problem by learning direct reward models from demonstration samples, and has been successfully applied to problems in a wide range of areas [1, 2, 3]. Recent advances exploit the ease of generating samples for learning from demonstration, and combining with with high capacity representations through Neural Networks in domains such as games [4] and autonomous driving [1]. While the possibility to create large amounts of training data without manual labelling enabled training large networks, corner cases still represent a challenge for deep learning as less training data is present. Our work targets initialising neural networks by employing human priors to improve performance in these cases. Submitted to 30th Conference on Neural Information Processing Systems: Deep Reinforcement Learning Workshop (NIPS 2016), Barcelona, Spain. arXiv:1612.04318v1  [cs.RO]  13 Dec 2016  S G Traversable Obstacle Planner Demonstrations Start Goal Vehicle Figure 1: Illustration of sparse feedback, showing a demonstration trajectory on the spatial cost map around the vehicle, as well as the region explored by the planning algorithm. Error feedback is only created for the area surrounding sample trajectories. While CNNs can be integrated straightforwardly into different domains, the IRL framework introduces additional challenges. One of the dominant inﬂuences is spatially sparse feedback from our objective function as displayed in Figure 1. For example, when training a model for image segmentation, the objective creates feedback for each individual pixel. When training with a loss based on Deep Inverse Reinforcement Learning on the other hand, error terms will focus on the region around the demonstration trajectories. These error terms are based on states visited by the demonstration samples and the planning algorithm, which inherently focuses around sample data. Our work addresses the shortcomings by pretraining the network towards a dense human-provided prior, to learn richer feature representations for untraversed areas and increase the network’s ability to generalise. We will show quantitatively that regression based pretraining improves prediction performance as well as classiﬁcation performance for traversable terrain. Furthermore, we qualitatively present the advantages in the context of corner cases of manual cost functions, where pretraining followed by IRL-based training is able to recover more accurate and safe cost representations. 2 Related Work A major share of early work in IRL focuses on small-scale scenarios and benchmarks [5, 6]. However, with recent technological advances, IRL approaches have been applied to larger state and feature spaces in real life applications [2, 1]. In particular, these techniques harness the potential of deep neural networks, learning rich representations that are able to model the relationship between the state of the environment and the reward structure implied by demonstrated behaviour. When working with large state',\n",
       " '1602.00639': 'Despite their promising potential for enhancing the capacity and coverage of cellular systems, small cell networks (SCNs) can also increase the overall power consumption of a cellular system since the access network and edge facilities take up to 83% of mobiles’ operator power consumption [2]. To this end, enhancing the energy efﬁciency of dense SCNs has emerged as a major research challenge [3]. In particular, there has been a recent signiﬁcant interest, not only in minimizing energy consumption, but also in maximizing the use of green energy This research been supported by the U.S. National Science Foundation under Grant CNS-1460333 and by Towards Energy-Efﬁcient Hyper-Dense Wireless Networks with Trillions of Devices, the Commissioned Research of National Institute of Information and Communications Technology (NICT), Japan, and the Academy of Finland CARMA project. A preliminary conference version [1] of this work was presented at IEEE ICC 2016. by deploying energy harvesting, self-powered base stations (BSs) that rely solely on renewable and clean energy for operation [4]. Thus, deploying self-powered BSs is currently being demonstrated by various network operators. For instance, LG Uplus deploys solar-powered LTE BSs in mountain areas of South Korea [5], and, also, a large solar-powered BS cluster is deployed in Tibet by China Mobile [6]. Clearly, one can realize the vision of truly green cellular networks by deploying selfpowered, energy harvesting small cell base stations (SBSs) that rely solely on renewable energy for their operation [7]. Recently, numerous works have focused on the use of energy harvesting techniques in cellular networks [8]–[17]. For instance, the work in [8] overviews key design issues for adopting energy harvesting into cellular networks and propose energy harvesting-aware user association and BS sleep mode optimization problems. With regards to the user association problem in energy harvesting scenarios, the authors in [9] consider a model in which wireless BSs are powered by both grid power and green energy in energy harvesting heterogeneous cellular networks. For this model, the authors propose a user association scheme that minimizes the average trafﬁc delay while maximizing the use of green energy. Furthermore, the authors in [10] propose a probabilistic framework to model energy harvesting and energy consumptions of BSs and investigate a distributed user association problem when BSs is powered by energy harvesting. Also, to study the problem of user association, in [11], the authors considered a network in which the uncertainty of energy harvesting is modeled within a competitive market with the SBSs being the consumers who seek to maximize their utility function. Reaping the beneﬁts of self-powered SBSs mandates effective and self-organizing ways to optimize the ON and OFF schedules of such SBSs, depending on uncertain and intermittent energy arrivals. Therefore, several recent works have focused on optimizing energy efﬁciency in energy harvesting systems by intelligently turning BSs ON and OFF [12]–[17]. For instance, the authors in [12] provide a model to measure the performance of heterogeneous networks',\n",
       " '1803.08134': 'In this paper, we explore the premise that less useful features (including their possible redundancies) in overparameterized deep nets can be pruned away to boost efﬁciency and accuracy. In our opinion, optimal deep features should be taskdependent. Prior to deep learning, features were usually handengineered with domain speciﬁc knowledge (Lowe, 1999; Ojala et al., 1996; Ahonen et al., 2004; Kumar et al., 2009; ˇStruc and Paveˇsi´c, 2009). With the success of deep learning, we no longer need to handcraft features, but people are still handcrafting various architectures, which impacts both the quality and quantity of features to be learned. Some features learned via arbitrary architectures may be of little utility for the current task at hand. Such features not only add to the storage and computational burden but may also skew the data analysis (e.g. image classiﬁcation in this paper) or result in over-ﬁtting when data is limited. ˚˚Corresponding author: Tel.: +0-000-000-0000; fax: +0-000-000-0000; e-mail: qing.tian@mail.mcgill.ca (Qing Tian) Furthermore, many researchers hand-design deep architectures on a particular large benchmark dataset (e.g. ImageNet), but expect to achieve an overall generalization ability. It is possible that such architectures hand-designed on one dataset cannot produce optimal features for other tasks, despite the large enough capacity. Instead of handcrafting ﬁxed nets and assuming their generalizability to various tasks, in this paper, we attempt to derive a range of deep models well-suited to the current task through task dependent network pruning (feature selection). We develop a deep Linear Discriminant Analysis (LDA) (Fisher, 1936) based neuron/ﬁlter pruning framework that is aware of both class separation and holistic cross-layer dependency. The pruning approach strategically selects useful deep features from a discriminative dimension reduction perspective. Since possible harmful dimensions can interfere or skew the classiﬁcation, our pruning approach has a potential to help with accuracy aside from efﬁciency gains. Key contributions that distinguish our approach from previous ones include: (1) Our pruning has a deep LDA neuron utility measure that is derived from ﬁnal task-dependent class separation. The LDA-based utility is calarXiv:1803.08134v6  [cs.CV]  24 Nov 2020  2 culated, unraveled, and traced backwards from the ﬁnal latent space where the linear assumption of LDA is reasonable and variances are more disentangled (Bengio et al., 2013). Those two factors make our LDA-based pruning directly along neuron dimensions well-grounded, which we will show in Sec. 3.1 through solving a generalized eigenvalue problem. In contrast, most previous pruning approaches have hard-coded or humaninjected utility measures (e.g. magnitudes of weights, variances, activation) and reduce model complexity along a direction that is not necessarily desirable for the task. (2) Through deep discriminant analysis, the proposed approach determines how many ﬁlters, and of what types, are appropriate in a given layer. By pruning deep modules, it provides',\n",
       " '1310.3438': 'In this work we consider the optimization problem min x∈Rn φ(x), (1) where φ is strongly convex and smooth. We propose a new algorithm, and call it ‘NSync (Nonuniform SYNchronous Coordinate descent). Algorithm 1 (‘NSync) Input: Initial point x0 ∈Rn, subset probabilities {pS} and stepsize parameters w1, . . . , wn > 0 for k = 0, 1, 2, . . . do Select a random set of coordinates ˆS ⊆{1, . . . , n} such that Prob( ˆS = S) = pS Updated selected coordinates: xk+1 = xk −P i∈ˆS 1 wi ∇iφ(xk)ei end for In ‘NSync, we ﬁrst assign a probability pS ≥0 to every subset S of [n] := {1, . . . , n}, with P S pS = 1, and pick stepsize parameters wi > 0, i = 1, 2, . . . , n. At every iteration, a random set ˆS is generated, independently from previous iterations, following the law Prob( ˆS = S) = pS, and then coordinates i ∈ˆS are updated in parallel by moving in the direction of the negative partial derivative with stepsize 1/wi. The updates are synchronized: no processor/thread is allowed to proceed before all updates are applied, generating the new iterate xk+1. We speciﬁcally study samplings ˆS which are non-uniform in the sense that pi := Prob(i ∈ˆS) = P S:i∈S pS is allowed to vary with i. By ∇iφ(x) we mean ⟨∇φ(x), ei⟩, where ei ∈Rn is the i-th unit coordinate vector. Literature. Serial stochastic coordinate descent methods were proposed and analyzed in [6, 13, 15, 18], and more recently in various settings in [12, 7, 8, 9, 21, 19, 24, 3]. Parallel methods were considered in [2, 16, 14], and more recently in [22, 5, 23, 4, 11, 20, 10, 1]. A memory distributed method scaling to big data problems was recently developed in [17]. A nonuniform coordinate 1 arXiv:1310.3438v1  [stat.ML]  13 Oct 2013  descent method updating a single coordinate at a time was proposed in [15], and one updating two coordinates at a time in [12]. To the best of our knowledge, ‘NSync is the ﬁrst nonuniform parallel coordinate descent method. 2 Analysis Our analysis of ‘NSync is based on two assumptions. The ﬁrst assumption generalizes the ESO concept introduced in [16] and later used in [22, 23, 5, 4, 17] to nonuniform samplings. The second assumption requires that φ be strongly convex. Notation: For x, y, u ∈Rn we write ∥x∥2 u := P i uix2 i , ⟨x, y⟩u := Pn i=1 uiyixi, x • y := (x1y1, . . . , xnyn) and u−1 := (1/u1, . . . , 1/un). For S ⊆[n] and h ∈Rn, let h[S] := P i∈S hiei. Assumption 1 (Nonuniform ESO: Expected Separable Overapproximation). Assume p = (p1, . . . , pn)T > 0 and that for some positive vector w ∈Rn and all x, h ∈Rn, E[φ(x + h[ ˆS])] ≤φ(x) + ⟨∇φ(x), h⟩p + 1 2∥h∥2 p•w. (2) Inequalities of type (2), in the uniform case (pi = pj for all i, j), were studied in [16, 22, 5, 17]. Assumption',\n",
       " '0805.3799': 'As a framework for analysis of narrative in many areas of application, ﬁlm scripts have a great deal to oﬀer. We present quite a number of innovations in this work: quantifying and automating a range of qualitative ways of addressing pattern recognition in narrative; use of metric embedding using Correspondence Analysis, and ultrametric embedding through hierarchical clustering of a data sequence, in order to capture semantics in the data; and verifying experimentally the well foundedness of much that McKee [15] describes in qualitative terms. Other than the data mining, two distinct levels of user are at issue here. Firstly and foremostly, we have the scriptwriter or screenwriter in mind. See 1 arXiv:0805.3799v1  [cs.AI]  24 May 2008  [15] for a content-based description of the scriptwriting process. Secondly and more indirectly we have the movie viewer in mind. The feasibility of using statistical learning methods in order to map a characterization of ﬁlm scripts (essentially using 22 characteristics) onto box oﬃce proﬁtability was pursued by [7]. The importance of such machine learning of what constitutes a good quality and/or potentially proﬁtable ﬁlm script has been the basis for (successful) commercial initiatives, as described by [8]. The business side of the movie business is elaborated on in some depth in terms of avenues to be explored in the future, in [6]. A ﬁlm script is semi-structured in that it is subdivided into scenes and sometimes other structural units. Furthermore there is metadata provided related to location (internal, external; particular or general location name); characters; day, night. There is also dialog and description of action in free text. There are literally thousands of ﬁlm scripts, for all genres, available and openly accessible (e.g. IMSDb, The Internet Movie Script Database, www.imsdb.com). While oﬀering just one data modality, viz. text, there is close linkage to other modalities, visual, speech and often music. An area of application of our work that is of particular importance is to movies for television. In contrast to a cinema movie, in television a serial dramatization is formulaic in its set of characters, their actions, location, and in content generally. In form it is even more formulaic, in length, initial scenes, positioning of advertisement breakpoints, and in other aspects of format. While screenwriting and subsequent aspects of cinema movie creation and development have been much studied (e.g. [15]), ﬁlm writing for television has been less so. The latter is often team-based, and much more “managed” on account of its linkages with other dramatizations in the same series, or in closely related series. These properties of television serial dramatization lead, perhaps even more than for cinema movie, to a need for tools to quantitatively support script writing. Film scripts constitute an outstanding template or model for other domains. One longer term goal of our work is for our tools to provide a platform for introducing interactivity into a movie. Interactivity with a ﬁlm or video includes the following',\n",
       " '1502.04434': 'Neural networks are widely used in machine learning. For example, they are showing the best results in image classiﬁcation (Szegedy et al. (2014); Lee et al. (2014)), image labeling (Karpathy & Fei-Fei (2014)) and speech recognition. Deep neural networks applied to large datasets can automatically learn from a huge number of features, that allow them to represent very complex relations between raw input data and output classes. However, it also means that deep neural networks can suffer from overﬁtting, and different regularization techniques are crucially important for good performance. It is often the case that there exist a number of variations of a given object that preserve its label. For example, image labels are usually invariant to small variations in their location on the image, size, angle, brightness, etc. In the area of voice recognition the result has to be invariant to the speech tone, speed and accent. Moreover, the predictions should always be robust to random noise. However, this knowledge is not incorporated in the learning process. In this work we propose two methods of achieving local invariance by extending the standard backpropagation algorithm. First of them enforces robustness of the loss function to all variations in the input vector. Second methods trains the predictions to be robust to variation of the input vector in the direction which changes the loss function the most. We refer to them as Loss Invariant BackPropagation (Loss IBP), and Prediction IBP. While one of them is faster, the other one demonstrates better performance. Both methods can be applied to all types of neural networks in combination with any other regularization technique. ∗http://www.demyanov.net 1  Under review as a conference paper at ICLR 2016 1.1 BACKPROPAGATION ALGORITHM We denote K as the number of layers in a neural network and yi, i ∈{0, . . . , K} as the activation vectors of each layer. The activation of the ﬁrst layer y0 is the input vector x. If the input is an image that consists of one or more feature maps, we still consider it as a vector by traversing the maps and concatenating them together. The transformation between layers might be different: convolution, matrix multiplication, non-linear transformation, etc. We assume that yi = fi(yi−1; wi), where wi is the set of weights, which may be empty. The computation of the layer activations is the ﬁrst (forward) pass of the backpropagation algorithm. Moreover, the loss function L(yK) can also be considered as a layer yK+1 of the length 1. The forward pass is thus a calculation of the composition of functions fK+1(fK(. . . f1(x) . . .)), applied to the input vector x. Let us denote the vectors of derivatives with respect to layer values ∂L/∂yi as dyi. Then, similar to the forward propagating functions yi = fi(yi−1; wi), we can deﬁne backward propagating functions dyi−1 = ˜fi(dyi; wi). We refer to them as reverse functions. According to the chain rule, we can obtain their matrix',\n",
       " '1704.06962': 'Given a noisy communication channel, the maximal cardinality of a codebook of blocklength n which can be decoded with block error probability no greater than ǫ is denoted as M∗(n, ǫ). The evaluation of this function – the fundamental performance limit of block coding – is alas computationally impossible for most channels of interest. As a resolution of this difﬁculty [1] proposed a closed-form normal approximation, based on the asymptotic expansion: log M∗(n, ǫ) = nC − √ nV Q−1(ǫ) + O(log n) , (1) where the capacity C and dispersion V are two intrinsic characteristics of the channel and Q−1(ǫ) is the inverse of the Q-function1. One immediate consequence of the normal approximation is an estimate for the minimal blocklength (delay) required to achieve a given fraction η of the channel capacity: n ≳ \\x12Q−1(ǫ) 1 −η \\x132 V C2 . (2) Asymptotic expansions such as (1) are rooted in the central-limit theorem and have been known classically for discrete memoryless channels [2], [3] and later extended in a wide variety of directions; see the surveys in [4], [5]. Authors are with the Department of Electrical Engineering and Computer Science, MIT, Cambridge, MA 02139 USA. e-mail: {austinc,yp}@mit.edu. This material is based upon work supported by the National Science Foundation CAREER award under grant agreement CCF-12-53205, by the NSF grant CCF-17-17842 and by the Center for Science of Information (CSoI), an NSF Science and Technology Center, under grant agreement CCF-09-39370. 1As usual, Q(x) = R ∞ x 1 √ 2π e−t2/2 dt . 1  The fading channel is the centerpiece of the theory and practice of wireless communication, and hence there are many slightly different variations of the model: differing assumptions on the dynamics and distribution of the fading process, antenna conﬁgurations, and channel state knowledge. The capacity of the fading channel was found independently by Telatar [6] and Foschini and Gans [7] for the case of Rayleigh fading and channel state information available at the receiver only (CSIR) and at both the transmitter and receiver (CSIRT). Motivated by the linear gains promised by capacity results, space time codes were introduced to exploit multiple antennas, most notable amongst them is Alamouti’s ingenious orthogonal scheme [8] along with a generalization of Tarokh, Jafarkhani and Calderbank [9]. Motivated by a recent surge of orthogonal frequency division (OFDM) technology, this paper focuses on an isotropic channel gain distribution, which is piecewise independent (“block-fading”) and assume full channel state information available at the receiver (CSIR). This work describes ﬁnite blocklength effects incurred by the fading on the fundamental communication limits. Some of the prior work on similar questions is as follows. Single antenna channel dispersion was computed in [10] for a more general stationary channel gain process with memory. In [11] ﬁniteblocklength effects are explored for the non-coherent block fading setup. Quasi-static fading channels in the general MIMO setting have been thoroughly investigated in [12], showing that',\n",
       " '1611.05995': 'Relay-assisted communication is one of the promising techniques that have been proposed for wireless networks. The main idea of a relay network is to improve the data transmission efﬁciency by implementation of intermediate relay nodes which support data transmission from a source to a destination. These devices are usually powered by ﬁxed but limited batteries. Thus, wireless networks may suffer from the short lifetime and require periodic battery replacement/recharging. However, the battery replacement may be costly or infeasible in, e.g., toxic environments. It has been recently proposed to use radio-frequency (RF) signals as a means of wireless energy transfer. Signiﬁcant advances in circuit design for RF energy transfer make the usage of energy transfer a viable solution for prolonging the lifespan of wireless networks, e.g., [1], [2]. Amplify-and-forward (AF) and decode-and-forward (DF) cooperative networks with wireless energy and information transfer are investigated in [3]–[7]. In [3], two relaying protocols, namely, power splitting relaying (PSR) and time switching relaying (TSR), with simultaneous wireless information and energy transfer, are proposed and evaluated in terms of system throughput. Moreover, [5] derives different power allocation strategies for energy harvesting DF relay networks with multiple source-destination pairs and a single energy harvesting relay. Multi-relay networks with information and energy transfer are also studied in [6], [7] using stochastic geometry. In the literature, so far, the main focus has been on investigating the energy harvesting wireless networks performance based on Shannon’s results on the achievable rates. To be speciﬁc, most results are obtained under the assumption that the achievable rate is given by log(1 + x) with x standing for the signal-to-interference-plus-noise ratio (SINR) at the receiver. This is an acceptable assumption when long codewords are used. On the other hand, in many applications, such as Internet of Things in which employing energy harvesting nodes is deemed as a core element, the codewords are required to be short to meet latency requirements [8]. As a result, analyzing the system performance using Shannon’s capacity formula does not provide realistic results in the aforementioned scenarios. Recently, an accurate approximation of the achievable rate with ﬁnite blocklength was presented in [9]. Using the results in [9], in [10] and [11] the performance of incremental redundancy HARQ and spectrum sharing cognitive radio were analyzed, respectively. Also, [12] studies the capacity of DF relay networks with ﬁxed energy supply. Thus, it is interesting to study the performance of relay networks with wireless energy and information transfer in the presence of ﬁnite-length codewords. In this paper, we investigate the outage probability and the throughput of AF relay networks with wireless energy and information transfer. Two well-known protocols for energy and information transfer, namely, TSR and PSR are considered. We use the recent results of [9] on the achievable rates of ﬁnite block-length codes to analyze the system performance. We derive two tight closed',\n",
       " '1804.00401': 'Motivation: Structured query language (SQL), despite its expressiveness, may hinder users with little or no relational database knowledge from exploring and making use of the data stored in an RDBMS. In order to effectively leverage their data sets, users are required to have prior knowledge about the schema information of their database, such as table names, columns and relations, as well as a working understanding of the syntax and semantics of SQL. These requirements set “a high bar for entry” for democratized data exploration and thus have triggered new research efforts to develop alternative interfaces that allow non-technical users to explore and interact with their data conveniently. While visual data exploration tools have recently gained signiﬁcant attention, Natural Language Interfaces to Databases (NLIDBs) appear as highly promising alternatives because they enable users to pose complex ad-hoc questions in a concise and convenient manner. For example, imagine that a medical doctor starts her new Figure 1: An Example Session in DBPal job at a hospital and wants to ﬁnd out about the age distribution of patients with the longest stays in the hospital. This question typically requires the doctor – when using a standard database interface directly – to write a complex nested SQL query. Even with a visual exploration tool such as Tableau [19] or Vizdom [6], a query like this is far from being trivial since it requires the user to execute multiple query steps and interactions. Alternatively, with an exploration tool supported by a natural language interface, the query would be as simple as stating “What is the age distribution of patients who stayed longest in the hospital?” Contribution: In this paper, we introduce DBPal, a relational database exploration tool that provides a robust and easy-to-use natural language (NL) interface with the purpose of improving the transparency of the underlying database schema and enhancing the expressiveness and ﬂexibility of human-data-interaction. Different from existing approaches, DBPal leverages deep neural network models as the core of its natural language interface system. In the following, we outline the two key features of DBPal that are based on deep neural network models. Robust Query Translation: We propose a novel query translation framework based on a sequence-to-sequence recurrent neural network model that has recently became a state-of-theart for machine translation task. Our notion of model robustness is deﬁned as the effectiveness of the translation model to 1 arXiv:1804.00401v1  [cs.DB]  2 Apr 2018  map linguistically varying utterances to ﬁnite predeﬁned relational database operations. Take, for example, the SQL expression SELECT * FROM patients WHERE diagnosis=’ﬂu’. There are numerous corresponding natural language utterances for this query, such as ”show all patients with diagnosis of ﬂu” or simply ”get ﬂu patients”. We aim to build a translation system that is invariant towards these linguistic alterations, no matter how complex or convoluted. A key challenge hereby is to curate a comprehensive training set for the',\n",
       " '1603.08233': 'Pattern recognition and classiﬁcation is one of the most challenging ongoing problems in computer science in which we seek to classify objects within an image into categories, typically with considerable variation among the objects within each category. With invariant pattern recognition, we seek to develop a model of each category that captures the essence of the class while compressing inessential variations. In this manner, invariant pattern recognition can tolerate (sometimes drastic) variations within a class, while at the same time recognizing diﬀerences across classes that can be minute but salient. One means of achieving this goal is through invariant feature extraction [1], where the image is transformed into feature vectors that may be invariant with respect to a set of transformations, such as displacement, rotation, scaling, skewing, and lighting changes. This method can also be used in a hierarchical setting, where subsequent layers extract compound features from features already extracted in lower levels, such that the last layer extracts features that are essentially the classes themselves [2]. Most of these existing methods have one thing in common: they arXiv:1603.08233v2  [cs.CV]  16 Jun 2016  2 Randal S. Olson et al. achieve invariance either by applying transformations to the image when searching for the best match, or by mapping the image to a representation that is itself invariant to such transformations. In contrast to these “passive” methods where transformations are applied to the image, we propose an active, attention-based method, where a virtual camera roams over and focuses on particular portions of the image, similar to how our own brain controls the focus of our attention [3]. In this case, the camera’s actions are guided by what the camera ﬁnds in the image itself: In essence, the camera searches the image to discover features that it recognizes, creating in the process a time series of experiences that guides further movements and eventually allows the camera to classify the image. We call this camera an “active categorical classiﬁer,” or ACC for short. Broadly speaking, the problem of classifying a spatial pattern is transformed into one of detecting diﬀerences within and between time series, namely the temporal sequence that the virtual camera generates in its sensors as it navigates the image. The method we propose here is inspired by models of visual attention [4], where attention to “salient” elements of an image or scene is guided by the image itself, such that only a small part of the incoming sensory information reaches short-term memory and visual awareness. Thus, focused attention overcomes the information-processing bottleneck imposed by massive sensory input (which can easily be 107 −108 bits per second in parallel at the optic nerve [4]), and serializes this stream to achieve near-real-time processing with limited computational requirements. In previous work, we have shown that it is possible to evolve robust controllers that navigate arbitrary mazes with near-perfect accuracy [5] and simulate realistic animal behavior [6]. Independently, we have',\n",
       " '1706.09278': 'Knowledge – lexical, world and common-sense – is crucial for tasks such as automated text comprehension and summarization, question answering, natural language dialogue systems. To make such knowledge available for automatic processing, the most common approach is to provide it as a collection of relation triples – entities or concepts connected by a relation: e.g., (concept:city:London, relation:country capital, concept:country:UK). Globally, such collections can be viewed as knowledge graphs (KGs), for example NELL [3], Freebase [1] and YAGO [16]. In such graphs, nodes (entities/concepts) may be connected by different types of relations. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and the full citation on the ﬁrst page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission and/or a fee. Request permissions from permissions@acm.org. K-CAP 2017, Austin, TX, USA © 2017 ACM. 978-1-4503-5553-7/17/12...$15.00 DOI: 10.1145/3148011.3154466 This results in a multi-graph, i.e. a graph with different types of links where a link type corresponds to a relation type. KGs are known to be incomplete [10], i.e., a signiﬁcant number of relations between entities are missing. Embedding the knowledge graph in a continuous vector space has been successfully used to address this problem [2, 13, 15]. Such models represent the components of the graph, i.e., the entities and relations, using real valued latent factors that encode the structure of the knowledge graph. For example the latent factor model should be able to recover Cologne from the latent representations of Moselle and river ﬂowsThrough city. Examples include the RESCAL [13] tensor factorization model, the TransE model [2] and their variations [9, 12]. We focus on the RESCAL model, one of the most ﬂexible and widely used models. RESCAL is a bilinear model that represents triples as a pairwise interaction of source and target entity latent factors (embeddings) through a matrix that represents the latent factors of the connecting relation. The entity and relation representations induced can be used to predict additional relations – edges – between known entities. Table 1 lists a few examples of entity type information in Freebase. Existing knowledge graphs are imbalanced – both relation and entity frequencies vary widely, as evident from the statistics on Freebase 15k shown in Figure 1. Since entity and relation embeddings are based on the connectivity structure of the graph, it is reasonable to ask what is the outcome of the knowledge graph embedding for entities and relations which are underrepresented in the graph, in particular, how good are they for the task of link prediction. Approaches',\n",
       " '1610.09322': 'Non-convex optimization is a critical component in modern machine learning. Unfortunately, theoretical guarantees for nonconvex optimization have been mostly negative, and the problems are computationally hard in the worst case. Nevertheless, simple local-search algorithms such as stochastic gradient descent have enjoyed great empirical success in areas such as deep learning. As such, recent research eﬀorts have attempted to bridge this gap between theory and practice. For example, one property that can guarantee the success of local search methods over nonconvex functions is when all local minima are also the global minima. Interestingly, it has been recently proven that many well known nonconvex problems do have this property, under mild conditions. Consequently, local-search methods, which are designed to ﬁnd a local optimum, automatically achieve global optimality. Examples of such problems include matrix completion [1], orthogonal tensor decomposition [2, 3], phase retrieval [4], complete dictionary learning [5], and so on. However, such a class of nonconvex problems is limited, and there are many practical problems with poor local optima, where local search methods can fail. ∗University of California, Irvine. Email:a.anandkumar@uci.edu †Duke University. Email:ericdy@cs.duke.edu ‡Duke University. Email:rongge@cs.duke.edu §Google Research. Email:hmobahi@csail.mit.edu 1 arXiv:1610.09322v4  [stat.ML]  14 Jun 2017  The above property, while very helpful, imposes a strong assumption on the nonconvex problem. A less restrictive requirement for the success of local search methods is the ability to initialize local search in the basin of attraction of the global optimum using another polynomial-time algorithm. This approach does not require all the local optima to be of good quality, and thus can cover a broader set of problems. Eﬃcient initialization strategies have recently been developed for many nonconvex problems such as overcomplete dictionary learning [6, 7], tensor decomposition [8], robust PCA [9], mixed linear regression [10] and so on. Although the list of such tractable nonconvex problems is growing, currently, the initialization algorithms are problem-speciﬁc and as such, cannot be directly extended to new problems. An interesting question is whether there exist common principles that can be used in designing eﬃcient initialization schemes for local search methods. In this paper, we demonstrate how a class of homotopy continuation methods may provide such a framework for eﬃcient initialization of local search schemes. 1.1 Homotopy Method The homotopy method is a general and a problem independent technique for tackling nonconvex problems. It starts from an objective function that is eﬃcient to optimize (e.g. convex function), and progressively transforms it to the required objective [11]. Throughout this progression, the solution of each intermediate objective is used to initialize a local search on the next one. A particular approach for constructing this progression is to smooth the objective function. Precisely, the objective function is convolved with the Gaussian kernel and the amount of smoothing is varied to obtain the set of transformations. Intuitively, smoothing “erases wiggles” on the objective surface (which can',\n",
       " '1707.01212': 'A successful approach in understanding real world data on which machine learning models are built to enable automated decision making, is to extract important and inﬂuential data points or features that best describes the underlying data [1], [2], [3]. These approaches can be uniﬁed as ﬁnding a subset S out of a collection V of items (data points, features, etc.) that maximize a scoring function f(S). The scoring function measures the information, relevance and quality of the selection. It may also discourage redundancy to obtain compact, informative subsets. Such subset selection problems are predominately useful when summarizing data sets to offer data scientists a ﬁrst impression of the scope of a data set, in identifying outliers, and for compressing training data sets to accelerate the training of data-hungry deep learning methods. The desiderata for the scoring function naturally imply notions of diminishing returns: for any two sets S ⊂T ⊂V and any item i /∈T, it holds that f(S ∪{i}) −f(S) ≥f(T ∪{i}) −f(T). A scoring function satisfying this diminishing return property is called a submodular function [4], [5]. Importantly, submodularity often implies tractable algorithms with good theoretical guarantees. In this paper we provide two algorithms for selecting prototypical examples from complex datasets. By showing that our scoring function f(.) satisﬁes a key property of weak submodularity [6], we derive strong theoretical bounds for our selection methods. Loosely speaking, weak submodularity is a class of approximately submodular functions. The weak part in these approximate submodular functions are precisely deﬁned in terms of their submodularity ratio as stated in (4). Showing that our problem is weakly submodular immediately leads to a standard greedy algorithm which we call ProtoGreedy. Our main contribution is a faster yet theoretically sound algorithm called ProtoDash for which we derive approximation guarantees. Our work builds on top of the Learn to Criticize method (L2C) [1] where the authors provide an approach to select prototypical (as well as outlying) examples from a given complex dataset for a pre-speciﬁed sparsity level m. We generalize this work to not only select prototypes for a given sparsity level m but also to associate non-negative weights with each of them indicative of the importance of each prototype. This extension leads to multiple advantages over L2C: a) the weights allow for assessing the importance of the prototypes, b) the non-negativity aids in making this comparison more natural and hence more easy to interpret [7], c) it provides a single coherent framework under which both prototypes and criticisms – which are the farthest (or least weighted) examples from our prototypes – can be found and d) our framework works for any symmetric positive deﬁnite kernel which is not the case for L2C. Additionally, we see our work as addressing one of the open questions laid out in [1] and we quote, ”For future work, we hope to further explore the properties of L2C such as the effect of the choice of kernel, and weaker conditions on the kernel matrix for submodularity.” To this end, we show',\n",
       " '1807.06677': 'Video summarization aims to select key frames/shots among videos to summarize the main storyline and has been widely investigated for facilitating video understanding [5, 7, 16, 20, 29, 34]. As shown in Figure 1, this task can be classiﬁed into two types: a) generic video summarization, which only takes the visual features of the video contents as the input and b) query-conditioned video summarization which conditions summarization on user queries. The generic video summarization task has been addressed at three different levels: shotlevel [14, 15], frame-level [11, 12], and object-level [17, 33] video summarization by selecting key shots/frames/objects in the videos. However, one main issue with generic video c⃝2018. The copyright of this document resides with its authors. It may be distributed unchanged freely in print or electronic forms. arXiv:1807.06677v1  [cs.CV]  17 Jul 2018  2 ZHANG et al.: QUERY-CONDITIONED VIDEO SUMMARIZATION Food + Sky Generic Video Summarization Query-Conditioned Video Summarization Video (User Query) (Key frames/shots) Figure 1: Different video summarization tasks. Generic video summarization aims to generate key contents of a video, while query-conditioned video summarization takes the user query into consideration and generates summaries accordingly. summarization is the fact that it does not take user preferences into account, since different users may have different preferences towards the video content, and a single evaluation metric is not robust enough for all video summaries [23]. Recently, another research direction, query-conditioned video summarization [22, 23, 27], has been explored, which takes advantage of different user queries in form of texts to learn more user-oriented summaries. It generates user-oriented summaries that have effective correlations between summaries and query, and capture the overall essence of the video. Several approaches to query-conditioned video summarization have been proposed. Sharghi et al. [22] ﬁrst extend a sequential DPP (seqDPP) [4] to extract key shots. Afterwards, they develop a more comprehensive dataset for this task, and propose a memory network [25] parameterized seqDPP model. However, there is still room to learn a better summarizer due to the limitation of the memory to jointly encode video and query. To address the above issue we develop a query-conditioned three-player generative adversarial network architecture. We encode the query and the video sequence to learn a joint representation combining visual and text information, and take this query-conditioned representation as the input to the generative adversarial network. A three-player structure is applied during joint training, in order to achieve superior regularization. The contribution in our work can be summarized as follows: ﬁrst, we propose a query-conditioned three-player adversarial network, which jointly encodes query and visual information and learns in an adversarial manner. Second, we introduce a three-player structure for the adversarial training. The discriminator regularizes the model via the three-player loss, which facilitates the generator to generate more related and meaningful video summaries. Two supervised losses a',\n",
       " '0712.4209': 'In the last few decades it has become apparent that many problems in Information Theory have analogies to certain problems in the area of statistical physics of disordered systems. Such analogies are useful because physical insights, as well as statistical mechanical tools and analysis techniques can be harnessed in order to advance the knowledge and the understanding with regard to the information–theoretic problem under discussion. 1  One important example of such an analogy is between the statistical physics of disordered magnetic materials, a.k.a. spin glasses, and the behavior of certain ensembles of random codes for source coding (see, e.g., [1], [2], [3], [4]) and for channel coding (see, e.g., [5] and references therein, [6], [7], [8], [9], [10], [11] [12], [13], [14], [15], [16], [17], [18], [19], [20]). Among the various models of interaction disorder in spin glasses, one of the most fascinating models is the random energy model (REM), invented by Derrida in the early eighties [21], [22], [23] (see also, e.g., [20], [24], [25], for later developments). The REM is on the one hand, extremely simple and easy to analyze, and on the other hand, rich enough to exhibit phase transitions. According to the REM, the diﬀerent spin conﬁgurations are distributed according to the Boltzmann distribution, namely, their probabilities are proportional to an exponential function of their negative energies, but the conﬁguration energies themselves are i.i.d. random variables, hence the name random energy model.1 In [5, Chap. 6], M´ezard and Montanari draw an interesting analogy between the REM and the statistical physics pertaining to ﬁnite temperature decoding [18] of ensembles of random block codes. The relevance of the REM here is due to the fact that in this context, the partition function that naturally arises has the log–likelihood function (of the channel output given the input codeword) as its energy function (Hamiltonian), and since the codewords are selected at random, then the induced energy levels are random variables. Consequently, the phase transitions of the REM are ‘inherited’ by ensembles of random block codes, as is shown in [5]. In [26], this subject was further studied and the free energies corresponding to the various phases were related to random coding exponents of the probability of error at rates below capacity and to the probability of correct decoding at rates above capacity. While the REM is a very simple and interesting model for capturing disorder, as described above, it is not quite faithful for the description of a real physical system. The reason is that according to the REM, any two distinct spin conﬁgurations, no matter how similar and close to each other, have independent, and hence unrelated, energies. A more realistic model must take into account the geometry and the structure of the physical system and thus allow dependencies between energies associated with closely related conﬁgurations. 1More details on this and other terminology described in the remaining part of this Introduction, will be given in the Section 3. 2',\n",
       " '1409.3870': 'FAILED',\n",
       " '1304.6487': 'Spectral clustering is one of the most popular clustering algorithms, whose key is to build a similarity graph to describe the similarities among different data points [1]. In the graph, each vertex denotes a data point, and the edge weight between two vertexes represents the similarity of the corresponding data points. Currently, there are two schemes to calculate the similarity among data points, i.e., Pairwise Distance-based Scheme (PDS) and Linear Representation-based Scheme (LRS). PDS computes the similarity between two points according to the distance between two points, e.g., Laplacian Eigenmaps (LE) [2]. On the other hand, LRS assumes that each data point could be denoted as a linear combination of some intra-subspace points [3]. Based on this observation, this scheme uses the linear representation coefﬁcients as a measure of similarity. Recently, LRS has attracted more interests from the ﬁeld of image clustering, since it capture the real structure of the data set better. Numerous clustering algorithms are developed based on LRS, such as Locally Linear Embedding (LLE) [4], Sparse Subspace Clustering (SSC) [3] and Low Rank Representation (LRR) [5]. It is notable that the above-mentioned similarity computation schemes suffer respectively from some limitations. Speciﬁcally, Pairwise Distance-based Scheme (PDS) is sensitive to noises and outliers, because it only depends on the distance  2 between the two considered data points, and ignores the global structure of the whole data set. Fig. 1(a) illustrates the disadvantages of PDS. On the other hand, Linear Representation-based Scheme (LRS) has the possibility that a data point is represented as a linear combination of the inter-subspace data points. Fig. 1(b) shows the drawbacks of LRS. SSC [3] and LRR [5] overcome this problem to some extent by bringing a sparsity constraint and a low-rank constraint into linear representation, but both of them are iterative algorithms with high computational complexity. In order to overcome the above-mentioned problems, this letter presents a novel scheme to construct the similarity graph, where the similarity computation among different data points depends on not only their pairwise distances but also mutually linear representation relationships. The proposed scheme, called Locally Linear Representation (LLR), encodes each data point using a set of data points which produce the minimal error, and are close to the objective point. Our developed scheme is more robust to noises and outliers than PDS. At the same time, being compared with LRS, it can effectively avoid selecting inter-subspaces points to represent the objective point. Moreover, the new scheme uses an analytic solution to construct the similarity graph, and has lower computational complexity than the iterative methods, such as SSC and LRR. 2 Locally Linear Representation Our basic idea was derived from a theoretical result in manifold learning that a topological manifold is a topological space which is locally homeomorphic to an Euclidean space [4]. It implies that in a subspace, mutually adjacent points can provide the linearly representation for each',\n",
       " '1204.2134': 'The watershed line or divide line of a topographic surface is the boundary separating its catchment basins. A drop of water falling on this surface glides along a line of steepest descent until it is captured by a regional minimum. A catchment basin is the attraction zone of a minimum. Catchment basins may overlap and the overlapping zone is precisely a divide line, as a drop of water falling on it may glide towards several distinct minima. Any gray tone image may be considered as a topographic surface, where the altitude is proportional to the gray-tone. Consider in particular the gradient of an image to segment. In absence of noise or texture, the inside of the objects and of the background appears as minima and the contours appear as crest lines separating the minima. Each object, appearing in the gradient image as the catchment basin of a minimum, is easily extracted by the watershed transform. Each minimum gives birth to a catchment basin ; with two many meaningless minima, oversegmentation occurs. Marker based segmentation regularizes the gradient image ; it consists in ﬂooding the topographic surface in order to keep only one regional minimum for each object of interest [2]. More generally, closing reconstructions or ﬂoodings regularize the gradient as they completely ﬁll some catchment basins up to their lowest pass point. As a result these catchment basins are absorbed by neighboring basins, yielding a coarser segmentation. To a series of increasing ﬂoodings will be associated a hierarchy [16]. The ﬁlling of lakes and subsequent absorption of their catchment basins by neighboring regions may be ordered according some geometric criteria, such as the depth of the lakes [9], [18], [19], their area or their volume [22],[23]. They may also be ﬁlled in an interactive mode and be a building block for interactive segmentation [26]. The watershed being a powerful tool for segmentation has been victim of its success : a number of deﬁnitions and algorithms have been published, claiming to construct a watershed line or catchment basins, although they obviously are not equivalent. It is out of the scope of the present paper to give an exhaustive bibliography of the concept of watershed. Distinct algorithms published in the literature will produce different results. But even the same algorithm may produce distinct results if one changes the scanning order of the image. Jos. Roerdink gives a review of the most popular watershed deﬁnitions and implementations [21]. An historical analysis with many references on how the watershed idea has been developed, triggered both by theoretical considerations and by technological possibilities for its implementation may be found in [17]. We propose an algorithm for the following situation : a gray tone image is given, represented on a grid or on a graph and we desire delineating its  catchment basin. Moreover we desire constructing a partition into catchment basins, often at the price of arbitrary divisions of the zones where they overlap. We will compare the performances between',\n",
       " '1105.2865': 'A. Background 1The work of this author was done while he was with the Division of Mathematical Sciences, School of Physical and Mathematical Sciences, Nanyang Technological University, 21 Nanyang Link, Singapore 637371. A part of this work is to be presented in the IEEE International Symposium on Information Theory (ISIT), St. Petersburg, Russia, July-August 2011. T He problem of Index Coding with Side Information (ICSI) was introduced by Birk and Kol [1], [2]. During the transmission, each client might miss a certain part of the data, due to intermittent reception, limited storage capacity or any other reasons. Via a slow backward channel, the clients let the server know which messages they already have in their possession, and which messages they are interested to receive. The server has to ﬁnd a way to deliver to each client all the messages he requested, yet spending a minimum number of transmissions. As it was shown in [1], the server can signiﬁcantly reduce the number of transmissions by coding the messages. The toy example in Figure 1 presents a scenario with one broadcast transmitter and four receivers. Each receiver requires a different information packet (we sometimes simply call it message). The na¨ıve approach requires four separate transmissions, one transmission per an information packet. However, by exploiting the knowledge on the subsets of messages that clients already have, and by using coding of the transmitted data, the server can just broadcast one coded packet. S R3 R4 R1 R2 P4 i=1 xi has x1, x2, x3 requests x4 has x2, x3, x4 requests x1 has x1, x3, x4 requests x2 has x1, x2, x4 requests x3 Fig. 1: An example of the ICSI problem Possible applications of index coding include communica2 tions scenarios, in which a satellite or a server broadcasts a set of messages to a set clients, such as daily newspaper delivery or video-on-demand. Index coding with side information can also be used in opportunistic wireless networks. These are the networks in which a wireless node can opportunistically listen to the wireless channel. The client may obtain packets that are not designated to it (see [3]–[5]). As a result, a node obtains some side information about the transmitted data. Exploiting this additional knowledge may help to increase the throughput of the system. The ICSI problem has been a subject of several recent studies [3], [6]–[13]. This problem can be viewed as a special case of the Network Coding (NC) problem [14], [15]. In particular, as it was shown in [3], [11], every instance of the NC problem can be reduced to an instance of the ICSI problem. B. Our contribution The preceding works on the ICSI problem consider scenario where the transmissions are error-free. In practice, of course, this might not be the case. In this work, we assume that the transmitted symbols are subject to errors. We extend some known results on index coding to a case where any receiver can correct up',\n",
       " '1805.03911': 'Identifying hidden patterns in a given dataset is a problem of great interest (Hodge and Austin, 2004; Yeung and Ruzzo, 2001; Berry and Castellanos, 2004), and as a consequence it has been extensively studied (Hastie et al., 2009, Chapter 14). This is precisely the objective of unsupervised learning (Ghahramani, 2004) – one has access to a dataset, and one wishes to ﬁnd underlying structure hidden in the data. The objective of this paper is to introduce the labelling problem, an unsupervised learning problem where one intends to assign to points in a datasets labels, an object that will be deﬁned in Section 2. 1.1 Labelling A cloud of points will share a label if unreasonably many of them share a common relationship. This relationship will not be determined by the individual points, but by the cloud of points as a whole. For example, if suﬃcient points in a Euclidean space lie on a hyperplane, the hyperplane captures a relationship between the points that is unlikely to be due to randomness. Therefore, one could label the cloud of points with that hyperplane. Consequently, points could have multiple labels since they do not have to lie on a single hyperplane. 1 arXiv:1805.03911v2  [stat.ML]  30 May 2018  Lyons and Perez Arribas This linear setting is a particular case of the noisy nonlinear framework we propose in Section 2 – the labelling problem. In this case, points will be labelled together if they satisfy a nonlinear relationship that is unlikely to be due to randomness – see Deﬁnition 1. This is a natural problem to consider, since many real-life problems consist of ﬁnding relationships that are not mutually exclusive. For instance, a group of people may share the property that they all like a particular movie – the movie would be a label assigned to this group of people – but each of them may also like other movies, which would relate them to other groups of people. That is, any given individual will have multiple labels: the movies he or she likes. Then, one could try to ﬁnd users that share the same labels – that is, users that like the same movies. Consider Figures 1 and 2. It is visually apparent that there are at least two labels in Figure 1, and three labels in Figure 2, and that some points have more than one label. Figure 1: Two overlapping circles. Figure 2: Three overlapping conics on the plane. Figure 3: Figure 1 with low signal-tonoise ratio. Figure 4: Figure 2 with low signal-tonoise ratio. Figures 3 and 4 were obtained by adding background noise to Figures 1 and 2 respectively, in order to obtain low signal-to-noise ratios. Now, it is challenging – if not impossible – to visually identify the patterns in the data, even though the patterns do still exist. Our 2  Labelling as an unsupervised learning problem goal is to explore the extent to which we can identify these labels in the presence',\n",
       " 'cs/0308003': 'For many computer vision applications, such as robot visual inspection and industrial metrology, where a camera is used as a sensor in the system, the camera is usually assumed to be fully calibrated beforehand. Camera calibration is the estimation of a set of parameters that describes the camera’s imaging process. With this set of parameters, a perspective projection matrix can directly link a point in the 3-D world reference frame to its projection (undistorted) on the image plane. This is given by: λ \\uf8ee \\uf8f0 u v 1 \\uf8f9 \\uf8fb= A [R | t] \\uf8ee \\uf8ef\\uf8ef\\uf8f0 Xw Y w Zw 1 \\uf8f9 \\uf8fa\\uf8fa\\uf8fb= \\uf8ee \\uf8f0 α γ u0 0 β v0 0 0 1 \\uf8f9 \\uf8fb \\uf8ee \\uf8f0 Xc Y c Zc \\uf8f9 \\uf8fb, (1) where (u, v) is the distortion-free image point on the image plane. The matrix A fully depends on the camera’s 5 intrinsic parameters (α, γ, β, u0, v0), with (α, β) being two scalars in the two image axes, (u0, v0) the coordinates of the principal point, and γ describing the skewness of the two image axes. [Xc, Y c, Zc]T denotes a point in the camera frame that is related to the corresponding point [Xw, Y w, Zw]T in the world reference frame by P c = RP w + t, with (R, t) being the rotation matrix and the translation vector. In camera calibration, lens distortion is very important for accurate 3-D measurement [1]. The lens distortion introduces certain amount of nonlinear distortions, denoted by a function F in Fig. 1, to the true image. The observed distorted image thus needs to go through the inverse function F −1 to output the corrected image. That is, the goal of lens undistortion, or image correction, is to achieve an overall one-to-one mapping. Among various nonlinear distortions, the radial distortion, which is along the radial direction from the center of distortion, is the most severe part [2], [3]. The removal or alleviation of radial distortion is commonly performed by ﬁrst applying a parametric radial distortion model, estimating the distortion coeﬃcients, and then correcting the distortion. Most of the existing works on the radial distortion models can be traced back to an early study in photogrammetry [4], where the radial distortion is governed by the following polynomial equation [4], [5], [6], [7]: rd = r + δr = r f(r, k) = r (1 + k1r2 + k2r4 + k3r6 + · · ·), (2) All correspondence should be addressed to Dr. YangQuan Chen. Tel.: 1(435)797-0148, Fax: 1(435)797-3054, Email: yqchen@.ece.usu .edu. CSOIS URL: http://www.csois.usu.edu/  2         True Image  Camera Distortion F  Undistortion F-1  Observed Image Corrected Image Fig. 1 Lens distortion and undistortion. which is equivalent to xd = x f(r, k), yd = y f(r, k), (3) where k = [k1, k2, k3, . . .] is a vector of distortion coeﬃcients. For cameras whose distortion is not perfectly radially symmetric around the center of distortion (which is assumed to be at the principal point in our discussion), radial distortion modeling will not be accurate enough for',\n",
       " '1810.00434': 'We consider the task of detecting objects in a video. Video is an important data source for real-world vision tasks such as surveillance analysis and autonomous driving. Such tasks require detecting objects in an accurate and efﬁcient manner. Processing video data is compute-intensive. A $50 camera can generate 1080p video stream at 25fps, while a $1000 Maxwell Titan X with SSD512 algorithm can only detect objects at 19 fps (Liu et al., 2016a). One approach to reducing the computational workload of video processing is to exploit the temporal and spatial locality of video: treating it as a sequence rather than running detection on each image separately. For most videos, the same object appears in adjacent frames(temporal locality) and in the nearby locations(spatial locality). We can therefore exploit this property to make object detection more efﬁcient. We propose CaTDet (Cascaded Tracking Detector), a computation-saving framework for video detection that incorporates the tracker into a cascaded system. It is designed for but not limited to moving-camera delay-sensitive scenarios, e.g., autonomous driving. As shown in Figure 1, CaTDet is a detector cascade with temporal feedback. The tracker and the inexpensive proposal network extract the interesting regions in an image, which reduces the workload on the expensive reﬁnement network. 1Stanford University 2Nvidia Corporation. Correspondence to: Huizi Mao <huizimao@stanford.edu>, William J. Dally <dally@stanford.edu>. For single-image object detection algorithms, various metrics such as Average Precision (Everingham et al., 2010) have been proposed to measure the detection quality. These metrics do not account for the temporal characteristics of a video. For many real-world video applications such as autonomous driving, the metric that matters is delay, the time from when an object ﬁrst appears in a video to when it is detected. Our contribution in this work is two-fold: the delay metric for object detection in video and CaTDet, a detection system to efﬁciently detect objects with the aid of temporal information. We evaluate CaTDet on KITTI (Geiger et al., 2012) and CityPersons (Zhang et al., 2017a) datasets, with both the traditional mAP metric and the new delay metric. The results show that CaTDet is able to achieve 5.1-8.7x speed-up with no loss of mAP and only a small increase in delay. 2 RELATED WORK Object detection from video. Others have also exploited the temporal properties of video to improve object detection. T-CNN (Kang et al., 2016) regularizes detection results with tracking output. In Detect and Track (Feichtenhofer et al., 2017), an end-to-end architecture is proposed which incorporates detection and tracking to improve accuracy. Both methods require future frames to predict current frame, therefore they are non-causal. Deep feature ﬂow (Zhu et al., 2017c) exploits temporal redundancy between neighboring frames by estimating optical ﬂow with FlowNet (Ilg et al., 2017). It achieves high speed-ups by skipping feature extraction for non-key frames. Flow-guided feature aggregation (Zhu et al., 2017b), on the other hand, tries to improve',\n",
       " '1608.08940': 'The main objective of word embeddings is to form a vector space of words that makes “sense”. Usually, this means that semantically similar words are together. One use for these language models is to estimate the probability of an n-gram being correct. [1] suggested that word embeddings can also be used to create reverse-dictionaries, in which one writes the deﬁnition of a word and the algorithm suggests a concept that ﬁts the deﬁnition. Even more, it is possible to create bilingual reverse dictionaries which can be quite useful in translation tasks. In recent works, several interesting properties of the resulting vector spaces were found [2]. There are many other applications of word embeddings [3] which make the topic a very active area of research in NLP. One way to create word embeddings is by using the bag of words (BOW) model where the word co-occurrence matrix is calculated. In this matrix, each row represents a unique word so that the i,j-element is the amount of times word j has co-occurred with word i. This matrix can become huge in the order of millions by millions, making its use diﬃcult in any application. As a result, modern models (GloVe [3], Word2Vec [4] learn to represent words with a ﬁxed reduced dimensionality. arXiv:1608.08940v1  [cs.CL]  31 Aug 2016  2 A simple technique for dimensionality reduction is Feature Hashing [5], also known as the hashing trick. The idea is to apply a hashing function to each feature of a high dimensional vector to determine a new dimension for the feature in a reduced space. Feature hashing has been used successfully to reduce the dimensionality of the BOW model for texts [5]. [6] used feature hashing to classify mail as spam or ham. To mitigate the eﬀect of collisions in the resulting vectors [7] proposes the use of a second hash function ξ that determines the sign of a feature. It has been shown that Feature Hashing preserves the inner product between vectors and the error can be bounded. This is explained using the JohnsonLindenstrauss lemma [8] [9] and showing that feature hashing is a particular case of a J-L projection where the projection matrix has exactly one +1 or −1 in each row. Because of this, if we apply the hashing trick to the word co-occurrence matrix we are able to obtain an embedding where the inner products between the embedded vectors accurately represent the inner products between the original vectors in the co-occurrence matrix. Our experiments conﬁrm that the distortion between using the full vectors and this embedding is minimal. This means that vectors that are close in the original matrix will also be close in the embedded space. Interestingly, embeddings can be constructed without the need of computing the word full-size matrix. This makes the algorithm eﬃcient, as memory consumption is reduced from O(n2) to O(n × k), where n is the size of the corpus in words and k is a ﬁxed dimensionality that can be small (in the order of',\n",
       " '1606.04695': 'Using reinforcement learning to train neural network controllers has recently led to rapid progress on a number of challenging control tasks [15, 17, 26]. Much of the success of these methods has been attributed to the ability of neural networks to learn useful abstractions or representations of the stream of observations, allowing the agents to generalize between similar states. Notably, these agents do not exploit another type of structure – the one present in the space of controls or policies. Indeed, not all sequences of low-level controls lead to interesting high-level behaviour and an agent that can automatically discover useful macro-actions should be capable of more efﬁcient exploration and learning. The discovery of such temporal abstractions has been a long-standing problem in both reinforcement learning and sequence prediction in general, yet no truly scalable and successful architectures exist. We propose a new deep recurrent neural network architecture, dubbed STRategic Attentive Writer (STRAW), that is capable of learning macro-actions in a reinforcement learning setting. Unlike the vast majority of reinforcement learning approaches [15, 17, 26], which output a single action after each observation, STRAW maintains a multi-step action plan. STRAW periodically updates the plan based on observations and commits to the plan between the replanning decision points. The replanning decisions as well as the commonly occurring sequences of actions, i.e. macro-actions, are learned from rewards. To encourage exploration with macro-actions we introduce a noisy communication channel between a feature extractor (e.g. convolutional neural network) and the planning modules, taking inspiration from recent developments in variational auto-encoders [10, 13, 24]. Injecting noise 29th Conference on Neural Information Processing Systems (NIPS 2016), Barcelona, Spain. arXiv:1606.04695v1  [cs.AI]  15 Jun 2016  at this level of the network generates randomness in plans updates that cover multiple time steps and thereby creates the desired effect. Our proposed architecture is a step towards more natural decision making, wherein one observation can generate a whole sequence of outputs if it is informative enough. This provides several important beneﬁts. First and foremost, it facilitates structured exploration in reinforcement learning – as the network learns meaningful action patterns it can use them to make longer exploratory steps in the state space [4]. Second, since the model does not need to process observations while it is committed its action plan, it learns to allocate computation to key moments thereby freeing up resources when the plan is being followed. Additionally, the acquisition of macro-actions can aid transfer and generalization to other related problems in the same domain (assuming that other problems from the domain share similar structure in terms of action-effects). We evaluate STRAW on a subset of Atari games that require longer term planning and show that it leads to substantial improvements in scores. We also demonstrate the generality of the STRAW architecture by training it on a text prediction task and show that it learns to use frequent n-grams as the macro-actions on this task. The following section reviews the related work. Section 3 deﬁnes the STRAW model formally',\n",
       " '1810.11730': 'The hallmark of learning new concepts from very few examples characterizes human intelligence. Though constantly pushing limits forward in various visual tasks, current deep learning approaches struggle in cases when abundant training data is impractical to gather. A straightforward idea to learn new concepts is to ﬁne-tune a model pre-trained on base categories, using limited data from another set of novel categories. However, this usually leads to catastrophic forgetting [1], i.e., ﬁne-tuning makes the model over-ﬁtting on novel classes, and agnostic to the majority of base classes [2, 3], deteriorating overall performance. One way to address this problem is to augment data for novel classes. Since generating images could be both unnecessary [4] and impractical [5] on large datasets, feature augmentation [6, 7] is more preferable in this scenario. Building upon learned representations [8, 9, 10], recently two variants of generative models show the promising capability of learning variation modes from base classes to imagine the missing pattern of novel classes. Hariharan et al. proposed Feature Hallucination (FH) [11], which can learn a ﬁnite set of transformation mappings between examples in each base category and directly apply them to seed novel points for extra data. However, since mappings are enumerable (even in large amount), this model suffers from poor generalization. To address this issue, Wang et al. [12] proposed Feature Imagination (FI), a meta-learning based generation framework that can train an agent to synthesize extra data given a speciﬁc task. They circumvented the demand for latent distribution of novel classes by end-to-end optimization. But the generation results usually collapse into certain modes. Finally, it should be noted that both works erroneously assume that intra-class variances of base classes are shareable with any novel classes. For example, the visual variability of the concept lemon cannot be generalized to other irrelevant categories such as raccoon. 32nd Conference on Neural Information Processing Systems (NeurIPS 2018), Montréal, Canada. arXiv:1810.11730v3  [cs.LG]  13 Dec 2018  Base set Novel set \\uf8f1 \\uf8f4 \\uf8f4 \\uf8f4 \\uf8f4 \\uf8f4 \\uf8f4 \\uf8f4 \\uf8f4 \\uf8f4 \\uf8f4 \\uf8f2 \\uf8f4 \\uf8f4 \\uf8f4 \\uf8f4 \\uf8f4 \\uf8f4 \\uf8f4 \\uf8f4 \\uf8f4 \\uf8f4 \\uf8f3 Figure 1: Conceptual illustration of our method. Given an example from a novel class, we translate examples from related base classes into the target class for augmentation. Image by [13]. In this work, we propose a new approach to addressing the problem of low-shot learning by enabling better feature augmentation beyond current limits. Our approaches are novel in two aspects: modeling and training strategy. We propose Covariance-Preserving Adversarial Augmentation Networks (CP-AAN), a new class of Generative Adversarial Networks (GAN) [14, 15] for feature augmentation. We take inspiration from unpaired image-to-image translation [16, 17] and formulate our feature augmentation problem as an imbalanced set-toset translation problem where the conditional distribution of examples of each novel class can be conceptually expressed as a mixture of related base classes. We ﬁrst extract all related base-novel class pairs by an intuitive yet effective approach called Neighborhood Batch Sampling. Then, our model aims to learn the',\n",
       " '1901.06486': 'R ECOGNITION of human affect is a very important aspect of human communication. We not only convey messages by their literal meaning, but also by how they are expressed and other forms of non-verbal communication. This includes cues like tone of voice, gesture, facial expression, or even more subtle elements such as body temperature and heart rate [1], [2]. Many of the main affect characteristics are universal across different languages and cultures. This motivates the creation of universal models. It is becoming increasingly important for machines to be able to recognize various forms of human affect. An affect recognition model should be universally applicable, not just in speciﬁc domains and languages. This will help us develop more advanced interactive systems [3], [4] that D. Bertero is with the Human Language Technology Center, Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, Clear Water Bay, Hong Kong (e-mail: dbertero@connect.ust.hk). O. Kampman is with the Human Language Technology Center, Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, Clear Water Bay, Hong Kong (e-mail: opkampman@connect.ust.hk). P. Fung is with the Human Language Technology Center, Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, Clear Water Bay, Hong Kong (e-mail: pascale@ece.ust.hk). Manuscript received - are able to detect and use affect, in addition to standard ASR and NLP techniques, to provide advanced services such as personality analysis, counseling, education, medical, or commercial services. We focus on affect recognition from audio and speech in this work through two universal affect characteristics retrievable from speech, namely emotion and personality. In the ﬁeld of emotion detection, there is no general agreement on the number of basic emotion descriptors [5]. It ranges from three (Anger, Happiness and Sadness, with the eventual inclusion of the Neutral class) to up to 20 for some commercial services. Each available corpus includes a different set of emotions. These emotions are often projected onto a plane formed by two main axes: Valence and Arousal [6]. This way the classiﬁcation task is reduced to the prediction of these two scores and the identiﬁcation of a point on the plane. This greatly simpliﬁes the classiﬁcation process and training procedure, but it is less natural for humans to understand and interpret the meaning of Valence and Arousal compared to discrete emotions labels. Furthermore, it poses difﬁculties and uncertainties in the annotation process. Various emotion types are usually obtained through clustering the plane. For these reasons, and to provide more detailed analysis on each emotion, we decided to perform classiﬁcation on discrete emotion values in our work described in this paper. For personality recognition a standard set of descriptors are ﬁve personality traits from the Big Five model [7]. Traits are patterns in thought and behavior. An individual scores between 0 (low) and 1 (high) for each trait. Thus, an individual’s persona',\n",
       " '1206.4646': 'FAILED',\n",
       " '1701.07405': 'Many emerging mobile applications, such as mobile gaming and augmented reality, are delay sensitive and have resulted in an increasingly high computing demand that frequently exceeds what mobile devices can deliver. Although cloud computing enables convenient access to a centralized pool of conﬁgurable computing resources, moving all the distributed data and computingintensive applications to clouds (which are often physically located in remote mega-scale data centers) is simply out of the question, since it would not only pose an extremely heavy burden on today’s already-congested backbone networks but also result in (sometimes intolerable) large transmission latencies that degrade the quality of service. Mobile edge computing (MEC) (a.k.a.  2 workload offloading local processing mobile device base station & edge server evice cloud server Fig. 1. Scenario of multi-cell MEC fog computing) thus has recently emerged as a remedy to the above limitations, which enables processing of (some) workloads locally at the network edge without moving them to the cloud [1] [2]. In MEC, network edge devices, such as base stations (BSs), access points and routers, are endowed with, albeit limited, computing and storage capabilities to serve users’ requests as a substitute of clouds, while signiﬁcantly reducing the transmission latency as they are placed in the proximity of end users. Although MEC promises enormous beneﬁts, designing energy efﬁcient (green) cellular networks faces signiﬁcant new challenges. To accommodate the continuously growing demand for ubiquitous information access, BSs are becoming increasingly densely deployed. As a result, the energy consumption of BSs becomes a major portion (60% - 80%) of the whole cellular network energy consumption [3], which is already one of the leading sources of the global carbon dioxide emissions. As one of the most popular and efﬁcient energy saving schemes, BS sleeping has been proposed and widely studied to realize substantial energy saving in cellular networks [4] [5] [6]. However, integrating MEC with BSs signiﬁcantly complicates the energy saving issue due to the fact that BSs now provide not only radio access services but also computing services. First, since computing resources on BSs are limited, ofﬂoading some workload to the remote cloud is inevitable. As a result, the workload ofﬂoading decisions and the sleeping decisions have to be jointly considered for each BS. Second, the long-term energy consumption couples the ofﬂoading and BS sleeping decisions over time, and yet the decisions have to be made without foreseeing the future system dynamics (workload, wireless channel conditions etc.). Third, dense cellular networks create a complex multi-cell environment where the workload demand, radio resources and computing resources are highly coupled in both the spatial and the temporal domains. Effective resource management requires careful coordination among all BSs in the network, and decentralized solutions are much favored in order to reduce complexity.  3 In this paper, we study the joint management of radio resources and computing resources in dense cellular networks with MEC integration in order to maximize the quality of service for users while keeping the energy consumption',\n",
       " '1807.10744': 'Visual search is a vital ability in animals for ﬁnding food and avoiding predators, and in humans it is used in everyday life and for tasks such as natural disaster monitoring, inspections or medical image representation (Eckstein 2011; Tsotsos 1990). Unfortunately, machines do not yet achieve a level of performance that matches the ability of humans in the majority of these visual search tasks, due to the diﬃculty of replicating the cognitive processes involved (Tsotsos 1990; Wolfe 2007). This, in particular, is true in applications such arXiv:1807.10744v1  [cs.RO]  27 Jul 2018  2 Amir Rasouli et al. as ﬁnding an object in unknown environments (Lanillos 2013). Here, although a brute-force approach can solve the problem, without the use of attentive processes, the process can be very time consuming and ineﬃcient. Attention plays an important role in managing the vast amount of information that is provided by the sensors. Therefore, it is important to incorporate, in a meaningful way, an attention model into the machine visual system to make informed decisions during an active overt visual search. According to Stone (Stone 1975), omitting the useful information provided by the visual sensors is similar to searching for an object with eyes closed. Although the object will eventually be found, the process can be very slow. In the context of visual search, visual stimuli are a valuable source of information regarding the object’s whereabouts and should be actively used during the visual search. An illustrative example of searching for an object using its color property is as follows: if the robot is looking for a red can (Fig. 1), it would be unproductive to search in places where the objects are blue. In non-visual search, there are algorithms that couple sensory stimuli with control actions to reach a pursued location. For instance, for locating continuous odor sources, gradient driven techniques (e.g. chemotaxis) can be applied to compute the next actions. As the the source of information becomes sparse and partially observable, more exploratory strategies such as infotaxis have been shown to be viable for ﬁnding the desired location (Vergassola et al. 2007). In the infotaxis technique, the searcher chooses an action (direction) that locally maximizes the expected rate of information acquisition, such as new sources of odor. In the context of visual search, the state-of-the-art general search algorithms are more oriented towards the decision-making process (Lanillos 2013). The majority of these methods are based on simplifying the sensor model as a detection/non-detection distribution (Bourgault et al. 2003). Here, the common approach is to model the sensors as a non-detection density function that depends on the state of the robot (Ye and Tsotsos 1999; Lanillos et al. 2014a). The drawback of such strategies is that their optimal implementation for the constrained cases1 are intractable (Trummel and Weisinger 1986; Ye and Tsotsos 2001) and are only applicable',\n",
       " '1608.06417': 'Source localization is a widespread and constantly recurring research topic in the areas of signal processing and wireless communications and networking. The location information and awareness is useful in many existing and emerging wireless networking solutions such as cellular, ad-hoc, self-organizing, context5 aware and cognitive radio networks [1, 2]. The Received Signal Strength (RSS)- based localization techniques are of particular interest due to the radio hardware prerequisites, i.e. the inherent presence of RSS measurement features in every wireless device. This means that the utilization of RSS-based localization in practice only requires software upgrades, while oﬀering suﬃcient precision and 10 ﬁdelity for a wide range of applications. The generic network setup for localization comprises a set of anchors (i.e. measuring sensors) distributed over a speciﬁc area and single (or multiple) wireless transmitting source(s). In the case of RSS-based localization, the anchors, upon receiving the signal broadcasted by the source, measure the received signal 15 power. The measurements are cooperatively combined and utilized by an RSS localization algorithm that produces an estimate of the transmitting source(s) position. A common and key requirement for proper operation of the localization algorithm is the knowledge of the precise positions of the anchors. In practical 20 applications, the anchor positions are usually obtained through previous estimation procedure (such as GPS or other self-localization technique). However, the previous estimation produces erroneous anchor position estimates that cause deterioration of the source localization performance and overall network topology uncertainty. We have recently been particularly active in the area of localization 25 2  with uncertain anchor positions [3, 4, 5] and there have been also other works considering dis-calibrations and uncertainties in the anchor positions [6, 7], but under a diﬀerent system model (based on time and frequency diﬀerence of arrival). In [3] we investigate the eﬀect of anchor position uncertainty on source localization performance and prove that severe accuracy degradations can occur. 30 In [4] we propose a joint localization framework, named Source Position Estimation for Anchor position uncertainty Reduction–SPEAR, that aims to jointly estimate the unknown positions of the sources and reduce the uncertainty of the anchor positions. The joint localization framework uses non-Bayesian estimation formalism since it models the unknown positions of the sources and the 35 uncertain anchors as deterministic parameters. [4] further introduces a Joint Maximum Likelihood (JML) localization algorithm as a typical representative of the joint localization framework, investigates its performance in typical scenarios and shows signiﬁcant source localization improvements. Furthermore, it is shown that the JML can signiﬁcantly reduce the initial anchor position uncer40 tainty. Thus, the joint localization framework can be eﬃciently used as powerful network topology calibration tool. In [5], we analyze the problem of source localization in presence of anchor position uncertainty and the joint localization framework theoretically. In particular, our work presented therein introduces theoretical framework for evaluation and assessment of the performance of the 45 joint localization algorithms by deriving its fundamental lower bounds. For this',\n",
       " '1711.10331': 'Structured prediction models are often used to solve the structure dependent problems in a wide range of application domains including natural language processing, bioinformatics, speech recognition, and computer vision. To solve the structure dependent problems, many structured prediction methods have been developed. Among them Email addresses: xusun@pku.edu.cn (Xu Sun), ws@pku.edu.cn (Weiwei Sun), shumingma@pku.edu.cn (Shuming Ma), renxc@pku.edu.cn (Xuancheng Ren), zhangyi16@pku.edu.cn (Yi Zhang), cswjli@comp.polyu.edu.hk (Wenjie Li), wanghf@pku.edu.cn (Houfeng Wang) 1This work is a substantial extension of a conference paper presented at NIPS 2014 [1]. Preprint submitted to Artiﬁcial Intelligence November 29, 2017 arXiv:1711.10331v1  [cs.LG]  25 Nov 2017  the representative models are conditional random ﬁelds (CRFs), deep neural networks, and structured perceptron models. In order to capture the structural information more accurately, some recent studies emphasize on intensifying structural dependencies in structured prediction by applying long range dependencies among tags, developing long distance features or global features, and so on. From the probabilistic perspective, complex structural dependencies may lead to better modeling power. However, this is not the case for most of the structured prediction problems. It has been noticed that some recent work that tries to intensify the structural dependencies does not really beneﬁt as expected, especially for neural network models. For example, in sequence labeling tasks, a natural way to increase the complexity of the structural dependencies is to make the model predict two or more consecutive tags for a position. The new label for a word now becomes a concatenation of several consecutive tags. To correctly predict the new label, the model can be forced to learn the complex structural dependencies involved in the transition of the new label. Nonetheless, the experiments contradict the hypothesis. With the increasing number of the tags to be predicted for a position, the performance of the model deteriorates. In the majority of the tasks we tested, the performance decreases substantially. We show the results in Section 4.1.1. We argue that over-emphasis on intensive structural dependencies could be misleading. Our study suggests that complex structures are actually harmful to model accuracy. Indeed, while it is obvious that intensive structural dependencies can eﬀectively incorporate the structural information, it is less obvious that intensive structural dependencies have a drawback of increasing the generalization risk. Increasing the generalization risk means that the trained models tend to overﬁt the training data. The more complex the structures are, the more instable the training is. Thus, the training is more likely to be aﬀected by the noise in the data, which leads to overﬁtting. Formally, our theoretical analysis reveals why and with what degree the structure complexity lowers the generalization ability of the trained models. Since this type of overﬁtting is caused by the structural complexity, it can hardly be solved by ordinary regularization methods, e.g., the weight regularization methods, such as L2',\n",
       " '1812.08685': 'Recent advances in automated video and audio editing tools, generative adversarial networks (GANs), and social media allow creation and fast dissemination of high quality tampered video content. Such content already led to appearance of deliberate misinformation, coined ‘fake news’, which is impacting political landscapes of several countries [1]. A recent surge of videos, often obscene, in which a face can be swapped with someone else’s using neural networks, so called Deepfakes1, are of a great public concern2. Accessible open source software and apps for such face swapping lead to large amounts of synthetically generated Deepfake videos appearing in social media and news, posing a signiﬁcant technical challenge for detection and ﬁltering of such content. Therefore, the development of efﬁcient tools that can automatically detect these videos with swapped faces is of a paramount importance. Until recently, most of the research was focusing on advancing the face swapping technology [2], [3], [4], [5]. However, P. Korshunov and S. Marcel are at Idiap Research Institute, Martigny, Switzerland; emails: {pavel.korshunov,sebastien.marcel}@idiap.ch 1Open source: https://github.com/deepfakes/faceswap 2BBC report (Feb 3, 2018): http://www.bbc.com/news/technology-42912529 responding to the public demand to detect face swapping technology, researchers are starting to work on databases and detection methods, including image and video data [6] generated with an older face swapping approach Face2Face [7] or videos collected using Snapchat3 application [8]. In this paper, we present a ﬁrst publicly available database of videos where faces are swapped using the open source GAN-based approach4, which is developed from the original autoencoder-based Deepfake algorithm1. We manually selected 16 similar looking pairs of people from publicly available VidTIMIT database5. For each 32 subject, we trained two different models, in the paper, referred to as low quality (LQ), with 64 × 64 input/output size, and high quality (HQ), with 128×128 size, models (see Figure 1 for examples). Since there are 10 videos per person in VidTIMIT database, we generated 320 videos corresponding to each version, resulting in total 620 videos with faces swapped. For the audio, we kept the original audio track of each video, i.e., no manipulation was done to the audio channel. It is also important to understand how much of a threat Deepfake videos are to face recognition systems. Because if these systems are not fooled by Deepfakes, creating a separate system for detecting Deepfakes would not be necessary. To the vulnerability of face recognition to Deepfake videos, we evaluate two state of the art systems: based on VGG [9] and Facenet6 [10] neural networks on both untampered videos and videos with faces swapped. For detection of the Deepfakes, we ﬁrst used an audiovisual approach that detects inconsistency between visual lip movements and speech in audio [11]. It allows us to understand how well the generated Deepfakes can mimic mouth movement and whether the lips are synchronized with the speech. We also applied several baseline methods from presentation',\n",
       " '1808.01119': 'Person re-identiﬁcation (person re-id) aims to identify a speciﬁc person at distinct times and locations. It is an essential task for several applications, such as long-term person tracking across camera views (Ristani and Tomasi 2018). Re-id task is still challenging due to the appearance variations of person. These variations usually come from occlusion, illumination, and viewpoint change in camera views. Recent approaches usually treat re-id task as a retrieval problem: given a query based on a single image or a set of images, and a gallery set of candidate person images, we need to rank these candidates according to some similarity metrics. Researchers have considered two scenarios, single-shot and multi-shot, for person re-id task. A lot of previous works have focused mainly on the single-shot scenario, while only a few lie in the latter. However, multi-shot person re-id is more suitable for practical surveillance applications, since person tracklets are available by applying object detection work in progress. and tracking algorithms. In this paper, we investigate person re-id task in the multi-shot scenario. Multi-shot person re-id methods require the comparison between two sets of images. Thanks to the rapid development of deep learning techniques, recent approaches adopt convolutional neural network (CNN) to extract the appearance feature of each image, and take temporal pooling strategies to aggregate an appearance feature sequence and form a ﬁxed-size vector representation. Common temporal pooling strategies include mean and max pooling, recurrent neural network (RNN), and attention models. Finally, the dissimilarity between two vectors is calculated based on a distance function, such as the Euclidean and cosine distance. However, using a ﬁxed-size vector as the representation of a set of images, previous re-id algorithms may ignore the matching evidence between two person tracklets. For example, when the system compares the image set of identity a to the image sets of a′ and b from the gallery set, the evidence showing that a and a′ are identical, and that showing a and b are not, may come from different images in set a. Hence, instead of aggregating appearance features by conventional pooling strategies, a better way should be to represent an image set by the whole appearance feature set, and discover the alignment/attention between two sets, as shown in Figure 1. In this paper, we propose the idea of visual distributional representation and use it to solve multi-shot person re-id task. Our approach treats a set of images, or a person tracklet as samples drawn from a probability distribution in appearance feature space. Based on this concept, our multi-shot person re-id algorithm consists of three parts: an appearance feature extractor, a probability estimator, and a distributional distance function. Speciﬁcally, we choose the Wasserstein distance between distributions as the function calculating the dissimilarity between two image sets. By doing so, we can model the diversity and',\n",
       " '1705.08435': 'Connected personal devices are now widespread: they can collect and process increasingly large and sensitive user data. As a concrete example, consider the health domain. Smart watches can record cardiac activities, mobile apps encourage users to participate to studies (about depression, concussion, etc.),1 and recent painless sensors can replace a ﬁnger prick for blood glucose testing (Cappon et al., 2017). Such information can be leveraged through machine learning to provide useful personalized services (e.g., personalized treatments) to the user/patient. A common practice is to centralize data from all devices on an external server for batch processing, sometimes without explicit consent from users and with little oversight. While this data concentration is ideal for the utility of the learning process, it raises serious privacy concerns and opens the door to potential misuse (e.g., exploitation for the purpose of recruitment, insurance pricing or granting loans). Therefore, in applications where the data is considered too sensitive to be shared (due to legislation or because the user opts out), one has to learn on each device separately without taking advantage of the multiplicity of data sources (e.g., information from similar users). This preserves privacy but leads to poor accuracy, in particular for new or moderately active users who have not collected much data. Instead of the above two extreme approaches, our goal is to design a solution allowing a large number of users (agents) to collaborate so as to learn more accurate personalized models while ensuring that their data stay on their local device and that the algorithm does not leak sensitive information to others. We consider a fully decentralized solution where agents operate asynchronously and communicate over a network in a peer-to-peer fashion, without any central entity to maintain a global state of the system or even to coordinate the protocol. The network acts as a communication network but also models similarities between users. While a decentralized architecture may be the only available option in some applications (e.g., IoT), it also provides interesting beneﬁts when a more traditional distributed (master/slave) architecture could be ∗first.last@inria.fr †first.last@epfl.ch 1See e.g., https://www.apple.com/researchkit/ 1 arXiv:1705.08435v2  [cs.LG]  19 Feb 2018  used. In particular, peer-to-peer algorithms provide scalability-by-design to large sets of devices thanks to the locality of their updates (Kermarrec and Taïani, 2015). For instance, it was recently shown that fully decentralized learning algorithms can perform better than their distributed counterparts because they avoid a communication bottleneck at the master node (Lian et al., 2017). Finally, a decentralized architecture intrinsically provides some security guarantees as it becomes much more diﬃcult for any party (or any external adversary) to observe the full state of the system. The problem of decentralized collaborative learning of personal models has been recently considered by Vanhaesebrouck et al. (2017), but they did not consider any privacy constraints. In fact, while there has been a large body of work',\n",
       " '1609.09226': 'W ITH the rapid growth of social media, such as Facebook, Twitter, and Sina Weibo, people are sharing information and expressing their attitudes publicly. Social media brings great convenience to users, and information can be spread rapidly and widely nowadays. However, rumors can also be spread on the Internet more easily. A rumor is an unveriﬁed and instrumentally relevant statement of information spreading among people [5]. Rumors bring signiﬁcant harm to daily life, social harmony, or even public security. With the growth of the Internet and social media, such harm will also grow greater. For instance, as the loss of MH370 has drawn worldwide attention, a great amount of rumors has spread on social media, e.g., MH370 has landed in China,1 the The authors are with the Center for Research on Intelligent Perception and Computing (CRIPAC), National Laboratory of Pattern Recognition (NLPR), Institute of Automation, Chinese Academy of Sciences (CASIA) and the University of Chinese Academy of Sciences (UCAS), Beijing, 100190, China. E-mail: {qiang.liu, shu.wu, feng.yu, wangliang, tnt}@nlpr.ia.ac.cn. 1http://www.ﬁreandreamitchell.com/2014/03/07/rumor-malaysia-airlinesmh370-landed-china/ loss of MH370 is caused by terrorists,2 and Russian jets are related to the loss of MH370.3 These rumors about MH370 mislead public attitudes to a wrong direction and delay the search of MH370. Up to October 10, 2015, on the biggest Chinese microblog website Sina Weibo,4 28,454 rumors have been reported and collected in its misinformation management center.5 Accordingly, it is crucial to evaluate information credibility and to detect rumors on social media. To automatically evaluate information credibility on social media, some methods have been recently proposed. Existing methods are mainly based on feature engineering, i.e., methods with handcrafted features. Most of them are based on content information and the source credibility at the microblog level [3][27][10] or event (containing a group of microblogs) level [16][42][22]. Some studies investigate the aggregation of credibility from the microblog level to the event level [14]. On the contrary, considering dynamic information, some work designs temporal features based on the prorogation properties over time [16] or trains a model with features generated from different time periods [22]. Moreover, some methods take usage of users’ feedbacks (comments and attitudes) to evaluate the credibility [8][29][42]. For instance, the Enquiry Post (EP) model [42] takes out signal tweets, which indicates users’ suspicious attitudes for detecting rumors and achieves satisfactory performance. It should be mentioned that the above methods have several limitations in evaluating information credibility on social media. First, methods based on feature engineering usually require great labor for designing features [3]. Secondly, a rough mergence resting on the statistical summation of different feature values is not competent to model complex interactions among them. For instance, there are two combinations: (1) a user with a high credibility posted a microblog and a user with low credibility reposted a microblog',\n",
       " '1503.01445': 'Throughout their lives people are exposed to a sheer endless variety of chemical compounds, many of which are potentially dangerous. Determining the toxicity of a chemical is of crucial importance in order to minimize our exposure to harmful substances in every day products. Toxicity is also a central issue in the development of new drugs, with more than 30 % of drug candidates failing in clinical trials because of undetected toxic effects (Kola & Landis, 2004; Arrowsmith, 2011). In 2008, the U. S. National Institutes of Health (NIH) and the U. S. Environmental Protection Agency (EPA), agreed on collaborating on future toxicity testing activities (Committee on Toxicity Testing and Assessment of Environmental Agents, National Research Council, 2007). Their efforts were later joined by the U. S. Food and Drug Administration (FDA) under the umbrella of the Tox21 Program. The program’s stated goals are to develop better toxicity assessment methods, as current methods are not likely to scale with the increased demand for effective toxicity testing. Current methods for testing the toxicity of a high number of chemicals rely on High-Throughput Screening (HTS). HTS experiments can investigate whether a chemical compound at a given concentration exhibits a certain type of toxicity, for a number of different compounds in parallel. These experiments are repeated with varying concentrations of the chemical compound, which allows to determine doseresponse curves (Inglese et al., 2006). From these curves one can reliably determine whether a compound activated a given pathway or receptor, inhibited it or did not interact at all. Conducting these HTS experiments is a timeand costintensive process. Typically, a compound has to be tested for several types of toxicity at different concentration levels. Thus, the whole procedure has to be rerun for many times for each compound. Usually, a cell line has to be cultivated to obtain a single data point. Even an unprecedented multi-million-dollar effort, the Tox21 project, could test only a few thousands of compounds for as few as twelve toxic effects. Therefore, accurate computational methods for accurate prediction of toxic effects are highly demanded. arXiv:1503.01445v1  [stat.ML]  4 Mar 2015  Toxicity Prediction using Deep Learning Existing computational approaches can be grouped into structureand ligand-based. The structure-based methods simulate physical interactions between the compound and a biomolecular target (Kitchen et al., 2004) but are only applicable if the complete 3D structure of all interacting molecules are known, and they are infeasible for larger compound data bases. Ligand-based approaches predict the interactions based on previous measurements (Jenkins et al., 2007). Previous machine learning efforts were almost always ligand-based, such as scoring approaches like the Naive Bayes statistics (Xia et al., 2004; Nigsch et al., 2008; Mussa et al., 2013), density estimation (R. et al., 2012; Harper et al., 2001), nearest neighbor, support vector machines, and shallow feed forward neural networks (Byvatov et al., 2003; Lowe et al., 2011). In 2012, the Merck Kaggle',\n",
       " '0904.1840': 'This paper provides a uniﬁed framework, high-dimensional consensus (HDC), for the analysis and design of linear distributed algorithms for large-scale networks–including distributed Jacobi algorithm [1], average-consensus [2], [3], [4], [5], [6], [7], distributed sensor localization [8], distributed matrix inversion [9], or leader-follower algorithms [10], [11]. These applications arise in many resource constrained largescale networks, e.g., sensor networks, teams of robotic platforms, but also in cyber-physical systems like the smart grid in electric power systems. We view these systems as a collection of nodes interacting over a sparse communication graph. The nodes have, in general, strict constraints on their communication and computation budget so that only local communication and low-order computation is feasible at each node. Linear distributed algorithms for constrained large-scale networks are iterative in nature; the information is fused over the iterations of the algorithm across the sparse network. In our formulation of HDC, we view the large-scale network as a graph with edges connecting sparsely a collection of nodes; each node is described by a state. The nodes are partitioned in anchors and sensors. Anchors do not update their state over the HDC iterations, while the sensors iteratively update their states by a linear, possibly convex, combination of their neighboring sensors’ states. The weights of this linear combination are the parameters of the HDC. For example, in sensor localization [8], the state at each node is its current position estimate. Anchors may be nodes instrumented with a GPS unit, knowing its precise location and the remaining nodes are the sensors that don’t know their location and for which HDC iteratively updates their state, i.e., their location, in a distributed fashion. The weights of HDC are for this problem the barycentric coordinates of the sensors with respect to a group of neighboring nodes, see [8]. We consider two main issues in HDC. Analysis: Forward Problem Given the HDC weights or parameters and the sparse underlying connectivity graph determine (i) under what conditions does the HDC converge; (ii) to what state does the HDC converge; and (iii) what is the convergence rate. The forward problem establishes the conditions for convergence, the convergence rate, and the convergent state of the network. Learning: Inverse Problem Given the desired state to which HDC should converge and the sparsity graph learn the HDC parameters so that indeed HDC does converge to that state. Due to the sparsity constraints, it may not be possible for HDC to converge exactly to the desired state. An interesting tradeoff that we pursue is between the speed of convergence and the quality of the limiting HDC converging state, given by some measure of the error between the ﬁnal state and the desired state. Clearly, the learning problem is an inverse problem that we will formulate as the minimization of a utility function under November 1, 2018 DRAFT  3 constraints. A na',\n",
       " '1605.04598': 'For many important multiterminal information theory problems, including those arising in network coding, distributed storage, and secret sharing, using a computer to perform an arbitrary achievability proof requires one to know an algorithm to determine if there exists an almost entropic polymatroid satisfying certain constraints on its rank function. Finding such an algorithm is a fundamental open problem in information theory, also known as the problem of characterization of the closure of the region of entropic vectors (Γ∗ N). We consider a special case of this very difﬁcult problem, which we call the Constrained Linear Representability Problem (CLRP) for polymatroids. We show that the ability to solve CLRP can automate the achievability proofs that one encounters while determining the performance of linear codes in multi-source multi-sink network coding over directed acyclic hypergraphs and in secret sharing and while proving new linear rank inequalities. Traditionally, the achievability constructions in proofs for these problems are performed manually, which makes them tedious and time consuming. A computer program to solve CLRP, at least for small and moderate instances, enables one, in turn, to pursue a computational agenda for approaching problems like network coding and secret sharing, which have proven difﬁcult to solve in general. This involves solving small instances of these problems to build large and exhaustive databases of solved instances which can then be analyzed to ﬁnd patterns and structure that allow one to make much more general statements about these problems [12], [15], [16]. All of these tasks would be impossible without the use of a computer due to sheer number of man hours required. This article develops and describes a method for solving constrained linear representability problems built from group theoretic techniques for combinatorial generation. More precisely, in section II, after reviewing the deﬁnition of the region of entropic vectors and its linear polymatroid inner bound, we deﬁne two variants of CLRP, one existential and one enumerative. Then, Section III shows in detail how the problems of calculating achievability proofs for fundamental limits for network coding rate regions and secret sharing can be viewed as instances of these CLRPs. Section IV then deﬁnes key concepts Support under National Science Foundation awards CCF-1016588 and CCF-1421828 is gratefully acknowledged. Jayant Apte and John MacLaren Walsh are with the Department of Electrical and Computer Engineering, Drexel University, Philadelphia, PA, USA (email: jsa46@drexel.edu, and jwalsh@coe.drexel.edu). Preliminary ideas related to this work were presented at ISIT 2014 [3]. arXiv:1605.04598v2  [cs.IT]  1 Feb 2017  1 and terminology which enable techniques developed for combinatorial generation to be applied to CLRP, explaining along the way key decisions enabling CLRP to be solved in an efﬁcient manner that can exploit problem symmetry and handle isomorphism. Building upon these ideas, section V presents the developed algorithm for solving CLRP, which is also implemented as a GAP package the Information Theoretic Achievability Prover– ITAP, the ﬁrst of its kind, accompanying the article. Finally, Section VI describes several quantities playing',\n",
       " '1608.08852': '1.1. Motivation: Feature Selection from Proteomics-Based Data Let us start with a classical problem situation from learning theory. Suppose we are given a collection of samples (s1, y1), . . . , (sm, ym) ∈Rp × {−1, +1} which are independently drawn from a random pair (S, Y) with unknown joint probability distribution on Rp × {−1, +1}. Here, the random vector S typically models a set of signal variables (or data variables), whereas the binary label Y assigns this data to a certain class-of-interest, which is either −1 or +1 in our case. A major challenge of supervised machine learning is then to ﬁnd an accurate predictor ˆF: Rp →{−1, +1} of this classiﬁcation procedure, such that ˆY := ˆF(S) coincides with the true variable Y, at least “with high probability.” In a very simple example scenario, we may assume that the observed labels can be described by a linear classiﬁcation model of the form1 yi = sign(⟨si, z0⟩), i = 1, . . . , m, (1.1) where z0 ∈Rp is an unknown signal vector (or parameter vector). The ultimate goal would be now to learn an estimator ˆz ∈Rp of z0, by merely using a small set of training pairs {(si, yi)}1≤i≤m. A good approximation of the true signal vector z0 would not only provide a reliable predictor ˆF(S) = sign(⟨S, ˆz⟩), but in fact, its non-zero entries supp( ˆz) = #{j | ˆzj ̸= 0} would even indicate which variables of the data S are (strongly) correlated with the associated class Y. Such a statement is of course much stronger than just correctly predicting the class label because in that way, we are able to understand the underlying observation process. The main focus of this work will be precisely on this type of problem, which is usually referred to as the task of feature selection, variable selection, or feature extraction in statistical learning theory. 1This is the same as assuming that Y = sign(⟨S, z0⟩) because each sample (si, yi) can be seen as an independent realization of (S, Y). But in this paper, we shall prefer the “sample notation” of (1.1), which seems to be more natural and convenient for our purposes. 1 arXiv:1608.08852v1  [stat.ML]  31 Aug 2016  2 1. INTRODUCTION Before continuing with the general problem issue, let us illustrate the above setup by a speciﬁc realworld example: The medical research of the last decades has shown that the early diagnosis of tumor diseases, such as cancer, can be signiﬁcantly improved by extracting new biomarkers from proteomics data. In this context, each sample pair (si, yi) ∈Rp × {−1, +1} corresponds to an individual proband of a clinical study. The class label yi simply speciﬁes whether the i-th test person suffers from a certain disease (yi = −1) or not (yi = +1), whereas each single entry (variable) of the data si = (si,1, . . . , si,p) contains the molecular concentration of a particular protein structure in the human body. In this sense, si represents',\n",
       " '1603.08318': 'Classiﬁcation is a major task in the ﬁelds of machine learning and pattern recognition. In binary classiﬁcation, a hypothesis is constructed from a feasible hypothesis space based on the training set {(xi, yi)}N i=1, where {xi}N i=1 is a set of data points with xi ∈Rd sampled i.i.d. under a distribution from an input subspace, and {yi}N i=1 with yi ∈{−1, +1} are their corresponding labels. The obtained hypothesis, also known as classiﬁer, is “good” when it is able to generalize well the “knowledge” learned from the training data to unseen instances. Multiple-class cases can be analogously accomplished by a group of binary classiﬁers [1]. Arguably, among existing classiﬁers, Support Vector Machine (SVM) [2][3] is the most popular one due to its promising performance. In general, the primal SVM can be modeled as follows: argmin {w,b} Ψ(w) + λ N X i=1 f(yi, φ(xi)T w + b), (1) where f(·) is a penalty function, Ψ(w) performs as a regularizer on the learner w and b is the bias. The function φ(·) is to map xi from the original D-dimensional feature space to a new Mdimensional one. Moreover, λ is a non-negative coefﬁcient that provides a trade-off between the loss term and the regularizer. If SVM adopts the hinge loss as penalty, the above (1) turns out to be: argmin {w,b} Ψ(w) + λ N X i=1 \\x001 −(φ(xi)T w + b)yi \\x01p +, (2) where the operator (u)+ := max(u, 0) keeps the input scalar u unchanged if u is non-negative, returns zero otherwise, the extension of which to vectors and matrices is simply applied elementwise. Furthermore, p is a constant typically in the range [1, 2] for being meaningful. In practice, p is often selected to be either 1 or 2 for ease of computation, which correspond to ℓ1-norm and ℓ2-norm loss primal SVMs, respectively. As for the regularization term, Ψ(w) := 1 2∥w∥2 2 (ℓ2 regularizer) and Ψ(w) := ∥w∥1 (ℓ1 regularizer) are two classical options. 1  As has been well recognized, a combination of various classiﬁers can improve predictions. Ensemble approaches, with Boosting [4] and Bagging [5] as representatives, make use of this recognition and achieve strong generalization performance. The generalization error of ensemble mainly depends on two factors, formally expressed as E = ¯E −¯A, where E is the mean-square error of the ensemble, ¯E represents the average mean-square error of component learners and ¯A stands for the average difference (diversity) between the ensemble and the components. Error-Ambiguity decomposition [6], Bias-Variance-Covariance decomposition [7] and Strength-Correlation decomposition [8] all conﬁrm the above principle. This indicates that jointly minimizing the training error and maximizing the diversity of base learners is key to the ensemble performance. Considering the popularity of SVM and the potential of ensemble, it would be',\n",
       " '1604.06743': 'In general we desire recommender systems that can quickly start providing good recommendations for new users, which is particularly challenging as no prior information for new users is available. This is often known as the cold-start problem. Despite the lack of prior information for new users, such systems typically have interacted with millions of previous users. Therefore, this problem can be cast as an instance of lifelong learning across sequential decision making tasks: how should information from prior users be leveraged to help improve the recommendations for a new user? Standard techniques like collaborative ﬁltering [Koren et al., 2009] provide good answers to this challenge, but such approaches are typically limited to myopically providing a single recommendation, rather than reasoning about the multi-step interactions the system may have with the user. This is important, because across a sequence of interactions it may be useful for the system to actively gather information (potentially sacriﬁce immediate performance outcomes) in order to maximize its beneﬁt over the longer run with the individual in question. One approach to this is to model users by a contextual bandit model [Bubeck, 2012; Zhou, 2015] with a single shared set of model parameters, and all prior users’ data can be leveraged to ﬁt those model parameters for use in interacting with a new user. Example algorithms are LinUCB [Li et al., 2010], Thompson sampling with linear payoffs [Agrawal and Goyal, 2013], and CoﬁneUCB [Yue et al., 2012]. However, these approaches work well only when there are many available features that describe users and capture user variability. If those features are not available, then we may need to fall back on a population average that may make poor recommendations for the current new individual. At the other extreme is to use learning algorithms such as LinUCB and Thompson sampling with linear payoffs to learn from scratch for each new user separately. Such systems can provide full personalization to an individual (using model parameters learned only for that user), but may take an enormous amount of interactions to achieve this, yielding very little value for a long period (and potentially causing the user to get frustrated or cease using the system). We instead propose an approach that provides partial personalization. We assume that users can be described as each belonging to one of a ﬁnite set of latent classes. Each class may be associated with a different set of model parameters, but within a class all individuals share the same parameters. Compared with the two extreme approaches mentioned above, partial personalization does not fully rely on user features to capture user variability, instead it leverages users’ latent class structure to more quickly start providing good recommendations for new users. Latent class structure has been explored in the noncontextual Multi-armed bandits setting [Lazaric et al., 2013; Maillard and Mannor, 2014]. In the contextual setting, the most closely related',\n",
       " '1606.06900': 'Consider the task of learning to answer complex natural language questions (e.g., “Where did the last 1st place ﬁnish occur?”) using only question-answer pairs as supervision (Clarke et al., 2010; Liang et al., 2011; Berant et al., 2013; Artzi and Zettlemoyer, 2013). Semantic parsers map the question into a logical form (e.g., R[Venue].argmax(Position.1st, Index)) that can be executed on a knowledge source to obtain the answer (denotation). Logical forms are very expressive since they can be recursively composed, but this very expressivity makes it more difﬁcult to search over the space of logical forms. Previous work sidesteps this obstacle by restricting the set of possible logical form compositions, but this is limiting. For instance, for the system in Pasupat and Liang (2015), in only 53.5% of the examples was the correct logical form even in the set of generated logical forms. The goal of this paper is to solve two main challenges that prevent us from generating more expressive logical forms. The ﬁrst challenge is computational: the number of logical forms grows exponentially as their size increases. Directly enumerating over all logical forms becomes infeasible, and pruning techniques such as beam search can inadvertently prune out correct logical forms. The second challenge is the large increase in spurious logical forms—those that do not reﬂect the semantics of the question but coincidentally execute to the correct denotation. For example, while logical forms z1, . . . , z5 in Figure 1 are all consistent (they execute to the correct answer y), the logical forms z4 and z5 are spurious and would give incorrect answers if the table were to change. We address these two challenges by solving two interconnected tasks. The ﬁrst task, which addresses the computational challenge, is to enumerate the set Z of all consistent logical forms given a question x, a knowledge source w (“world”), and the target denotation y (Section 4). Observing that the space of possible denotations grows much more slowly than the space of logical forms, we perform dynamic programming on denotations (DPD) to make search feasible. Our method is guaranteed to ﬁnd all consistent logical forms up to some bounded size. Given the set Z of consistent logical forms, the second task is to ﬁlter out spurious logical forms from Z (Section 5). Using the property that spurious logical forms ultimately give a wrong answer when the data in the world w changes, we create arXiv:1606.06900v2  [cs.CL]  15 Nov 2016  Year Venue Position Event Time 2001 Hungary 2nd 400m 47.12 2003 Finland 1st 400m 46.69 2005 Germany 11th 400m 46.62 2007 Thailand 1st relay 182.05 2008 China 7th relay 180.32 x: “Where did the last 1st place ﬁnish occur?” y: Thailand Consistent Correct z1: R[Venue].argmax(Position.1st, Index) Among rows with Position = 1st, pick the one with maximum index, then return the Venue of',\n",
       " '1605.02260': 'The RGB-D images have been provided in the real-world visual analysis systems thanks to the wide availability of affordable RGB-D sensors, e.g. the Microsoft Kinect. Compared with the primitive RGB, the RGB-D can bring remarkable performanceimprovement for various visual tasks due to the access to the depth information complementary to RGB [28, 11, 20]. Actually, the depth has some profitable attributes for visual analysis, e.g. being invariant to lighting or color variations, and providing geometrical cues for image structures [29]. For object detection, which is one of typical complex visual tasks, the acquisition of RGB-D images is applicable and beneﬁcial. However, how to effectively utilize the provided depth information of RGB-D RGB Disparity Height Angle Contour Color Contour Disparity Height Angle Derivation Fused Features Depth Derivation Figure 1. Illustration of learning rich features for RGB-D object detection. Various property maps are derived to describe the object from different perspectives. The features for these maps are learned independently and then fused for the ﬁnal classiﬁcation. Speciﬁcally, the derived maps include geometry contour from the color/depth pairs, and horizontal disparity, height above ground, angle with gravity from the depth data. These maps, as well as the RGB image, are sent into different CNNs for feature learning. And the features are joint before being fed into the classiﬁer. images is still an open question. In recent years, Convolutional Neural Network(CNN) has achieved great success in computer vision and obtained the best performance in various visual tasks [30, 17, 23]. CNN is generally considered as an end-to-end feature extractor to automatically learn discriminative features from millions of input images [22]. In this paper, we also adopt CNN to extract rich features from the RGB-D images, i.e. we are under the CNN model to investigate the exploitation of the depth information. For the RGB-D object detection with CNN, the key is how to elegantly coordinate the RGB with depth information in feature learning. In the previous literatures, some intuitive methods have been proposed [3, 16]. Roughly, we can divide them into two broad categories according to the strategy the depth is treated. The ﬁrst one is to straightforwardly add the depth map to CNN as the fourth channel along with the RGB [3]. That is, the depth is processed in the same way as the RGB, and they are together convolved  for granted. However, it makes no semantic sense to directly merge the depth and color maps, since they contain disparate information. The second is to process the color and depth separately, and they are combined before being fed into the ﬁnal classiﬁer, where the extracted features are joint. Speciﬁcally, two independent CNN networks are learned: one for RGB and one for depth [16]. As for the depth network, the input can be the original depth data or encoded data from the depth, e.g. height above ground, and',\n",
       " '1704.03718': 'The eXtreme Multi-label Learning (XML) addresses the problem of learning a classifier which can automatically tag a data sample with the most relevant subset of labels from a large label set. For instance, there are more than a million labels (i.e., categories) on Wikipedia and it is expect to build a classifier that can annotate a new article or a web page with a subset of relevant Wikipedia categories. However, XML becomes significantly challenging in order to simultaneously deal with massive labels, dimensions and training samples. Compared with traditional multi-label learning methods [26], the extreme multi-label learning methods even more focus on tackling the problem with both extremely high input feature dimension and label dimension. It should also be emphasized that multi-label learning is distinct from multi-class classification [32] which only aims to predict a single mutually exclusive label. Contact author is Xiangfeng Wang. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. ICMR ’18, June 11–14, 2018, Yokohama, Japan © 2018 Association for Computing Machinery. ACM ISBN 978-1-4503-5046-4/18/06...$15.00 https://doi.org/10.1145/3206025.3206030 But in contrast, multi-label learning allows for the co-existence of more than one labels for a single data sample. One straightforward method is to train an independent oneagainst-all classifier for each label, which is clearly not optimal for multi-label learning because the dependency between class labels should not be leveraged. Furthermore, for extreme multi-label leaning, this is not practical since it becomes computationally intractable to train a massive number of classifiers, e.g., one million classifiers. Although the issue could possibly be ameliorated if the label hierarchy is established, it is usually impracticable to guarantee this structure in many applications [4]. The issue also lies in the prediction stage, where all the classifiers need to be evaluated in every testing data sample procedure. To address all these challenges, state-of-the-art extreme multi-label learning methods have been proposed recently, which in general can be divided into two categories: tree based methods and embedding based methods. Tree based methods [1, 21, 30] become popular as they enjoy notable accuracy improvement over traditional embedding based methods. The idea is how to learn the hierarchy from training data. Usually the root is initialized to contain the whole label set. Further the node partition scheme is introduced to determine which labels should be assigned',\n",
       " '1801.07386': 'In graph mining and social network science, a variety of measures are used to quantify the similarity between nodes in a graph, including the shortest path distance, Jaccard’s coeﬃcient between node neighborhoods, the Adamic-Adar coeﬃcient [2], and hub-authority-based metrics [32, 11]. An important family of similarity measures are based on random walks, including SimRank [25], random walks with restarts [52], commute times [20], personalized PageRank [42, 26, 7], and DeepWalk embeddings [43]. These measures capture both local and global graph structure and hence are widely used in graph clustering and community detection [4, 46], anomaly detection [44], collaborative ﬁltering [20, 47, 57], link prediction [38], and many other applications (including outside of network science, such as in computer vision [22]). In this work we focus on these random walk-based similarity metrics. We initiate the study of a fundamental question: How much information about a network can be learned given access to a subset of potentially noisy estimates of pairwise node similarities? This question is important from a privacy perspective. A common privacy breach is social link disclosure [58], in which an attacker attempts to learn potentially sensitive links between nodes in a network. Such attacks are very common; fake accounts with engineered proﬁles are used to inﬁltrate and spy on social groups, potential employers may want to inspect the social network of a job candidate, and advertisers may wish to probe the demographic and interest information of a user to oﬀer targeted ads. Thus, characterizing the ability of an attacker to reveal link information using pairwise node similarities is important in understanding the privacy implications of releasing such similarities, or information which can be used to compute them. From a data mining perspective, computing all pairwise node similarities can be infeasible for large networks since the number of similarities grows quadratically in the number of nodes. Additionally, when the network cannot be accessed in full but can only be probed via crawling with random walks (e.g., a by third party studying a social network [30]), we may only have access to estimates of pairwise similarities rather than their exact values. Thus, understanding what information can still be learned from a partial, potentially noisy, set of node similarities is important when using these metrics in large scale graph mining. 1.1 Learning from Eﬀective Resistances In this paper, we focus on commute times, which are one of the most widely used random walkbased similarities. Commute times are a scaled version of eﬀective resistances, they form a metric, and have major algorithmic applications, such as spectral graph sparsiﬁcation [49]. Our ideas can be extended to related similarity measures, such as personalized PageRank, which we discuss in Section 4.4. It was shown in the seminal work of Liben-Nowell and Kleinberg [38] that eﬀective resistances can be used to predict a signiﬁcant fraction of future links appearing in networks from existing links, typically ranging from 5% up to 33%. A diﬃculty associated with',\n",
       " '1805.07732': 'Reinforcement learning (RL) considers a problem where an agent interacts with the environment to maximize the cumulative reward trough time. A standard approach to solve the RL problem is called value function based reinforcement learning, which ﬁnds a policy that maximizes the value function V (s) [Sutton and Barto, 1998]. Thus, the estimation of the value function of a given stationary policy of a Markov Decision Process (MDP) is an important subroutine of generalized policy iteration [Sutton and Barto, 1998] and a key intermediate step to generate good control policy [Gelly and Silver, 2008, Tesauro, 1992]. The value function is known to solve the Bellman equation, which succinctly describes the recursive relation on state-action value function Q(s, a). Qπ(s, a) = ER(s, a) + γEs′,a′Qπ(s′, a′), where the expectation is taken over the next state s′ ∼P(·|s, a), the reward R(s, a) and the action a′ from policy π, γ is the discount factor. Hence, many RL algorithms are based on the idea of solving the above Bellman equation in a sample driven way, and one popular technique is the temporal-diﬀerence (TD) learning [Sutton and Barto, 1998]. The last several years have witnessed the success of the TD learning with the value function approximation [Mnih et al., 2015, Van Hasselt et al., 2016], especially when using 1 arXiv:1805.07732v3  [cs.LG]  3 Apr 2019  a deep neural network. In their seminal work, Tsitsiklis and Van Roy [1996] proved that the TD(λ) algorithm converges when a linear function approximator is implemented and states are sampled according to the policy evaluated (sometimes referred as on-policy setting in RL literature). However, if either the function approximator is non-linear, or the on-policy setting does not hold, there are counterexamples that demonstrates that TD(λ) may diverge. To mitigate this problem, a family of TD-style algorithms called Gradient Temporal Diﬀerence (GTD) are proposed by [Sutton et al., 2009a,b] that address the instability of the TD algorithm with the linear function approximator in the oﬀ-policy setting. These works rely on the objective function called mean-squared projected Bellman error (MSPBE) whose unique optimum are the ﬁxed points of the TD(0) algorithm. Bhatnagar et al. [2009] extend this idea to the non-linear smooth function approximator (e.g., neural networks) and prove the convergence of the algorithm under mild conditions. In the control setting, Maei et al. [2010] propose Greedy-GQ which has similar objective function as MSPBE but w.r.t. the Bellman optimality operator. Recently, the distributional perspective on reinforcement learning has gained much attention. Rather than study on the expectation of the long term return (i.e., Q(s, a)), it explicitly takes into consideration the stochastic nature of the long term return Z(s, a) (whose expectation is Q(s, a)). The recursion of Z(s, a) is described by the distributional Bellman equation as follows, Z(s, a',\n",
       " ...}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_file, \"w\", encoding='utf-8') as f:\n",
    "    for filename, text in results.items():\n",
    "        f.write(text + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(failures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenate_files('graph-v2/data-v2.txt', 'graph-v2/ANC_500.txt', 'graph-v2/data-v2-500.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== data-v2-500.txt ===\n",
      "Mean word count: 606\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for txtf in ['data-v2-500.txt']:\n",
    "    total_word_count = 0\n",
    "    total_lines = 0\n",
    "\n",
    "    with open(f'graph-v2/{txtf}', 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            total_word_count += len(line.split())\n",
    "            total_lines += 1\n",
    "\n",
    "    mean_word_count = total_word_count / total_lines if total_lines > 0 else 0\n",
    "    print(f'=== {txtf} ===')\n",
    "    print(\"Mean word count:\", math.ceil(mean_word_count))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Parallel*** (Only works for downloading and processing papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_range(paper_ids, start, end):\n",
    "    results = [(i, \"FAILED\") for i in range(start, end)]\n",
    "    failed_papers = [[] for _ in range(3)]  # Track failures: [download, extraction, introduction]\n",
    "    \n",
    "    #for i, paper_id in enumerate(paper_ids, start=start):\n",
    "    for i, paper_id in enumerate(tqdm(paper_ids, total=len(paper_ids), desc=\"Processing Papers\"), start=start):\n",
    "\n",
    "        pdf_stream = download_pdf(paper_id)\n",
    "        if not pdf_stream:\n",
    "            failed_papers[0].append((i, paper_id))\n",
    "            continue\n",
    "        \n",
    "        text = extract_text_from_pdf(pdf_stream)\n",
    "        if text is None:\n",
    "            failed_papers[1].append((i, paper_id))\n",
    "            continue\n",
    "        \n",
    "        introduction_text = extract_introduction(text)\n",
    "        if introduction_text is None:\n",
    "            failed_papers[2].append((i, paper_id))\n",
    "            continue\n",
    "        \n",
    "        results[i - start] = (i, introduction_text)\n",
    "    \n",
    "    return results, failed_papers\n",
    "\n",
    "def process_papers_parallel(id_file, ranges, output_file, max_workers=5):\n",
    "    with open(id_file, \"r\") as f:\n",
    "        paper_ids = [line.strip() for line in f]\n",
    "    \n",
    "    failed_papers = [[] for _ in range(3)]  # Track failures: [download, extraction, introduction]\n",
    "    results = [\"FAILED\"] * len(paper_ids)  # Initialize output list with \"FAILED\"\n",
    "    \n",
    "    with ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "        future_to_range = {executor.submit(process_range, paper_ids[r[0]:r[1]], r[0], r[1]): r for r in ranges}\n",
    "        \n",
    "        for future in future_to_range:\n",
    "            range_results, range_failures = future.result()\n",
    "            for i, text in range_results:\n",
    "                results[i] = text\n",
    "            for j in range(3):\n",
    "                failed_papers[j].extend(range_failures[j])\n",
    "    \n",
    "\n",
    "    return failed_papers, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 5259], [5259, 10518], [10518, 15777], [15777, 21036], [21036, 26295], [26295, 31554], [31554, 36813], [36813, 42072], [42072, 47331], [47331, 52596]]\n"
     ]
    }
   ],
   "source": [
    "# Create ranges\n",
    "num_ids = 52596\n",
    "batch_size = int(num_ids / 6) # 6 is the number of processes  \n",
    "\n",
    "ranges = []\n",
    "\n",
    "start = 0\n",
    "while start < num_ids:\n",
    "    end = min(start + batch_size, num_ids)\n",
    "    ranges.append([start, end])\n",
    "    start = end\n",
    "\n",
    "ranges[-2][1] = ranges[-1][1]\n",
    "del ranges[-1]\n",
    "print(ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_papers, results = process_papers_parallel(id_file, ranges, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_file, \"w\", encoding='utf-8') as f:\n",
    "    for text in results:\n",
    "        f.write(text + \"\\n\")\n",
    "    \n",
    "with open(\"graph-v2/Failed_papers.txt\", \"w\") as f:\n",
    "    f.write(\"Failed Downloads:\\n\")\n",
    "    for idx, pid in failed_papers[0]:\n",
    "        f.write(f\"{idx}: {pid}\\n\")\n",
    "    f.write(\"\\nFailed Extraction:\\n\")\n",
    "    for idx, pid in failed_papers[1]:\n",
    "        f.write(f\"{idx}: {pid}\\n\")\n",
    "    f.write(\"\\nFailed Introduction Detection:\\n\")\n",
    "    for idx, pid in failed_papers[2]:\n",
    "        f.write(f\"{idx}: {pid}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArXiv_Citation_Network",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
